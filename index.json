{
  "README.html": {
    "href": "README.html",
    "title": "| accouter",
    "keywords": "A semantic and open source administrative template with responsive and clean design."
  },
  "docs/getting-started.html": {
    "href": "docs/getting-started.html",
    "title": "Getting Started | accouter",
    "keywords": "Getting Started"
  },
  "docs/index.html": {
    "href": "docs/index.html",
    "title": "Documentations | accouter",
    "keywords": "Documentations"
  },
  "index.html": {
    "href": "index.html",
    "title": "Accouter | accouter",
    "keywords": "This is the HOMEPAGE."
  },
  "interface/alerts.html": {
    "href": "interface/alerts.html",
    "title": "Alerts | accouter",
    "keywords": "Alerts"
  },
  "interface/index.html": {
    "href": "interface/index.html",
    "title": "Interfaces | accouter",
    "keywords": "Interfaces"
  },
  "layout/index.html": {
    "href": "layout/index.html",
    "title": "Layout | accouter",
    "keywords": ""
  },
  "node_modules/@adobe/css-tools/Readme.html": {
    "href": "node_modules/@adobe/css-tools/Readme.html",
    "title": "| accouter",
    "keywords": "@adobe/css-tools This is a fork of the npm css package due to low maintenance CSS parser / stringifier. Installation $ npm install @adobe/css-tools Usage import { parse, stringify } from '@adobe/css-tools' let obj = parse('body { font-size: 12px; }', options); let css = stringify(obj, options); API parse(code, [options]) Accepts a CSS string and returns an AST object. options: silent: silently fail on parse errors. source: the path to the file containing css. Makes errors and source maps more helpful, by letting them know where code comes from. stringify(object, [options]) Accepts an AST object (as css.parse produces) and returns a CSS string. options: indent: the string used to indent the output. Defaults to two spaces. compress: omit comments and extraneous whitespace. Example var ast = parse('body { font-size: 12px; }', { source: 'source.css' }); var css = stringify(ast); Errors Errors thrown during parsing have the following properties: message: String. The full error message with the source position. reason: String. The error message without position. filename: String or undefined. The value of options.source if passed to css.parse. Otherwise undefined. line: Integer. column: Integer. source: String. The portion of code that couldn't be parsed. When parsing with the silent option, errors are listed in the parsingErrors property of the stylesheet node instead of being thrown. If you create any errors in plugins such as in rework, you must set the same properties for consistency. AST Interactively explore the AST with http://iamdustan.com/reworkcss_ast_explorer/. Common properties All nodes have the following properties. position Information about the position in the source string that corresponds to the node. Object: start: Object: line: Number. column: Number. end: Object: line: Number. column: Number. source: String or undefined. The value of options.source if passed to css.parse. Otherwise undefined. content: String. The full source string passed to css.parse. The line and column numbers are 1-based: The first line is 1 and the first column of a line is 1 (not 0). The position property lets you know from which source file the node comes from (if available), what that file contains, and what part of that file was parsed into the node. type String. The possible values are the ones listed in the Types section below. parent A reference to the parent node, or null if the node has no parent. Types The available values of node.type are listed below, as well as the available properties of each node (other than the common properties listed above.) stylesheet The root node returned by css.parse. stylesheet: Object: rules: Array of nodes with the types rule, comment and any of the at-rule types. parsingErrors: Array of Errors. Errors collected during parsing when option silent is true. rule selectors: Array of Strings. The list of selectors of the rule, split on commas. Each selector is trimmed from whitespace and comments. declarations: Array of nodes with the types declaration and comment. declaration property: String. The property name, trimmed from whitespace and comments. May not be empty. value: String. The value of the property, trimmed from whitespace and comments. Empty values are allowed. comment A rule-level or declaration-level comment. Comments inside selectors, properties and values etc. are lost. comment: String. The part between the starting /* and the ending */ of the comment, including whitespace. charset The @charset at-rule. charset: String. The part following @charset . custom-media The @custom-media at-rule. name: String. The ---prefixed name. media: String. The part following the name. document The @document at-rule. document: String. The part following @document . vendor: String or undefined. The vendor prefix in @document, or undefined if there is none. rules: Array of nodes with the types rule, comment and any of the at-rule types. font-face The @font-face at-rule. declarations: Array of nodes with the types declaration and comment. host The @host at-rule. rules: Array of nodes with the types rule, comment and any of the at-rule types. import The @import at-rule. import: String. The part following @import . keyframes The @keyframes at-rule. name: String. The name of the keyframes rule. vendor: String or undefined. The vendor prefix in @keyframes, or undefined if there is none. keyframes: Array of nodes with the types keyframe and comment. keyframe values: Array of Strings. The list of “selectors” of the keyframe rule, split on commas. Each “selector” is trimmed from whitespace. declarations: Array of nodes with the types declaration and comment. media The @media at-rule. media: String. The part following @media . rules: Array of nodes with the types rule, comment and any of the at-rule types. namespace The @namespace at-rule. namespace: String. The part following @namespace . page The @page at-rule. selectors: Array of Strings. The list of selectors of the rule, split on commas. Each selector is trimmed from whitespace and comments. declarations: Array of nodes with the types declaration and comment. supports The @supports at-rule. supports: String. The part following @supports . rules: Array of nodes with the types rule, comment and any of the at-rule types. container The @container at-rule. conatiner: String. The part following @container . rules: Array of nodes with the types rule, comment and any of the at-rule types. layer The @layer at-rule. layer: String. The part following @layer . rules: Array of nodes with the types rule, comment and any of the at-rule types. This may be null, if the rule did not contain any. Example CSS: body { background: #eee; color: #888; } Parse tree: { \"type\": \"stylesheet\", \"stylesheet\": { \"rules\": [ { \"type\": \"rule\", \"selectors\": [ \"body\" ], \"declarations\": [ { \"type\": \"declaration\", \"property\": \"background\", \"value\": \"#eee\", \"position\": { \"start\": { \"line\": 2, \"column\": 3 }, \"end\": { \"line\": 2, \"column\": 19 } } }, { \"type\": \"declaration\", \"property\": \"color\", \"value\": \"#888\", \"position\": { \"start\": { \"line\": 3, \"column\": 3 }, \"end\": { \"line\": 3, \"column\": 14 } } } ], \"position\": { \"start\": { \"line\": 1, \"column\": 1 }, \"end\": { \"line\": 4, \"column\": 2 } } } ] } } License MIT"
  },
  "node_modules/@isaacs/cliui/README.html": {
    "href": "node_modules/@isaacs/cliui/README.html",
    "title": "| accouter",
    "keywords": "@isaacs/cliui Temporary fork of cliui. easily create complex multi-column command-line-interfaces. Example const ui = require('cliui')() ui.div('Usage: $0 [command] [options]') ui.div({ text: 'Options:', padding: [2, 0, 1, 0] }) ui.div( { text: \"-f, --file\", width: 20, padding: [0, 4, 0, 4] }, { text: \"the file to load.\" + chalk.green(\"(if this description is long it wraps).\") , width: 20 }, { text: chalk.red(\"[required]\"), align: 'right' } ) console.log(ui.toString()) Deno/ESM Support As of v7 cliui supports Deno and ESM: import cliui from \"https://deno.land/x/cliui/deno.ts\"; const ui = cliui({}) ui.div('Usage: $0 [command] [options]') ui.div({ text: 'Options:', padding: [2, 0, 1, 0] }) ui.div({ text: \"-f, --file\", width: 20, padding: [0, 4, 0, 4] }) console.log(ui.toString()) Layout DSL cliui exposes a simple layout DSL: If you create a single ui.div, passing a string rather than an object: \\n: characters will be interpreted as new rows. \\t: characters will be interpreted as new columns. \\s: characters will be interpreted as padding. as an example... var ui = require('./')({ width: 60 }) ui.div( 'Usage: node ./bin/foo.js\\n' + ' <regex>\\t provide a regex\\n' + ' <glob>\\t provide a glob\\t [required]' ) console.log(ui.toString()) will output: Usage: node ./bin/foo.js <regex> provide a regex <glob> provide a glob [required] Methods cliui = require('cliui') cliui({width: integer}) Specify the maximum width of the UI being generated. If no width is provided, cliui will try to get the current window's width and use it, and if that doesn't work, width will be set to 80. cliui({wrap: boolean}) Enable or disable the wrapping of text in a column. cliui.div(column, column, column) Create a row with any number of columns, a column can either be a string, or an object with the following options: text: some text to place in the column. width: the width of a column. align: alignment, right or center. padding: [top, right, bottom, left]. border: should a border be placed around the div? cliui.span(column, column, column) Similar to div, except the next row will be appended without a new line being created. cliui.resetOutput() Resets the UI elements of the current cliui instance, maintaining the values set for width and wrap."
  },
  "node_modules/@isaacs/cliui/node_modules/ansi-regex/readme.html": {
    "href": "node_modules/@isaacs/cliui/node_modules/ansi-regex/readme.html",
    "title": "ansi-regex | accouter",
    "keywords": "ansi-regex Regular expression for matching ANSI escape codes Install $ npm install ansi-regex Usage import ansiRegex from 'ansi-regex'; ansiRegex().test('\\u001B[4mcake\\u001B[0m'); //=> true ansiRegex().test('cake'); //=> false '\\u001B[4mcake\\u001B[0m'.match(ansiRegex()); //=> ['\\u001B[4m', '\\u001B[0m'] '\\u001B[4mcake\\u001B[0m'.match(ansiRegex({onlyFirst: true})); //=> ['\\u001B[4m'] '\\u001B]8;;https://github.com\\u0007click\\u001B]8;;\\u0007'.match(ansiRegex()); //=> ['\\u001B]8;;https://github.com\\u0007', '\\u001B]8;;\\u0007'] API ansiRegex(options?) Returns a regex for matching ANSI escape codes. options Type: object onlyFirst Type: boolean Default: false (Matches any ANSI escape codes in a string) Match only the first ANSI escape. FAQ Why do you test for codes not in the ECMA 48 standard? Some of the codes we run as a test are codes that we acquired finding various lists of non-standard or manufacturer specific codes. We test for both standard and non-standard codes, as most of them follow the same or similar format and can be safely matched in strings without the risk of removing actual string content. There are a few non-standard control codes that do not follow the traditional format (i.e. they end in numbers) thus forcing us to exclude them from the test because we cannot reliably match them. On the historical side, those ECMA standards were established in the early 90's whereas the VT100, for example, was designed in the mid/late 70's. At that point in time, control codes were still pretty ungoverned and engineers used them for a multitude of things, namely to activate hardware ports that may have been proprietary. Somewhere else you see a similar 'anarchy' of codes is in the x86 architecture for processors; there are a ton of \"interrupts\" that can mean different things on certain brands of processors, most of which have been phased out. Maintainers Sindre Sorhus Josh Junon Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "node_modules/@isaacs/cliui/node_modules/ansi-styles/readme.html": {
    "href": "node_modules/@isaacs/cliui/node_modules/ansi-styles/readme.html",
    "title": "ansi-styles | accouter",
    "keywords": "ansi-styles ANSI escape codes for styling strings in the terminal You probably want the higher-level chalk module for styling your strings. Install npm install ansi-styles Usage import styles from 'ansi-styles'; console.log(`${styles.green.open}Hello world!${styles.green.close}`); // Color conversion between 256/truecolor // NOTE: When converting from truecolor to 256 colors, the original color // may be degraded to fit the new color palette. This means terminals // that do not support 16 million colors will best-match the // original color. console.log(`${styles.color.ansi(styles.rgbToAnsi(199, 20, 250))}Hello World${styles.color.close}`) console.log(`${styles.color.ansi256(styles.rgbToAnsi256(199, 20, 250))}Hello World${styles.color.close}`) console.log(`${styles.color.ansi16m(...styles.hexToRgb('#abcdef'))}Hello World${styles.color.close}`) API open and close Each style has an open and close property. modifierNames, foregroundColorNames, backgroundColorNames, and colorNames All supported style strings are exposed as an array of strings for convenience. colorNames is the combination of foregroundColorNames and backgroundColorNames. This can be useful if you need to validate input: import {modifierNames, foregroundColorNames} from 'ansi-styles'; console.log(modifierNames.includes('bold')); //=> true console.log(foregroundColorNames.includes('pink')); //=> false Styles Modifiers reset bold dim italic (Not widely supported) underline overline Supported on VTE-based terminals, the GNOME terminal, mintty, and Git Bash. inverse hidden strikethrough (Not widely supported) Colors black red green yellow blue magenta cyan white blackBright (alias: gray, grey) redBright greenBright yellowBright blueBright magentaBright cyanBright whiteBright Background colors bgBlack bgRed bgGreen bgYellow bgBlue bgMagenta bgCyan bgWhite bgBlackBright (alias: bgGray, bgGrey) bgRedBright bgGreenBright bgYellowBright bgBlueBright bgMagentaBright bgCyanBright bgWhiteBright Advanced usage By default, you get a map of styles, but the styles are also available as groups. They are non-enumerable so they don't show up unless you access them explicitly. This makes it easier to expose only a subset in a higher-level module. styles.modifier styles.color styles.bgColor Example import styles from 'ansi-styles'; console.log(styles.color.green.open); Raw escape codes (i.e. without the CSI escape prefix \\u001B[ and render mode postfix m) are available under styles.codes, which returns a Map with the open codes as keys and close codes as values. Example import styles from 'ansi-styles'; console.log(styles.codes.get(36)); //=> 39 16 / 256 / 16 million (TrueColor) support ansi-styles allows converting between various color formats and ANSI escapes, with support for 16, 256 and 16 million colors. The following color spaces are supported: rgb hex ansi256 ansi To use these, call the associated conversion function with the intended output, for example: import styles from 'ansi-styles'; styles.color.ansi(styles.rgbToAnsi(100, 200, 15)); // RGB to 16 color ansi foreground code styles.bgColor.ansi(styles.hexToAnsi('#C0FFEE')); // HEX to 16 color ansi foreground code styles.color.ansi256(styles.rgbToAnsi256(100, 200, 15)); // RGB to 256 color ansi foreground code styles.bgColor.ansi256(styles.hexToAnsi256('#C0FFEE')); // HEX to 256 color ansi foreground code styles.color.ansi16m(100, 200, 15); // RGB to 16 million color foreground code styles.bgColor.ansi16m(...styles.hexToRgb('#C0FFEE')); // Hex (RGB) to 16 million color foreground code Related ansi-escapes - ANSI escape codes for manipulating the terminal Maintainers Sindre Sorhus Josh Junon For enterprise Available as part of the Tidelift Subscription. The maintainers of ansi-styles and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more."
  },
  "node_modules/@isaacs/cliui/node_modules/emoji-regex/README.html": {
    "href": "node_modules/@isaacs/cliui/node_modules/emoji-regex/README.html",
    "title": "emoji-regex | accouter",
    "keywords": "emoji-regex emoji-regex offers a regular expression to match all emoji symbols and sequences (including textual representations of emoji) as per the Unicode Standard. This repository contains a script that generates this regular expression based on Unicode data. Because of this, the regular expression can easily be updated whenever new emoji are added to the Unicode standard. Installation Via npm: npm install emoji-regex In Node.js: const emojiRegex = require('emoji-regex/RGI_Emoji.js'); // Note: because the regular expression has the global flag set, this module // exports a function that returns the regex rather than exporting the regular // expression itself, to make it impossible to (accidentally) mutate the // original regular expression. const text = ` \\u{231A}: ⌚ default emoji presentation character (Emoji_Presentation) \\u{2194}\\u{FE0F}: ↔️ default text presentation character rendered as emoji \\u{1F469}: 👩 emoji modifier base (Emoji_Modifier_Base) \\u{1F469}\\u{1F3FF}: 👩🏿 emoji modifier base followed by a modifier `; const regex = emojiRegex(); let match; while (match = regex.exec(text)) { const emoji = match[0]; console.log(`Matched sequence ${ emoji } — code points: ${ [...emoji].length }`); } Console output: Matched sequence ⌚ — code points: 1 Matched sequence ⌚ — code points: 1 Matched sequence ↔️ — code points: 2 Matched sequence ↔️ — code points: 2 Matched sequence 👩 — code points: 1 Matched sequence 👩 — code points: 1 Matched sequence 👩🏿 — code points: 2 Matched sequence 👩🏿 — code points: 2 Regular expression flavors The package comes with three distinct regular expressions: // This is the recommended regular expression to use. It matches all // emoji recommended for general interchange, as defined via the // `RGI_Emoji` property in the Unicode Standard. // https://unicode.org/reports/tr51/#def_rgi_set // When in doubt, use this! const emojiRegexRGI = require('emoji-regex/RGI_Emoji.js'); // This is the old regular expression, prior to `RGI_Emoji` being // standardized. In addition to all `RGI_Emoji` sequences, it matches // some emoji you probably don’t want to match (such as emoji component // symbols that are not meant to be used separately). const emojiRegex = require('emoji-regex/index.js'); // This regular expression matches even more emoji than the previous // one, including emoji that render as text instead of icons (i.e. // emoji that are not `Emoji_Presentation` symbols and that aren’t // forced to render as emoji by a variation selector). const emojiRegexText = require('emoji-regex/text.js'); Additionally, in environments which support ES2015 Unicode escapes, you may require ES2015-style versions of the regexes: const emojiRegexRGI = require('emoji-regex/es2015/RGI_Emoji.js'); const emojiRegex = require('emoji-regex/es2015/index.js'); const emojiRegexText = require('emoji-regex/es2015/text.js'); For maintainers How to update emoji-regex after new Unicode Standard releases Update the Unicode data dependency in package.json by running the following commands: # Example: updating from Unicode v12 to Unicode v13. npm uninstall @unicode/unicode-12.0.0 npm install @unicode/unicode-13.0.0 --save-dev Generate the new output: npm run build Verify that tests still pass: npm test Send a pull request with the changes, and get it reviewed & merged. On the main branch, bump the emoji-regex version number in package.json: npm version patch -m 'Release v%s' Instead of patch, use minor or major as needed. Note that this produces a Git commit + tag. Push the release commit and tag: git push Our CI then automatically publishes the new release to npm. Author Mathias Bynens License emoji-regex is available under the MIT license."
  },
  "node_modules/@isaacs/cliui/node_modules/string-width/readme.html": {
    "href": "node_modules/@isaacs/cliui/node_modules/string-width/readme.html",
    "title": "string-width | accouter",
    "keywords": "string-width Get the visual width of a string - the number of columns required to display it Some Unicode characters are fullwidth and use double the normal width. ANSI escape codes are stripped and doesn't affect the width. Useful to be able to measure the actual width of command-line output. Install $ npm install string-width Usage import stringWidth from 'string-width'; stringWidth('a'); //=> 1 stringWidth('古'); //=> 2 stringWidth('\\u001B[1m古\\u001B[22m'); //=> 2 API stringWidth(string, options?) string Type: string The string to be counted. options Type: object ambiguousIsNarrow Type: boolean Default: false Count ambiguous width characters as having narrow width (count of 1) instead of wide width (count of 2). Related string-width-cli - CLI for this module string-length - Get the real length of a string widest-line - Get the visual width of the widest line in a string Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "node_modules/@isaacs/cliui/node_modules/strip-ansi/readme.html": {
    "href": "node_modules/@isaacs/cliui/node_modules/strip-ansi/readme.html",
    "title": "strip-ansi | accouter",
    "keywords": "strip-ansi Strip ANSI escape codes from a string Install $ npm install strip-ansi Usage import stripAnsi from 'strip-ansi'; stripAnsi('\\u001B[4mUnicorn\\u001B[0m'); //=> 'Unicorn' stripAnsi('\\u001B]8;;https://github.com\\u0007Click\\u001B]8;;\\u0007'); //=> 'Click' strip-ansi for enterprise Available as part of the Tidelift Subscription. The maintainers of strip-ansi and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more. Related strip-ansi-cli - CLI for this module strip-ansi-stream - Streaming version of this module has-ansi - Check if a string has ANSI escape codes ansi-regex - Regular expression for matching ANSI escape codes chalk - Terminal string styling done right Maintainers Sindre Sorhus Josh Junon"
  },
  "node_modules/@isaacs/cliui/node_modules/wrap-ansi/readme.html": {
    "href": "node_modules/@isaacs/cliui/node_modules/wrap-ansi/readme.html",
    "title": "wrap-ansi | accouter",
    "keywords": "wrap-ansi Wordwrap a string with ANSI escape codes Install $ npm install wrap-ansi Usage import chalk from 'chalk'; import wrapAnsi from 'wrap-ansi'; const input = 'The quick brown ' + chalk.red('fox jumped over ') + 'the lazy ' + chalk.green('dog and then ran away with the unicorn.'); console.log(wrapAnsi(input, 20)); API wrapAnsi(string, columns, options?) Wrap words to the specified column width. string Type: string String with ANSI escape codes. Like one styled by chalk. Newline characters will be normalized to \\n. columns Type: number Number of columns to wrap the text to. options Type: object hard Type: boolean Default: false By default the wrap is soft, meaning long words may extend past the column width. Setting this to true will make it hard wrap at the column width. wordWrap Type: boolean Default: true By default, an attempt is made to split words at spaces, ensuring that they don't extend past the configured columns. If wordWrap is false, each column will instead be completely filled splitting words as necessary. trim Type: boolean Default: true Whitespace on all lines is removed by default. Set this option to false if you don't want to trim. Related slice-ansi - Slice a string with ANSI escape codes cli-truncate - Truncate a string to a specific width in the terminal chalk - Terminal string styling done right jsesc - Generate ASCII-only output from Unicode strings. Useful for creating test fixtures. Maintainers Sindre Sorhus Josh Junon Benjamin Coe Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "node_modules/@jest/schemas/README.html": {
    "href": "node_modules/@jest/schemas/README.html",
    "title": "@jest/schemas | accouter",
    "keywords": "@jest/schemas Experimental and currently incomplete module for JSON schemas for Jest's configuration."
  },
  "node_modules/@nodelib/fs.scandir/README.html": {
    "href": "node_modules/@nodelib/fs.scandir/README.html",
    "title": "| accouter",
    "keywords": "@nodelib/fs.scandir List files and directories inside the specified directory. 💡 Highlights The package is aimed at obtaining information about entries in the directory. 💰 Returns useful information: name, path, dirent and stats (optional). ⚙️ On Node.js 10.10+ uses the mechanism without additional calls to determine the entry type. See old and modern mode. 🔗 Can safely work with broken symbolic links. Install npm install @nodelib/fs.scandir Usage import * as fsScandir from '@nodelib/fs.scandir'; fsScandir.scandir('path', (error, stats) => { /* … */ }); API .scandir(path, [optionsOrSettings], callback) Returns an array of plain objects (Entry) with information about entry for provided path with standard callback-style. fsScandir.scandir('path', (error, entries) => { /* … */ }); fsScandir.scandir('path', {}, (error, entries) => { /* … */ }); fsScandir.scandir('path', new fsScandir.Settings(), (error, entries) => { /* … */ }); .scandirSync(path, [optionsOrSettings]) Returns an array of plain objects (Entry) with information about entry for provided path. const entries = fsScandir.scandirSync('path'); const entries = fsScandir.scandirSync('path', {}); const entries = fsScandir.scandirSync(('path', new fsScandir.Settings()); path Required: true Type: string | Buffer | URL A path to a file. If a URL is provided, it must use the file: protocol. optionsOrSettings Required: false Type: Options | Settings Default: An instance of Settings class An Options object or an instance of Settings class. 📖 When you pass a plain object, an instance of the Settings class will be created automatically. If you plan to call the method frequently, use a pre-created instance of the Settings class. Settings([options]) A class of full settings of the package. const settings = new fsScandir.Settings({ followSymbolicLinks: false }); const entries = fsScandir.scandirSync('path', settings); Entry name — The name of the entry (unknown.txt). path — The path of the entry relative to call directory (root/unknown.txt). dirent — An instance of fs.Dirent class. On Node.js below 10.10 will be emulated by DirentFromStats class. stats (optional) — An instance of fs.Stats class. For example, the scandir call for tools directory with one directory inside: { dirent: Dirent { name: 'typedoc', /* … */ }, name: 'typedoc', path: 'tools/typedoc' } Options stats Type: boolean Default: false Adds an instance of fs.Stats class to the Entry. 📖 Always use fs.readdir without the withFileTypes option. ??TODO?? followSymbolicLinks Type: boolean Default: false Follow symbolic links or not. Call fs.stat on symbolic link if true. throwErrorOnBrokenSymbolicLink Type: boolean Default: true Throw an error when symbolic link is broken if true or safely use lstat call if false. pathSegmentSeparator Type: string Default: path.sep By default, this package uses the correct path separator for your OS (\\ on Windows, / on Unix-like systems). But you can set this option to any separator character(s) that you want to use instead. fs Type: FileSystemAdapter Default: A default FS methods By default, the built-in Node.js module (fs) is used to work with the file system. You can replace any method with your own. interface FileSystemAdapter { lstat?: typeof fs.lstat; stat?: typeof fs.stat; lstatSync?: typeof fs.lstatSync; statSync?: typeof fs.statSync; readdir?: typeof fs.readdir; readdirSync?: typeof fs.readdirSync; } const settings = new fsScandir.Settings({ fs: { lstat: fakeLstat } }); old and modern mode This package has two modes that are used depending on the environment and parameters of use. old Node.js below 10.10 or when the stats option is enabled When working in the old mode, the directory is read first (fs.readdir), then the type of entries is determined (fs.lstat and/or fs.stat for symbolic links). modern Node.js 10.10+ and the stats option is disabled In the modern mode, reading the directory (fs.readdir with the withFileTypes option) is combined with obtaining information about its entries. An additional call for symbolic links (fs.stat) is still present. This mode makes fewer calls to the file system. It's faster. Changelog See the Releases section of our GitHub project for changelog for each release version. License This software is released under the terms of the MIT license."
  },
  "node_modules/@nodelib/fs.stat/README.html": {
    "href": "node_modules/@nodelib/fs.stat/README.html",
    "title": "| accouter",
    "keywords": "@nodelib/fs.stat Get the status of a file with some features. 💡 Highlights Wrapper around standard method fs.lstat and fs.stat with some features. 🔰 Normally follows symbolic link. ⚙️ Can safely work with broken symbolic link. Install npm install @nodelib/fs.stat Usage import * as fsStat from '@nodelib/fs.stat'; fsStat.stat('path', (error, stats) => { /* … */ }); API .stat(path, [optionsOrSettings], callback) Returns an instance of fs.Stats class for provided path with standard callback-style. fsStat.stat('path', (error, stats) => { /* … */ }); fsStat.stat('path', {}, (error, stats) => { /* … */ }); fsStat.stat('path', new fsStat.Settings(), (error, stats) => { /* … */ }); .statSync(path, [optionsOrSettings]) Returns an instance of fs.Stats class for provided path. const stats = fsStat.stat('path'); const stats = fsStat.stat('path', {}); const stats = fsStat.stat('path', new fsStat.Settings()); path Required: true Type: string | Buffer | URL A path to a file. If a URL is provided, it must use the file: protocol. optionsOrSettings Required: false Type: Options | Settings Default: An instance of Settings class An Options object or an instance of Settings class. 📖 When you pass a plain object, an instance of the Settings class will be created automatically. If you plan to call the method frequently, use a pre-created instance of the Settings class. Settings([options]) A class of full settings of the package. const settings = new fsStat.Settings({ followSymbolicLink: false }); const stats = fsStat.stat('path', settings); Options followSymbolicLink Type: boolean Default: true Follow symbolic link or not. Call fs.stat on symbolic link if true. markSymbolicLink Type: boolean Default: false Mark symbolic link by setting the return value of isSymbolicLink function to always true (even after fs.stat). 📖 Can be used if you want to know what is hidden behind a symbolic link, but still continue to know that it is a symbolic link. throwErrorOnBrokenSymbolicLink Type: boolean Default: true Throw an error when symbolic link is broken if true or safely return lstat call if false. fs Type: FileSystemAdapter Default: A default FS methods By default, the built-in Node.js module (fs) is used to work with the file system. You can replace any method with your own. interface FileSystemAdapter { lstat?: typeof fs.lstat; stat?: typeof fs.stat; lstatSync?: typeof fs.lstatSync; statSync?: typeof fs.statSync; } const settings = new fsStat.Settings({ fs: { lstat: fakeLstat } }); Changelog See the Releases section of our GitHub project for changelog for each release version. License This software is released under the terms of the MIT license."
  },
  "node_modules/@nodelib/fs.walk/README.html": {
    "href": "node_modules/@nodelib/fs.walk/README.html",
    "title": "| accouter",
    "keywords": "@nodelib/fs.walk A library for efficiently walking a directory recursively. 💡 Highlights 💰 Returns useful information: name, path, dirent and stats (optional). 🚀 On Node.js 10.10+ uses the mechanism without additional calls to determine the entry type for performance reasons. See old and modern mode. ⚙️ Built-in directories/files and error filtering system. 🔗 Can safely work with broken symbolic links. Install npm install @nodelib/fs.walk Usage import * as fsWalk from '@nodelib/fs.walk'; fsWalk.walk('path', (error, entries) => { /* … */ }); API .walk(path, [optionsOrSettings], callback) Reads the directory recursively and asynchronously. Requires a callback function. 📖 If you want to use the Promise API, use util.promisify. fsWalk.walk('path', (error, entries) => { /* … */ }); fsWalk.walk('path', {}, (error, entries) => { /* … */ }); fsWalk.walk('path', new fsWalk.Settings(), (error, entries) => { /* … */ }); .walkStream(path, [optionsOrSettings]) Reads the directory recursively and asynchronously. Readable Stream is used as a provider. const stream = fsWalk.walkStream('path'); const stream = fsWalk.walkStream('path', {}); const stream = fsWalk.walkStream('path', new fsWalk.Settings()); .walkSync(path, [optionsOrSettings]) Reads the directory recursively and synchronously. Returns an array of entries. const entries = fsWalk.walkSync('path'); const entries = fsWalk.walkSync('path', {}); const entries = fsWalk.walkSync('path', new fsWalk.Settings()); path Required: true Type: string | Buffer | URL A path to a file. If a URL is provided, it must use the file: protocol. optionsOrSettings Required: false Type: Options | Settings Default: An instance of Settings class An Options object or an instance of Settings class. 📖 When you pass a plain object, an instance of the Settings class will be created automatically. If you plan to call the method frequently, use a pre-created instance of the Settings class. Settings([options]) A class of full settings of the package. const settings = new fsWalk.Settings({ followSymbolicLinks: true }); const entries = fsWalk.walkSync('path', settings); Entry name — The name of the entry (unknown.txt). path — The path of the entry relative to call directory (root/unknown.txt). dirent — An instance of fs.Dirent class. [stats] — An instance of fs.Stats class. Options basePath Type: string Default: undefined By default, all paths are built relative to the root path. You can use this option to set custom root path. In the example below we read the files from the root directory, but in the results the root path will be custom. fsWalk.walkSync('root'); // → ['root/file.txt'] fsWalk.walkSync('root', { basePath: 'custom' }); // → ['custom/file.txt'] concurrency Type: number Default: Infinity The maximum number of concurrent calls to fs.readdir. 📖 The higher the number, the higher performance and the load on the File System. If you want to read in quiet mode, set the value to 4 * os.cpus().length (4 is default size of thread pool work scheduling). deepFilter Type: DeepFilterFunction Default: undefined A function that indicates whether the directory will be read deep or not. // Skip all directories that starts with `node_modules` const filter: DeepFilterFunction = (entry) => !entry.path.startsWith('node_modules'); entryFilter Type: EntryFilterFunction Default: undefined A function that indicates whether the entry will be included to results or not. // Exclude all `.js` files from results const filter: EntryFilterFunction = (entry) => !entry.name.endsWith('.js'); errorFilter Type: ErrorFilterFunction Default: undefined A function that allows you to skip errors that occur when reading directories. For example, you can skip ENOENT errors if required: // Skip all ENOENT errors const filter: ErrorFilterFunction = (error) => error.code == 'ENOENT'; stats Type: boolean Default: false Adds an instance of fs.Stats class to the Entry. 📖 Always use fs.readdir with additional fs.lstat/fs.stat calls to determine the entry type. followSymbolicLinks Type: boolean Default: false Follow symbolic links or not. Call fs.stat on symbolic link if true. throwErrorOnBrokenSymbolicLink Type: boolean Default: true Throw an error when symbolic link is broken if true or safely return lstat call if false. pathSegmentSeparator Type: string Default: path.sep By default, this package uses the correct path separator for your OS (\\ on Windows, / on Unix-like systems). But you can set this option to any separator character(s) that you want to use instead. fs Type: FileSystemAdapter Default: A default FS methods By default, the built-in Node.js module (fs) is used to work with the file system. You can replace any method with your own. interface FileSystemAdapter { lstat: typeof fs.lstat; stat: typeof fs.stat; lstatSync: typeof fs.lstatSync; statSync: typeof fs.statSync; readdir: typeof fs.readdir; readdirSync: typeof fs.readdirSync; } const settings = new fsWalk.Settings({ fs: { lstat: fakeLstat } }); Changelog See the Releases section of our GitHub project for changelog for each release version. License This software is released under the terms of the MIT license."
  },
  "node_modules/@pkgjs/parseargs/CHANGELOG.html": {
    "href": "node_modules/@pkgjs/parseargs/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog 0.11.0 (2022-10-08) Features add default option parameter (#142) (cd20847) 0.10.0 (2022-07-21) Features add parsed meta-data to returned properties (#129) (91bfb4d) 0.9.1 (2022-06-20) Bug Fixes runtime: support node 14+ (#135) (6a1c5a6) 0.9.0 (2022-05-23) ⚠ BREAKING CHANGES drop handling of electron arguments (#121) Code Refactoring drop handling of electron arguments (#121) (a2ffd53) 0.8.0 (2022-05-16) ⚠ BREAKING CHANGES switch type:string option arguments to greedy, but with error for suspect cases in strict mode (#88) positionals now opt-in when strict:true (#116) create result.values with null prototype (#111) Features create result.values with null prototype (#111) (9d539c3) positionals now opt-in when strict:true (#116) (3643338) switch type:string option arguments to greedy, but with error for suspect cases in strict mode (#88) (c2b5e72) 0.7.1 (2022-04-15) Bug Fixes resist pollution (#106) (ecf2dec) 0.7.0 (2022-04-13) Features Add strict mode to parser (#74) (8267d02) 0.6.0 (2022-04-11) ⚠ BREAKING CHANGES rework results to remove redundant flags property and store value true for boolean options (#83) switch to existing ERR_INVALID_ARG_VALUE (#97) Code Refactoring rework results to remove redundant flags property and store value true for boolean options (#83) (be153db) switch to existing ERR_INVALID_ARG_VALUE (#97) (084a23f) 0.5.0 (2022-04-10) ⚠ BREAKING CHANGES Require type to be specified for each supplied option (#95) Features Require type to be specified for each supplied option (#95) (02cd018) 0.4.0 (2022-03-12) ⚠ BREAKING CHANGES parsing, revisit short option groups, add support for combined short and value (#75) restructure configuration to take options bag (#63) Code Refactoring parsing, revisit short option groups, add support for combined short and value (#75) (a92600f) restructure configuration to take options bag (#63) (b412095) 0.3.0 (2022-02-06) Features parser: support short-option groups (#59) (882067b) 0.2.0 (2022-02-05) Features basic support for shorts (#50) (a2f36d7) Bug Fixes always store value for a=b (#43) (a85e8dc) support single dash as positional (#49) (d795bf8) 0.1.1 (2022-01-25) Bug Fixes only use arrays in results for multiples (#42) (c357584) 0.1.0 (2022-01-22) Features expand scenarios covered by default arguments for environments (#20) (582ada7) update readme and include contributing guidelines (8edd6fc) Bug Fixes do not strip excess leading dashes on long option names (#21) (f848590) name & readme (3f057c1) package.json values (9bac300) update readme name (957d8d9) Build System first release as minor (421c6e2)"
  },
  "node_modules/@pkgjs/parseargs/README.html": {
    "href": "node_modules/@pkgjs/parseargs/README.html",
    "title": "parseArgs | accouter",
    "keywords": "parseArgs Polyfill of util.parseArgs() util.parseArgs([config]) Stability: 1 - Experimental config {Object} Used to provide arguments for parsing and to configure the parser. config supports the following properties: args {string[]} array of argument strings. Default: process.argv with execPath and filename removed. options {Object} Used to describe arguments known to the parser. Keys of options are the long names of options and values are an {Object} accepting the following properties: type {string} Type of argument, which must be either boolean or string. multiple {boolean} Whether this option can be provided multiple times. If true, all values will be collected in an array. If false, values for the option are last-wins. Default: false. short {string} A single character alias for the option. default {string | boolean | string[] | boolean[]} The default option value when it is not set by args. It must be of the same type as the the type property. When multiple is true, it must be an array. strict {boolean} Should an error be thrown when unknown arguments are encountered, or when arguments are passed that do not match the type configured in options. Default: true. allowPositionals {boolean} Whether this command accepts positional arguments. Default: false if strict is true, otherwise true. tokens {boolean} Return the parsed tokens. This is useful for extending the built-in behavior, from adding additional checks through to reprocessing the tokens in different ways. Default: false. Returns: {Object} The parsed command line arguments: values {Object} A mapping of parsed option names with their {string} or {boolean} values. positionals {string[]} Positional arguments. tokens {Object[] | undefined} See parseArgs tokens section. Only returned if config includes tokens: true. Provides a higher level API for command-line argument parsing than interacting with process.argv directly. Takes a specification for the expected arguments and returns a structured object with the parsed options and positionals. import { parseArgs } from 'node:util'; const args = ['-f', '--bar', 'b']; const options = { foo: { type: 'boolean', short: 'f' }, bar: { type: 'string' } }; const { values, positionals } = parseArgs({ args, options }); console.log(values, positionals); // Prints: [Object: null prototype] { foo: true, bar: 'b' } [] const { parseArgs } = require('node:util'); const args = ['-f', '--bar', 'b']; const options = { foo: { type: 'boolean', short: 'f' }, bar: { type: 'string' } }; const { values, positionals } = parseArgs({ args, options }); console.log(values, positionals); // Prints: [Object: null prototype] { foo: true, bar: 'b' } [] util.parseArgs is experimental and behavior may change. Join the conversation in pkgjs/parseargs to contribute to the design. parseArgs tokens Detailed parse information is available for adding custom behaviours by specifying tokens: true in the configuration. The returned tokens have properties describing: all tokens kind {string} One of 'option', 'positional', or 'option-terminator'. index {number} Index of element in args containing token. So the source argument for a token is args[token.index]. option tokens name {string} Long name of option. rawName {string} How option used in args, like -f of --foo. value {string | undefined} Option value specified in args. Undefined for boolean options. inlineValue {boolean | undefined} Whether option value specified inline, like --foo=bar. positional tokens value {string} The value of the positional argument in args (i.e. args[index]). option-terminator token The returned tokens are in the order encountered in the input args. Options that appear more than once in args produce a token for each use. Short option groups like -xy expand to a token for each option. So -xxx produces three tokens. For example to use the returned tokens to add support for a negated option like --no-color, the tokens can be reprocessed to change the value stored for the negated option. import { parseArgs } from 'node:util'; const options = { 'color': { type: 'boolean' }, 'no-color': { type: 'boolean' }, 'logfile': { type: 'string' }, 'no-logfile': { type: 'boolean' }, }; const { values, tokens } = parseArgs({ options, tokens: true }); // Reprocess the option tokens and overwrite the returned values. tokens .filter((token) => token.kind === 'option') .forEach((token) => { if (token.name.startsWith('no-')) { // Store foo:false for --no-foo const positiveName = token.name.slice(3); values[positiveName] = false; delete values[token.name]; } else { // Resave value so last one wins if both --foo and --no-foo. values[token.name] = token.value ?? true; } }); const color = values.color; const logfile = values.logfile ?? 'default.log'; console.log({ logfile, color }); const { parseArgs } = require('node:util'); const options = { 'color': { type: 'boolean' }, 'no-color': { type: 'boolean' }, 'logfile': { type: 'string' }, 'no-logfile': { type: 'boolean' }, }; const { values, tokens } = parseArgs({ options, tokens: true }); // Reprocess the option tokens and overwrite the returned values. tokens .filter((token) => token.kind === 'option') .forEach((token) => { if (token.name.startsWith('no-')) { // Store foo:false for --no-foo const positiveName = token.name.slice(3); values[positiveName] = false; delete values[token.name]; } else { // Resave value so last one wins if both --foo and --no-foo. values[token.name] = token.value ?? true; } }); const color = values.color; const logfile = values.logfile ?? 'default.log'; console.log({ logfile, color }); Example usage showing negated options, and when an option is used multiple ways then last one wins. $ node negate.js { logfile: 'default.log', color: undefined } $ node negate.js --no-logfile --no-color { logfile: false, color: false } $ node negate.js --logfile=test.log --color { logfile: 'test.log', color: true } $ node negate.js --no-logfile --logfile=test.log --color --no-color { logfile: 'test.log', color: false } Table of Contents util.parseArgs([config]) Scope Version Matchups 🚀 Getting Started 🙌 Contributing 💡 process.mainArgs Proposal Implementation: 📃 Examples F.A.Qs Links & Resources Scope It is already possible to build great arg parsing modules on top of what Node.js provides; the prickly API is abstracted away by these modules. Thus, process.parseArgs() is not necessarily intended for library authors; it is intended for developers of simple CLI tools, ad-hoc scripts, deployed Node.js applications, and learning materials. It is exceedingly difficult to provide an API which would both be friendly to these Node.js users while being extensible enough for libraries to build upon. We chose to prioritize these use cases because these are currently not well-served by Node.js' API. Version Matchups Node.js @pkgjs/parseArgs v18.3.0 v0.9.1 v16.17.0, v18.7.0 0.10.0 🚀 Getting Started Install dependencies. npm install Open the index.js file and start editing! Test your code by calling parseArgs through our test file npm test 🙌 Contributing Any person who wants to contribute to the initiative is welcome! Please first read the Contributing Guide Additionally, reading the Examples w/ Output section of this document will be the best way to familiarize yourself with the target expected behavior for parseArgs() once it is fully implemented. This package was implemented using tape as its test harness. 💡 process.mainArgs Proposal Note: This can be moved forward independently of the util.parseArgs() proposal/work. Implementation: process.mainArgs = process.argv.slice(process._exec ? 1 : 2) 📃 Examples const { parseArgs } = require('@pkgjs/parseargs'); const { parseArgs } = require('@pkgjs/parseargs'); // specify the options that may be used const options = { foo: { type: 'string'}, bar: { type: 'boolean' }, }; const args = ['--foo=a', '--bar']; const { values, positionals } = parseArgs({ args, options }); // values = { foo: 'a', bar: true } // positionals = [] const { parseArgs } = require('@pkgjs/parseargs'); // type:string & multiple const options = { foo: { type: 'string', multiple: true, }, }; const args = ['--foo=a', '--foo', 'b']; const { values, positionals } = parseArgs({ args, options }); // values = { foo: [ 'a', 'b' ] } // positionals = [] const { parseArgs } = require('@pkgjs/parseargs'); // shorts const options = { foo: { short: 'f', type: 'boolean' }, }; const args = ['-f', 'b']; const { values, positionals } = parseArgs({ args, options, allowPositionals: true }); // values = { foo: true } // positionals = ['b'] const { parseArgs } = require('@pkgjs/parseargs'); // unconfigured const options = {}; const args = ['-f', '--foo=a', '--bar', 'b']; const { values, positionals } = parseArgs({ strict: false, args, options, allowPositionals: true }); // values = { f: true, foo: 'a', bar: true } // positionals = ['b'] F.A.Qs Is cmd --foo=bar baz the same as cmd baz --foo=bar? yes Does the parser execute a function? no Does the parser execute one of several functions, depending on input? no Can subcommands take options that are distinct from the main command? no Does it output generated help when no options match? no Does it generated short usage? Like: usage: ls [-ABCFGHLOPRSTUWabcdefghiklmnopqrstuwx1] [file ...] no (no usage/help at all) Does the user provide the long usage text? For each option? For the whole command? no Do subcommands (if implemented) have their own usage output? no Does usage print if the user runs cmd --help? no Does it set process.exitCode? no Does usage print to stderr or stdout? N/A Does it check types? (Say, specify that an option is a boolean, number, etc.) no Can an option have more than one type? (string or false, for example) no Can the user define a type? (Say, type: path to call path.resolve() on the argument.) no Does a --foo=0o22 mean 0, 22, 18, or \"0o22\"? \"0o22\" Does it coerce types? no Does --no-foo coerce to --foo=false? For all options? Only boolean options? no, it sets {values:{'no-foo': true}} Is --foo the same as --foo=true? Only for known booleans? Only at the end? no, they are not the same. There is no special handling of true as a value so it is just another string. Does it read environment variables? Ie, is FOO=1 cmd the same as cmd --foo=1? no Do unknown arguments raise an error? Are they parsed? Are they treated as positional arguments? no, they are parsed, not treated as positionals Does -- signal the end of options? yes Is -- included as a positional? no Is program -- foo the same as program foo? yes, both store {positionals:['foo']} Does the API specify whether a -- was present/relevant? no Is -bar the same as --bar? no, -bar is a short option or options, with expansion logic that follows the Utility Syntax Guidelines in POSIX.1-2017. -bar expands to -b, -a, -r. Is ---foo the same as --foo? no the first is a long option named '-foo' the second is a long option named 'foo' Is - a positional? ie, bash some-test.sh | tap - yes Links & Resources Initial Tooling Issue Initial Proposal parseArgs Proposal"
  },
  "node_modules/@sinclair/typebox/readme.html": {
    "href": "node_modules/@sinclair/typebox/readme.html",
    "title": "TypeBox | accouter",
    "keywords": "TypeBox JSON Schema Type Builder with Static Type Resolution for TypeScript Install Npm $ npm install @sinclair/typebox --save Deno import { Static, Type } from 'npm:@sinclair/typebox' Esm import { Static, Type } from 'https://esm.sh/@sinclair/typebox' Example import { Static, Type } from '@sinclair/typebox' const T = Type.Object({ // const T = { x: Type.Number(), // type: 'object', y: Type.Number(), // required: ['x', 'y', 'z'], z: Type.Number() // properties: { }) // x: { type: 'number' }, // y: { type: 'number' }, // z: { type: 'number' } // } // } type T = Static<typeof T> // type T = { // x: number, // y: number, // z: number // } Overview TypeBox is a runtime type builder that creates in-memory JSON Schema objects that can be statically inferred as TypeScript types. The schemas produced by this library are designed to match the static type assertion rules of the TypeScript compiler. TypeBox enables one to create a unified type that can be statically checked by TypeScript and runtime asserted using standard JSON Schema validation. This library is designed to enable JSON schema to compose with the same flexibility as TypeScript's type system. It can be used as a simple tool to build up complex schemas or integrated into REST or RPC services to help validate data received over the wire. License MIT Contents Install Overview Usage Types Standard Extended Modifiers Options Generics References Recursive Conditional Template Literal Guards Unsafe Strict Values Create Clone Check Convert Cast Equal Hash Diff Patch Errors Mutate Pointer TypeCheck Ajv TypeCompiler TypeSystem Types Formats Policies Benchmark Compile Validate Compression Contribute Usage The following shows general usage. import { Static, Type } from '@sinclair/typebox' //-------------------------------------------------------------------------------------------- // // Let's say you have the following type ... // //-------------------------------------------------------------------------------------------- type T = { id: string, name: string, timestamp: number } //-------------------------------------------------------------------------------------------- // // ... you can express this type in the following way. // //-------------------------------------------------------------------------------------------- const T = Type.Object({ // const T = { id: Type.String(), // type: 'object', name: Type.String(), // properties: { timestamp: Type.Integer() // id: { }) // type: 'string' // }, // name: { // type: 'string' // }, // timestamp: { // type: 'integer' // } // }, // required: [ // 'id', // 'name', // 'timestamp' // ] // } //-------------------------------------------------------------------------------------------- // // ... then infer back to the original static type this way. // //-------------------------------------------------------------------------------------------- type T = Static<typeof T> // type T = { // id: string, // name: string, // timestamp: number // } //-------------------------------------------------------------------------------------------- // // ... then use the type both as JSON schema and as a TypeScript type. // //-------------------------------------------------------------------------------------------- import { Value } from '@sinclair/typebox/value' function receive(value: T) { // ... as a Static Type if(Value.Check(T, value)) { // ... as a JSON Schema // ok... } } Types TypeBox types are JSON schema fragments that can be composed into more complex types. Each fragment is structured such that a JSON schema compliant validator can runtime assert a value the same way TypeScript will statically assert a type. TypeBox provides a set of Standard types which are used create JSON schema compliant schematics as well as an Extended type set used to create schematics for constructs native to JavaScript. Standard Types The following table lists the Standard TypeBox types. These types are fully compatible with the JSON Schema Draft 6 specification. ┌────────────────────────────────┬─────────────────────────────┬────────────────────────────────┐ │ TypeBox │ TypeScript │ JSON Schema │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Any() │ type T = any │ const T = { } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Unknown() │ type T = unknown │ const T = { } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.String() │ type T = string │ const T = { │ │ │ │ type: 'string' │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Number() │ type T = number │ const T = { │ │ │ │ type: 'number' │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Integer() │ type T = number │ const T = { │ │ │ │ type: 'integer' │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Boolean() │ type T = boolean │ const T = { │ │ │ │ type: 'boolean' │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Null() │ type T = null │ const T = { │ │ │ │ type: 'null' │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Literal(42) │ type T = 42 │ const T = { │ │ │ │ const: 42, │ │ │ │ type: 'number' │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Array( │ type T = number[] │ const T = { │ │ Type.Number() │ │ type: 'array', │ │ ) │ │ items: { │ │ │ │ type: 'number' │ │ │ │ } │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Object({ │ type T = { │ const T = { │ │ x: Type.Number(), │ x: number, │ type: 'object', │ │ y: Type.Number() │ y: number │ required: ['x', 'y'], │ │ }) │ } │ properties: { │ │ │ │ x: { │ │ │ │ type: 'number' │ │ │ │ }, { │ │ │ │ type: 'number' │ │ │ │ } │ │ │ │ } │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Tuple([ │ type T = [number, number] │ const T = { │ │ Type.Number(), │ │ type: 'array', │ │ Type.Number() │ │ items: [{ │ │ ]) │ │ type: 'number' │ │ │ │ }, { │ │ │ │ type: 'number' │ │ │ │ }], │ │ │ │ additionalItems: false, │ │ │ │ minItems: 2, │ │ │ │ maxItems: 2 │ │ │ │ } │ │ │ │ │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ enum Foo { │ enum Foo { │ const T = { │ │ A, │ A, │ anyOf: [{ │ │ B │ B │ type: 'number', │ │ } │ } │ const: 0 │ │ │ │ }, { │ │ const T = Type.Enum(Foo) │ type T = Foo │ type: 'number', │ │ │ │ const: 1 │ │ │ │ }] │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.KeyOf( │ type T = keyof { │ const T = { │ │ Type.Object({ │ x: number, │ anyOf: [{ │ │ x: Type.Number(), │ y: number │ type: 'string', │ │ y: Type.Number() │ } │ const: 'x' │ │ }) │ │ }, { │ │ ) │ │ type: 'string', │ │ │ │ const: 'y' │ │ │ │ }] │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Union([ │ type T = string | number │ const T = { │ │ Type.String(), │ │ anyOf: [{ │ │ Type.Number() │ │ type: 'string' │ │ ]) │ │ }, { │ │ │ │ type: 'number' │ │ │ │ }] │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Intersect([ │ type T = { │ const T = { │ │ Type.Object({ │ x: number │ allOf: [{ │ │ x: Type.Number() │ } & { │ type: 'object', │ │ }), │ y: number │ required: ['x'], │ │ Type.Object({ │ } │ properties: { │ │ y: Type.Number() │ │ x: { │ │ ]) │ │ type: 'number' │ │ ]) │ │ } │ │ │ │ } │ │ │ │ }, { │ │ │ │ type: 'object', | │ │ │ required: ['y'], │ │ │ │ properties: { │ │ │ │ y: { │ │ │ │ type: 'number' │ │ │ │ } │ │ │ │ } │ │ │ │ }] │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Composite([ │ type I = { │ const T = { │ │ Type.Object({ │ x: number │ type: 'object', │ │ x: Type.Number() │ } & { │ required: ['x', 'y'], │ │ }), │ y: number │ properties: { │ │ Type.Object({ │ } │ x: { │ │ y: Type.Number() │ │ type: 'number' │ │ }) │ type T = { │ }, │ │ ]) │ [K in keyof I]: I[K] │ y: { │ │ │ } │ type: 'number' │ │ │ │ } │ │ │ │ } │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Never() │ type T = never │ const T = { │ │ │ │ not: {} │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Not( | type T = string │ const T = { │ | Type.Union([ │ │ allOf: [{ │ │ Type.Literal('x'), │ │ not: { │ │ Type.Literal('y'), │ │ anyOf: [ │ │ Type.Literal('z') │ │ { const: 'x' }, │ │ ]), │ │ { const: 'y' }, │ │ Type.String() │ │ { const: 'z' } │ │ ) │ │ ] │ │ │ │ } │ │ │ │ }, { │ │ │ │ type: 'string' │ │ │ │ }] │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Extends( │ type T = │ const T = { │ │ Type.String(), │ string extends number │ const: false, │ │ Type.Number(), │ true : false │ type: 'boolean' │ │ Type.Literal(true), │ │ } │ │ Type.Literal(false) │ │ │ │ ) │ │ │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Extract( │ type T = Extract< │ const T = { │ │ Type.Union([ │ string | number, │ type: 'string' │ │ Type.String(), │ string │ } │ │ Type.Number(), │ > │ │ │ ]), │ │ │ │ Type.String() │ │ │ │ ) │ │ │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Exclude( │ type T = Exclude< │ const T = { │ │ Type.Union([ │ string | number, │ type: 'number' │ │ Type.String(), │ string │ } │ │ Type.Number(), │ > │ │ │ ]), │ │ │ │ Type.String() │ │ │ │ ) │ │ │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const U = Type.Union([ │ type U = 'open' | 'close' │ const T = { │ │ Type.Literal('open'), │ │ type: 'string', │ │ Type.Literal('close') │ type T = `on${U}` │ pattern: '^on(open|close)$' │ │ ]) │ │ } │ │ │ │ │ │ const T = Type │ │ │ │ .TemplateLiteral([ │ │ │ │ Type.Literal('on'), │ │ │ │ U │ │ │ │ ]) │ │ │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Record( │ type T = Record< │ const T = { │ │ Type.String(), │ string, │ type: 'object', │ │ Type.Number() │ number │ patternProperties: { │ │ ) │ > │ '^.*$': { │ │ │ │ type: 'number' │ │ │ │ } │ │ │ │ } │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Partial( │ type T = Partial<{ │ const T = { │ │ Type.Object({ │ x: number, │ type: 'object', │ │ x: Type.Number(), │ y: number │ properties: { │ │ y: Type.Number() | }> │ x: { │ │ }) │ │ type: 'number' │ │ ) │ │ }, │ │ │ │ y: { │ │ │ │ type: 'number' │ │ │ │ } │ │ │ │ } │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Required( │ type T = Required<{ │ const T = { │ │ Type.Object({ │ x?: number, │ type: 'object', │ │ x: Type.Optional( │ y?: number │ required: ['x', 'y'], │ │ Type.Number() | }> │ properties: { │ │ ), │ │ x: { │ │ y: Type.Optional( │ │ type: 'number' │ │ Type.Number() │ │ }, │ │ ) │ │ y: { │ │ }) │ │ type: 'number' │ │ ) │ │ } │ │ │ │ } │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Pick( │ type T = Pick<{ │ const T = { │ │ Type.Object({ │ x: number, │ type: 'object', │ │ x: Type.Number(), │ y: number │ required: ['x'], │ │ y: Type.Number() │ }, 'x'> │ properties: { │ │ }), ['x'] | │ x: { │ │ ) │ │ type: 'number' │ │ │ │ } │ │ │ │ } │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Omit( │ type T = Omit<{ │ const T = { │ │ Type.Object({ │ x: number, │ type: 'object', │ │ x: Type.Number(), │ y: number │ required: ['y'], │ │ y: Type.Number() │ }, 'x'> │ properties: { │ │ }), ['x'] | │ y: { │ │ ) │ │ type: 'number' │ │ │ │ } │ │ │ │ } │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Object({ │ type T = { │ const R = { │ │ x: Type.Number(), │ x: number, │ $ref: 'T' │ │ y: Type.Number() │ y: number │ } │ │ }, { $id: 'T' }) | } │ │ │ │ │ │ │ const R = Type.Ref(T) │ type R = T │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ │ └────────────────────────────────┴─────────────────────────────┴────────────────────────────────┘ Extended Types TypeBox provides several extended types that can be used to produce schematics for common JavaScript constructs. These types can not be used with standard JSON schema validators; but are useful to help frame schematics for RPC interfaces that may receive JSON validated data. Extended types are prefixed with the [Extended] doc comment for convenience. The following table lists the supported types. ┌────────────────────────────────┬─────────────────────────────┬────────────────────────────────┐ │ TypeBox │ TypeScript │ Extended Schema │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Constructor([ │ type T = new ( │ const T = { │ │ Type.String(), │ arg0: string, │ type: 'object', │ │ Type.Number() │ arg1: number │ instanceOf: 'Constructor', │ │ ], Type.Boolean()) │ ) => boolean │ parameters: [{ │ │ │ │ type: 'string' │ │ │ │ }, { │ │ │ │ type: 'number' │ │ │ │ }], │ │ │ │ return: { │ │ │ │ type: 'boolean' │ │ │ │ } │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Function([ │ type T = ( │ const T = { │ | Type.String(), │ arg0: string, │ type : 'object', │ │ Type.Number() │ arg1: number │ instanceOf: 'Function', │ │ ], Type.Boolean()) │ ) => boolean │ parameters: [{ │ │ │ │ type: 'string' │ │ │ │ }, { │ │ │ │ type: 'number' │ │ │ │ }], │ │ │ │ return: { │ │ │ │ type: 'boolean' │ │ │ │ } │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Promise( │ type T = Promise<string> │ const T = { │ │ Type.String() │ │ type: 'object', │ │ ) │ │ instanceOf: 'Promise', │ │ │ │ item: { │ │ │ │ type: 'string' │ │ │ │ } │ │ │ │ } │ │ │ │ │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Uint8Array() │ type T = Uint8Array │ const T = { │ │ │ │ type: 'object', │ │ │ │ instanceOf: 'Uint8Array' │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Date() │ type T = Date │ const T = { │ │ │ │ type: 'object', │ │ │ │ instanceOf: 'Date' │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Undefined() │ type T = undefined │ const T = { │ │ │ │ type: 'null', │ │ │ │ typeOf: 'Undefined' │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.RegEx(/foo/) │ type T = string │ const T = { │ │ │ │ type: 'string', │ │ │ │ pattern: 'foo' │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Symbol() │ type T = symbol │ const T = { │ │ │ │ type: 'null', │ │ │ │ typeOf: 'Symbol' │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.BigInt() │ type T = bigint │ const T = { │ │ │ │ type: 'null', │ │ │ │ typeOf: 'BigInt' │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Void() │ type T = void │ const T = { │ │ │ │ type: 'null' │ │ │ │ typeOf: 'Void' │ │ │ │ } │ │ │ │ │ └────────────────────────────────┴─────────────────────────────┴────────────────────────────────┘ Modifiers TypeBox provides modifiers that allow schema properties to be statically inferred as readonly or optional. The following table shows the supported modifiers and how they map between TypeScript and JSON Schema. ┌────────────────────────────────┬─────────────────────────────┬────────────────────────────────┐ │ TypeBox │ TypeScript │ JSON Schema │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Object({ │ type T = { │ const T = { │ │ name: Type.Optional( │ name?: string │ type: 'object', │ │ Type.String() │ } │ properties: { │ │ ) │ │ name: { │ │ }) │ │ type: 'string' │ │ │ │ } │ │ │ │ } │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Object({ │ type T = { │ const T = { │ │ name: Type.Readonly( │ readonly name: string │ type: 'object', │ │ Type.String() │ } │ properties: { │ │ ) │ │ name: { │ │ }) │ │ type: 'string' │ │ │ │ } │ │ │ │ }, │ │ │ │ required: ['name'] │ │ │ │ } │ │ │ │ │ ├────────────────────────────────┼─────────────────────────────┼────────────────────────────────┤ │ const T = Type.Object({ │ type T = { │ const T = { │ │ name: Type.ReadonlyOptional( │ readonly name?: string │ type: 'object', │ │ Type.String() │ } │ properties: { │ │ ) │ │ name: { │ │ }) │ │ type: 'string' │ │ │ │ } │ │ │ │ } │ │ │ │ } │ │ │ │ │ └────────────────────────────────┴─────────────────────────────┴────────────────────────────────┘ Options You can pass JSON Schema options on the last argument of any type. Option hints specific to each type are provided for convenience. // String must be an email const T = Type.String({ // const T = { format: 'email' // type: 'string', }) // format: 'email' // } // Mumber must be a multiple of 2 const T = Type.Number({ // const T = { multipleOf: 2 // type: 'number', }) // multipleOf: 2 // } // Array must have at least 5 integer values const T = Type.Array(Type.Integer(), { // const T = { minItems: 5 // type: 'array', }) // minItems: 5, // items: { // type: 'integer' // } // } Generic Types Generic types can be created with generic functions constrained to type TSchema. The following creates a generic Vector<T> type. import { Type, Static, TSchema } from '@sinclair/typebox' const Vector = <T extends TSchema>(t: T) => Type.Object({ x: t, y: t, z: t }) const NumberVector = Vector(Type.Number()) // const NumberVector = { // type: 'object', // required: ['x', 'y', 'z'], // properties: { // x: { type: 'number' }, // y: { type: 'number' }, // z: { type: 'number' } // } // } type NumberVector = Static<typeof NumberVector> // type NumberVector = { // x: number, // y: number, // z: number // } const BooleanVector = Vector(Type.Boolean()) // const BooleanVector = { // type: 'object', // required: ['x', 'y', 'z'], // properties: { // x: { type: 'boolean' }, // y: { type: 'boolean' }, // z: { type: 'boolean' } // } // } type BooleanVector = Static<typeof BooleanVector> // type BooleanVector = { // x: boolean, // y: boolean, // z: boolean // } The following creates a generic Nullable<T> type. const Nullable = <T extends TSchema>(schema: T) => Type.Union([schema, Type.Null()]) const T = Nullable(Type.String()) // const T = { // anyOf: [ // { type: 'string' }, // { type: 'null' } // ] // } type T = Static<typeof T> // type T = string | null Reference Types Reference types are supported with Type.Ref. The target type must specify a valid $id. const T = Type.String({ $id: 'T' }) // const T = { // $id: 'T', // type: 'string' // } const R = Type.Ref(T) // const R = { // $ref: 'T' // } Recursive Types Recursive types are supported with Type.Recursive const Node = Type.Recursive(Node => Type.Object({ // const Node = { id: Type.String(), // $id: 'Node', nodes: Type.Array(Node) // type: 'object', }), { $id: 'Node' }) // properties: { // id: { // type: 'string' // }, // nodes: { // type: 'array', // items: { // $ref: 'Node' // } // } // }, // required: [ // 'id', // 'nodes' // ] // } type Node = Static<typeof Node> // type Node = { // id: string // nodes: Node[] // } function test(node: Node) { const id = node.nodes[0].nodes[0].id // id is string } Conditional Types Conditional types are supported with Type.Extends, Type.Exclude and Type.Extract // TypeScript type T0 = string extends number ? true : false // type T0 = false type T1 = Extract<string | number, number> // type T1 = number type T2 = Exclude<string | number, number> // type T2 = string // TypeBox const T0 = Type.Extends(Type.String(), Type.Number(), Type.Literal(true), Type.Literal(false)) const T1 = Type.Extract(Type.Union([Type.String(), Type.Number()]), Type.Number()) const T2 = Type.Exclude(Type.Union([Type.String(), Type.Number()]), Type.Number()) type T0 = Static<typeof T0> // type T0 = false type T1 = Static<typeof T1> // type T1 = number type T2 = Static<typeof T2> // type T2 = string Template Literal Types Template Literal types are supported with Type.TemplateLiteral // TypeScript type T = `option${'A'|'B'}` // type T = 'optionA' | 'optionB' type R = Record<T, string> // type R = { // optionA: string // optionB: string // } // TypeBox const T = Type.TemplateLiteral([ // const T = { Type.Literal('option'), // pattern: '^option(A|B)$', Type.Union([ // type: 'string' Type.Literal('A'), // } Type.Literal('B') ]) ]) const R = Type.Record(T, Type.String()) // const R = { // type: 'object', // required: ['optionA', 'optionB'], // properties: { // optionA: { // type: 'string' // }, // optionB: { // type: 'string' // } // } // } type T = Static<typeof T> // type T = 'optionA' | 'optionB' type R = Static<typeof R> // type R = { // optionA: string // optionB: string // } Unsafe Use Type.Unsafe to create custom schematics with user defined inference rules. const T = Type.Unsafe<string>({ type: 'number' }) // const T = { // type: 'number' // } type T = Static<typeof T> // type T = string The Type.Unsafe type can be useful to express specific OpenAPI schema representations. import { Type, Static, TSchema } from '@sinclair/typebox' // Nullable<T> function Nullable<T extends TSchema>(schema: T) { return Type.Unsafe<Static<T> | null>({ ...schema, nullable: true }) } const T = Nullable(Type.String()) // const T = { // type: 'string', // nullable: true // } type T = Static<typeof T> // type T = string | null // StringEnum<string[]> function StringEnum<T extends string[]>(values: [...T]) { return Type.Unsafe<T[number]>({ type: 'string', enum: values }) } const T = StringEnum(['A', 'B', 'C']) // const T = { // enum: ['A', 'B', 'C'] // } type T = Static<typeof T> // type T = 'A' | 'B' | 'C' Guards TypeBox provides a TypeGuard module that can be used for reflection and asserting values as types. import { Type, TypeGuard } from '@sinclair/typebox' const T = Type.String() if(TypeGuard.TString(T)) { // T is TString } Strict TypeBox schemas contain the Kind and Modifier symbol properties. These properties are used for type composition and reflection. These properties are not strictly valid JSON schema; so in some cases it may be desirable to omit them. TypeBox provides a Type.Strict function that will omit these properties if necessary. const T = Type.Object({ // const T = { name: Type.Optional(Type.String()) // [Kind]: 'Object', }) // type: 'object', // properties: { // name: { // [Kind]: 'String', // type: 'string', // [Modifier]: 'Optional' // } // } // } const U = Type.Strict(T) // const U = { // type: 'object', // properties: { // name: { // type: 'string' // } // } // } Values TypeBox provides an optional utility module that can be used to perform common operations on JavaScript values. This module includes functionality to create, check and cast values from types as well as check equality, clone, diff and patch JavaScript values. This module is provided via optional import. import { Value } from '@sinclair/typebox/value' Create Use the Create function to create a value from a type. TypeBox will use default values if specified. const T = Type.Object({ x: Type.Number(), y: Type.Number({ default: 42 }) }) const A = Value.Create(T) // const A = { x: 0, y: 42 } Clone Use the Clone function to deeply clone a value const A = Value.Clone({ x: 1, y: 2, z: 3 }) // const A = { x: 1, y: 2, z: 3 } Check Use the Check function to type check a value const T = Type.Object({ x: Type.Number() }) const R = Value.Check(T, { x: 1 }) // const R = true Convert Use the Convert function to convert a value into its target type if a reasonable conversion is possible. const T = Type.Object({ x: Type.Number() }) const R1 = Value.Convert(T, { x: '3.14' }) // const R1 = { x: 3.14 } const R2 = Value.Convert(T, { x: 'not a number' }) // const R2 = { x: 'not a number' } Cast Use the Cast function to cast a value into a type. The cast function will retain as much information as possible from the original value. const T = Type.Object({ x: Type.Number(), y: Type.Number() }, { additionalProperties: false }) const X = Value.Cast(T, null) // const X = { x: 0, y: 0 } const Y = Value.Cast(T, { x: 1 }) // const Y = { x: 1, y: 0 } const Z = Value.Cast(T, { x: 1, y: 2, z: 3 }) // const Z = { x: 1, y: 2 } Equal Use the Equal function to deeply check for value equality. const R = Value.Equal( // const R = true { x: 1, y: 2, z: 3 }, { x: 1, y: 2, z: 3 } ) Hash Use the Hash function to create a FNV1A-64 non cryptographic hash of a value. const A = Value.Hash({ x: 1, y: 2, z: 3 }) // const A = 2910466848807138541n const B = Value.Hash({ x: 1, y: 4, z: 3 }) // const B = 1418369778807423581n Diff Use the Diff function to produce a sequence of edits to transform one value into another. const E = Value.Diff( // const E = [ { x: 1, y: 2, z: 3 }, // { type: 'update', path: '/y', value: 4 }, { y: 4, z: 5, w: 6 } // { type: 'update', path: '/z', value: 5 }, ) // { type: 'insert', path: '/w', value: 6 }, // { type: 'delete', path: '/x' } // ] Patch Use the Patch function to apply edits const A = { x: 1, y: 2 } const B = { x: 3 } const E = Value.Diff(A, B) // const E = [ // { type: 'update', path: '/x', value: 3 }, // { type: 'delete', path: '/y' } // ] const C = Value.Patch<typeof B>(A, E) // const C = { x: 3 } Errors Use the Errors function enumerate validation errors. const T = Type.Object({ x: Type.Number(), y: Type.Number() }) const R = [...Value.Errors(T, { x: '42' })] // const R = [{ // schema: { type: 'number' }, // path: '/x', // value: '42', // message: 'Expected number' // }, { // schema: { type: 'number' }, // path: '/y', // value: undefined, // message: 'Expected number' // }] Mutate Use the Mutate function to perform a deep mutable value assignment while retaining internal references. const Y = { z: 1 } // const Y = { z: 1 } const X = { y: Y } // const X = { y: { z: 1 } } const A = { x: X } // const A = { x: { y: { z: 1 } } } Value.Mutate(A, { x: { y: { z: 2 } } }) // const A' = { x: { y: { z: 2 } } } const R0 = A.x.y.z === 2 // const R0 = 2 const R1 = A.x.y === Y // const R1 = true const R2 = A.x === X // const R2 = true Pointer Use ValuePointer to perform mutable updates on existing values using RFC6901 JSON Pointers. import { ValuePointer } from '@sinclair/typebox/value' const A = { x: 0, y: 0, z: 0 } ValuePointer.Set(A, '/x', 1) // const A' = { x: 1, y: 0, z: 0 } ValuePointer.Set(A, '/y', 1) // const A' = { x: 1, y: 1, z: 0 } ValuePointer.Set(A, '/z', 1) // const A' = { x: 1, y: 1, z: 1 } TypeCheck TypeBox types target JSON Schema draft 6 so are compatible with any validator that supports this specification. TypeBox also provides a built in type checking compiler designed specifically for high performance compilation and value assertion. The following sections detail using Ajv and TypeBox's compiler infrastructure. Ajv The following shows the recommended setup for Ajv. $ npm install ajv ajv-formats --save import { Type } from '@sinclair/typebox' import addFormats from 'ajv-formats' import Ajv from 'ajv' const ajv = addFormats(new Ajv({}), [ 'date-time', 'time', 'date', 'email', 'hostname', 'ipv4', 'ipv6', 'uri', 'uri-reference', 'uuid', 'uri-template', 'json-pointer', 'relative-json-pointer', 'regex' ]) const C = ajv.compile(Type.Object({ x: Type.Number(), y: Type.Number(), z: Type.Number() })) const R = C({ x: 1, y: 2, z: 3 }) // const R = true TypeCompiler The TypeBox TypeCompiler is a high performance JIT compiler that transforms TypeBox types into optimized JavaScript validation routines. The compiler is tuned for fast compilation as well as fast value assertion. It is designed to serve as a validation backend that can be integrated into larger applications; but can also be used as a general purpose validator. The TypeCompiler is provided as an optional import. import { TypeCompiler } from '@sinclair/typebox/compiler' Use the Compile(...) function to compile a type. const C = TypeCompiler.Compile(Type.Object({ // const C: TypeCheck<TObject<{ x: Type.Number(), // x: TNumber; y: Type.Number(), // y: TNumber; z: Type.Number() // z: TNumber; })) // }>> const R = C.Check({ x: 1, y: 2, z: 3 }) // const R = true Use the Errors(...) function to produce diagnostic errors for a value. The Errors(...) function will return an iterator that if enumerated; will perform an exhaustive check across the entire value and yield any error found. For performance, this function should only be called after failed Check(...). Applications may also choose to yield only the first value to avoid exhaustive error generation. const C = TypeCompiler.Compile(Type.Object({ // const C: TypeCheck<TObject<{ x: Type.Number(), // x: TNumber; y: Type.Number(), // y: TNumber; z: Type.Number() // z: TNumber; })) // }>> const value = { } const errors = [...C.Errors(value)] // const errors = [{ // schema: { type: 'number' }, // path: '/x', // value: undefined, // message: 'Expected number' // }, { // schema: { type: 'number' }, // path: '/y', // value: undefined, // message: 'Expected number' // }, { // schema: { type: 'number' }, // path: '/z', // value: undefined, // message: 'Expected number' // }] Compiled routines can be inspected with the .Code() function. const C = TypeCompiler.Compile(Type.String()) // const C: TypeCheck<TString> console.log(C.Code()) // return function check(value) { // return ( // (typeof value === 'string') // ) // } TypeSystem The TypeBox TypeSystem module provides functionality to define types above and beyond the Standard and Extended type sets as well as control various assertion polices. Configurations made to the TypeSystem module are observed by both TypeCompiler and Value modules. The TypeSystem module is provided as an optional import. import { TypeSystem } from '@sinclair/typebox/system' Types Use the Type(...) function to create a custom type. This function will return a type factory function that can be used to construct the type. The following creates a Point type. type PointOptions = { } // The Type Options type PointType = { x: number, y: number } // The Static<T> Type const Point = TypeSystem.Type<PointType, PointOptions>('Point', (options, value) => { return ( typeof value === 'object' && value !== null && typeof value.x === 'number' && typeof value.y === 'number' ) }) const T = Point() type T = Static<typeof T> // type T = { x: number, y: number } const R = Value.Check(T, { x: 1, y: 2 }) // const R = true Formats Use the Format(...) function to create a custom string format. The following creates a format that checks for lowercase strings. TypeSystem.Format('lowercase', value => value === value.toLowerCase()) // format should be lowercase const T = Type.String({ format: 'lowercase' }) const A = Value.Check(T, 'Hello') // const A = false const B = Value.Check(T, 'hello') // const B = true Policies TypeBox validates using JSON Schema assertion policies by default. It is possible to override these policies and have TypeBox assert using TypeScript policies. The following overrides are available. // Allow arrays to validate as object types (default is false) // // const A: {} = [] - allowed in TS TypeSystem.AllowArrayObjects = true // Allow numeric values to be NaN or + or - Infinity (default is false) // // const A: number = NaN - allowed in TS TypeSystem.AllowNaN = true Benchmark This project maintains a set of benchmarks that measure Ajv, Value and TypeCompiler compilation and validation performance. These benchmarks can be run locally by cloning this repository and running npm run benchmark. The results below show for Ajv version 8.12.0. For additional comparative benchmarks, please refer to typescript-runtime-type-benchmarks. Compile This benchmark measures compilation performance for varying types. You can review this benchmark here. ┌────────────────────────────┬────────────┬──────────────┬──────────────┬──────────────┐ │ (index) │ Iterations │ Ajv │ TypeCompiler │ Performance │ ├────────────────────────────┼────────────┼──────────────┼──────────────┼──────────────┤ │ Literal_String │ 1000 │ ' 257 ms' │ ' 8 ms' │ ' 32.13 x' │ │ Literal_Number │ 1000 │ ' 203 ms' │ ' 4 ms' │ ' 50.75 x' │ │ Literal_Boolean │ 1000 │ ' 183 ms' │ ' 4 ms' │ ' 45.75 x' │ │ Primitive_Number │ 1000 │ ' 174 ms' │ ' 8 ms' │ ' 21.75 x' │ │ Primitive_String │ 1000 │ ' 158 ms' │ ' 9 ms' │ ' 17.56 x' │ │ Primitive_String_Pattern │ 1000 │ ' 213 ms' │ ' 13 ms' │ ' 16.38 x' │ │ Primitive_Boolean │ 1000 │ ' 136 ms' │ ' 6 ms' │ ' 22.67 x' │ │ Primitive_Null │ 1000 │ ' 144 ms' │ ' 6 ms' │ ' 24.00 x' │ │ Object_Unconstrained │ 1000 │ ' 1176 ms' │ ' 38 ms' │ ' 30.95 x' │ │ Object_Constrained │ 1000 │ ' 1181 ms' │ ' 31 ms' │ ' 38.10 x' │ │ Object_Vector3 │ 1000 │ ' 387 ms' │ ' 8 ms' │ ' 48.38 x' │ │ Object_Box3D │ 1000 │ ' 1693 ms' │ ' 25 ms' │ ' 67.72 x' │ │ Tuple_Primitive │ 1000 │ ' 470 ms' │ ' 15 ms' │ ' 31.33 x' │ │ Tuple_Object │ 1000 │ ' 1206 ms' │ ' 17 ms' │ ' 70.94 x' │ │ Composite_Intersect │ 1000 │ ' 567 ms' │ ' 20 ms' │ ' 28.35 x' │ │ Composite_Union │ 1000 │ ' 515 ms' │ ' 21 ms' │ ' 24.52 x' │ │ Math_Vector4 │ 1000 │ ' 787 ms' │ ' 10 ms' │ ' 78.70 x' │ │ Math_Matrix4 │ 1000 │ ' 386 ms' │ ' 8 ms' │ ' 48.25 x' │ │ Array_Primitive_Number │ 1000 │ ' 349 ms' │ ' 7 ms' │ ' 49.86 x' │ │ Array_Primitive_String │ 1000 │ ' 336 ms' │ ' 4 ms' │ ' 84.00 x' │ │ Array_Primitive_Boolean │ 1000 │ ' 284 ms' │ ' 3 ms' │ ' 94.67 x' │ │ Array_Object_Unconstrained │ 1000 │ ' 1704 ms' │ ' 19 ms' │ ' 89.68 x' │ │ Array_Object_Constrained │ 1000 │ ' 1456 ms' │ ' 18 ms' │ ' 80.89 x' │ │ Array_Tuple_Primitive │ 1000 │ ' 792 ms' │ ' 15 ms' │ ' 52.80 x' │ │ Array_Tuple_Object │ 1000 │ ' 1552 ms' │ ' 17 ms' │ ' 91.29 x' │ │ Array_Composite_Intersect │ 1000 │ ' 744 ms' │ ' 18 ms' │ ' 41.33 x' │ │ Array_Composite_Union │ 1000 │ ' 783 ms' │ ' 15 ms' │ ' 52.20 x' │ │ Array_Math_Vector4 │ 1000 │ ' 1093 ms' │ ' 14 ms' │ ' 78.07 x' │ │ Array_Math_Matrix4 │ 1000 │ ' 684 ms' │ ' 6 ms' │ ' 114.00 x' │ └────────────────────────────┴────────────┴──────────────┴──────────────┴──────────────┘ Validate This benchmark measures validation performance for varying types. You can review this benchmark here. ┌────────────────────────────┬────────────┬──────────────┬──────────────┬──────────────┬──────────────┐ │ (index) │ Iterations │ ValueCheck │ Ajv │ TypeCompiler │ Performance │ ├────────────────────────────┼────────────┼──────────────┼──────────────┼──────────────┼──────────────┤ │ Literal_String │ 1000000 │ ' 27 ms' │ ' 6 ms' │ ' 5 ms' │ ' 1.20 x' │ │ Literal_Number │ 1000000 │ ' 23 ms' │ ' 21 ms' │ ' 11 ms' │ ' 1.91 x' │ │ Literal_Boolean │ 1000000 │ ' 21 ms' │ ' 20 ms' │ ' 10 ms' │ ' 2.00 x' │ │ Primitive_Number │ 1000000 │ ' 26 ms' │ ' 19 ms' │ ' 11 ms' │ ' 1.73 x' │ │ Primitive_String │ 1000000 │ ' 25 ms' │ ' 19 ms' │ ' 10 ms' │ ' 1.90 x' │ │ Primitive_String_Pattern │ 1000000 │ ' 155 ms' │ ' 49 ms' │ ' 43 ms' │ ' 1.14 x' │ │ Primitive_Boolean │ 1000000 │ ' 23 ms' │ ' 19 ms' │ ' 10 ms' │ ' 1.90 x' │ │ Primitive_Null │ 1000000 │ ' 24 ms' │ ' 19 ms' │ ' 10 ms' │ ' 1.90 x' │ │ Object_Unconstrained │ 1000000 │ ' 804 ms' │ ' 35 ms' │ ' 28 ms' │ ' 1.25 x' │ │ Object_Constrained │ 1000000 │ ' 1041 ms' │ ' 55 ms' │ ' 41 ms' │ ' 1.34 x' │ │ Object_Vector3 │ 1000000 │ ' 380 ms' │ ' 26 ms' │ ' 20 ms' │ ' 1.30 x' │ │ Object_Box3D │ 1000000 │ ' 1785 ms' │ ' 65 ms' │ ' 52 ms' │ ' 1.25 x' │ │ Object_Recursive │ 1000000 │ ' 4984 ms' │ ' 396 ms' │ ' 114 ms' │ ' 3.47 x' │ │ Tuple_Primitive │ 1000000 │ ' 168 ms' │ ' 24 ms' │ ' 16 ms' │ ' 1.50 x' │ │ Tuple_Object │ 1000000 │ ' 673 ms' │ ' 30 ms' │ ' 26 ms' │ ' 1.15 x' │ │ Composite_Intersect │ 1000000 │ ' 751 ms' │ ' 28 ms' │ ' 20 ms' │ ' 1.40 x' │ │ Composite_Union │ 1000000 │ ' 489 ms' │ ' 24 ms' │ ' 16 ms' │ ' 1.50 x' │ │ Math_Vector4 │ 1000000 │ ' 259 ms' │ ' 23 ms' │ ' 13 ms' │ ' 1.77 x' │ │ Math_Matrix4 │ 1000000 │ ' 1002 ms' │ ' 40 ms' │ ' 30 ms' │ ' 1.33 x' │ │ Array_Primitive_Number │ 1000000 │ ' 252 ms' │ ' 22 ms' │ ' 15 ms' │ ' 1.47 x' │ │ Array_Primitive_String │ 1000000 │ ' 227 ms' │ ' 22 ms' │ ' 18 ms' │ ' 1.22 x' │ │ Array_Primitive_Boolean │ 1000000 │ ' 150 ms' │ ' 23 ms' │ ' 22 ms' │ ' 1.05 x' │ │ Array_Object_Unconstrained │ 1000000 │ ' 4754 ms' │ ' 71 ms' │ ' 64 ms' │ ' 1.11 x' │ │ Array_Object_Constrained │ 1000000 │ ' 4787 ms' │ ' 142 ms' │ ' 123 ms' │ ' 1.15 x' │ │ Array_Object_Recursive │ 1000000 │ ' 19088 ms' │ ' 1735 ms' │ ' 314 ms' │ ' 5.53 x' │ │ Array_Tuple_Primitive │ 1000000 │ ' 650 ms' │ ' 41 ms' │ ' 31 ms' │ ' 1.32 x' │ │ Array_Tuple_Object │ 1000000 │ ' 2770 ms' │ ' 67 ms' │ ' 55 ms' │ ' 1.22 x' │ │ Array_Composite_Intersect │ 1000000 │ ' 2693 ms' │ ' 50 ms' │ ' 39 ms' │ ' 1.28 x' │ │ Array_Composite_Union │ 1000000 │ ' 1982 ms' │ ' 72 ms' │ ' 33 ms' │ ' 2.18 x' │ │ Array_Math_Vector4 │ 1000000 │ ' 1068 ms' │ ' 40 ms' │ ' 26 ms' │ ' 1.54 x' │ │ Array_Math_Matrix4 │ 1000000 │ ' 4609 ms' │ ' 115 ms' │ ' 88 ms' │ ' 1.31 x' │ └────────────────────────────┴────────────┴──────────────┴──────────────┴──────────────┴──────────────┘ Compression The following table lists esbuild compiled and minified sizes for each TypeBox module. ┌──────────────────────┬────────────┬────────────┬─────────────┐ │ (index) │ Compiled │ Minified │ Compression │ ├──────────────────────┼────────────┼────────────┼─────────────┤ │ typebox/compiler │ '124.3 kb' │ ' 55.7 kb' │ '2.23 x' │ │ typebox/errors │ '107.8 kb' │ ' 47.9 kb' │ '2.25 x' │ │ typebox/system │ ' 73.3 kb' │ ' 30.2 kb' │ '2.43 x' │ │ typebox/value │ '170.7 kb' │ ' 74.2 kb' │ '2.30 x' │ │ typebox │ ' 72.0 kb' │ ' 29.7 kb' │ '2.43 x' │ └──────────────────────┴────────────┴────────────┴─────────────┘ Contribute TypeBox is open to community contribution. Please ensure you submit an open issue before submitting your pull request. The TypeBox project preferences open community discussion prior to accepting new features."
  },
  "node_modules/@sindresorhus/merge-streams/readme.html": {
    "href": "node_modules/@sindresorhus/merge-streams/readme.html",
    "title": "merge-streams | accouter",
    "keywords": "merge-streams Merge multiple streams into a unified stream Install npm install @sindresorhus/merge-streams Usage import mergeStreams from '@sindresorhus/merge-streams'; const stream = mergeStreams([streamA, streamB]); for await (const chunk of stream) { console.log(chunk); //=> 'A1' //=> 'B1' //=> 'A2' //=> 'B2' } API mergeStreams(streams: stream.Readable[]): MergedStream Merges an array of readable streams and returns a new readable stream that emits data from the individual streams as it arrives. If you provide an empty array, it returns an already-ended stream. MergedStream Type: stream.Readable A single stream combining the output of multiple streams. MergedStream.add(stream: stream.Readable): void Pipe a new readable stream. Throws if MergedStream has already ended. MergedStream.remove(stream: stream.Readable): boolean Unpipe a stream previously added using either mergeStreams(streams) or MergedStream.add(stream). Returns false if the stream was not previously added, or if it was already removed by MergedStream.remove(stream). The removed stream is not automatically ended."
  },
  "node_modules/@socket.io/component-emitter/Readme.html": {
    "href": "node_modules/@socket.io/component-emitter/Readme.html",
    "title": "@socket.io/component-emitter | accouter",
    "keywords": "@socket.io/component-emitter Event emitter component. This project is a fork of the component-emitter project, with Socket.IO-specific TypeScript typings. Installation $ npm i @socket.io/component-emitter API Emitter(obj) The Emitter may also be used as a mixin. For example a \"plain\" object may become an emitter, or you may extend an existing prototype. As an Emitter instance: import { Emitter } from '@socket.io/component-emitter'; var emitter = new Emitter; emitter.emit('something'); As a mixin: import { Emitter } from '@socket.io/component-emitter'; var user = { name: 'tobi' }; Emitter(user); user.emit('im a user'); As a prototype mixin: import { Emitter } from '@socket.io/component-emitter'; Emitter(User.prototype); Emitter#on(event, fn) Register an event handler fn. Emitter#once(event, fn) Register a single-shot event handler fn, removed immediately after it is invoked the first time. Emitter#off(event, fn) Pass event and fn to remove a listener. Pass event to remove all listeners on that event. Pass nothing to remove all listeners on all events. Emitter#emit(event, ...) Emit an event with variable option args. Emitter#listeners(event) Return an array of callbacks, or an empty array. Emitter#hasListeners(event) Check if this emitter has event handlers. License MIT"
  },
  "node_modules/@trysound/sax/README.html": {
    "href": "node_modules/@trysound/sax/README.html",
    "title": "svg/sax | accouter",
    "keywords": "svg/sax A maintained fork of sax-js sax-style parser for XML and HTML. Designed with node in mind, but should work fine in the browser or other CommonJS implementations. What This Is A very simple tool to parse through an XML string. A stepping stone to a streaming HTML parser. A handy way to deal with RSS and other mostly-ok-but-kinda-broken XML docs. What This Is (probably) Not An HTML Parser - That's a fine goal, but this isn't it. It's just XML. A DOM Builder - You can use it to build an object model out of XML, but it doesn't do that out of the box. XSLT - No DOM = no querying. 100% Compliant with (some other SAX implementation) - Most SAX implementations are in Java and do a lot more than this does. An XML Validator - It does a little validation when in strict mode, but not much. A Schema-Aware XSD Thing - Schemas are an exercise in fetishistic masochism. A DTD-aware Thing - Fetching DTDs is a much bigger job. Regarding <!DOCTYPEs and <!ENTITYs The parser will handle the basic XML entities in text nodes and attribute values: &amp; &lt; &gt; &apos; &quot;. It's possible to define additional entities in XML by putting them in the DTD. This parser doesn't do anything with that. If you want to listen to the ondoctype event, and then fetch the doctypes, and read the entities and add them to parser.ENTITIES, then be my guest. Unknown entities will fail in strict mode, and in loose mode, will pass through unmolested. Usage var sax = require(\"./lib/sax\"), strict = true, // set to false for html-mode parser = sax.parser(strict); parser.onerror = function (e) { // an error happened. }; parser.ontext = function (t) { // got some text. t is the string of text. }; parser.onopentag = function (node) { // opened a tag. node has \"name\" and \"attributes\" }; parser.onattribute = function (attr) { // an attribute. attr has \"name\" and \"value\" }; parser.onend = function () { // parser stream is done, and ready to have more stuff written to it. }; parser.write('<xml>Hello, <who name=\"world\">world</who>!</xml>').close(); Arguments Pass the following arguments to the parser function. All are optional. strict - Boolean. Whether or not to be a jerk. Default: false. opt - Object bag of settings regarding string formatting. All default to false. Settings supported: trim - Boolean. Whether or not to trim text and comment nodes. normalize - Boolean. If true, then turn any whitespace into a single space. lowercase - Boolean. If true, then lowercase tag names and attribute names in loose mode, rather than uppercasing them. xmlns - Boolean. If true, then namespaces are supported. position - Boolean. If false, then don't track line/col/position. strictEntities - Boolean. If true, only parse predefined XML entities (&amp;, &apos;, &gt;, &lt;, and &quot;) Methods write - Write bytes onto the stream. You don't have to do this all at once. You can keep writing as much as you want. close - Close the stream. Once closed, no more data may be written until it is done processing the buffer, which is signaled by the end event. resume - To gracefully handle errors, assign a listener to the error event. Then, when the error is taken care of, you can call resume to continue parsing. Otherwise, the parser will not continue while in an error state. Members At all times, the parser object will have the following members: line, column, position - Indications of the position in the XML document where the parser currently is looking. startTagPosition - Indicates the position where the current tag starts. closed - Boolean indicating whether or not the parser can be written to. If it's true, then wait for the ready event to write again. strict - Boolean indicating whether or not the parser is a jerk. opt - Any options passed into the constructor. tag - The current tag being dealt with. And a bunch of other stuff that you probably shouldn't touch. Events All events emit with a single argument. To listen to an event, assign a function to on<eventname>. Functions get executed in the this-context of the parser object. The list of supported events are also in the exported EVENTS array. error - Indication that something bad happened. The error will be hanging out on parser.error, and must be deleted before parsing can continue. By listening to this event, you can keep an eye on that kind of stuff. Note: this happens much more in strict mode. Argument: instance of Error. text - Text node. Argument: string of text. doctype - The <!DOCTYPE declaration. Argument: doctype string. processinginstruction - Stuff like <?xml foo=\"blerg\" ?>. Argument: object with name and body members. Attributes are not parsed, as processing instructions have implementation dependent semantics. sgmldeclaration - Random SGML declarations. Stuff like <!ENTITY p> would trigger this kind of event. This is a weird thing to support, so it might go away at some point. SAX isn't intended to be used to parse SGML, after all. opentagstart - Emitted immediately when the tag name is available, but before any attributes are encountered. Argument: object with a name field and an empty attributes set. Note that this is the same object that will later be emitted in the opentag event. opentag - An opening tag. Argument: object with name and attributes. In non-strict mode, tag names are uppercased, unless the lowercase option is set. If the xmlns option is set, then it will contain namespace binding information on the ns member, and will have a local, prefix, and uri member. closetag - A closing tag. In loose mode, tags are auto-closed if their parent closes. In strict mode, well-formedness is enforced. Note that self-closing tags will have closeTag emitted immediately after openTag. Argument: tag name. attribute - An attribute node. Argument: object with name and value. In non-strict mode, attribute names are uppercased, unless the lowercase option is set. If the xmlns option is set, it will also contains namespace information. comment - A comment node. Argument: the string of the comment. opencdata - The opening tag of a <![CDATA[ block. cdata - The text of a <![CDATA[ block. Since <![CDATA[ blocks can get quite large, this event may fire multiple times for a single block, if it is broken up into multiple write()s. Argument: the string of random character data. closecdata - The closing tag (]]>) of a <![CDATA[ block. opennamespace - If the xmlns option is set, then this event will signal the start of a new namespace binding. closenamespace - If the xmlns option is set, then this event will signal the end of a namespace binding. end - Indication that the closed stream has ended. ready - Indication that the stream has reset, and is ready to be written to. noscript - In non-strict mode, <script> tags trigger a \"script\" event, and their contents are not checked for special xml characters. If you pass noscript: true, then this behavior is suppressed. Reporting Problems It's best to write a failing test if you find an issue. I will always accept pull requests with failing tests if they demonstrate intended behavior, but it is very hard to figure out what issue you're describing without a test. Writing a test is also the best way for you yourself to figure out if you really understand the issue you think you have with sax-js."
  },
  "node_modules/@types/cookie/README.html": {
    "href": "node_modules/@types/cookie/README.html",
    "title": "Installation | accouter",
    "keywords": "Installation npm install --save @types/cookie Summary This package contains type definitions for cookie (https://github.com/jshttp/cookie). Details Files were exported from https://github.com/DefinitelyTyped/DefinitelyTyped/tree/master/types/cookie. Additional Details Last updated: Tue, 06 Jul 2021 20:32:30 GMT Dependencies: none Global values: none Credits These definitions were written by Pine Mizune, and Piotr Błażejewicz."
  },
  "node_modules/@types/cors/README.html": {
    "href": "node_modules/@types/cors/README.html",
    "title": "Installation | accouter",
    "keywords": "Installation npm install --save @types/cors Summary This package contains type definitions for cors (https://github.com/expressjs/cors/). Details Files were exported from https://github.com/DefinitelyTyped/DefinitelyTyped/tree/master/types/cors. index.d.ts /// <reference types=\"node\" /> import { IncomingHttpHeaders } from \"http\"; type StaticOrigin = boolean | string | RegExp | Array<boolean | string | RegExp>; type CustomOrigin = ( requestOrigin: string | undefined, callback: (err: Error | null, origin?: StaticOrigin) => void, ) => void; declare namespace e { interface CorsRequest { method?: string | undefined; headers: IncomingHttpHeaders; } interface CorsOptions { /** * @default '*'' */ origin?: StaticOrigin | CustomOrigin | undefined; /** * @default 'GET,HEAD,PUT,PATCH,POST,DELETE' */ methods?: string | string[] | undefined; allowedHeaders?: string | string[] | undefined; exposedHeaders?: string | string[] | undefined; credentials?: boolean | undefined; maxAge?: number | undefined; /** * @default false */ preflightContinue?: boolean | undefined; /** * @default 204 */ optionsSuccessStatus?: number | undefined; } type CorsOptionsDelegate<T extends CorsRequest = CorsRequest> = ( req: T, callback: (err: Error | null, options?: CorsOptions) => void, ) => void; } declare function e<T extends e.CorsRequest = e.CorsRequest>( options?: e.CorsOptions | e.CorsOptionsDelegate<T>, ): ( req: T, res: { statusCode?: number | undefined; setHeader(key: string, value: string): any; end(): any; }, next: (err?: any) => any, ) => void; export = e; Additional Details Last updated: Mon, 20 Nov 2023 23:36:24 GMT Dependencies: @types/node Credits These definitions were written by Alan Plum, and Gaurav Sharma."
  },
  "node_modules/@types/node/README.html": {
    "href": "node_modules/@types/node/README.html",
    "title": "Installation | accouter",
    "keywords": "Installation npm install --save @types/node Summary This package contains type definitions for node (https://nodejs.org/). Details Files were exported from https://github.com/DefinitelyTyped/DefinitelyTyped/tree/master/types/node. Additional Details Last updated: Sun, 02 Jun 2024 20:07:09 GMT Dependencies: undici-types Credits These definitions were written by Microsoft TypeScript, Alberto Schiabel, Alvis HT Tang, Andrew Makarov, Benjamin Toueg, Chigozirim C., David Junger, Deividas Bakanas, Eugene Y. Q. Shen, Hannes Magnusson, Huw, Kelvin Jin, Klaus Meinhardt, Lishude, Mariusz Wiktorczyk, Mohsen Azimi, Nikita Galkin, Parambir Singh, Sebastian Silbermann, Thomas den Hollander, Wilco Bakker, wwwy3y3, Samuel Ainsworth, Kyle Uehlein, Thanik Bhongbhibhat, Marcin Kopacz, Trivikram Kamat, Junxiao Shi, Ilia Baryshnikov, ExE Boss, Piotr Błażejewicz, Anna Henningsen, Victor Perin, Yongsheng Zhang, NodeJS Contributors, Linus Unnebäck, wafuwafu13, Matteo Collina, and Dmitry Semigradsky."
  },
  "node_modules/accepts/HISTORY.html": {
    "href": "node_modules/accepts/HISTORY.html",
    "title": "1.3.8 / 2022-02-02 | accouter",
    "keywords": "1.3.8 / 2022-02-02 deps: mime-types@~2.1.34 deps: mime-db@~1.51.0 deps: negotiator@0.6.3 1.3.7 / 2019-04-29 deps: negotiator@0.6.2 Fix sorting charset, encoding, and language with extra parameters 1.3.6 / 2019-04-28 deps: mime-types@~2.1.24 deps: mime-db@~1.40.0 1.3.5 / 2018-02-28 deps: mime-types@~2.1.18 deps: mime-db@~1.33.0 1.3.4 / 2017-08-22 deps: mime-types@~2.1.16 deps: mime-db@~1.29.0 1.3.3 / 2016-05-02 deps: mime-types@~2.1.11 deps: mime-db@~1.23.0 deps: negotiator@0.6.1 perf: improve Accept parsing speed perf: improve Accept-Charset parsing speed perf: improve Accept-Encoding parsing speed perf: improve Accept-Language parsing speed 1.3.2 / 2016-03-08 deps: mime-types@~2.1.10 Fix extension of application/dash+xml Update primary extension for audio/mp4 deps: mime-db@~1.22.0 1.3.1 / 2016-01-19 deps: mime-types@~2.1.9 deps: mime-db@~1.21.0 1.3.0 / 2015-09-29 deps: mime-types@~2.1.7 deps: mime-db@~1.19.0 deps: negotiator@0.6.0 Fix including type extensions in parameters in Accept parsing Fix parsing Accept parameters with quoted equals Fix parsing Accept parameters with quoted semicolons Lazy-load modules from main entry point perf: delay type concatenation until needed perf: enable strict mode perf: hoist regular expressions perf: remove closures getting spec properties perf: remove a closure from media type parsing perf: remove property delete from media type parsing 1.2.13 / 2015-09-06 deps: mime-types@~2.1.6 deps: mime-db@~1.18.0 1.2.12 / 2015-07-30 deps: mime-types@~2.1.4 deps: mime-db@~1.16.0 1.2.11 / 2015-07-16 deps: mime-types@~2.1.3 deps: mime-db@~1.15.0 1.2.10 / 2015-07-01 deps: mime-types@~2.1.2 deps: mime-db@~1.14.0 1.2.9 / 2015-06-08 deps: mime-types@~2.1.1 perf: fix deopt during mapping 1.2.8 / 2015-06-07 deps: mime-types@~2.1.0 deps: mime-db@~1.13.0 perf: avoid argument reassignment & argument slice perf: avoid negotiator recursive construction perf: enable strict mode perf: remove unnecessary bitwise operator 1.2.7 / 2015-05-10 deps: negotiator@0.5.3 Fix media type parameter matching to be case-insensitive 1.2.6 / 2015-05-07 deps: mime-types@~2.0.11 deps: mime-db@~1.9.1 deps: negotiator@0.5.2 Fix comparing media types with quoted values Fix splitting media types with quoted commas 1.2.5 / 2015-03-13 deps: mime-types@~2.0.10 deps: mime-db@~1.8.0 1.2.4 / 2015-02-14 Support Node.js 0.6 deps: mime-types@~2.0.9 deps: mime-db@~1.7.0 deps: negotiator@0.5.1 Fix preference sorting to be stable for long acceptable lists 1.2.3 / 2015-01-31 deps: mime-types@~2.0.8 deps: mime-db@~1.6.0 1.2.2 / 2014-12-30 deps: mime-types@~2.0.7 deps: mime-db@~1.5.0 1.2.1 / 2014-12-30 deps: mime-types@~2.0.5 deps: mime-db@~1.3.1 1.2.0 / 2014-12-19 deps: negotiator@0.5.0 Fix list return order when large accepted list Fix missing identity encoding when q=0 exists Remove dynamic building of Negotiator class 1.1.4 / 2014-12-10 deps: mime-types@~2.0.4 deps: mime-db@~1.3.0 1.1.3 / 2014-11-09 deps: mime-types@~2.0.3 deps: mime-db@~1.2.0 1.1.2 / 2014-10-14 deps: negotiator@0.4.9 Fix error when media type has invalid parameter 1.1.1 / 2014-09-28 deps: mime-types@~2.0.2 deps: mime-db@~1.1.0 deps: negotiator@0.4.8 Fix all negotiations to be case-insensitive Stable sort preferences of same quality according to client order 1.1.0 / 2014-09-02 update mime-types 1.0.7 / 2014-07-04 Fix wrong type returned from type when match after unknown extension 1.0.6 / 2014-06-24 deps: negotiator@0.4.7 1.0.5 / 2014-06-20 fix crash when unknown extension given 1.0.4 / 2014-06-19 use mime-types 1.0.3 / 2014-06-11 deps: negotiator@0.4.6 Order by specificity when quality is the same 1.0.2 / 2014-05-29 Fix interpretation when header not in request deps: pin negotiator@0.4.5 1.0.1 / 2014-01-18 Identity encoding isn't always acceptable deps: negotiator@~0.4.0 1.0.0 / 2013-12-27 Genesis"
  },
  "node_modules/accepts/README.html": {
    "href": "node_modules/accepts/README.html",
    "title": "accepts | accouter",
    "keywords": "accepts Higher level content negotiation based on negotiator. Extracted from koa for general use. In addition to negotiator, it allows: Allows types as an array or arguments list, ie (['text/html', 'application/json']) as well as ('text/html', 'application/json'). Allows type shorthands such as json. Returns false when no types match Treats non-existent headers as * Installation This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install accepts API var accepts = require('accepts') accepts(req) Create a new Accepts object for the given req. .charset(charsets) Return the first accepted charset. If nothing in charsets is accepted, then false is returned. .charsets() Return the charsets that the request accepts, in the order of the client's preference (most preferred first). .encoding(encodings) Return the first accepted encoding. If nothing in encodings is accepted, then false is returned. .encodings() Return the encodings that the request accepts, in the order of the client's preference (most preferred first). .language(languages) Return the first accepted language. If nothing in languages is accepted, then false is returned. .languages() Return the languages that the request accepts, in the order of the client's preference (most preferred first). .type(types) Return the first accepted type (and it is returned as the same text as what appears in the types array). If nothing in types is accepted, then false is returned. The types array can contain full MIME types or file extensions. Any value that is not a full MIME types is passed to require('mime-types').lookup. .types() Return the types that the request accepts, in the order of the client's preference (most preferred first). Examples Simple type negotiation This simple example shows how to use accepts to return a different typed respond body based on what the client wants to accept. The server lists it's preferences in order and will get back the best match between the client and server. var accepts = require('accepts') var http = require('http') function app (req, res) { var accept = accepts(req) // the order of this list is significant; should be server preferred order switch (accept.type(['json', 'html'])) { case 'json': res.setHeader('Content-Type', 'application/json') res.write('{\"hello\":\"world!\"}') break case 'html': res.setHeader('Content-Type', 'text/html') res.write('<b>hello, world!</b>') break default: // the fallback is text/plain, so no need to specify it above res.setHeader('Content-Type', 'text/plain') res.write('hello, world!') break } res.end() } http.createServer(app).listen(3000) You can test this out with the cURL program: curl -I -H'Accept: text/html' http://localhost:3000/ License MIT"
  },
  "node_modules/aggregate-error/readme.html": {
    "href": "node_modules/aggregate-error/readme.html",
    "title": "aggregate-error | accouter",
    "keywords": "aggregate-error Create an error from multiple errors Note: With Node.js 15, there's now a built-in AggregateError type. Install $ npm install aggregate-error Usage import AggregateError from 'aggregate-error'; const error = new AggregateError([new Error('foo'), 'bar', {message: 'baz'}]); throw error; /* AggregateError: Error: foo at Object.<anonymous> (/Users/sindresorhus/dev/aggregate-error/example.js:3:33) Error: bar at Object.<anonymous> (/Users/sindresorhus/dev/aggregate-error/example.js:3:13) Error: baz at Object.<anonymous> (/Users/sindresorhus/dev/aggregate-error/example.js:3:13) at AggregateError (/Users/sindresorhus/dev/aggregate-error/index.js:19:3) at Object.<anonymous> (/Users/sindresorhus/dev/aggregate-error/example.js:3:13) at Module._compile (module.js:556:32) at Object.Module._extensions..js (module.js:565:10) at Module.load (module.js:473:32) at tryModuleLoad (module.js:432:12) at Function.Module._load (module.js:424:3) at Module.runMain (module.js:590:10) at run (bootstrap_node.js:394:7) at startup (bootstrap_node.js:149:9) */ for (const individualError of error.errors) { console.log(individualError); } //=> [Error: foo] //=> [Error: bar] //=> [Error: baz] API AggregateError(errors) Returns an Error. errors Type: Array<Error|object|string> If a string, a new Error is created with the string as the error message. If a non-Error object, a new Error is created with all properties from the object copied over."
  },
  "node_modules/ansi-colors/README.html": {
    "href": "node_modules/ansi-colors/README.html",
    "title": "ansi-colors | accouter",
    "keywords": "ansi-colors Easily add ANSI colors to your text and symbols in the terminal. A faster drop-in replacement for chalk, kleur and turbocolor (without the dependencies and rendering bugs). Please consider following this project's author, Brian Woodward, and consider starring the project to show your ❤️ and support. Install Install with npm: $ npm install --save ansi-colors Why use this? ansi-colors is the fastest Node.js library for terminal styling. A more performant drop-in replacement for chalk, with no dependencies. Blazing fast - Fastest terminal styling library in node.js, 10-20x faster than chalk! Drop-in replacement for chalk. No dependencies (Chalk has 7 dependencies in its tree!) Safe - Does not modify the String.prototype like colors. Supports nested colors, and does not have the nested styling bug that is present in colorette, chalk, and kleur. Supports chained colors. Toggle color support on or off. Usage const c = require('ansi-colors'); console.log(c.red('This is a red string!')); console.log(c.green('This is a red string!')); console.log(c.cyan('This is a cyan string!')); console.log(c.yellow('This is a yellow string!')); Chained colors console.log(c.bold.red('this is a bold red message')); console.log(c.bold.yellow.italic('this is a bold yellow italicized message')); console.log(c.green.bold.underline('this is a bold green underlined message')); Nested colors console.log(c.yellow(`foo ${c.red.bold('red')} bar ${c.cyan('cyan')} baz`)); Nested styling bug ansi-colors does not have the nested styling bug found in colorette, chalk, and kleur. const { bold, red } = require('ansi-styles'); console.log(bold(`foo ${red.dim('bar')} baz`)); const colorette = require('colorette'); console.log(colorette.bold(`foo ${colorette.red(colorette.dim('bar'))} baz`)); const kleur = require('kleur'); console.log(kleur.bold(`foo ${kleur.red.dim('bar')} baz`)); const chalk = require('chalk'); console.log(chalk.bold(`foo ${chalk.red.dim('bar')} baz`)); Results in the following (sans icons and labels) Toggle color support Easily enable/disable colors. const c = require('ansi-colors'); // disable colors manually c.enabled = false; // or use a library to automatically detect support c.enabled = require('color-support').hasBasic; console.log(c.red('I will only be colored red if the terminal supports colors')); Strip ANSI codes Use the .unstyle method to strip ANSI codes from a string. console.log(c.unstyle(c.blue.bold('foo bar baz'))); //=> 'foo bar baz' Available styles Note that bright and bright-background colors are not always supported. Colors Background Colors Bright Colors Bright Background Colors black bgBlack blackBright bgBlackBright red bgRed redBright bgRedBright green bgGreen greenBright bgGreenBright yellow bgYellow yellowBright bgYellowBright blue bgBlue blueBright bgBlueBright magenta bgMagenta magentaBright bgMagentaBright cyan bgCyan cyanBright bgCyanBright white bgWhite whiteBright bgWhiteBright gray grey (gray is the U.S. spelling, grey is more commonly used in the Canada and U.K.) Style modifiers dim bold hidden italic underline inverse strikethrough reset Aliases Create custom aliases for styles. const colors = require('ansi-colors'); colors.alias('primary', colors.yellow); colors.alias('secondary', colors.bold); console.log(colors.primary.secondary('Foo')); Themes A theme is an object of custom aliases. const colors = require('ansi-colors'); colors.theme({ danger: colors.red, dark: colors.dim.gray, disabled: colors.gray, em: colors.italic, heading: colors.bold.underline, info: colors.cyan, muted: colors.dim, primary: colors.blue, strong: colors.bold, success: colors.green, underline: colors.underline, warning: colors.yellow }); // Now, we can use our custom styles alongside the built-in styles! console.log(colors.danger.strong.em('Error!')); console.log(colors.warning('Heads up!')); console.log(colors.info('Did you know...')); console.log(colors.success.bold('It worked!')); Performance Libraries tested ansi-colors v3.0.4 chalk v2.4.1 Mac MacBook Pro, Intel Core i7, 2.3 GHz, 16 GB. Load time Time it takes to load the first time require() is called: ansi-colors - 1.915ms chalk - 12.437ms Benchmarks # All Colors ansi-colors x 173,851 ops/sec ±0.42% (91 runs sampled) chalk x 9,944 ops/sec ±2.53% (81 runs sampled))) # Chained colors ansi-colors x 20,791 ops/sec ±0.60% (88 runs sampled) chalk x 2,111 ops/sec ±2.34% (83 runs sampled) # Nested colors ansi-colors x 59,304 ops/sec ±0.98% (92 runs sampled) chalk x 4,590 ops/sec ±2.08% (82 runs sampled) Windows Windows 10, Intel Core i7-7700k CPU @ 4.2 GHz, 32 GB Load time Time it takes to load the first time require() is called: ansi-colors - 1.494ms chalk - 11.523ms Benchmarks # All Colors ansi-colors x 193,088 ops/sec ±0.51% (95 runs sampled)) chalk x 9,612 ops/sec ±3.31% (77 runs sampled))) # Chained colors ansi-colors x 26,093 ops/sec ±1.13% (94 runs sampled) chalk x 2,267 ops/sec ±2.88% (80 runs sampled)) # Nested colors ansi-colors x 67,747 ops/sec ±0.49% (93 runs sampled) chalk x 4,446 ops/sec ±3.01% (82 runs sampled)) About Contributing Pull requests and stars are always welcome. For bugs and feature requests, please create an issue. Running Tests Running and reviewing unit tests is a great way to get familiarized with a library and its API. You can install dependencies and run tests with the following command: $ npm install && npm test Building docs (This project's readme.md is generated by verb, please don't edit the readme directly. Any changes to the readme must be made in the .verb.md readme template.) To generate the readme, run the following command: $ npm install -g verbose/verb#dev verb-generate-readme && verb Related projects You might also be interested in these projects: ansi-wrap: Create ansi colors by passing the open and close codes. | homepage strip-color: Strip ANSI color codes from a string. No dependencies. | homepage Contributors Commits Contributor 48 jonschlinkert 42 doowb 6 lukeed 2 Silic0nS0ldier 1 dwieeb 1 jorgebucaran 1 madhavarshney 1 chapterjason Author Brian Woodward GitHub Profile Twitter Profile LinkedIn Profile License Copyright © 2019, Brian Woodward. Released under the MIT License. This file was generated by verb-generate-readme, v0.8.0, on July 01, 2019."
  },
  "node_modules/ansi-regex/readme.html": {
    "href": "node_modules/ansi-regex/readme.html",
    "title": "ansi-regex | accouter",
    "keywords": "ansi-regex Regular expression for matching ANSI escape codes Install $ npm install ansi-regex Usage const ansiRegex = require('ansi-regex'); ansiRegex().test('\\u001B[4mcake\\u001B[0m'); //=> true ansiRegex().test('cake'); //=> false '\\u001B[4mcake\\u001B[0m'.match(ansiRegex()); //=> ['\\u001B[4m', '\\u001B[0m'] '\\u001B[4mcake\\u001B[0m'.match(ansiRegex({onlyFirst: true})); //=> ['\\u001B[4m'] '\\u001B]8;;https://github.com\\u0007click\\u001B]8;;\\u0007'.match(ansiRegex()); //=> ['\\u001B]8;;https://github.com\\u0007', '\\u001B]8;;\\u0007'] API ansiRegex(options?) Returns a regex for matching ANSI escape codes. options Type: object onlyFirst Type: boolean Default: false (Matches any ANSI escape codes in a string) Match only the first ANSI escape. FAQ Why do you test for codes not in the ECMA 48 standard? Some of the codes we run as a test are codes that we acquired finding various lists of non-standard or manufacturer specific codes. We test for both standard and non-standard codes, as most of them follow the same or similar format and can be safely matched in strings without the risk of removing actual string content. There are a few non-standard control codes that do not follow the traditional format (i.e. they end in numbers) thus forcing us to exclude them from the test because we cannot reliably match them. On the historical side, those ECMA standards were established in the early 90's whereas the VT100, for example, was designed in the mid/late 70's. At that point in time, control codes were still pretty ungoverned and engineers used them for a multitude of things, namely to activate hardware ports that may have been proprietary. Somewhere else you see a similar 'anarchy' of codes is in the x86 architecture for processors; there are a ton of \"interrupts\" that can mean different things on certain brands of processors, most of which have been phased out. Maintainers Sindre Sorhus Josh Junon Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "node_modules/ansi-styles/readme.html": {
    "href": "node_modules/ansi-styles/readme.html",
    "title": "ansi-styles | accouter",
    "keywords": "ansi-styles ANSI escape codes for styling strings in the terminal You probably want the higher-level chalk module for styling your strings. Install $ npm install ansi-styles Usage const style = require('ansi-styles'); console.log(`${style.green.open}Hello world!${style.green.close}`); // Color conversion between 16/256/truecolor // NOTE: If conversion goes to 16 colors or 256 colors, the original color // may be degraded to fit that color palette. This means terminals // that do not support 16 million colors will best-match the // original color. console.log(style.bgColor.ansi.hsl(120, 80, 72) + 'Hello world!' + style.bgColor.close); console.log(style.color.ansi256.rgb(199, 20, 250) + 'Hello world!' + style.color.close); console.log(style.color.ansi16m.hex('#abcdef') + 'Hello world!' + style.color.close); API Each style has an open and close property. Styles Modifiers reset bold dim italic (Not widely supported) underline inverse hidden strikethrough (Not widely supported) Colors black red green yellow blue magenta cyan white blackBright (alias: gray, grey) redBright greenBright yellowBright blueBright magentaBright cyanBright whiteBright Background colors bgBlack bgRed bgGreen bgYellow bgBlue bgMagenta bgCyan bgWhite bgBlackBright (alias: bgGray, bgGrey) bgRedBright bgGreenBright bgYellowBright bgBlueBright bgMagentaBright bgCyanBright bgWhiteBright Advanced usage By default, you get a map of styles, but the styles are also available as groups. They are non-enumerable so they don't show up unless you access them explicitly. This makes it easier to expose only a subset in a higher-level module. style.modifier style.color style.bgColor Example console.log(style.color.green.open); Raw escape codes (i.e. without the CSI escape prefix \\u001B[ and render mode postfix m) are available under style.codes, which returns a Map with the open codes as keys and close codes as values. Example console.log(style.codes.get(36)); //=> 39 256 / 16 million (TrueColor) support ansi-styles uses the color-convert package to allow for converting between various colors and ANSI escapes, with support for 256 and 16 million colors. The following color spaces from color-convert are supported: rgb hex keyword hsl hsv hwb ansi ansi256 To use these, call the associated conversion function with the intended output, for example: style.color.ansi.rgb(100, 200, 15); // RGB to 16 color ansi foreground code style.bgColor.ansi.rgb(100, 200, 15); // RGB to 16 color ansi background code style.color.ansi256.hsl(120, 100, 60); // HSL to 256 color ansi foreground code style.bgColor.ansi256.hsl(120, 100, 60); // HSL to 256 color ansi foreground code style.color.ansi16m.hex('#C0FFEE'); // Hex (RGB) to 16 million color foreground code style.bgColor.ansi16m.hex('#C0FFEE'); // Hex (RGB) to 16 million color background code Related ansi-escapes - ANSI escape codes for manipulating the terminal Maintainers Sindre Sorhus Josh Junon For enterprise Available as part of the Tidelift Subscription. The maintainers of ansi-styles and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more."
  },
  "node_modules/anymatch/README.html": {
    "href": "node_modules/anymatch/README.html",
    "title": "anymatch | accouter",
    "keywords": "anymatch Javascript module to match a string against a regular expression, glob, string, or function that takes the string as an argument and returns a truthy or falsy value. The matcher can also be an array of any or all of these. Useful for allowing a very flexible user-defined config to define things like file paths. Note: This module has Bash-parity, please be aware that Windows-style backslashes are not supported as separators. See https://github.com/micromatch/micromatch#backslashes for more information. Usage npm install anymatch anymatch(matchers, testString, [returnIndex], [options]) matchers: (Array|String|RegExp|Function) String to be directly matched, string with glob patterns, regular expression test, function that takes the testString as an argument and returns a truthy value if it should be matched, or an array of any number and mix of these types. testString: (String|Array) The string to test against the matchers. If passed as an array, the first element of the array will be used as the testString for non-function matchers, while the entire array will be applied as the arguments for function matchers. options: (Object [optional]_) Any of the picomatch options. returnIndex: (Boolean [optional]) If true, return the array index of the first matcher that that testString matched, or -1 if no match, instead of a boolean result. const anymatch = require('anymatch'); const matchers = [ 'path/to/file.js', 'path/anyjs/**/*.js', /foo.js$/, string => string.includes('bar') && string.length > 10 ] ; anymatch(matchers, 'path/to/file.js'); // true anymatch(matchers, 'path/anyjs/baz.js'); // true anymatch(matchers, 'path/to/foo.js'); // true anymatch(matchers, 'path/to/bar.js'); // true anymatch(matchers, 'bar.js'); // false // returnIndex = true anymatch(matchers, 'foo.js', {returnIndex: true}); // 2 anymatch(matchers, 'path/anyjs/foo.js', {returnIndex: true}); // 1 // any picomatc // using globs to match directories and their children anymatch('node_modules', 'node_modules'); // true anymatch('node_modules', 'node_modules/somelib/index.js'); // false anymatch('node_modules/**', 'node_modules/somelib/index.js'); // true anymatch('node_modules/**', '/absolute/path/to/node_modules/somelib/index.js'); // false anymatch('**/node_modules/**', '/absolute/path/to/node_modules/somelib/index.js'); // true const matcher = anymatch(matchers); ['foo.js', 'bar.js'].filter(matcher); // [ 'foo.js' ] anymatch master* ❯ anymatch(matchers) You can also pass in only your matcher(s) to get a curried function that has already been bound to the provided matching criteria. This can be used as an Array#filter callback. var matcher = anymatch(matchers); matcher('path/to/file.js'); // true matcher('path/anyjs/baz.js', true); // 1 ['foo.js', 'bar.js'].filter(matcher); // ['foo.js'] Changelog See release notes page on GitHub v3.0: Removed startIndex and endIndex arguments. Node 8.x-only. v2.0: micromatch moves away from minimatch-parity and inline with Bash. This includes handling backslashes differently (see https://github.com/micromatch/micromatch#backslashes for more information). v1.2: anymatch uses micromatch for glob pattern matching. Issues with glob pattern matching should be reported directly to the micromatch issue tracker. License ISC"
  },
  "node_modules/argparse/CHANGELOG.html": {
    "href": "node_modules/argparse/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog, and this project adheres to Semantic Versioning. 2.0.1 - 2020-08-29 Fixed Fix issue with process.argv when used with interpreters (coffee, ts-node, etc.), #150. 2.0.0 - 2020-08-14 Changed Full rewrite. Now port from python 3.9.0 & more precise following. See doc for difference and migration info. node.js 10+ required Removed most of local docs in favour of original ones. 1.0.10 - 2018-02-15 Fixed Use .concat instead of + for arrays, #122. 1.0.9 - 2016-09-29 Changed Rerelease after 1.0.8 - deps cleanup. 1.0.8 - 2016-09-29 Changed Maintenance (deps bump, fix node 6.5+ tests, coverage report). 1.0.7 - 2016-03-17 Changed Teach addArgument to accept string arg names. #97, @tomxtobin. 1.0.6 - 2016-02-06 Changed Maintenance: moved to eslint & updated CS. 1.0.5 - 2016-02-05 Changed Removed lodash dependency to significantly reduce install size. Thanks to @mourner. 1.0.4 - 2016-01-17 Changed Maintenance: lodash update to 4.0.0. 1.0.3 - 2015-10-27 Fixed Fix parse = in args: --examplepath=\"C:\\myfolder\\env=x64\". #84, @CatWithApple. 1.0.2 - 2015-03-22 Changed Relaxed lodash version dependency. 1.0.1 - 2015-02-20 Changed Changed dependencies to be compatible with ancient nodejs. 1.0.0 - 2015-02-19 Changed Maintenance release. Replaced underscore with lodash. Bumped version to 1.0.0 to better reflect semver meaning. HISTORY.md -> CHANGELOG.md 0.1.16 - 2013-12-01 Changed Maintenance release. Updated dependencies and docs. 0.1.15 - 2013-05-13 Fixed Fixed #55, @trebor89 0.1.14 - 2013-05-12 Fixed Fixed #62, @maxtaco 0.1.13 - 2013-04-08 Changed Added .npmignore to reduce package size 0.1.12 - 2013-02-10 Fixed Fixed conflictHandler (#46), @hpaulj 0.1.11 - 2013-02-07 Added Added 70+ tests (ported from python), @hpaulj Added conflictHandler, @applepicke Added fromfilePrefixChar, @hpaulj Fixed Multiple bugfixes, @hpaulj 0.1.10 - 2012-12-30 Added Added mutual exclusion support, thanks to @hpaulj Fixed Fixed options check for storeConst & appendConst actions, thanks to @hpaulj 0.1.9 - 2012-12-27 Fixed Fixed option dest interferens with other options (issue #23), thanks to @hpaulj Fixed default value behavior with * positionals, thanks to @hpaulj Improve getDefault() behavior, thanks to @hpaulj Improve negative argument parsing, thanks to @hpaulj 0.1.8 - 2012-12-01 Fixed Fixed parser parents (issue #19), thanks to @hpaulj Fixed negative argument parse (issue #20), thanks to @hpaulj 0.1.7 - 2012-10-14 Fixed Fixed 'choices' argument parse (issue #16) Fixed stderr output (issue #15) 0.1.6 - 2012-09-09 Fixed Fixed check for conflict of options (thanks to @tomxtobin) 0.1.5 - 2012-09-03 Fixed Fix parser #setDefaults method (thanks to @tomxtobin) 0.1.4 - 2012-07-30 Fixed Fixed pseudo-argument support (thanks to @CGamesPlay) Fixed addHelp default (should be true), if not set (thanks to @benblank) 0.1.3 - 2012-06-27 Fixed Fixed formatter api name: Formatter -> HelpFormatter 0.1.2 - 2012-05-29 Fixed Removed excess whitespace in help Fixed error reporting, when parcer with subcommands called with empty arguments Added Added basic tests 0.1.1 - 2012-05-23 Fixed Fixed line wrapping in help formatter Added better error reporting on invalid arguments 0.1.0 - 2012-05-16 Added First release."
  },
  "node_modules/argparse/README.html": {
    "href": "node_modules/argparse/README.html",
    "title": "argparse | accouter",
    "keywords": "argparse CLI arguments parser for node.js, with sub-commands support. Port of python's argparse (version 3.9.0). Difference with original. JS has no keyword arguments support. Pass options instead: new ArgumentParser({ description: 'example', add_help: true }). JS has no python's types int, float, ... Use string-typed names: .add_argument('-b', { type: 'int', help: 'help' }). %r format specifier uses require('util').inspect(). More details in doc. Example test.js file: #!/usr/bin/env node 'use strict'; const { ArgumentParser } = require('argparse'); const { version } = require('./package.json'); const parser = new ArgumentParser({ description: 'Argparse example' }); parser.add_argument('-v', '--version', { action: 'version', version }); parser.add_argument('-f', '--foo', { help: 'foo bar' }); parser.add_argument('-b', '--bar', { help: 'bar foo' }); parser.add_argument('--baz', { help: 'baz bar' }); console.dir(parser.parse_args()); Display help: $ ./test.js -h usage: test.js [-h] [-v] [-f FOO] [-b BAR] [--baz BAZ] Argparse example optional arguments: -h, --help show this help message and exit -v, --version show program's version number and exit -f FOO, --foo FOO foo bar -b BAR, --bar BAR bar foo --baz BAZ baz bar Parse arguments: $ ./test.js -f=3 --bar=4 --baz 5 { foo: '3', bar: '4', baz: '5' } API docs Since this is a port with minimal divergence, there's no separate documentation. Use original one instead, with notes about difference. Original doc. Original tutorial. Difference with python. argparse for enterprise Available as part of the Tidelift Subscription The maintainers of argparse and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more."
  },
  "node_modules/array-buffer-byte-length/CHANGELOG.html": {
    "href": "node_modules/array-buffer-byte-length/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.1 - 2024-02-03 Commits [patch] add types 598d446 [Dev Deps] update @ljharb/eslint-config, aud, npmignore, object-inspect, tape 2572345 [Tests] add coverage d27357d [Deps] update call-bind, is-array-buffer 2ea13ad [meta] add missing engines.node 380e96d [Deps] update is-array-buffer cfa7093 [meta] add sideEffects flag 7297ddd v1.0.0 - 2023-02-28 Commits Initial implementation, tests, readme 2db6cad Initial commit b2a0c9c npm init 376acdb Only apps should have lockfiles 70cf325"
  },
  "node_modules/array-buffer-byte-length/README.html": {
    "href": "node_modules/array-buffer-byte-length/README.html",
    "title": "array-buffer-byte-length | accouter",
    "keywords": "array-buffer-byte-length Get the byte length of an ArrayBuffer, even in engines without a .byteLength method. Example const assert = require('assert'); const byteLength = require('array-buffer-byte-length'); assert.equal(byteLength([]), NaN, 'an array is not an ArrayBuffer, yields NaN'); assert.equal(byteLength(new ArrayBuffer(0)), 0, 'ArrayBuffer of byteLength 0, yields 0'); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/arraybuffer.prototype.slice/CHANGELOG.html": {
    "href": "node_modules/arraybuffer.prototype.slice/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.3 - 2024-02-04 Commits [Deps] update array-buffer-byte-length, call-bind, define-properties, es-abstract, get-intrinsic, is-array-buffer d9b6859 [Dev Deps] update aud, npmignore, object-inspect, tape 38cb58d [Refactor] use es-errors where possible, so things that only need those do not need get-intrinsic 5c07bef v1.0.2 - 2023-09-05 Commits [Deps] update es-abstract a9ab0d2 [Dev Deps] update tape 6b24af5 [Fix] move es-abstract to runtime deps 63a8397 v1.0.1 - 2023-07-11 Commits [Fix] node < 0.11 has an own nonconfigurable slice property; use it 554823c [Dev Deps] update @es-shims/api, @ljharb/eslint-config, aud, es-abstract, tape 53b0421 [Deps] update define-properties, get-intrinsic 4966b02 v1.0.0 - 2023-07-09 Commits Initial implementation, tests, readme 36b4b5e Initial commit 51499df npm init 8ec604e Only apps should have lockfiles ac54435"
  },
  "node_modules/arraybuffer.prototype.slice/README.html": {
    "href": "node_modules/arraybuffer.prototype.slice/README.html",
    "title": "ArrayBuffer.prototype.slice | accouter",
    "keywords": "ArrayBuffer.prototype.slice An ES spec-compliant ArrayBuffer.prototype.slice shim. Invoke its \"shim\" method to shim ArrayBuffer.prototype.slice if it is unavailable. This package implements the es-shim API interface. It works in an ES5-supported environment and complies with the spec. Most common usage: var assert = require('assert'); var slice = require('arraybuffer.prototype.slice'); var ab = new ArrayBuffer(1); var arr = new Uint8Array(ab); arr[0] = 123; var ab2 = slice(ab); var arr2 = new Uint8Array(ab2); arr2[0] = 234; assert.deepEqual(arr, new Uint8Array([123])); assert.deepEqual(arr2, new Uint8Array([234])); if (!ArrayBuffer.prototype.transfer) { slice.shim(); } var ab2 = ab.slice(); var arr2 = new Uint8Array(ab2); arr2[0] = 234; assert.deepEqual(arr, new Uint8Array([123])); assert.deepEqual(arr2, new Uint8Array([234])); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/arrify/readme.html": {
    "href": "node_modules/arrify/readme.html",
    "title": "arrify | accouter",
    "keywords": "arrify Convert a value to an array Install $ npm install arrify Usage import arrify from 'arrify'; arrify('🦄'); //=> ['🦄'] arrify(['🦄']); //=> ['🦄'] arrify(new Set(['🦄'])); //=> ['🦄'] arrify(null); //=> [] arrify(undefined); //=> [] Specifying null or undefined results in an empty array. Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "node_modules/async-each-series/Readme.html": {
    "href": "node_modules/async-each-series/Readme.html",
    "title": "async-each-series | accouter",
    "keywords": "async-each-series Apply an async function to each Array element in series Installation Install with npm: $ npm install async-each-series Install with component(1): $ component install jb55/async-each-series Examples Node.js var each = require('async-each-series'); each(['foo','bar','baz'], function(el, next) { setTimeout(function () { console.log(el); next(); }, Math.random() * 5000); }, function (err) { console.log('finished'); }); //=> foo //=> bar //=> baz //=> finished API eachSeries(array, iterator(elem, cb(err, elem)), finishedCb(err)) License The MIT License (MIT) Copyright (c) 2014 William Casarin Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/async/CHANGELOG.html": {
    "href": "node_modules/async/CHANGELOG.html",
    "title": "v2.6.4 | accouter",
    "keywords": "v2.6.4 Fix potential prototype pollution exploit (#1828) v2.6.3 Updated lodash to squelch a security warning (#1675) v2.6.2 Updated lodash to squelch a security warning (#1620) v2.6.1 Updated lodash to prevent npm audit warnings. (#1532, #1533) Made async-es more optimized for webpack users (#1517) Fixed a stack overflow with large collections and a synchronous iterator (#1514) Various small fixes/chores (#1505, #1511, #1527, #1530) v2.6.0 Added missing aliases for many methods. Previously, you could not (e.g.) require('async/find') or use async.anyLimit. (#1483) Improved queue performance. (#1448, #1454) Add missing sourcemap (#1452, #1453) Various doc updates (#1448, #1471, #1483) v2.5.0 Added concatLimit, the Limit equivalent of concat (#1426, #1430) concat improvements: it now preserves order, handles falsy values and the iteratee callback takes a variable number of arguments (#1437, #1436) Fixed an issue in queue where there was a size discrepancy between workersList().length and running() (#1428, #1429) Various doc fixes (#1422, #1424) v2.4.1 Fixed a bug preventing functions wrapped with timeout() from being re-used. (#1418, #1419) v2.4.0 Added tryEach, for running async functions in parallel, where you only expect one to succeed. (#1365, #687) Improved performance, most notably in parallel and waterfall (#1395) Added queue.remove(), for removing items in a queue (#1397, #1391) Fixed using eval, preventing Async from running in pages with Content Security Policy (#1404, #1403) Fixed errors thrown in an asyncifyed function's callback being caught by the underlying Promise (#1408) Fixed timing of queue.empty() (#1367) Various doc fixes (#1314, #1394, #1412) v2.3.0 Added support for ES2017 async functions. Wherever you can pass a Node-style/CPS function that uses a callback, you can also pass an async function. Previously, you had to wrap async functions with asyncify. The caveat is that it will only work if async functions are supported natively in your environment, transpiled implementations can't be detected. (#1386, #1390) Small doc fix (#1392) v2.2.0 Added groupBy, and the Series/Limit equivalents, analogous to _.groupBy (#1364) Fixed transform bug when callback was not passed (#1381) Added note about reflect to parallel docs (#1385) v2.1.5 Fix auto bug when function names collided with Array.prototype (#1358) Improve some error messages (#1349) Avoid stack overflow case in queue Fixed an issue in some, every and find where processing would continue after the result was determined. Cleanup implementations of some, every and find v2.1.3 Make bundle size smaller Create optimized hotpath for filter in array case. v2.1.2 Fixed a stackoverflow bug with detect, some, every on large inputs (#1293). v2.1.0 retry and retryable now support an optional errorFilter function that determines if the task should retry on the error (#1256, #1261) Optimized array iteration in race, cargo, queue, and priorityQueue (#1253) Added alias documentation to doc site (#1251, #1254) Added BootStrap scrollspy to docs to highlight in the sidebar the current method being viewed (#1289, #1300) Various minor doc fixes (#1263, #1264, #1271, #1278, #1280, #1282, #1302) v2.0.1 Significantly optimized all iteration based collection methods such as each, map, filter, etc (#1245, #1246, #1247). v2.0.0 Lots of changes here! First and foremost, we have a slick new site for docs. Special thanks to **@hargasinski** for his work converting our old docs to jsdoc format and implementing the new website. Also huge ups to **@ivanseidel** for designing our new logo. It was a long process for both of these tasks, but I think these changes turned out extraordinary well. The biggest feature is modularization. You can now require(\"async/series\") to only require the series function. Every Async library function is available this way. You still can require(\"async\") to require the entire library, like you could do before. We also provide Async as a collection of ES2015 modules. You can now import {each} from 'async-es' or import waterfall from 'async-es/waterfall'. If you are using only a few Async functions, and are using a ES bundler such as Rollup, this can significantly lower your build size. Major thanks to **@Kikobeats**, **@aearly** and **@megawac** for doing the majority of the modularization work, as well as **@jdalton** and **@Rich-Harris** for advisory work on the general modularization strategy. Another one of the general themes of the 2.0 release is standardization of what an \"async\" function is. We are now more strictly following the node-style continuation passing style. That is, an async function is a function that: Takes a variable number of arguments The last argument is always a callback The callback can accept any number of arguments The first argument passed to the callback will be treated as an error result, if the argument is truthy Any number of result arguments can be passed after the \"error\" argument The callback is called once and exactly once, either on the same tick or later tick of the JavaScript event loop. There were several cases where Async accepted some functions that did not strictly have these properties, most notably auto, every, some, filter, reject and detect. Another theme is performance. We have eliminated internal deferrals in all cases where they make sense. For example, in waterfall and auto, there was a setImmediate between each task -- these deferrals have been removed. A setImmediate call can add up to 1ms of delay. This might not seem like a lot, but it can add up if you are using many Async functions in the course of processing a HTTP request, for example. Nearly all asynchronous functions that do I/O already have some sort of deferral built in, so the extra deferral is unnecessary. The trade-off of this change is removing our built-in stack-overflow defense. Many synchronous callback calls in series can quickly overflow the JS call stack. If you do have a function that is sometimes synchronous (calling its callback on the same tick), and are running into stack overflows, wrap it with async.ensureAsync(). Another big performance win has been re-implementing queue, cargo, and priorityQueue with doubly linked lists instead of arrays. This has lead to queues being an order of magnitude faster on large sets of tasks. New Features Async is now modularized. Individual functions can be require()d from the main package. (require('async/auto')) (#984, #996) Async is also available as a collection of ES2015 modules in the new async-es package. (import {forEachSeries} from 'async-es') (#984, #996) Added race, analogous to Promise.race(). It will run an array of async tasks in parallel and will call its callback with the result of the first task to respond. (#568, #1038) Collection methods now accept ES2015 iterators. Maps, Sets, and anything that implements the iterator spec can now be passed directly to each, map, parallel, etc.. (#579, #839, #1074) Added mapValues, for mapping over the properties of an object and returning an object with the same keys. (#1157, #1177) Added timeout, a wrapper for an async function that will make the task time-out after the specified time. (#1007, #1027) Added reflect and reflectAll, analagous to Promise.reflect(), a wrapper for async tasks that always succeeds, by gathering results and errors into an object. (#942, #1012, #1095) constant supports dynamic arguments -- it will now always use its last argument as the callback. (#1016, #1052) setImmediate and nextTick now support arguments to partially apply to the deferred function, like the node-native versions do. (#940, #1053) auto now supports resolving cyclic dependencies using Kahn's algorithm (#1140). Added autoInject, a relative of auto that automatically spreads a task's dependencies as arguments to the task function. (#608, #1055, #1099, #1100) You can now limit the concurrency of auto tasks. (#635, #637) Added retryable, a relative of retry that wraps an async function, making it retry when called. (#1058) retry now supports specifying a function that determines the next time interval, useful for exponential backoff, logging and other retry strategies. (#1161) retry will now pass all of the arguments the task function was resolved with to the callback (#1231). Added q.unsaturated -- callback called when a queue's number of running workers falls below a threshold. (#868, #1030, #1033, #1034) Added q.error -- a callback called whenever a queue task calls its callback with an error. (#1170) applyEach and applyEachSeries now pass results to the final callback. (#1088) Breaking changes Calling a callback more than once is considered an error, and an error will be thrown. This had an explicit breaking change in waterfall. If you were relying on this behavior, you should more accurately represent your control flow as an event emitter or stream. (#814, #815, #1048, #1050) auto task functions now always take the callback as the last argument. If a task has dependencies, the results object will be passed as the first argument. To migrate old task functions, wrap them with _.flip (#1036, #1042) Internal setImmediate calls have been refactored away. This may make existing flows vulnerable to stack overflows if you use many synchronous functions in series. Use ensureAsync to work around this. (#696, #704, #1049, #1050) map used to return an object when iterating over an object. map now always returns an array, like in other libraries. The previous object behavior has been split out into mapValues. (#1157, #1177) filter, reject, some, every, detect and their families like {METHOD}Series and {METHOD}Limit now expect an error as the first callback argument, rather than just a simple boolean. Pass null as the first argument, or use fs.access instead of fs.exists. (#118, #774, #1028, #1041) {METHOD} and {METHOD}Series are now implemented in terms of {METHOD}Limit. This is a major internal simplification, and is not expected to cause many problems, but it does subtly affect how functions execute internally. (#778, #847) retry's callback is now optional. Previously, omitting the callback would partially apply the function, meaning it could be passed directly as a task to series or auto. The partially applied \"control-flow\" behavior has been separated out into retryable. (#1054, #1058) The test function for whilst, until, and during used to be passed non-error args from the iteratee function's callback, but this led to weirdness where the first call of the test function would be passed no args. We have made it so the test function is never passed extra arguments, and only the doWhilst, doUntil, and doDuring functions pass iteratee callback arguments to the test function (#1217, #1224) The q.tasks array has been renamed q._tasks and is now implemented as a doubly linked list (DLL). Any code that used to interact with this array will need to be updated to either use the provided helpers or support DLLs (#1205). The timing of the q.saturated() callback in a queue has been modified to better reflect when tasks pushed to the queue will start queueing. (#724, #1078) Removed iterator method in favour of ES2015 iterator protocol which natively supports arrays (#1237) Dropped support for Component, Jam, SPM, and Volo (#1175, ##176) Bug Fixes Improved handling of no dependency cases in auto & autoInject (#1147). Fixed a bug where the callback generated by asyncify with Promises could resolve twice (#1197). Fixed several documented optional callbacks not actually being optional (#1223). Other Added someSeries and everySeries for symmetry, as well as a complete set of any/anyLimit/anySeries and all//allLmit/allSeries aliases. Added find as an alias for detect. (as well as findLimitandfindSeries`). Various doc fixes (#1005, #1008, #1010, #1015, #1021, #1037, #1039, #1051, #1102, #1107, #1121, #1123, #1129, #1135, #1138, #1141, #1153, #1216, #1217, #1232, #1233, #1236, #1238) Thank you **@aearly** and **@megawac** for taking the lead on version 2 of async. v1.5.2 Allow using \"constructor\" as an argument in memoize (#998) Give a better error messsage when auto dependency checking fails (#994) Various doc updates (#936, #956, #979, #1002) v1.5.1 Fix issue with pause in queue with concurrency enabled (#946) while and until now pass the final result to callback (#963) auto will properly handle concurrency when there is no callback (#966) auto will no. properly stop execution when an error occurs (#988, #993) Various doc fixes (#971, #980) v1.5.0 Added transform, analogous to _.transform (#892) map now returns an object when an object is passed in, rather than array with non-numeric keys. map will begin always returning an array with numeric indexes in the next major release. (#873) auto now accepts an optional concurrency argument to limit the number o. running tasks (#637) Added queue#workersList(), to retrieve the lis. of currently running tasks. (#891) Various code simplifications (#896, #904) Various doc fixes 📜 (#890, #894, #903, #905, #912) v1.4.2 Ensure coverage files don't get published on npm (#879) v1.4.1 Add in overlooked detectLimit method (#866) Removed unnecessary files from npm releases (#861) Removed usage of a reserved word to prevent 💥 in older environments (#870) v1.4.0 asyncify now supports promises (#840) Added Limit versions of filter and reject (#836) Add Limit versions of detect, some and every (#828, #829) some, every and detect now short circuit early (#828, #829) Improve detection of the global object (#804), enabling use in WebWorkers whilst now called with arguments from iterator (#823) during now gets called with arguments from iterator (#824) Code simplifications and optimizations aplenty (diff) v1.3.0 New Features: Added constant Added asyncify/wrapSync for making sync functions work with callbacks. (#671, #806) Added during and doDuring, which are like whilst with an async truth test. (#800) retry now accepts an interval parameter to specify a delay between retries. (#793) async should work better in Web Workers due to better root detection (#804) Callbacks are now optional in whilst, doWhilst, until, and doUntil (#642) Various internal updates (#786, #801, #802, #803) Various doc fixes (#790, #794) Bug Fixes: cargo now exposes the payload size, and cargo.payload can be changed on the fly after the cargo is created. (#740, #744, #783) v1.2.1 Bug Fix: Small regression with synchronous iterator behavior in eachSeries with a 1-element array. Before 1.1.0, eachSeries's callback was called on the same tick, which this patch restores. In 2.0.0, it will be called on the next tick. (#782) v1.2.0 New Features: Added timesLimit (#743) concurrency can be changed after initialization in queue by setting q.concurrency. The new concurrency will be reflected the next time a task is processed. (#747, #772) Bug Fixes: Fixed a regression in each and family with empty arrays that have additional properties. (#775, #777) v1.1.1 Bug Fix: Small regression with synchronous iterator behavior in eachSeries with a 1-element array. Before 1.1.0, eachSeries's callback was called on the same tick, which this patch restores. In 2.0.0, it will be called on the next tick. (#782) v1.1.0 New Features: cargo now supports all of the same methods and event callbacks as queue. Added ensureAsync - A wrapper that ensures an async function calls its callback on a later tick. (#769) Optimized map, eachOf, and waterfall families of functions Passing a null or undefined array to map, each, parallel and families will be treated as an empty array (#667). The callback is now optional for the composed results of compose and seq. (#618) Reduced file size by 4kb, (minified version by 1kb) Added code coverage through nyc and coveralls (#768) Bug Fixes: forever will no longer stack overflow with a synchronous iterator (#622) eachLimit and other limit functions will stop iterating once an error occurs (#754) Always pass null in callbacks when there is no error (#439) Ensure proper conditions when calling drain() after pushing an empty data set to a queue (#668) each and family will properly handle an empty array (#578) eachSeries and family will finish if the underlying array is modified during execution (#557) queue will throw if a non-function is passed to q.push() (#593) Doc fixes (#629, #766) v1.0.0 No known breaking changes, we are simply complying with semver from here on out. Changes: Start using a changelog! Add forEachOf for iterating over Objects (or to iterate Arrays with indexes available) (#168 #704 #321) Detect deadlocks in auto (#663) Better support for require.js (#527) Throw if queue created with concurrency 0 (#714) Fix unneeded iteration in queue.resume() (#758) Guard against timer mocking overriding setImmediate (#609 #611) Miscellaneous doc fixes (#542 #596 #615 #628 #631 #690 #729) Use single noop function internally (#546) Optimize internal _each, _map and _keys functions."
  },
  "node_modules/async/README.html": {
    "href": "node_modules/async/README.html",
    "title": "| accouter",
    "keywords": "Async is a utility module which provides straight-forward, powerful functions for working with asynchronous JavaScript. Although originally designed for use with Node.js and installable via npm install --save async, it can also be used directly in the browser. This version of the package is optimized for the Node.js environment. If you use Async with webpack, install async-es instead. For Documentation, visit https://caolan.github.io/async/ For Async v1.5.x documentation, go HERE // for use with Node-style callbacks... var async = require(\"async\"); var obj = {dev: \"/dev.json\", test: \"/test.json\", prod: \"/prod.json\"}; var configs = {}; async.forEachOf(obj, (value, key, callback) => { fs.readFile(__dirname + value, \"utf8\", (err, data) => { if (err) return callback(err); try { configs[key] = JSON.parse(data); } catch (e) { return callback(e); } callback(); }); }, err => { if (err) console.error(err.message); // configs is now a map of JSON data doSomethingWith(configs); }); var async = require(\"async\"); // ...or ES2017 async functions async.mapLimit(urls, 5, async function(url) { const response = await fetch(url) return response.body }, (err, results) => { if (err) throw err // results is now an array of the response bodies console.log(results) })"
  },
  "node_modules/available-typed-arrays/CHANGELOG.html": {
    "href": "node_modules/available-typed-arrays/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.7 - 2024-02-19 Commits [Refactor] use possible-typed-array-names ac86abf v1.0.6 - 2024-01-31 Commits [actions] reuse common workflows 1850353 [meta] use npmignore to autogenerate an npmignore file 5c7de12 [patch] add types fcfb0ea [actions] update codecov uploader d844945 [Dev Deps] update eslint, @ljharb/eslint-config, array.prototype.every, safe-publish-latest, tape a2be6f4 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape b283a3e [actions] update rebase action to use reusable workflow 0ad1f2d [Dev Deps] update @ljharb/eslint-config, array.prototype.every, aud, tape cd36e81 [meta] simplify \"exports\" f696e5f [Dev Deps] update aud, npmignore, tape bf20080 v1.0.5 - 2021-08-30 Fixed [Refactor] use globalThis if available #12 Commits [Dev Deps] update eslint, @ljharb/eslint-config, tape 1199790 v1.0.4 - 2021-05-25 Commits [Refactor] Remove array.prototype.filter dependency f39c90e [Dev Deps] update eslint, auto-changelog b2e3a03 [meta] create FUNDING.yml 8c0e758 [Tests] fix harmony test matrix ef96549 [meta] add sideEffects flag 288cca0 v1.0.3 - 2021-05-19 Commits [Tests] migrate tests to Github Actions 3ef082c [meta] do not publish github action workflow files fd95ffd [actions] use node/install instead of node/run; use codecov action eb6bd65 [Tests] run nyc on all tests 636c946 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape 70a3b61 [actions] add \"Allow Edits\" workflow bd09c45 [Dev Deps] update eslint, @ljharb/eslint-config, array.prototype.every, aud, tape 8f97523 [readme] fix URLs 75418e2 [readme] add actions and codecov badges 4a8bc30 [Dev Deps] update eslint, @ljharb/eslint-config, aud 65198ac [actions] update workflows 7f816eb [Refactor] use array.prototype.filter instead of array-filter 2dd1038 [actions] switch Automatic Rease workflow to pull_request_target event 9b45e91 [Dev Deps] update auto-changelog, tape 0003a5b [meta] use prepublishOnly script for npm 7+ d884dd1 [readme] remove travis badge 9da2b3c [Dev Deps] update auto-changelog; add aud 41b1336 [Tests] only audit prod deps 2571826 v1.0.2 - 2020-01-26 Commits [actions] add automatic rebasing / merge commit blocking 3229a74 [Dev Deps] update @ljharb/eslint-config 9579abe [Fix] remove require condition to avoid experimental warning 2cade6b v1.0.1 - 2020-01-24 Commits [meta] add \"exports\" 5942917 v1.0.0 - 2020-01-24 Commits Initial commit 2bc5144 readme 31e4796 npm init 9194266 Tests b539830 Implementation 6577df2 [meta] add auto-changelog 7b43310 [Tests] add npm run lint dedfbc1 [Tests] use shared travis-ci configs c459d78 Only apps should have lockfiles d294668 [meta] add funding field 6e70bc1 [meta] add safe-publish-latest dd89ca2"
  },
  "node_modules/available-typed-arrays/README.html": {
    "href": "node_modules/available-typed-arrays/README.html",
    "title": "available-typed-arrays | accouter",
    "keywords": "available-typed-arrays Returns an array of Typed Array names that are available in the current environment. Example var availableTypedArrays = require('available-typed-arrays'); var assert = require('assert'); assert.deepStrictEqual( availableTypedArrays().sort(), [ 'Int8Array', 'Uint8Array', 'Uint8ClampedArray', 'Int16Array', 'Uint16Array', 'Int32Array', 'Uint32Array', 'Float32Array', 'Float64Array', 'BigInt64Array', 'BigUint64Array' ].sort() ); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/balanced-match/LICENSE.html": {
    "href": "node_modules/balanced-match/LICENSE.html",
    "title": "| accouter",
    "keywords": "(MIT) Copyright (c) 2013 Julian Gruber <julian@juliangruber.com&gt; Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/balanced-match/README.html": {
    "href": "node_modules/balanced-match/README.html",
    "title": "balanced-match | accouter",
    "keywords": "balanced-match Match balanced string pairs, like { and } or <b> and </b>. Supports regular expressions as well! Example Get the first matching pair of braces: var balanced = require('balanced-match'); console.log(balanced('{', '}', 'pre{in{nested}}post')); console.log(balanced('{', '}', 'pre{first}between{second}post')); console.log(balanced(/\\s+\\{\\s+/, /\\s+\\}\\s+/, 'pre { in{nest} } post')); The matches are: $ node example.js { start: 3, end: 14, pre: 'pre', body: 'in{nested}', post: 'post' } { start: 3, end: 9, pre: 'pre', body: 'first', post: 'between{second}post' } { start: 3, end: 17, pre: 'pre', body: 'in{nest}', post: 'post' } API var m = balanced(a, b, str) For the first non-nested matching pair of a and b in str, return an object with those keys: start the index of the first match of a end the index of the matching b pre the preamble, a and b not included body the match, a and b not included post the postscript, a and b not included If there's no match, undefined will be returned. If the str contains more a than b / there are unmatched pairs, the first match that was closed will be used. For example, {{a} will match ['{', 'a', ''] and {a}} will match ['', 'a', '}']. var r = balanced.range(a, b, str) For the first non-nested matching pair of a and b in str, return an array with indexes: [ <a index>, <b index> ]. If there's no match, undefined will be returned. If the str contains more a than b / there are unmatched pairs, the first match that was closed will be used. For example, {{a} will match [ 1, 3 ] and {a}} will match [0, 2]. Installation With npm do: npm install balanced-match Security contact information To report a security vulnerability, please use the Tidelift security contact. Tidelift will coordinate the fix and disclosure. License (MIT) Copyright (c) 2013 Julian Gruber <julian@juliangruber.com&gt; Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/base64id/CHANGELOG.html": {
    "href": "node_modules/base64id/CHANGELOG.html",
    "title": "2.0.0 (2019-05-27) | accouter",
    "keywords": "2.0.0 (2019-05-27) Code Refactoring buffer: replace deprecated Buffer constructor usage (#11) (ccfba54) BREAKING CHANGES buffer: drop support for Node.js ≤ 4.4.x and 5.0.0 - 5.9.x See: https://nodejs.org/en/docs/guides/buffer-constructor-deprecation/"
  },
  "node_modules/base64id/README.html": {
    "href": "node_modules/base64id/README.html",
    "title": "base64id | accouter",
    "keywords": "base64id Node.js module that generates a base64 id. Uses crypto.randomBytes when available, falls back to unsafe methods for node.js <= 0.4. To increase performance, random bytes are buffered to minimize the number of synchronous calls to crypto.randomBytes. Installation $ npm install base64id Usage var base64id = require('base64id'); var id = base64id.generateId();"
  },
  "node_modules/batch/History.html": {
    "href": "node_modules/batch/History.html",
    "title": "0.6.1 / 2017-05-16 | accouter",
    "keywords": "0.6.1 / 2017-05-16 fix process.nextTick detection in Node.js 0.6.0 / 2017-03-25 always invoke end callback asynchronously fix compatibility with component v1 fix license field 0.5.3 / 2015-10-01 fix for browserify 0.5.2 / 2014-12-22 add brower field add license to package.json 0.5.1 / 2014-06-19 add repository field to readme (exciting) 0.5.0 / 2013-07-29 add .throws(true) to opt-in to responding with an array of error objects make new optional 0.4.0 / 2013-06-05 add catching of immediate callback errors 0.3.2 / 2013-03-15 remove Emitter call in constructor 0.3.1 / 2013-03-13 add Emitter() mixin for client. Closes #8 0.3.0 / 2013-03-13 add component.json add result example add .concurrency support add concurrency example add parallel example 0.2.1 / 2012-11-08 add .start, .end, and .duration properties change dependencies to devDependencies 0.2.0 / 2012-10-04 add progress events. Closes #5 (BREAKING CHANGE) 0.1.1 / 2012-07-03 change \"complete\" event to \"progress\" 0.1.0 / 2012-07-03 add Emitter inheritance and emit \"complete\" [burcu] 0.0.3 / 2012-06-02 Callback results should be in the order of the queued functions. 0.0.2 / 2012-02-12 any node 0.0.1 / 2010-01-03 Initial release"
  },
  "node_modules/batch/Readme.html": {
    "href": "node_modules/batch/Readme.html",
    "title": "batch | accouter",
    "keywords": "batch Simple async batch with concurrency control and progress reporting. Installation $ npm install batch API var Batch = require('batch') , batch = new Batch; batch.concurrency(4); ids.forEach(function(id){ batch.push(function(done){ User.get(id, done); }); }); batch.on('progress', function(e){ }); batch.end(function(err, users){ }); Progress events Contain the \"job\" index, response value, duration information, and completion data. { index: 1, value: 'bar', pending: 2, total: 3, complete: 2, percent: 66, start: Thu Oct 04 2012 12:25:53 GMT-0700 (PDT), end: Thu Oct 04 2012 12:25:53 GMT-0700 (PDT), duration: 0 } License MIT"
  },
  "node_modules/binary-extensions/readme.html": {
    "href": "node_modules/binary-extensions/readme.html",
    "title": "binary-extensions | accouter",
    "keywords": "binary-extensions List of binary file extensions The list is just a JSON file and can be used anywhere. Install npm install binary-extensions Usage const binaryExtensions = require('binary-extensions'); console.log(binaryExtensions); //=> ['3ds', '3g2', …] Related is-binary-path - Check if a filepath is a binary file text-extensions - List of text file extensions"
  },
  "node_modules/boolbase/README.html": {
    "href": "node_modules/boolbase/README.html",
    "title": "| accouter",
    "keywords": "#boolbase This very simple module provides two basic functions, one that always returns true (trueFunc) and one that always returns false (falseFunc). ###WTF? By having only a single instance of these functions around, it's possible to do some nice optimizations. Eg. CSSselect uses these functions to determine whether a selector won't match any elements. If that's the case, the DOM doesn't even have to be touched. ###And why is this a separate module? I'm trying to modularize CSSselect and most modules depend on these functions. IMHO, having a separate module is the easiest solution to this problem."
  },
  "node_modules/brace-expansion/README.html": {
    "href": "node_modules/brace-expansion/README.html",
    "title": "brace-expansion | accouter",
    "keywords": "brace-expansion Brace expansion, as known from sh/bash, in JavaScript. Example var expand = require('brace-expansion'); expand('file-{a,b,c}.jpg') // => ['file-a.jpg', 'file-b.jpg', 'file-c.jpg'] expand('-v{,,}') // => ['-v', '-v', '-v'] expand('file{0..2}.jpg') // => ['file0.jpg', 'file1.jpg', 'file2.jpg'] expand('file-{a..c}.jpg') // => ['file-a.jpg', 'file-b.jpg', 'file-c.jpg'] expand('file{2..0}.jpg') // => ['file2.jpg', 'file1.jpg', 'file0.jpg'] expand('file{0..4..2}.jpg') // => ['file0.jpg', 'file2.jpg', 'file4.jpg'] expand('file-{a..e..2}.jpg') // => ['file-a.jpg', 'file-c.jpg', 'file-e.jpg'] expand('file{00..10..5}.jpg') // => ['file00.jpg', 'file05.jpg', 'file10.jpg'] expand('{{A..C},{a..c}}') // => ['A', 'B', 'C', 'a', 'b', 'c'] expand('ppp{,config,oe{,conf}}') // => ['ppp', 'pppconfig', 'pppoe', 'pppoeconf'] API var expand = require('brace-expansion'); var expanded = expand(str) Return an array of all possible and valid expansions of str. If none are found, [str] is returned. Valid expansions are: /^(.*,)+(.+)?$/ // {a,b,...} A comma separated list of options, like {a,b} or {a,{b,c}} or {,a,}. /^-?\\d+\\.\\.-?\\d+(\\.\\.-?\\d+)?$/ // {x..y[..incr]} A numeric sequence from x to y inclusive, with optional increment. If x or y start with a leading 0, all the numbers will be padded to have equal length. Negative numbers and backwards iteration work too. /^-?\\d+\\.\\.-?\\d+(\\.\\.-?\\d+)?$/ // {x..y[..incr]} An alphabetic sequence from x to y inclusive, with optional increment. x and y must be exactly one character, and if given, incr must be a number. For compatibility reasons, the string ${ is not eligible for brace expansion. Installation With npm do: npm install brace-expansion Contributors Julian Gruber Isaac Z. Schlueter Sponsors This module is proudly supported by my Sponsors! Do you want to support modules like this to improve their quality, stability and weigh in on new features? Then please consider donating to my Patreon. Not sure how much of my modules you're using? Try feross/thanks! Security contact information To report a security vulnerability, please use the Tidelift security contact. Tidelift will coordinate the fix and disclosure. License (MIT) Copyright (c) 2013 Julian Gruber <julian@juliangruber.com&gt; Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/braces/README.html": {
    "href": "node_modules/braces/README.html",
    "title": "braces | accouter",
    "keywords": "braces Bash-like brace expansion, implemented in JavaScript. Safer than other brace expansion libs, with complete support for the Bash 4.3 braces specification, without sacrificing speed. Please consider following this project's author, Jon Schlinkert, and consider starring the project to show your ❤️ and support. Install Install with npm: $ npm install --save braces v3.0.0 Released!! See the changelog for details. Why use braces? Brace patterns make globs more powerful by adding the ability to match specific ranges and sequences of characters. Accurate - complete support for the Bash 4.3 Brace Expansion specification (passes all of the Bash braces tests) fast and performant - Starts fast, runs fast and scales well as patterns increase in complexity. Organized code base - The parser and compiler are easy to maintain and update when edge cases crop up. Well-tested - Thousands of test assertions, and passes all of the Bash, minimatch, and brace-expansion unit tests (as of the date this was written). Safer - You shouldn't have to worry about users defining aggressive or malicious brace patterns that can break your application. Braces takes measures to prevent malicious regex that can be used for DDoS attacks (see catastrophic backtracking). Supports lists - (aka \"sets\") a/{b,c}/d => ['a/b/d', 'a/c/d'] Supports sequences - (aka \"ranges\") {01..03} => ['01', '02', '03'] Supports steps - (aka \"increments\") {2..10..2} => ['2', '4', '6', '8', '10'] Supports escaping - To prevent evaluation of special characters. Usage The main export is a function that takes one or more brace patterns and options. const braces = require('braces'); // braces(patterns[, options]); console.log(braces(['{01..05}', '{a..e}'])); //=> ['(0[1-5])', '([a-e])'] console.log(braces(['{01..05}', '{a..e}'], { expand: true })); //=> ['01', '02', '03', '04', '05', 'a', 'b', 'c', 'd', 'e'] Brace Expansion vs. Compilation By default, brace patterns are compiled into strings that are optimized for creating regular expressions and matching. Compiled console.log(braces('a/{x,y,z}/b')); //=> ['a/(x|y|z)/b'] console.log(braces(['a/{01..20}/b', 'a/{1..5}/b'])); //=> [ 'a/(0[1-9]|1[0-9]|20)/b', 'a/([1-5])/b' ] Expanded Enable brace expansion by setting the expand option to true, or by using braces.expand() (returns an array similar to what you'd expect from Bash, or echo {1..5}, or minimatch): console.log(braces('a/{x,y,z}/b', { expand: true })); //=> ['a/x/b', 'a/y/b', 'a/z/b'] console.log(braces.expand('{01..10}')); //=> ['01','02','03','04','05','06','07','08','09','10'] Lists Expand lists (like Bash \"sets\"): console.log(braces('a/{foo,bar,baz}/*.js')); //=> ['a/(foo|bar|baz)/*.js'] console.log(braces.expand('a/{foo,bar,baz}/*.js')); //=> ['a/foo/*.js', 'a/bar/*.js', 'a/baz/*.js'] Sequences Expand ranges of characters (like Bash \"sequences\"): console.log(braces.expand('{1..3}')); // ['1', '2', '3'] console.log(braces.expand('a/{1..3}/b')); // ['a/1/b', 'a/2/b', 'a/3/b'] console.log(braces('{a..c}', { expand: true })); // ['a', 'b', 'c'] console.log(braces('foo/{a..c}', { expand: true })); // ['foo/a', 'foo/b', 'foo/c'] // supports zero-padded ranges console.log(braces('a/{01..03}/b')); //=> ['a/(0[1-3])/b'] console.log(braces('a/{001..300}/b')); //=> ['a/(0{2}[1-9]|0[1-9][0-9]|[12][0-9]{2}|300)/b'] See fill-range for all available range-expansion options. Steppped ranges Steps, or increments, may be used with ranges: console.log(braces.expand('{2..10..2}')); //=> ['2', '4', '6', '8', '10'] console.log(braces('{2..10..2}')); //=> ['(2|4|6|8|10)'] When the .optimize method is used, or options.optimize is set to true, sequences are passed to to-regex-range for expansion. Nesting Brace patterns may be nested. The results of each expanded string are not sorted, and left to right order is preserved. \"Expanded\" braces console.log(braces.expand('a{b,c,/{x,y}}/e')); //=> ['ab/e', 'ac/e', 'a/x/e', 'a/y/e'] console.log(braces.expand('a/{x,{1..5},y}/c')); //=> ['a/x/c', 'a/1/c', 'a/2/c', 'a/3/c', 'a/4/c', 'a/5/c', 'a/y/c'] \"Optimized\" braces console.log(braces('a{b,c,/{x,y}}/e')); //=> ['a(b|c|/(x|y))/e'] console.log(braces('a/{x,{1..5},y}/c')); //=> ['a/(x|([1-5])|y)/c'] Escaping Escaping braces A brace pattern will not be expanded or evaluted if either the opening or closing brace is escaped: console.log(braces.expand('a\\\\{d,c,b}e')); //=> ['a{d,c,b}e'] console.log(braces.expand('a{d,c,b\\\\}e')); //=> ['a{d,c,b}e'] Escaping commas Commas inside braces may also be escaped: console.log(braces.expand('a{b\\\\,c}d')); //=> ['a{b,c}d'] console.log(braces.expand('a{d\\\\,c,b}e')); //=> ['ad,ce', 'abe'] Single items Following bash conventions, a brace pattern is also not expanded when it contains a single character: console.log(braces.expand('a{b}c')); //=> ['a{b}c'] Options options.maxLength Type: Number Default: 10,000 Description: Limit the length of the input string. Useful when the input string is generated or your application allows users to pass a string, et cetera. console.log(braces('a/{b,c}/d', { maxLength: 3 })); //=> throws an error options.expand Type: Boolean Default: undefined Description: Generate an \"expanded\" brace pattern (alternatively you can use the braces.expand() method, which does the same thing). console.log(braces('a/{b,c}/d', { expand: true })); //=> [ 'a/b/d', 'a/c/d' ] options.nodupes Type: Boolean Default: undefined Description: Remove duplicates from the returned array. options.rangeLimit Type: Number Default: 1000 Description: To prevent malicious patterns from being passed by users, an error is thrown when braces.expand() is used or options.expand is true and the generated range will exceed the rangeLimit. You can customize options.rangeLimit or set it to Inifinity to disable this altogether. Examples // pattern exceeds the \"rangeLimit\", so it's optimized automatically console.log(braces.expand('{1..1000}')); //=> ['([1-9]|[1-9][0-9]{1,2}|1000)'] // pattern does not exceed \"rangeLimit\", so it's NOT optimized console.log(braces.expand('{1..100}')); //=> ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100'] options.transform Type: Function Default: undefined Description: Customize range expansion. Example: Transforming non-numeric values const alpha = braces.expand('x/{a..e}/y', { transform(value, index) { // When non-numeric values are passed, \"value\" is a character code. return 'foo/' + String.fromCharCode(value) + '-' + index; }, }); console.log(alpha); //=> [ 'x/foo/a-0/y', 'x/foo/b-1/y', 'x/foo/c-2/y', 'x/foo/d-3/y', 'x/foo/e-4/y' ] Example: Transforming numeric values const numeric = braces.expand('{1..5}', { transform(value) { // when numeric values are passed, \"value\" is a number return 'foo/' + value * 2; }, }); console.log(numeric); //=> [ 'foo/2', 'foo/4', 'foo/6', 'foo/8', 'foo/10' ] options.quantifiers Type: Boolean Default: undefined Description: In regular expressions, quanitifiers can be used to specify how many times a token can be repeated. For example, a{1,3} will match the letter a one to three times. Unfortunately, regex quantifiers happen to share the same syntax as Bash lists The quantifiers option tells braces to detect when regex quantifiers are defined in the given pattern, and not to try to expand them as lists. Examples const braces = require('braces'); console.log(braces('a/b{1,3}/{x,y,z}')); //=> [ 'a/b(1|3)/(x|y|z)' ] console.log(braces('a/b{1,3}/{x,y,z}', { quantifiers: true })); //=> [ 'a/b{1,3}/(x|y|z)' ] console.log(braces('a/b{1,3}/{x,y,z}', { quantifiers: true, expand: true })); //=> [ 'a/b{1,3}/x', 'a/b{1,3}/y', 'a/b{1,3}/z' ] options.keepEscaping Type: Boolean Default: undefined Description: Do not strip backslashes that were used for escaping from the result. What is \"brace expansion\"? Brace expansion is a type of parameter expansion that was made popular by unix shells for generating lists of strings, as well as regex-like matching when used alongside wildcards (globs). In addition to \"expansion\", braces are also used for matching. In other words: brace expansion is for generating new lists brace matching is for filtering existing lists More about brace expansion (click to expand) There are two main types of brace expansion: lists: which are defined using comma-separated values inside curly braces: {a,b,c} sequences: which are defined using a starting value and an ending value, separated by two dots: a{1..3}b. Optionally, a third argument may be passed to define a \"step\" or increment to use: a{1..100..10}b. These are also sometimes referred to as \"ranges\". Here are some example brace patterns to illustrate how they work: Sets {a,b,c} => a b c {a,b,c}{1,2} => a1 a2 b1 b2 c1 c2 Sequences {1..9} => 1 2 3 4 5 6 7 8 9 {4..-4} => 4 3 2 1 0 -1 -2 -3 -4 {1..20..3} => 1 4 7 10 13 16 19 {a..j} => a b c d e f g h i j {j..a} => j i h g f e d c b a {a..z..3} => a d g j m p s v y Combination Sets and sequences can be mixed together or used along with any other strings. {a,b,c}{1..3} => a1 a2 a3 b1 b2 b3 c1 c2 c3 foo/{a,b,c}/bar => foo/a/bar foo/b/bar foo/c/bar The fact that braces can be \"expanded\" from relatively simple patterns makes them ideal for quickly generating test fixtures, file paths, and similar use cases. Brace matching In addition to expansion, brace patterns are also useful for performing regular-expression-like matching. For example, the pattern foo/{1..3}/bar would match any of following strings: foo/1/bar foo/2/bar foo/3/bar But not: baz/1/qux baz/2/qux baz/3/qux Braces can also be combined with glob patterns to perform more advanced wildcard matching. For example, the pattern */{1..3}/* would match any of following strings: foo/1/bar foo/2/bar foo/3/bar baz/1/qux baz/2/qux baz/3/qux Brace matching pitfalls Although brace patterns offer a user-friendly way of matching ranges or sets of strings, there are also some major disadvantages and potential risks you should be aware of. tldr \"brace bombs\" brace expansion can eat up a huge amount of processing resources as brace patterns increase linearly in size, the system resources required to expand the pattern increase exponentially users can accidentally (or intentially) exhaust your system's resources resulting in the equivalent of a DoS attack (bonus: no programming knowledge is required!) For a more detailed explanation with examples, see the geometric complexity section. The solution Jump to the performance section to see how Braces solves this problem in comparison to other libraries. Geometric complexity At minimum, brace patterns with sets limited to two elements have quadradic or O(n^2) complexity. But the complexity of the algorithm increases exponentially as the number of sets, and elements per set, increases, which is O(n^c). For example, the following sets demonstrate quadratic (O(n^2)) complexity: {1,2}{3,4} => (2X2) => 13 14 23 24 {1,2}{3,4}{5,6} => (2X2X2) => 135 136 145 146 235 236 245 246 But add an element to a set, and we get a n-fold Cartesian product with O(n^c) complexity: {1,2,3}{4,5,6}{7,8,9} => (3X3X3) => 147 148 149 157 158 159 167 168 169 247 248 249 257 258 259 267 268 269 347 348 349 357 358 359 367 368 369 Now, imagine how this complexity grows given that each element is a n-tuple: {1..100}{1..100} => (100X100) => 10,000 elements (38.4 kB) {1..100}{1..100}{1..100} => (100X100X100) => 1,000,000 elements (5.76 MB) Although these examples are clearly contrived, they demonstrate how brace patterns can quickly grow out of control. More information Interested in learning more about brace expansion? linuxjournal/bash-brace-expansion rosettacode/Brace_expansion cartesian product Performance Braces is not only screaming fast, it's also more accurate the other brace expansion libraries. Better algorithms Fortunately there is a solution to the \"brace bomb\" problem: don't expand brace patterns into an array when they're used for matching. Instead, convert the pattern into an optimized regular expression. This is easier said than done, and braces is the only library that does this currently. The proof is in the numbers Minimatch gets exponentially slower as patterns increase in complexity, braces does not. The following results were generated using braces() and minimatch.braceExpand(), respectively. Pattern braces [minimatch][] {1..9007199254740991}[^1] 298 B (5ms 459μs) N/A (freezes) {1..1000000000000000} 41 B (1ms 15μs) N/A (freezes) {1..100000000000000} 40 B (890μs) N/A (freezes) {1..10000000000000} 39 B (2ms 49μs) N/A (freezes) {1..1000000000000} 38 B (608μs) N/A (freezes) {1..100000000000} 37 B (397μs) N/A (freezes) {1..10000000000} 35 B (983μs) N/A (freezes) {1..1000000000} 34 B (798μs) N/A (freezes) {1..100000000} 33 B (733μs) N/A (freezes) {1..10000000} 32 B (5ms 632μs) 78.89 MB (16s 388ms 569μs) {1..1000000} 31 B (1ms 381μs) 6.89 MB (1s 496ms 887μs) {1..100000} 30 B (950μs) 588.89 kB (146ms 921μs) {1..10000} 29 B (1ms 114μs) 48.89 kB (14ms 187μs) {1..1000} 28 B (760μs) 3.89 kB (1ms 453μs) {1..100} 22 B (345μs) 291 B (196μs) {1..10} 10 B (533μs) 20 B (37μs) {1..3} 7 B (190μs) 5 B (27μs) Faster algorithms When you need expansion, braces is still much faster. (the following results were generated using braces.expand() and minimatch.braceExpand(), respectively) Pattern braces [minimatch][] {1..10000000} 78.89 MB (2s 698ms 642μs) 78.89 MB (18s 601ms 974μs) {1..1000000} 6.89 MB (458ms 576μs) 6.89 MB (1s 491ms 621μs) {1..100000} 588.89 kB (20ms 728μs) 588.89 kB (156ms 919μs) {1..10000} 48.89 kB (2ms 202μs) 48.89 kB (13ms 641μs) {1..1000} 3.89 kB (1ms 796μs) 3.89 kB (1ms 958μs) {1..100} 291 B (424μs) 291 B (211μs) {1..10} 20 B (487μs) 20 B (72μs) {1..3} 5 B (166μs) 5 B (27μs) If you'd like to run these comparisons yourself, see test/support/generate.js. Benchmarks Running benchmarks Install dev dependencies: npm i -d && npm benchmark Latest results Braces is more accurate, without sacrificing performance. ● expand - range (expanded) braces x 53,167 ops/sec ±0.12% (102 runs sampled) minimatch x 11,378 ops/sec ±0.10% (102 runs sampled) ● expand - range (optimized for regex) braces x 373,442 ops/sec ±0.04% (100 runs sampled) minimatch x 3,262 ops/sec ±0.18% (100 runs sampled) ● expand - nested ranges (expanded) braces x 33,921 ops/sec ±0.09% (99 runs sampled) minimatch x 10,855 ops/sec ±0.28% (100 runs sampled) ● expand - nested ranges (optimized for regex) braces x 287,479 ops/sec ±0.52% (98 runs sampled) minimatch x 3,219 ops/sec ±0.28% (101 runs sampled) ● expand - set (expanded) braces x 238,243 ops/sec ±0.19% (97 runs sampled) minimatch x 538,268 ops/sec ±0.31% (96 runs sampled) ● expand - set (optimized for regex) braces x 321,844 ops/sec ±0.10% (97 runs sampled) minimatch x 140,600 ops/sec ±0.15% (100 runs sampled) ● expand - nested sets (expanded) braces x 165,371 ops/sec ±0.42% (96 runs sampled) minimatch x 337,720 ops/sec ±0.28% (100 runs sampled) ● expand - nested sets (optimized for regex) braces x 242,948 ops/sec ±0.12% (99 runs sampled) minimatch x 87,403 ops/sec ±0.79% (96 runs sampled) About Contributing Pull requests and stars are always welcome. For bugs and feature requests, please create an issue. Running Tests Running and reviewing unit tests is a great way to get familiarized with a library and its API. You can install dependencies and run tests with the following command: $ npm install && npm test Building docs (This project's readme.md is generated by verb, please don't edit the readme directly. Any changes to the readme must be made in the .verb.md readme template.) To generate the readme, run the following command: $ npm install -g verbose/verb#dev verb-generate-readme && verb Contributors Commits Contributor 197 jonschlinkert 4 doowb 1 es128 1 eush77 1 hemanth 1 wtgtybhertgeghgtwtg Author Jon Schlinkert GitHub Profile Twitter Profile LinkedIn Profile License Copyright © 2019, Jon Schlinkert. Released under the MIT License. This file was generated by verb-generate-readme, v0.8.0, on April 08, 2019."
  },
  "node_modules/browser-stdout/README.html": {
    "href": "node_modules/browser-stdout/README.html",
    "title": "| accouter",
    "keywords": "wat? process.stdout in your browser. wai? iono. cuz hakz. hau? var BrowserStdout = require('browser-stdout') myStream.pipe(BrowserStdout()) monkey You can monkey-patch process.stdout for your dependency graph like this: process.stdout = require('browser-stdout')() var coolTool = require('module-that-uses-stdout-somewhere-in-its-depths') opts opts are passed directly to stream.Writable. additionally, a label arg can be used to label console output. BrowserStdout({ objectMode: true, label: 'dataz', }) ur doin it rong i accept pr's."
  },
  "node_modules/browser-sync-client/README.html": {
    "href": "node_modules/browser-sync-client/README.html",
    "title": "browser-sync-client | accouter",
    "keywords": "browser-sync-client Client-side script for BrowserSync Contributors 177 Shane Osbourne 2 Sergey Slipchenko 1 Hugo Dias 1 Shinnosuke Watanabe 1 Tim Schaub 1 Shane Daniel 1 Matthieu Vachon License Copyright (c) 2014 Shane Osbourne Licensed under the MIT license."
  },
  "node_modules/browser-sync-ui/README.html": {
    "href": "node_modules/browser-sync-ui/README.html",
    "title": "Browsersync UI | accouter",
    "keywords": "Browsersync UI Comes bundled with the Browsersync module (version 2.0.0 onwards). License Copyright (c) 2016 Shane Osbourne Licensed under the Apache 2.0 license."
  },
  "node_modules/browser-sync/readme.html": {
    "href": "node_modules/browser-sync/readme.html",
    "title": "| accouter",
    "keywords": "Keep multiple browsers & devices in sync when building websites. Follow @Browsersync on twitter for news & updates. Features Please visit browsersync.io for a full run-down of features Requirements Browsersync works by injecting an asynchronous script tag (<script async>...</script>) right after the <body> tag during initial request. In order for this to work properly the <body> tag must be present. Alternatively you can provide a custom rule for the snippet using snippetOptions Upgrading from 1.x to 2.x ? Providing you haven't accessed any internal properties, everything will just work as there are no breaking changes to the public API. Internally however, we now use an immutable data structure for storing/retrieving options. So whereas before you could access urls like this... browserSync({server: true}, function(err, bs) { console.log(bs.options.urls.local); }); ... you now access them in the following way: browserSync({server: true}, function(err, bs) { console.log(bs.options.getIn([\"urls\", \"local\"])); }); Install and trouble shooting browsersync.io docs Integrations / recipes Browsersync recipes Support If you've found Browser-sync useful and would like to contribute to its continued development & support, please feel free to send a donation of any size - it would be greatly appreciated! Support via PayPal Supported by Originally supported by JH - they provided financial support as well as access to a professional designer to help with Branding. Apache 2 Copyright (c) 2021 Shane Osbourne"
  },
  "node_modules/browserslist/README.html": {
    "href": "node_modules/browserslist/README.html",
    "title": "Browserslist | accouter",
    "keywords": "Browserslist The config to share target browsers and Node.js versions between different front-end tools. It is used in: Autoprefixer Babel postcss-preset-env eslint-plugin-compat stylelint-no-unsupported-browser-features postcss-normalize obsolete-webpack-plugin All tools will find target browsers automatically, when you add the following to package.json: \"browserslist\": [ \"defaults and fully supports es6-module\", \"maintained node versions\" ] Or in .browserslistrc config: # Browsers that we support defaults and fully supports es6-module maintained node versions Developers set their version lists using queries like last 2 versions to be free from updating versions manually. Browserslist will use caniuse-lite with Can I Use data for this queries. You can check how config works at our playground: browsersl.ist Docs Read full docs here."
  },
  "node_modules/bs-recipes/readme.html": {
    "href": "node_modules/bs-recipes/readme.html",
    "title": "| accouter",
    "keywords": "Browsersync recipes. There are endless amounts of possible integrations and workflow scenarios when using Browsersync, so this project is an attempt to highlight as many of them as we can, whilst providing full, working examples. Here's what we have currently... Grunt, SASS, HTML/CSS injection example Grunt & SASS Grunt, SASS & Autoprefixer Browserify, Babelify + Watchify + Sourcemaps Example Gulp, SASS + Pug Templates Gulp & Ruby SASS Gulp & SASS Gulp & Swig Templates Gulp, SASS + Slow running tasks HTML/CSS injection example Middleware + CSS example Proxy example + injecting custom css file Server example Server with pre-gzipped assets example Server includes example Server + Logging + History API fallback middlewares Example Webpack + Babel Webpack + Monkey Hot Loader Webpack + Preact Hot Loader Webpack + React Hot Loader Webpack + React Transform HMR Webpack + TypeScript Webpack, TypeScript + React ... each one is a full, working example - just have a look at the readme.md in each one for installation instructions. Contributions / Feedback Spotted an error? Couldn't get one of the examples running? Have your own sweet setup that you want to show off to the world? We'd love to receive your feedback and contributions - so please get in touch! We aim to make this project the canonical source of example projects & code snippets related to running Browsersync. How to contribute an example First thing you should do, is take a look at our simplest example here - this will give you a great head-start on setting up your code. Then, fork this repo and clone your fork down to your local machine. Now create a new folder inside recipes (note the naming structure). This is where you create your awesome example. You're free to do as you like, but there are a couple of rules you'll need to follow to ensure the project can build. Required Files package.json (see below for requirements) app.js (or any JS file showing the example) ./app directory. Always include the minimum HTML, JS & CSS needed to prove your example. Do NOT include readme.md (this is created dynamically for you) any other files that are not related to your example. package.json requirements start command: For consistency, ensure your example can be run with the command npm start. To do this, you just need to provide something along these lines: \"scripts\": { \"start\": \"node app.js\" }, main file: We inline your main Javascript file into the readme.md, so don't miss this field. \"main\": \"app.js\" // or gulpfile.js etc description: We use this as the Title. So make it short and descriptive, such as \"description\": \"Server example\" Finally, build. After you've added your example in the recipes folder, return to the root and run npm install && npm run build This will install Crossbow.js and compile the project. Commit everything that has changed and push it up to your fork. Send a Pull Request when you're ready, or if you'd like us to have a look over your code before that, just ping us twitter and we'll take a look!"
  },
  "node_modules/bs-recipes/recipes/grunt.html.injection/desc.html": {
    "href": "node_modules/bs-recipes/recipes/grunt.html.injection/desc.html",
    "title": "| accouter",
    "keywords": "To see the live HTML injecting, along with CSS injection, simply perform changes to either index.html or css/main.css"
  },
  "node_modules/bs-recipes/recipes/grunt.html.injection/readme.html": {
    "href": "node_modules/bs-recipes/recipes/grunt.html.injection/readme.html",
    "title": "| accouter",
    "keywords": "#Browsersync - Grunt, SASS, HTML/CSS injection example Installation/Usage: To try this example, follow these 4 simple steps. Step 1: Clone this entire repo $ git clone https://github.com/Browsersync/recipes.git bs-recipes Step 2: Move into the directory containing this example $ cd bs-recipes/recipes/grunt.html.injection Step 3: Install dependencies $ npm install Step 4: Run the example $ npm start Additional Info: To see the live HTML injecting, along with CSS injection, simply perform changes to either index.html or css/main.css Preview of Gruntfile.js: // This shows a full config file! module.exports = function (grunt) { grunt.initConfig({ watch: { files: 'app/scss/**/*.scss', tasks: ['bsReload:css'] }, sass: { dev: { files: { 'app/css/main.css': 'app/scss/main.scss' } } }, browserSync: { dev: { options: { watchTask: true, server: './app', plugins: [ { module: \"bs-html-injector\", options: { files: \"./app/*.html\" } } ] } } }, bsReload: { css: \"main.css\" } }); // load npm tasks grunt.loadNpmTasks('grunt-contrib-sass'); grunt.loadNpmTasks('grunt-contrib-watch'); grunt.loadNpmTasks('grunt-browser-sync'); // define default task grunt.registerTask('default', ['browserSync', 'watch']); };"
  },
  "node_modules/bs-recipes/recipes/grunt.sass.autoprefixer/desc.html": {
    "href": "node_modules/bs-recipes/recipes/grunt.sass.autoprefixer/desc.html",
    "title": "| accouter",
    "keywords": "This example shows how you can chain potentially slow-running tasks, but still achieve CSS Injection. The trick, as seen below, is to use the bsReload task that now comes bundled with grunt-browser-sync since 2.1.0 Don't forget the spawn: false option for the watch task - it's a requirement that allows Browsersync to work correctly watch: { options: { spawn: false // Important, don't remove this! }, files: 'app/**/*.scss', tasks: ['sass', 'autoprefixer', 'bsReload:css'] },"
  },
  "node_modules/bs-recipes/recipes/grunt.sass.autoprefixer/readme.html": {
    "href": "node_modules/bs-recipes/recipes/grunt.sass.autoprefixer/readme.html",
    "title": "| accouter",
    "keywords": "#Browsersync - Grunt, SASS & Autoprefixer Installation/Usage: To try this example, follow these 4 simple steps. Step 1: Clone this entire repo $ git clone https://github.com/Browsersync/recipes.git bs-recipes Step 2: Move into the directory containing this example $ cd bs-recipes/recipes/grunt.sass.autoprefixer Step 3: Install dependencies $ npm install Step 4: Run the example $ npm start Additional Info: This example shows how you can chain potentially slow-running tasks, but still achieve CSS Injection. The trick, as seen below, is to use the bsReload task that now comes bundled with grunt-browser-sync since 2.1.0 Don't forget the spawn: false option for the watch task - it's a requirement that allows Browsersync to work correctly watch: { options: { spawn: false // Important, don't remove this! }, files: 'app/**/*.scss', tasks: ['sass', 'autoprefixer', 'bsReload:css'] }, Preview of Gruntfile.js: module.exports = function (grunt) { grunt.initConfig({ dirs: { css: \"app/css\", scss: \"app/scss\" }, watch: { options: { spawn: false }, sass: { files: '<%= dirs.scss %>/**/*.scss', tasks: ['sass', 'autoprefixer', 'bsReload:css'] }, html: { files: 'app/*.html', tasks: ['bsReload:all'] } }, sass: { dev: { files: { '<%= dirs.css %>/main.css': '<%= dirs.scss %>/main.scss' } } }, autoprefixer: { options: { browsers: ['last 5 versions', 'ie 8'] }, css: { src: '<%= dirs.css %>/main.css', dest: '<%= dirs.css %>/main.css' } }, browserSync: { dev: { options: { server: \"./app\", background: true } } }, bsReload: { css: { reload: \"main.css\" }, all: { reload: true } } }); // load npm tasks grunt.loadNpmTasks('grunt-contrib-sass'); grunt.loadNpmTasks('grunt-autoprefixer'); grunt.loadNpmTasks('grunt-browser-sync'); grunt.loadNpmTasks('grunt-contrib-watch'); // define default task grunt.registerTask('default', ['browserSync', 'watch']); };"
  },
  "node_modules/bs-recipes/recipes/grunt.sass/desc.html": {
    "href": "node_modules/bs-recipes/recipes/grunt.sass/desc.html",
    "title": "| accouter",
    "keywords": ""
  },
  "node_modules/bs-recipes/recipes/grunt.sass/readme.html": {
    "href": "node_modules/bs-recipes/recipes/grunt.sass/readme.html",
    "title": "| accouter",
    "keywords": "#Browsersync - Grunt & SASS Installation/Usage: To try this example, follow these 4 simple steps. Step 1: Clone this entire repo $ git clone https://github.com/Browsersync/recipes.git bs-recipes Step 2: Move into the directory containing this example $ cd bs-recipes/recipes/grunt.sass Step 3: Install dependencies $ npm install Step 4: Run the example $ npm start Additional Info: Preview of Gruntfile.js: // This shows a full config file! module.exports = function (grunt) { grunt.initConfig({ watch: { files: 'app/scss/**/*.scss', tasks: ['sass'] }, sass: { dev: { files: { 'app/css/main.css': 'app/scss/main.scss' } } }, browserSync: { dev: { bsFiles: { src : [ 'app/css/*.css', 'app/*.html' ] }, options: { watchTask: true, server: './app' } } } }); // load npm tasks grunt.loadNpmTasks('grunt-contrib-sass'); grunt.loadNpmTasks('grunt-contrib-watch'); grunt.loadNpmTasks('grunt-browser-sync'); // define default task grunt.registerTask('default', ['browserSync', 'watch']); };"
  },
  "node_modules/bs-recipes/recipes/gulp.browserify/desc.html": {
    "href": "node_modules/bs-recipes/recipes/gulp.browserify/desc.html",
    "title": "| accouter",
    "keywords": "This one is a beast. Write your React JSX code, in ES6, compiled by Browserify and auto-reload all devices when the compilation is complete."
  },
  "node_modules/bs-recipes/recipes/gulp.browserify/readme.html": {
    "href": "node_modules/bs-recipes/recipes/gulp.browserify/readme.html",
    "title": "| accouter",
    "keywords": "#Browsersync - Browserify, Babelify + Watchify + Sourcemaps Example Installation/Usage: To try this example, follow these 4 simple steps. Step 1: Clone this entire repo $ git clone https://github.com/Browsersync/recipes.git bs-recipes Step 2: Move into the directory containing this example $ cd bs-recipes/recipes/gulp.browserify Step 3: Install dependencies $ npm install Step 4: Run the example $ npm start Additional Info: This one is a beast. Write your React JSX code, in ES6, compiled by Browserify and auto-reload all devices when the compilation is complete. Preview of gulpfile.js: var gulp = require('gulp'); var gutil = require('gulp-util'); var source = require('vinyl-source-stream'); var babelify = require('babelify'); var watchify = require('watchify'); var exorcist = require('exorcist'); var browserify = require('browserify'); var browserSync = require('browser-sync').create(); // Watchify args contains necessary cache options to achieve fast incremental bundles. // See watchify readme for details. Adding debug true for source-map generation. watchify.args.debug = true; // Input file. var bundler = watchify(browserify('./app/js/app.js', watchify.args)); // Babel transform bundler.transform(babelify.configure({ sourceMapRelative: 'app/js' })); // On updates recompile bundler.on('update', bundle); function bundle() { gutil.log('Compiling JS...'); return bundler.bundle() .on('error', function (err) { gutil.log(err.message); browserSync.notify(\"Browserify Error!\"); this.emit(\"end\"); }) .pipe(exorcist('app/js/dist/bundle.js.map')) .pipe(source('bundle.js')) .pipe(gulp.dest('./app/js/dist')) .pipe(browserSync.stream({once: true})); } /** * Gulp task alias */ gulp.task('bundle', function () { return bundle(); }); /** * First bundle, then serve from the ./app directory */ gulp.task('default', ['bundle'], function () { browserSync.init({ server: \"./app\" }); });"
  },
  "node_modules/bs-recipes/recipes/gulp.pug/desc.html": {
    "href": "node_modules/bs-recipes/recipes/gulp.pug/desc.html",
    "title": "| accouter",
    "keywords": "This is an upgraded version of gulp.jade recipe from BrowserSync . Some useful links: template engine : pug documentation (was: Jade) and its integration with gulp: gulp-pug css preprocessing : node-sass and its integration with gulp: gulp-sass and of course gulp"
  },
  "node_modules/bs-recipes/recipes/gulp.pug/readme.html": {
    "href": "node_modules/bs-recipes/recipes/gulp.pug/readme.html",
    "title": "| accouter",
    "keywords": "#Browsersync - Gulp, SASS + Pug Templates Installation/Usage: To try this example, follow these 4 simple steps. Step 1: Clone this entire repo $ git clone https://github.com/Browsersync/recipes.git bs-recipes Step 2: Move into the directory containing this example $ cd bs-recipes/recipes/gulp.pug Step 3: Install dependencies $ npm install Step 4: Run the example $ npm start Additional Info: This is an upgraded version of gulp.jade recipe from BrowserSync . Some useful links: template engine : pug documentation (was: Jade) and its integration with gulp: gulp-pug css preprocessing : node-sass and its integration with gulp: gulp-sass and of course gulp Preview of gulpfile.js: var gulp = require('gulp'); var browserSync = require('browser-sync'); var sass = require('gulp-sass'); var pug = require('gulp-pug'); var reload = browserSync.reload; /** * Compile pug files into HTML */ gulp.task('templates', function() { var YOUR_LOCALS = { \"message\": \"This app is powered by gulp.pug recipe for BrowserSync\" }; return gulp.src('./app/*.pug') .pipe(pug({ locals: YOUR_LOCALS })) .pipe(gulp.dest('./dist/')); }); /** * Important!! * Separate task for the reaction to `.pug` files */ gulp.task('pug-watch', ['templates'], reload); /** * Sass task for live injecting into all browsers */ gulp.task('sass', function () { return gulp.src('./app/scss/*.scss') .pipe(sass()).on('error', sass.logError) .pipe(gulp.dest('./dist/css')) .pipe(reload({stream: true})); }); /** * Serve and watch the scss/pug files for changes */ gulp.task('default', ['sass', 'templates'], function () { browserSync({server: './dist'}); gulp.watch('./app/scss/*.scss', ['sass']); gulp.watch('./app/*.pug', ['pug-watch']); });"
  },
  "node_modules/bs-recipes/recipes/gulp.ruby.sass/desc.html": {
    "href": "node_modules/bs-recipes/recipes/gulp.ruby.sass/desc.html",
    "title": "| accouter",
    "keywords": "This example highlights both the stream support for injecting CSS, aswell as the support for calling reload directly following html changes. We also need to filter out any source maps created by ruby-sass."
  },
  "node_modules/bs-recipes/recipes/gulp.ruby.sass/readme.html": {
    "href": "node_modules/bs-recipes/recipes/gulp.ruby.sass/readme.html",
    "title": "| accouter",
    "keywords": "#Browsersync - Gulp & Ruby SASS Installation/Usage: To try this example, follow these 4 simple steps. Step 1: Clone this entire repo $ git clone https://github.com/Browsersync/recipes.git bs-recipes Step 2: Move into the directory containing this example $ cd bs-recipes/recipes/gulp.ruby.sass Step 3: Install dependencies $ npm install Step 4: Run the example $ npm start Additional Info: This example highlights both the stream support for injecting CSS, aswell as the support for calling reload directly following html changes. We also need to filter out any source maps created by ruby-sass. Preview of gulpfile.js: var gulp = require('gulp'); var browserSync = require('browser-sync'); var filter = require('gulp-filter'); var sass = require('gulp-ruby-sass'); var sourcemaps = require('gulp-sourcemaps'); var reload = browserSync.reload; var src = { scss: 'app/scss/*.scss', css: 'app/css', html: 'app/*.html' }; /** * Kick off the sass stream with source maps + error handling */ function sassStream () { return sass('app/scss', {sourcemap: true}) .on('error', function (err) { console.error('Error!', err.message); }) .pipe(sourcemaps.write('./', { includeContent: false, sourceRoot: '/app/scss' })); } /** * Start the Browsersync Static Server + Watch files */ gulp.task('serve', ['sass'], function() { browserSync({ server: \"./app\" }); gulp.watch(src.scss, ['sass']); gulp.watch(src.html).on('change', reload); }); /** * Compile sass, filter the results, inject CSS into all browsers */ gulp.task('sass', function() { return sassStream() .pipe(gulp.dest(src.css)) .pipe(filter(\"**/*.css\")) .pipe(reload({stream: true})); }); /** * Default task */ gulp.task('default', ['serve']);"
  },
  "node_modules/bs-recipes/recipes/gulp.sass/desc.html": {
    "href": "node_modules/bs-recipes/recipes/gulp.sass/desc.html",
    "title": "| accouter",
    "keywords": "This example highlights both the stream support for injecting CSS, as well as the support for calling reload directly following html changes."
  },
  "node_modules/bs-recipes/recipes/gulp.sass/readme.html": {
    "href": "node_modules/bs-recipes/recipes/gulp.sass/readme.html",
    "title": "| accouter",
    "keywords": "#Browsersync - Gulp & SASS Installation/Usage: To try this example, follow these 4 simple steps. Step 1: Clone this entire repo $ git clone https://github.com/Browsersync/recipes.git bs-recipes Step 2: Move into the directory containing this example $ cd bs-recipes/recipes/gulp.sass Step 3: Install dependencies $ npm install Step 4: Run the example $ npm start Additional Info: This example highlights both the stream support for injecting CSS, as well as the support for calling reload directly following html changes. Preview of gulpfile.js: var gulp = require('gulp'); var browserSync = require('browser-sync').create(); var sass = require('gulp-sass'); var reload = browserSync.reload; var src = { scss: 'app/scss/*.scss', css: 'app/css', html: 'app/*.html' }; // Static Server + watching scss/html files gulp.task('serve', ['sass'], function() { browserSync.init({ server: \"./app\" }); gulp.watch(src.scss, ['sass']); gulp.watch(src.html).on('change', reload); }); // Compile sass into CSS gulp.task('sass', function() { return gulp.src(src.scss) .pipe(sass()) .pipe(gulp.dest(src.css)) .pipe(reload({stream: true})); }); gulp.task('default', ['serve']);"
  },
  "node_modules/bs-recipes/recipes/gulp.swig/desc.html": {
    "href": "node_modules/bs-recipes/recipes/gulp.swig/desc.html",
    "title": "| accouter",
    "keywords": "This example will build HTML files from ./app with gulp-swig and place them into the dist folder. Browsersync then serves from that folder and reloads after the templates are compiled."
  },
  "node_modules/bs-recipes/recipes/gulp.swig/readme.html": {
    "href": "node_modules/bs-recipes/recipes/gulp.swig/readme.html",
    "title": "| accouter",
    "keywords": "#Browsersync - Gulp & Swig Templates Installation/Usage: To try this example, follow these 4 simple steps. Step 1: Clone this entire repo $ git clone https://github.com/Browsersync/recipes.git bs-recipes Step 2: Move into the directory containing this example $ cd bs-recipes/recipes/gulp.swig Step 3: Install dependencies $ npm install Step 4: Run the example $ npm start Additional Info: This example will build HTML files from ./app with gulp-swig and place them into the dist folder. Browsersync then serves from that folder and reloads after the templates are compiled. Preview of gulpfile.js: var gulp = require('gulp'); var browserSync = require('browser-sync'); var sass = require('gulp-sass'); var swig = require('gulp-swig'); var reload = browserSync.reload; var src = { scss: 'app/scss/*.scss', css: 'app/css', html: 'app/*.html' }; // Static Server + watching scss/html files gulp.task('serve', ['sass'], function() { browserSync({ server: \"./dist\" }); gulp.watch(src.scss, ['sass']); gulp.watch(src.html, ['templates']); }); // Swig templates gulp.task('templates', function() { return gulp.src(src.html) .pipe(swig()) .pipe(gulp.dest('./dist')) .on(\"end\", reload); }); // Compile sass into CSS gulp.task('sass', function() { return gulp.src(src.scss) .pipe(sass()) .pipe(gulp.dest(src.css)) .pipe(reload({stream: true})); }); gulp.task('default', ['serve']);"
  },
  "node_modules/bs-recipes/recipes/gulp.task.sequence/desc.html": {
    "href": "node_modules/bs-recipes/recipes/gulp.task.sequence/desc.html",
    "title": "| accouter",
    "keywords": "This example highlights a common problem where you don't want to reload the browser until a 2 or more slow-running tasks have completed. The solution is to create the intermediate task that ensures browserSync.reload is not called until both slow tasks are complete."
  },
  "node_modules/bs-recipes/recipes/gulp.task.sequence/readme.html": {
    "href": "node_modules/bs-recipes/recipes/gulp.task.sequence/readme.html",
    "title": "| accouter",
    "keywords": "#Browsersync - Gulp, SASS + Slow running tasks Installation/Usage: To try this example, follow these 4 simple steps. Step 1: Clone this entire repo $ git clone https://github.com/Browsersync/recipes.git bs-recipes Step 2: Move into the directory containing this example $ cd bs-recipes/recipes/gulp.task.sequence Step 3: Install dependencies $ npm install Step 4: Run the example $ npm start Additional Info: This example highlights a common problem where you don't want to reload the browser until a 2 or more slow-running tasks have completed. The solution is to create the intermediate task that ensures browserSync.reload is not called until both slow tasks are complete. Preview of gulpfile.js: var gulp = require('gulp'); var browserSync = require('browser-sync'); var sass = require('gulp-sass'); var reload = browserSync.reload; var through = require(\"through2\"); /** * A slow task */ gulp.task('slow1', function () { return gulp.src('./app/*.html') .pipe(slowStream()); }); /** * Another Slow task */ gulp.task('slow2', function () { return gulp.src('./app/*.html') .pipe(slowStream()); }); /** * Separate task for the reaction to a file change */ gulp.task('html-watch', ['slow1', 'slow2'], reload); /** * Sass task for live injecting into all browsers */ gulp.task('sass', function () { return gulp.src('./app/scss/*.scss') .pipe(sass()) .pipe(gulp.dest('./app/css')) .pipe(reload({stream: true})); }); /** * Serve and watch the html files for changes */ gulp.task('default', function () { browserSync({server: './app'}); gulp.watch('./app/scss/*.scss', ['sass']); gulp.watch('./app/*.html', ['html-watch']); }); /** * Simulate a slow task */ function slowStream () { return through.obj(function (file, enc, cb) { this.push(file); setTimeout(cb, 2000); }); }"
  },
  "node_modules/bs-recipes/recipes/html.injection/desc.html": {
    "href": "node_modules/bs-recipes/recipes/html.injection/desc.html",
    "title": "| accouter",
    "keywords": "To see the live HTML injecting, along with CSS injection, simply perform changes to either index.html or css/main.css"
  },
  "node_modules/bs-recipes/recipes/html.injection/readme.html": {
    "href": "node_modules/bs-recipes/recipes/html.injection/readme.html",
    "title": "| accouter",
    "keywords": "#Browsersync - HTML/CSS injection example Installation/Usage: To try this example, follow these 4 simple steps. Step 1: Clone this entire repo $ git clone https://github.com/Browsersync/recipes.git bs-recipes Step 2: Move into the directory containing this example $ cd bs-recipes/recipes/html.injection Step 3: Install dependencies $ npm install Step 4: Run the example $ npm start Additional Info: To see the live HTML injecting, along with CSS injection, simply perform changes to either index.html or css/main.css Preview of app.js: /** * Require Browsersync */ var bs = require('browser-sync').create(); /** * Run Browsersync with server config */ bs.init({ server: \"app\", files: [\"app/css/*.css\"], plugins: [ { module: \"bs-html-injector\", options: { files: [\"app/*.html\"] } } ] });"
  },
  "node_modules/bs-recipes/recipes/middleware.css.injection/desc.html": {
    "href": "node_modules/bs-recipes/recipes/middleware.css.injection/desc.html",
    "title": "| accouter",
    "keywords": "Perform changes to app/css/main.less to see live css injection"
  },
  "node_modules/bs-recipes/recipes/middleware.css.injection/readme.html": {
    "href": "node_modules/bs-recipes/recipes/middleware.css.injection/readme.html",
    "title": "| accouter",
    "keywords": "#Browsersync - Middleware + CSS example Installation/Usage: To try this example, follow these 4 simple steps. Step 1: Clone this entire repo $ git clone https://github.com/Browsersync/recipes.git bs-recipes Step 2: Move into the directory containing this example $ cd bs-recipes/recipes/middleware.css.injection Step 3: Install dependencies $ npm install Step 4: Run the example $ npm start Additional Info: Perform changes to app/css/main.less to see live css injection Preview of app.js: /** * Require Browsersync */ var browserSync = require(\"browser-sync\"); /** * Run the middleware on files that contain .less */ function lessMiddleware (req, res, next) { var parsed = require(\"url\").parse(req.url); if (parsed.pathname.match(/\\.less$/)) { return less(parsed.pathname).then(function (o) { res.setHeader('Content-Type', 'text/css'); res.end(o.css); }); } next(); } /** * Compile less */ function less(src) { var f = require('fs').readFileSync('app' + src).toString(); return require('less').render(f); } /** * Run Browsersync with less middleware */ browserSync({ files: \"app/css/*.less\", server: \"app\", injectFileTypes: [\"less\"], /** * Catch all requests, if any are for .less files, recompile on the fly and * send back a CSS response */ middleware: lessMiddleware });"
  },
  "node_modules/bs-recipes/recipes/proxy.custom-css/desc.html": {
    "href": "node_modules/bs-recipes/recipes/proxy.custom-css/desc.html",
    "title": "| accouter",
    "keywords": "To see the live-updating and CSS injecting, simply perform changes to app/static/_custom.css"
  },
  "node_modules/bs-recipes/recipes/proxy.custom-css/readme.html": {
    "href": "node_modules/bs-recipes/recipes/proxy.custom-css/readme.html",
    "title": "| accouter",
    "keywords": "#Browsersync - Proxy example + injecting custom css file Installation/Usage: To try this example, follow these 4 simple steps. Step 1: Clone this entire repo $ git clone https://github.com/Browsersync/recipes.git bs-recipes Step 2: Move into the directory containing this example $ cd bs-recipes/recipes/proxy.custom-css Step 3: Install dependencies $ npm install Step 4: Run the example $ npm start Additional Info: To see the live-updating and CSS injecting, simply perform changes to app/static/_custom.css Preview of app.js: /** * Require Browsersync */ var browserSync = require('browser-sync').create(); /** * Run Browsersync with server config * You can use an arrays for files to specify multiple files */ browserSync.init({ proxy: \"example.com\", serveStatic: [\"app/static\"], files: \"app/static/_custom.css\", snippetOptions: { rule: { match: /<\\/head>/i, fn: function (snippet, match) { return '<link rel=\"stylesheet\" type=\"text/css\" href=\"/_custom.css\"/>' + snippet + match; } } } });"
  },
  "node_modules/bs-recipes/recipes/server.gzipped.assets/desc.html": {
    "href": "node_modules/bs-recipes/recipes/server.gzipped.assets/desc.html",
    "title": "| accouter",
    "keywords": "This example shows how you can use the connect-gzip-static middleware to serve already-gzipped assets."
  },
  "node_modules/bs-recipes/recipes/server.gzipped.assets/readme.html": {
    "href": "node_modules/bs-recipes/recipes/server.gzipped.assets/readme.html",
    "title": "| accouter",
    "keywords": "#Browsersync - Server with pre-gzipped assets example Installation/Usage: To try this example, follow these 4 simple steps. Step 1: Clone this entire repo $ git clone https://github.com/Browsersync/recipes.git bs-recipes Step 2: Move into the directory containing this example $ cd bs-recipes/recipes/server.gzipped.assets Step 3: Install dependencies $ npm install Step 4: Run the example $ npm start Additional Info: This example shows how you can use the connect-gzip-static middleware to serve already-gzipped assets. Preview of app.js: /** * Require Browsersync */ var browserSync = require('browser-sync').create(); var middleware = require('connect-gzip-static')('./app'); /** * Run Browsersync with server config * Add middleware with override:true to ensure all files are * picked up. */ browserSync.init({ server: 'app', files: ['app/*.html', 'app/css/*.css'] }, function (err, bs) { bs.addMiddleware(\"*\", middleware, { override: true }); });"
  },
  "node_modules/bs-recipes/recipes/server.includes/desc.html": {
    "href": "node_modules/bs-recipes/recipes/server.includes/desc.html",
    "title": "| accouter",
    "keywords": ""
  },
  "node_modules/bs-recipes/recipes/server.includes/readme.html": {
    "href": "node_modules/bs-recipes/recipes/server.includes/readme.html",
    "title": "| accouter",
    "keywords": "#Browsersync - Server includes example Installation/Usage: To try this example, follow these 4 simple steps. Step 1: Clone this entire repo $ git clone https://github.com/Browsersync/recipes.git bs-recipes Step 2: Move into the directory containing this example $ cd bs-recipes/recipes/server.includes Step 3: Install dependencies $ npm install Step 4: Run the example $ npm start Additional Info: Preview of app.js: /** * Require Browsersync */ var browserSync = require('browser-sync').create(); var fs = require('fs'); /** * Run Browsersync with server config */ browserSync.init({ server: 'app', files: ['app/*.html', 'app/css/*.css'], rewriteRules: [ { match: /@include\\(\"(.+?)\"\\)/g, fn: function (match, filename) { if (fs.existsSync(filename)) { return fs.readFileSync(filename); } else { return '<span style=\"color: red\">'+filename+' could not be found</span>'; } } } ] });"
  },
  "node_modules/bs-recipes/recipes/server.middleware/desc.html": {
    "href": "node_modules/bs-recipes/recipes/server.middleware/desc.html",
    "title": "| accouter",
    "keywords": "This example adds the connect-logger middleware"
  },
  "node_modules/bs-recipes/recipes/server.middleware/readme.html": {
    "href": "node_modules/bs-recipes/recipes/server.middleware/readme.html",
    "title": "| accouter",
    "keywords": "#Browsersync - Server + Logging + History API fallback middlewares Example Installation/Usage: To try this example, follow these 4 simple steps. Step 1: Clone this entire repo $ git clone https://github.com/Browsersync/recipes.git bs-recipes Step 2: Move into the directory containing this example $ cd bs-recipes/recipes/server.middleware Step 3: Install dependencies $ npm install Step 4: Run the example $ npm start Additional Info: This example adds the connect-logger middleware Preview of app.js: /** * Require Browsersync */ var browserSync = require('browser-sync').create(); var historyApiFallback = require('connect-history-api-fallback') /** * Run Browsersync with server config */ browserSync.init({ server: \"app\", files: [\"app/*.html\", \"app/css/*.css\"], middleware: [require(\"connect-logger\")(), historyApiFallback()] });"
  },
  "node_modules/bs-recipes/recipes/server/desc.html": {
    "href": "node_modules/bs-recipes/recipes/server/desc.html",
    "title": "| accouter",
    "keywords": "To see the live-updating and CSS injecting, simply perform changes to either index.html or css/main.css"
  },
  "node_modules/bs-recipes/recipes/server/readme.html": {
    "href": "node_modules/bs-recipes/recipes/server/readme.html",
    "title": "| accouter",
    "keywords": "#Browsersync - Server example Installation/Usage: To try this example, follow these 4 simple steps. Step 1: Clone this entire repo $ git clone https://github.com/Browsersync/recipes.git bs-recipes Step 2: Move into the directory containing this example $ cd bs-recipes/recipes/server Step 3: Install dependencies $ npm install Step 4: Run the example $ npm start Additional Info: To see the live-updating and CSS injecting, simply perform changes to either index.html or css/main.css Preview of app.js: /** * Require Browsersync */ var browserSync = require('browser-sync'); /** * Run Browsersync with server config */ browserSync({ server: \"app\", files: [\"app/*.html\", \"app/css/*.css\"] });"
  },
  "node_modules/bs-recipes/recipes/webpack.babel/desc.html": {
    "href": "node_modules/bs-recipes/recipes/webpack.babel/desc.html",
    "title": "| accouter",
    "keywords": "Edit any files within the src folder"
  },
  "node_modules/bs-recipes/recipes/webpack.babel/readme.html": {
    "href": "node_modules/bs-recipes/recipes/webpack.babel/readme.html",
    "title": "| accouter",
    "keywords": "#Browsersync - Webpack + Babel Installation/Usage: To try this example, follow these 4 simple steps. Step 1: Clone this entire repo $ git clone https://github.com/Browsersync/recipes.git bs-recipes Step 2: Move into the directory containing this example $ cd bs-recipes/recipes/webpack.babel Step 3: Install dependencies $ npm install Step 4: Run the example $ npm start Additional Info: Edit any files within the src folder Preview of app.js: /** * Require Browsersync along with webpack and middleware for it */ var browserSync = require('browser-sync').create(); var webpack = require('webpack'); var webpackDevMiddleware = require('webpack-dev-middleware'); var stripAnsi = require('strip-ansi'); /** * Require ./webpack.config.js and make a bundler from it */ var webpackConfig = require('./webpack.config'); var bundler = webpack(webpackConfig); /** * Reload all devices when bundle is complete * or send a fullscreen error message to the browser instead */ bundler.plugin('done', function (stats) { if (stats.hasErrors() || stats.hasWarnings()) { return browserSync.sockets.emit('fullscreen:message', { title: \"Webpack Error:\", body: stripAnsi(stats.toString()), timeout: 100000 }); } browserSync.reload(); }); /** * Run Browsersync and use middleware for Hot Module Replacement */ browserSync.init({ server: 'app', open: false, logFileChanges: false, middleware: [ webpackDevMiddleware(bundler, { publicPath: webpackConfig.output.publicPath, stats: {colors: true} }) ], plugins: ['bs-fullscreen-message'], files: [ 'app/css/*.css', 'app/*.html' ] });"
  },
  "node_modules/bs-recipes/recipes/webpack.monkey-hot-loader/desc.html": {
    "href": "node_modules/bs-recipes/recipes/webpack.monkey-hot-loader/desc.html",
    "title": "| accouter",
    "keywords": "To see monkey-hot-loader in action, edit top-level functions (inc, dec) inside main.js file"
  },
  "node_modules/bs-recipes/recipes/webpack.monkey-hot-loader/readme.html": {
    "href": "node_modules/bs-recipes/recipes/webpack.monkey-hot-loader/readme.html",
    "title": "| accouter",
    "keywords": "#Browsersync - Webpack + Monkey Hot Loader Installation/Usage: To try this example, follow these 4 simple steps. Step 1: Clone this entire repo $ git clone https://github.com/Browsersync/recipes.git bs-recipes Step 2: Move into the directory containing this example $ cd bs-recipes/recipes/webpack.monkey-hot-loader Step 3: Install dependencies $ npm install Step 4: Run the example $ npm start Additional Info: To see monkey-hot-loader in action, edit top-level functions (inc, dec) inside main.js file Preview of app.js: /** * Require Browsersync along with webpack and middleware for it */ var browserSync = require('browser-sync'); var webpack = require('webpack'); var webpackDevMiddleware = require('webpack-dev-middleware'); var webpackHotMiddleware = require('webpack-hot-middleware'); /** * Require ./webpack.config.js and make a bundler from it */ var webpackConfig = require('./webpack.config'); var bundler = webpack(webpackConfig); /** * Run Browsersync and use middleware for Hot Module Replacement */ browserSync({ server: { baseDir: 'app', middleware: [ webpackDevMiddleware(bundler, { // IMPORTANT: dev middleware can't access config, so we should // provide publicPath by ourselves publicPath: webpackConfig.output.publicPath, // pretty colored output stats: { colors: true } // for other settings see // http://webpack.github.io/docs/webpack-dev-middleware.html }), // bundler should be the same as above webpackHotMiddleware(bundler) ] }, // no need to watch '*.js' here, webpack will take care of it for us, // including full page reloads if HMR won't work files: [ 'app/css/*.css', 'app/*.html' ] });"
  },
  "node_modules/bs-recipes/recipes/webpack.preact-hot-loader/desc.html": {
    "href": "node_modules/bs-recipes/recipes/webpack.preact-hot-loader/desc.html",
    "title": "| accouter",
    "keywords": "To see preact-hot-loader in action, edit js/HelloWorld.jsx"
  },
  "node_modules/bs-recipes/recipes/webpack.preact-hot-loader/readme.html": {
    "href": "node_modules/bs-recipes/recipes/webpack.preact-hot-loader/readme.html",
    "title": "| accouter",
    "keywords": "#Browsersync - Webpack + Preact Hot Loader Installation/Usage: To try this example, follow these 4 simple steps. Step 1: Clone this entire repo $ git clone https://github.com/Browsersync/recipes.git bs-recipes Step 2: Move into the directory containing this example $ cd bs-recipes/recipes/webpack.preact-hot-loader Step 3: Install dependencies $ npm install Step 4: Run the example $ npm start Additional Info: To see preact-hot-loader in action, edit js/HelloWorld.jsx Preview of app.js: /** * Require Browsersync along with webpack and middleware for it */ var browserSync = require('browser-sync').create(); var webpack = require('webpack'); var webpackDevMiddleware = require('webpack-dev-middleware'); var webpackHotMiddleware = require('webpack-hot-middleware'); /** * Require ./webpack.config.js and make a bundler from it */ var webpackConfig = require('./webpack.config.dev'); var bundler = webpack(webpackConfig); /** * */ browserSync.init({ server: 'app', middleware: [ webpackDevMiddleware(bundler, { // IMPORTANT: dev middleware can't access config, so we should // provide publicPath by ourselves publicPath: webpackConfig.output.publicPath, // pretty colored output stats: {colors: true} // for other settings see // http://webpack.github.io/docs/webpack-dev-middleware.html }), // bundler should be the same as above webpackHotMiddleware(bundler) ], // no need to watch '*.js' here, webpack will take care of it for us, // including full page reloads if HMR won't work files: [ 'app/css/*.css', 'app/*.html' ] });"
  },
  "node_modules/bs-recipes/recipes/webpack.react-hot-loader/desc.html": {
    "href": "node_modules/bs-recipes/recipes/webpack.react-hot-loader/desc.html",
    "title": "| accouter",
    "keywords": "To see react-hot-loader in action, edit js/HelloWorld.jsx"
  },
  "node_modules/bs-recipes/recipes/webpack.react-hot-loader/readme.html": {
    "href": "node_modules/bs-recipes/recipes/webpack.react-hot-loader/readme.html",
    "title": "| accouter",
    "keywords": "#Browsersync - Webpack + React Hot Loader Installation/Usage: To try this example, follow these 4 simple steps. Step 1: Clone this entire repo $ git clone https://github.com/Browsersync/recipes.git bs-recipes Step 2: Move into the directory containing this example $ cd bs-recipes/recipes/webpack.react-hot-loader Step 3: Install dependencies $ npm install Step 4: Run the example $ npm start Additional Info: To see react-hot-loader in action, edit js/HelloWorld.jsx Preview of app.js: /** * Require Browsersync along with webpack and middleware for it */ var browserSync = require('browser-sync'); var webpack = require('webpack'); var webpackDevMiddleware = require('webpack-dev-middleware'); var webpackHotMiddleware = require('webpack-hot-middleware'); /** * Require ./webpack.config.js and make a bundler from it */ var webpackConfig = require('./webpack.config'); var bundler = webpack(webpackConfig); /** * Run Browsersync and use middleware for Hot Module Replacement */ browserSync({ server: { baseDir: 'app', middleware: [ webpackDevMiddleware(bundler, { // IMPORTANT: dev middleware can't access config, so we should // provide publicPath by ourselves publicPath: webpackConfig.output.publicPath, // pretty colored output stats: { colors: true } // for other settings see // http://webpack.github.io/docs/webpack-dev-middleware.html }), // bundler should be the same as above webpackHotMiddleware(bundler) ] }, // no need to watch '*.js' here, webpack will take care of it for us, // including full page reloads if HMR won't work files: [ 'app/css/*.css', 'app/*.html' ] });"
  },
  "node_modules/bs-recipes/recipes/webpack.react-transform-hmr/desc.html": {
    "href": "node_modules/bs-recipes/recipes/webpack.react-transform-hmr/desc.html",
    "title": "| accouter",
    "keywords": "To see react-transform-hmr in action, edit js/HelloWorld.jsx"
  },
  "node_modules/bs-recipes/recipes/webpack.react-transform-hmr/readme.html": {
    "href": "node_modules/bs-recipes/recipes/webpack.react-transform-hmr/readme.html",
    "title": "| accouter",
    "keywords": "#Browsersync - Webpack + React Transform HMR Installation/Usage: To try this example, follow these 4 simple steps. Step 1: Clone this entire repo $ git clone https://github.com/Browsersync/recipes.git bs-recipes Step 2: Move into the directory containing this example $ cd bs-recipes/recipes/webpack.react-transform-hmr Step 3: Install dependencies $ npm install Step 4: Run the example $ npm start Additional Info: To see react-transform-hmr in action, edit js/HelloWorld.jsx Preview of app.js: /** * Require Browsersync along with webpack and middleware for it */ var browserSync = require('browser-sync'); var webpack = require('webpack'); var webpackDevMiddleware = require('webpack-dev-middleware'); var webpackHotMiddleware = require('webpack-hot-middleware'); /** * Require ./webpack.config.js and make a bundler from it */ var webpackConfig = require('./webpack.config'); var bundler = webpack(webpackConfig); /** * Run Browsersync and use middleware for Hot Module Replacement */ browserSync({ server: { baseDir: 'app', middleware: [ webpackDevMiddleware(bundler, { // IMPORTANT: dev middleware can't access config, so we should // provide publicPath by ourselves publicPath: webpackConfig.output.publicPath, // pretty colored output stats: { colors: true } // for other settings see // http://webpack.github.io/docs/webpack-dev-middleware.html }), // bundler should be the same as above webpackHotMiddleware(bundler) ] }, // no need to watch '*.js' here, webpack will take care of it for us, // including full page reloads if HMR won't work files: [ 'app/css/*.css', 'app/*.html' ] });"
  },
  "node_modules/bs-recipes/recipes/webpack.typescript.react/desc.html": {
    "href": "node_modules/bs-recipes/recipes/webpack.typescript.react/desc.html",
    "title": "| accouter",
    "keywords": "Run npm run preview for the 8k (zipped) production version"
  },
  "node_modules/bs-recipes/recipes/webpack.typescript.react/readme.html": {
    "href": "node_modules/bs-recipes/recipes/webpack.typescript.react/readme.html",
    "title": "| accouter",
    "keywords": "#Browsersync - Webpack, TypeScript + React Installation/Usage: To try this example, follow these 4 simple steps. Step 1: Clone this entire repo $ git clone https://github.com/Browsersync/recipes.git bs-recipes Step 2: Move into the directory containing this example $ cd bs-recipes/recipes/webpack.typescript.react Step 3: Install dependencies $ npm install Step 4: Run the example $ npm start Additional Info: Run npm run preview for the 8k (zipped) production version Preview of app.js: /** * Require Browsersync along with webpack and middleware for it */ var browserSync = require('browser-sync').create(); var webpack = require('webpack'); var webpackDevMiddleware = require('webpack-dev-middleware'); var stripAnsi = require('strip-ansi'); /** * Require ./webpack.config.js and make a bundler from it */ var webpackConfig = require('./webpack.dev.config'); var bundler = webpack(webpackConfig); /** * Reload all devices when bundle is complete * or send a fullscreen error message to the browser instead */ bundler.plugin('done', function (stats) { if (stats.hasErrors() || stats.hasWarnings()) { return browserSync.sockets.emit('fullscreen:message', { title: \"Webpack Error:\", body: stripAnsi(stats.toString()), timeout: 100000 }); } browserSync.reload(); }); /** * Run Browsersync and use middleware for Hot Module Replacement */ browserSync.init({ server: 'app', logFileChanges: false, middleware: [ webpackDevMiddleware(bundler, { publicPath: webpackConfig.output.publicPath, stats: {colors: true} }) ], plugins: ['bs-fullscreen-message'], files: [ 'app/css/*.css', 'app/*.html' ] });"
  },
  "node_modules/bs-recipes/recipes/webpack.typescript/desc.html": {
    "href": "node_modules/bs-recipes/recipes/webpack.typescript/desc.html",
    "title": "| accouter",
    "keywords": "See src/main.ts"
  },
  "node_modules/bs-recipes/recipes/webpack.typescript/readme.html": {
    "href": "node_modules/bs-recipes/recipes/webpack.typescript/readme.html",
    "title": "| accouter",
    "keywords": "#Browsersync - Webpack + TypeScript Installation/Usage: To try this example, follow these 4 simple steps. Step 1: Clone this entire repo $ git clone https://github.com/Browsersync/recipes.git bs-recipes Step 2: Move into the directory containing this example $ cd bs-recipes/recipes/webpack.typescript Step 3: Install dependencies $ npm install Step 4: Run the example $ npm start Additional Info: See src/main.ts Preview of app.js: /** * Require Browsersync along with webpack and middleware for it */ var browserSync = require('browser-sync').create(); var webpack = require('webpack'); var webpackDevMiddleware = require('webpack-dev-middleware'); var stripAnsi = require('strip-ansi'); /** * Require ./webpack.config.js and make a bundler from it */ var webpackConfig = require('./webpack.config'); var bundler = webpack(webpackConfig); /** * Reload all devices when bundle is complete * or send a fullscreen error message to the browser instead */ bundler.plugin('done', function (stats) { if (stats.hasErrors() || stats.hasWarnings()) { return browserSync.sockets.emit('fullscreen:message', { title: \"Webpack Error:\", body: stripAnsi(stats.toString()), timeout: 100000 }); } browserSync.reload(); }); /** * Run Browsersync and use middleware for Hot Module Replacement */ browserSync.init({ server: 'app', open: false, logFileChanges: false, middleware: [ webpackDevMiddleware(bundler, { publicPath: webpackConfig.output.publicPath, stats: {colors: true} }) ], plugins: ['bs-fullscreen-message'], files: [ 'app/css/*.css', 'app/*.html' ] });"
  },
  "node_modules/bytes/History.html": {
    "href": "node_modules/bytes/History.html",
    "title": "3.1.2 / 2022-01-27 | accouter",
    "keywords": "3.1.2 / 2022-01-27 Fix return value for un-parsable strings 3.1.1 / 2021-11-15 Fix \"thousandsSeparator\" incorrecting formatting fractional part 3.1.0 / 2019-01-22 Add petabyte (pb) support 3.0.0 / 2017-08-31 Change \"kB\" to \"KB\" in format output Remove support for Node.js 0.6 Remove support for ComponentJS 2.5.0 / 2017-03-24 Add option \"unit\" 2.4.0 / 2016-06-01 Add option \"unitSeparator\" 2.3.0 / 2016-02-15 Drop partial bytes on all parsed units Fix non-finite numbers to .format to return null Fix parsing byte string that looks like hex perf: hoist regular expressions 2.2.0 / 2015-11-13 add option \"decimalPlaces\" add option \"fixedDecimals\" 2.1.0 / 2015-05-21 add .format export add .parse export 2.0.2 / 2015-05-20 remove map recreation remove unnecessary object construction 2.0.1 / 2015-05-07 fix browserify require remove node.extend dependency 2.0.0 / 2015-04-12 add option \"case\" add option \"thousandsSeparator\" return \"null\" on invalid parse input support proper round-trip: bytes(bytes(num)) === num units no longer case sensitive when parsing 1.0.0 / 2014-05-05 add negative support. fixes #6 0.3.0 / 2014-03-19 added terabyte support 0.2.1 / 2013-04-01 add .component 0.2.0 / 2012-10-28 bytes(200).should.eql('200b') 0.1.0 / 2012-07-04 add bytes to string conversion [yields]"
  },
  "node_modules/bytes/Readme.html": {
    "href": "node_modules/bytes/Readme.html",
    "title": "Bytes utility | accouter",
    "keywords": "Bytes utility Utility to parse a string bytes (ex: 1TB) to bytes (1099511627776) and vice-versa. Installation This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install bytes Usage var bytes = require('bytes'); bytes(number｜string value, [options]): number｜string｜null Default export function. Delegates to either bytes.format or bytes.parse based on the type of value. Arguments Name Type Description value number｜string Number value to format or string value to parse options Object Conversion options for format Returns Name Type Description results string｜number｜null Return null upon error. Numeric value in bytes, or string value otherwise. Example bytes(1024); // output: '1KB' bytes('1KB'); // output: 1024 bytes.format(number value, [options]): string｜null Format the given value in bytes into a string. If the value is negative, it is kept as such. If it is a float, it is rounded. Arguments Name Type Description value number Value in bytes options Object Conversion options Options Property Type Description decimalPlaces number｜null Maximum number of decimal places to include in output. Default value to 2. fixedDecimals boolean｜null Whether to always display the maximum number of decimal places. Default value to false thousandsSeparator string｜null Example of values: ' ', ',' and '.'... Default value to ''. unit string｜null The unit in which the result will be returned (B/KB/MB/GB/TB). Default value to '' (which means auto detect). unitSeparator string｜null Separator to use between number and unit. Default value to ''. Returns Name Type Description results string｜null Return null upon error. String value otherwise. Example bytes.format(1024); // output: '1KB' bytes.format(1000); // output: '1000B' bytes.format(1000, {thousandsSeparator: ' '}); // output: '1 000B' bytes.format(1024 * 1.7, {decimalPlaces: 0}); // output: '2KB' bytes.format(1024, {unitSeparator: ' '}); // output: '1 KB' bytes.parse(string｜number value): number｜null Parse the string value into an integer in bytes. If no unit is given, or value is a number, it is assumed the value is in bytes. Supported units and abbreviations are as follows and are case-insensitive: b for bytes kb for kilobytes mb for megabytes gb for gigabytes tb for terabytes pb for petabytes The units are in powers of two, not ten. This means 1kb = 1024b according to this parser. Arguments Name Type Description value string｜number String to parse, or number in bytes. Returns Name Type Description results number｜null Return null upon error. Value in bytes otherwise. Example bytes.parse('1KB'); // output: 1024 bytes.parse('1024'); // output: 1024 bytes.parse(1024); // output: 1024 License MIT"
  },
  "node_modules/call-bind/CHANGELOG.html": {
    "href": "node_modules/call-bind/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.7 - 2024-02-12 Commits [Refactor] use es-define-property 09b76a0 [Deps] update get-intrinsic, set-function-length ad5136d v1.0.6 - 2024-02-05 Commits [Dev Deps] update aud, npmignore, tape d564d5c [Deps] update get-intrinsic, set-function-length cfc2bdc [Refactor] use es-errors, so things that only need those do not need get-intrinsic 64cd289 [meta] add missing engines.node 32a4038 v1.0.5 - 2023-10-19 Commits [Fix] throw an error on non-functions as early as possible f262408 [Deps] update set-function-length 3fff271 v1.0.4 - 2023-10-19 v1.0.3 - 2023-10-19 Commits [actions] reuse common workflows a994df6 [meta] use npmignore to autogenerate an npmignore file eef3ef2 [readme] flesh out content 1845ccf [actions] use node/install instead of node/run; use codecov action 5b47d53 [Refactor] use set-function-length a0e165c [Dev Deps] update @ljharb/eslint-config, aud, tape 9c50103 [meta] simplify \"exports\" 019c6d0 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, safe-publish-latest, tape 23bd718 [actions] update codecov uploader 62552d7 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape ec81665 [Dev Deps] update eslint, @ljharb/eslint-config, safe-publish-latest, tape 35d67fc [Dev Deps] update eslint, @ljharb/eslint-config, aud, tape 0266d8d [Dev Deps] update @ljharb/eslint-config, aud, tape 43a5b28 [Deps] update define-data-property, function-bind, get-intrinsic 780eb36 [Dev Deps] update aud, tape 90d50ad [meta] use prepublishOnly script for npm 7+ 44c5433 [Deps] update get-intrinsic 86bfbfc [Deps] update get-intrinsic 5c53354 [actions] update checkout action 4c393a8 [Deps] update get-intrinsic 4e70bde [Deps] update get-intrinsic 55ae803 v1.0.2 - 2021-01-11 Commits [Fix] properly include the receiver in the bound length dbae7bc v1.0.1 - 2021-01-08 Commits [Tests] migrate tests to Github Actions b6db284 [meta] do not publish github action workflow files ec7fe46 [Fix] preserve original function’s length when possible adbceaa [Tests] gather coverage data on every job d69e23c [Dev Deps] update eslint, @ljharb/eslint-config, aud, tape 2fd3586 [Deps] update get-intrinsic f23e931 [Deps] update get-intrinsic 72d9f44 [meta] fix FUNDING.yml e723573 [eslint] ignore coverage output 15e76d2 [meta] add Automatic Rebase and Require Allow Edits workflows 8fa4dab v1.0.0 - 2020-10-30 Commits Initial commit 306cf98 Tests e10d0bb Implementation 43852ed npm init 408f860 [meta] add Automatic Rebase and Require Allow Edits workflows fb349b2 [meta] add auto-changelog c4001fc [meta] add \"funding\"; create FUNDING.yml d4d6d29 [Tests] add npm run lint dedfb98 Only apps should have lockfiles 54ac776 [meta] add safe-publish-latest 9ea8e43"
  },
  "node_modules/call-bind/README.html": {
    "href": "node_modules/call-bind/README.html",
    "title": "call-bind | accouter",
    "keywords": "call-bind Robustly .call.bind() a function. Getting started npm install --save call-bind Usage/Examples const assert = require('assert'); const callBind = require('call-bind'); const callBound = require('call-bind/callBound'); function f(a, b) { assert.equal(this, 1); assert.equal(a, 2); assert.equal(b, 3); assert.equal(arguments.length, 2); } const fBound = callBind(f); const slice = callBound('Array.prototype.slice'); delete Function.prototype.call; delete Function.prototype.bind; fBound(1, 2, 3); assert.deepEqual(slice([1, 2, 3, 4], 1, -1), [2, 3]); Tests Clone the repo, npm install, and run npm test"
  },
  "node_modules/camelcase/readme.html": {
    "href": "node_modules/camelcase/readme.html",
    "title": "camelcase | accouter",
    "keywords": "camelcase Convert a dash/dot/underscore/space separated string to camelCase or PascalCase: foo-bar → fooBar Correctly handles Unicode strings. If you use this on untrusted user input, don't forget to limit the length to something reasonable. Install $ npm install camelcase If you need to support Firefox < 78, stay on version 5 as version 6 uses regex features not available in Firefox < 78. Usage const camelCase = require('camelcase'); camelCase('foo-bar'); //=> 'fooBar' camelCase('foo_bar'); //=> 'fooBar' camelCase('Foo-Bar'); //=> 'fooBar' camelCase('розовый_пушистый_единорог'); //=> 'розовыйПушистыйЕдинорог' camelCase('Foo-Bar', {pascalCase: true}); //=> 'FooBar' camelCase('--foo.bar', {pascalCase: false}); //=> 'fooBar' camelCase('Foo-BAR', {preserveConsecutiveUppercase: true}); //=> 'fooBAR' camelCase('fooBAR', {pascalCase: true, preserveConsecutiveUppercase: true})); //=> 'FooBAR' camelCase('foo bar'); //=> 'fooBar' console.log(process.argv[3]); //=> '--foo-bar' camelCase(process.argv[3]); //=> 'fooBar' camelCase(['foo', 'bar']); //=> 'fooBar' camelCase(['__foo__', '--bar'], {pascalCase: true}); //=> 'FooBar' camelCase(['foo', 'BAR'], {pascalCase: true, preserveConsecutiveUppercase: true}) //=> 'FooBAR' camelCase('lorem-ipsum', {locale: 'en-US'}); //=> 'loremIpsum' API camelCase(input, options?) input Type: string | string[] String to convert to camel case. options Type: object pascalCase Type: boolean Default: false Uppercase the first character: foo-bar → FooBar preserveConsecutiveUppercase Type: boolean Default: false Preserve the consecutive uppercase characters: foo-BAR → FooBAR. locale Type: false | string | string[] Default: The host environment’s current locale. The locale parameter indicates the locale to be used to convert to upper/lower case according to any locale-specific case mappings. If multiple locales are given in an array, the best available locale is used. const camelCase = require('camelcase'); camelCase('lorem-ipsum', {locale: 'en-US'}); //=> 'loremIpsum' camelCase('lorem-ipsum', {locale: 'tr-TR'}); //=> 'loremİpsum' camelCase('lorem-ipsum', {locale: ['en-US', 'en-GB']}); //=> 'loremIpsum' camelCase('lorem-ipsum', {locale: ['tr', 'TR', 'tr-TR']}); //=> 'loremİpsum' Setting locale: false ignores the platform locale and uses the Unicode Default Case Conversion algorithm: const camelCase = require('camelcase'); // On a platform with 'tr-TR' camelCase('lorem-ipsum'); //=> 'loremİpsum' camelCase('lorem-ipsum', {locale: false}); //=> 'loremIpsum' camelcase for enterprise Available as part of the Tidelift Subscription. The maintainers of camelcase and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more. Related decamelize - The inverse of this module uppercamelcase - Like this module, but to PascalCase instead of camelCase titleize - Capitalize every word in string humanize-string - Convert a camelized/dasherized/underscored string into a humanized one camelcase-keys - Convert object keys to camel case"
  },
  "node_modules/caniuse-api/CHANGELOG.html": {
    "href": "node_modules/caniuse-api/CHANGELOG.html",
    "title": "3.0.0 - 2018-07-10 | accouter",
    "keywords": "3.0.0 - 2018-07-10 Upgraded: browserslist 2.1.0 - 2018-06-06 (never released to npm) Upgraded: browserslist, caniuse-lite 2.0.0 - 2017-05-03 Changed: we now use caniuse-lite instead if caniuse-db (#59) 1.6.1 - 2017-04-07 Added: export the feature list (#48) 1.5.3 - 2017-02-01 Removed unused dependency (#54 - @wtgtybhertgeghgtwtg) 1.5.2 - 2016-09-05 Fixed: no more generation postinstall hook \\o/. (#47 - @alexisvincent) 1.5.1 - 2016-08-06 Fixed: Do not fail when browserslist gives a browser that caniuse-api doesn't know about (#45 - @onigoetz) 1.5.0 - 2016-06-01 Added: JSPM support with explicit file extensions (#40) Upgraded: dependecies (lodash.memoize, lodash.uniq, shelljs, babel-tape-runner, tape, tap-spec) Upgraded: ask travis to only test node stable Upgraded: some tests fixed, some tests added 1.4.1 - 2015-10-18 Fixed: generator.js was missing 1.4.0 - 2015-10-18 Upgraded: browserslist 1.x Upgraded: shelljs 0.5.x Added: output to notify if generation has been made or not (related to #25) 1.3.2 - 2015-06-23 Fixed: lodash.uniq dep (#31) 1.3.1 - 2015-03-31 Fixed: Windows support 1.3.0 - 2015-03-30 Added: better exception messages Added: full browserify compatibility (by avoiding dynamic require) 1.2.2 - 2015-02-06 Fixed: postinstall hook for Windows 1.2.1 - 2015-02-04 Changed: Allow in browser usage by avoiding require.resolve and using a generated json instead or reading a directory (#20] 1.2.0 [YANKED] 1.1.0 - 2015-02-03 Fixed: usage of caniuse-db outside the package itself Changed: upgrade to browserslist 0.2.x 1.0.0 - 2014-12-16 Added: package is now automatically tested by Travis-CI 0.1.0 - 2014-12-15 Changed: complete API changes, released as caniuse-api package 0.0.1 - 2014-12-09 ✨Initial release"
  },
  "node_modules/caniuse-api/README.html": {
    "href": "node_modules/caniuse-api/README.html",
    "title": "caniuse-api | accouter",
    "keywords": "caniuse-api request the caniuse data to check browsers compatibilities Installation $ yarn add caniuse-api Usage const caniuse = require('caniuse-api') caniuse.getSupport('border-radius') caniuse.isSupported('border-radius', 'ie 8, ie 9') caniuse.setBrowserScope('> 5%, last 1 version') caniuse.getSupport('border-radius') // ... API caniuse.getSupport(feature) ask since which browsers versions a feature is available y: Since which browser version the feature is available n: Up to which browser version the feature is unavailable a: Up to which browser version the feature is partially supported x: Up to which browser version the feature is prefixed caniuse.getSupport('border-radius', true) /* { and_chr: { y: 67 }, and_ff: { y: 60 }, and_qq: { y: 1.2 }, and_uc: { y: 11.8 }, android: { y: 2.1, x: 2.1 }, baidu: { y: 7.12 }, chrome: { y: 4, x: 4 }, edge: { y: 12 }, firefox: { a: 2, x: 3.6, y: 3 }, ie: { n: 8, y: 9 }, ie_mob: { y: 10 }, ios_saf: { y: 3.2, x: 3.2 }, op_mini: {}, op_mob: { n: 10, y: 11 }, opera: { n: 10, y: 10.5 }, safari: { y: 3.1, x: 4 }, samsung: { y: 4 } } */ caniuse.isSupported(feature, browsers) ask if a feature is supported by some browsers caniuse.isSupported('border-radius', 'ie 8, ie 9') // false caniuse.isSupported('border-radius', 'ie 9') // true caniuse.find(query) search for a caniuse feature name Ex: caniuse.find('radius') // ['border-radius'] caniuse.find('nothingness') // [] caniuse.find('css3') /* [ 'css3-attr', 'css3-boxsizing', 'css3-colors', 'css3-cursors-grab', 'css3-cursors-newer', 'css3-cursors', 'css3-tabsize' ] */ caniuse.getLatestStableBrowsers() get the current version for each browser caniuse.getLatestStableBrowsers() /* [ 'and_chr 67', 'and_ff 60', 'and_qq 1.2', 'and_uc 11.8', 'android 67', 'baidu 7.12', 'bb 10', 'chrome 67', 'edge 17', 'firefox 61', 'ie 11', 'ie_mob 11', 'ios_saf 11.3-11.4', 'op_mini all', 'op_mob 46', 'opera 53', 'safari 11.1', 'samsung 7.2' ] */ caniuse.getBrowserScope() returns a list of browsers currently used for the scope of operations caniuse.getBrowserScope() /* [ 'and_chr', 'and_ff', 'and_qq', 'and_uc', 'android', 'baidu', 'chrome', 'edge', 'firefox', 'ie', 'ie_mob', 'ios_saf', 'op_mini', 'op_mob', 'opera', 'safari', 'samsung' ] */ caniuse.setBrowserScope(browserscope) if you do not like the default browser scope, you can set it globally by using this method browserscope should be a 'autoprefixer' formatted string caniuse.setBrowserScope('> 5%, last 2 versions, Firefox ESR, Opera 12.1') Changelog License"
  },
  "node_modules/caniuse-lite/README.html": {
    "href": "node_modules/caniuse-lite/README.html",
    "title": "caniuse-lite | accouter",
    "keywords": "caniuse-lite A smaller version of caniuse-db, with only the essentials! Docs Read full docs here."
  },
  "node_modules/chalk/readme.html": {
    "href": "node_modules/chalk/readme.html",
    "title": "| accouter",
    "keywords": "Terminal string styling done right Sindre Sorhus' open source work is supported by the community on GitHub Sponsors and Dev Special thanks to: All your environment variables, in one place Stop struggling with scattered API keys, hacking together home-brewed tools, and avoiding access controls. Keep your team and servers in sync with Doppler. Highlights Expressive API Highly performant Ability to nest styles 256/Truecolor color support Auto-detects color support Doesn't extend String.prototype Clean and focused Actively maintained Used by ~50,000 packages as of January 1, 2020 Install $ npm install chalk Usage const chalk = require('chalk'); console.log(chalk.blue('Hello world!')); Chalk comes with an easy to use composable API where you just chain and nest the styles you want. const chalk = require('chalk'); const log = console.log; // Combine styled and normal strings log(chalk.blue('Hello') + ' World' + chalk.red('!')); // Compose multiple styles using the chainable API log(chalk.blue.bgRed.bold('Hello world!')); // Pass in multiple arguments log(chalk.blue('Hello', 'World!', 'Foo', 'bar', 'biz', 'baz')); // Nest styles log(chalk.red('Hello', chalk.underline.bgBlue('world') + '!')); // Nest styles of the same type even (color, underline, background) log(chalk.green( 'I am a green line ' + chalk.blue.underline.bold('with a blue substring') + ' that becomes green again!' )); // ES2015 template literal log(` CPU: ${chalk.red('90%')} RAM: ${chalk.green('40%')} DISK: ${chalk.yellow('70%')} `); // ES2015 tagged template literal log(chalk` CPU: {red ${cpu.totalPercent}%} RAM: {green ${ram.used / ram.total * 100}%} DISK: {rgb(255,131,0) ${disk.used / disk.total * 100}%} `); // Use RGB colors in terminal emulators that support it. log(chalk.keyword('orange')('Yay for orange colored text!')); log(chalk.rgb(123, 45, 67).underline('Underlined reddish color')); log(chalk.hex('#DEADED').bold('Bold gray!')); Easily define your own themes: const chalk = require('chalk'); const error = chalk.bold.red; const warning = chalk.keyword('orange'); console.log(error('Error!')); console.log(warning('Warning!')); Take advantage of console.log string substitution: const name = 'Sindre'; console.log(chalk.green('Hello %s'), name); //=> 'Hello Sindre' API chalk.<style>[.<style>...](string, [string...]) Example: chalk.red.bold.underline('Hello', 'world'); Chain styles and call the last one as a method with a string argument. Order doesn't matter, and later styles take precedent in case of a conflict. This simply means that chalk.red.yellow.green is equivalent to chalk.green. Multiple arguments will be separated by space. chalk.level Specifies the level of color support. Color support is automatically detected, but you can override it by setting the level property. You should however only do this in your own code as it applies globally to all Chalk consumers. If you need to change this in a reusable module, create a new instance: const ctx = new chalk.Instance({level: 0}); Level Description 0 All colors disabled 1 Basic color support (16 colors) 2 256 color support 3 Truecolor support (16 million colors) chalk.supportsColor Detect whether the terminal supports color. Used internally and handled for you, but exposed for convenience. Can be overridden by the user with the flags --color and --no-color. For situations where using --color is not possible, use the environment variable FORCE_COLOR=1 (level 1), FORCE_COLOR=2 (level 2), or FORCE_COLOR=3 (level 3) to forcefully enable color, or FORCE_COLOR=0 to forcefully disable. The use of FORCE_COLOR overrides all other color support checks. Explicit 256/Truecolor mode can be enabled using the --color=256 and --color=16m flags, respectively. chalk.stderr and chalk.stderr.supportsColor chalk.stderr contains a separate instance configured with color support detected for stderr stream instead of stdout. Override rules from chalk.supportsColor apply to this too. chalk.stderr.supportsColor is exposed for convenience. Styles Modifiers reset - Resets the current color chain. bold - Make text bold. dim - Emitting only a small amount of light. italic - Make text italic. (Not widely supported) underline - Make text underline. (Not widely supported) inverse- Inverse background and foreground colors. hidden - Prints the text, but makes it invisible. strikethrough - Puts a horizontal line through the center of the text. (Not widely supported) visible- Prints the text only when Chalk has a color level > 0. Can be useful for things that are purely cosmetic. Colors black red green yellow blue magenta cyan white blackBright (alias: gray, grey) redBright greenBright yellowBright blueBright magentaBright cyanBright whiteBright Background colors bgBlack bgRed bgGreen bgYellow bgBlue bgMagenta bgCyan bgWhite bgBlackBright (alias: bgGray, bgGrey) bgRedBright bgGreenBright bgYellowBright bgBlueBright bgMagentaBright bgCyanBright bgWhiteBright Tagged template literal Chalk can be used as a tagged template literal. const chalk = require('chalk'); const miles = 18; const calculateFeet = miles => miles * 5280; console.log(chalk` There are {bold 5280 feet} in a mile. In {bold ${miles} miles}, there are {green.bold ${calculateFeet(miles)} feet}. `); Blocks are delimited by an opening curly brace ({), a style, some content, and a closing curly brace (}). Template styles are chained exactly like normal Chalk styles. The following three statements are equivalent: console.log(chalk.bold.rgb(10, 100, 200)('Hello!')); console.log(chalk.bold.rgb(10, 100, 200)`Hello!`); console.log(chalk`{bold.rgb(10,100,200) Hello!}`); Note that function styles (rgb(), hsl(), keyword(), etc.) may not contain spaces between parameters. All interpolated values (chalk`${foo}`) are converted to strings via the .toString() method. All curly braces ({ and }) in interpolated value strings are escaped. 256 and Truecolor color support Chalk supports 256 colors and Truecolor (16 million colors) on supported terminal apps. Colors are downsampled from 16 million RGB values to an ANSI color format that is supported by the terminal emulator (or by specifying {level: n} as a Chalk option). For example, Chalk configured to run at level 1 (basic color support) will downsample an RGB value of #FF0000 (red) to 31 (ANSI escape for red). Examples: chalk.hex('#DEADED').underline('Hello, world!') chalk.keyword('orange')('Some orange text') chalk.rgb(15, 100, 204).inverse('Hello!') Background versions of these models are prefixed with bg and the first level of the module capitalized (e.g. keyword for foreground colors and bgKeyword for background colors). chalk.bgHex('#DEADED').underline('Hello, world!') chalk.bgKeyword('orange')('Some orange text') chalk.bgRgb(15, 100, 204).inverse('Hello!') The following color models can be used: rgb - Example: chalk.rgb(255, 136, 0).bold('Orange!') hex - Example: chalk.hex('#FF8800').bold('Orange!') keyword (CSS keywords) - Example: chalk.keyword('orange').bold('Orange!') hsl - Example: chalk.hsl(32, 100, 50).bold('Orange!') hsv - Example: chalk.hsv(32, 100, 100).bold('Orange!') hwb - Example: chalk.hwb(32, 0, 50).bold('Orange!') ansi - Example: chalk.ansi(31).bgAnsi(93)('red on yellowBright') ansi256 - Example: chalk.bgAnsi256(194)('Honeydew, more or less') Windows If you're on Windows, do yourself a favor and use Windows Terminal instead of cmd.exe. Origin story colors.js used to be the most popular string styling module, but it has serious deficiencies like extending String.prototype which causes all kinds of problems and the package is unmaintained. Although there are other packages, they either do too much or not enough. Chalk is a clean and focused alternative. chalk for enterprise Available as part of the Tidelift Subscription. The maintainers of chalk and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more. Related chalk-cli - CLI for this module ansi-styles - ANSI escape codes for styling strings in the terminal supports-color - Detect whether a terminal supports color strip-ansi - Strip ANSI escape codes strip-ansi-stream - Strip ANSI escape codes from a stream has-ansi - Check if a string has ANSI escape codes ansi-regex - Regular expression for matching ANSI escape codes wrap-ansi - Wordwrap a string with ANSI escape codes slice-ansi - Slice a string with ANSI escape codes color-convert - Converts colors between different models chalk-animation - Animate strings in the terminal gradient-string - Apply color gradients to strings chalk-pipe - Create chalk style schemes with simpler style strings terminal-link - Create clickable links in the terminal Maintainers Sindre Sorhus Josh Junon"
  },
  "node_modules/chokidar/README.html": {
    "href": "node_modules/chokidar/README.html",
    "title": "Chokidar | accouter",
    "keywords": "Chokidar Minimal and efficient cross-platform file watching library Why? Node.js fs.watch: Doesn't report filenames on MacOS. Doesn't report events at all when using editors like Sublime on MacOS. Often reports events twice. Emits most changes as rename. Does not provide an easy way to recursively watch file trees. Does not support recursive watching on Linux. Node.js fs.watchFile: Almost as bad at event handling. Also does not provide any recursive watching. Results in high CPU utilization. Chokidar resolves these problems. Initially made for Brunch (an ultra-swift web app build tool), it is now used in Microsoft's Visual Studio Code, gulp, karma, PM2, browserify, webpack, BrowserSync, and many others. It has proven itself in production environments. Version 3 is out! Check out our blog post about it: Chokidar 3: How to save 32TB of traffic every week How? Chokidar does still rely on the Node.js core fs module, but when using fs.watch and fs.watchFile for watching, it normalizes the events it receives, often checking for truth by getting file stats and/or dir contents. On MacOS, chokidar by default uses a native extension exposing the Darwin FSEvents API. This provides very efficient recursive watching compared with implementations like kqueue available on most *nix platforms. Chokidar still does have to do some work to normalize the events received that way as well. On most other platforms, the fs.watch-based implementation is the default, which avoids polling and keeps CPU usage down. Be advised that chokidar will initiate watchers recursively for everything within scope of the paths that have been specified, so be judicious about not wasting system resources by watching much more than needed. Getting started Install with npm: npm install chokidar Then require and use it in your code: const chokidar = require('chokidar'); // One-liner for current directory chokidar.watch('.').on('all', (event, path) => { console.log(event, path); }); API // Example of a more typical implementation structure // Initialize watcher. const watcher = chokidar.watch('file, dir, glob, or array', { ignored: /(^|[\\/\\\\])\\../, // ignore dotfiles persistent: true }); // Something to use when events are received. const log = console.log.bind(console); // Add event listeners. watcher .on('add', path => log(`File ${path} has been added`)) .on('change', path => log(`File ${path} has been changed`)) .on('unlink', path => log(`File ${path} has been removed`)); // More possible events. watcher .on('addDir', path => log(`Directory ${path} has been added`)) .on('unlinkDir', path => log(`Directory ${path} has been removed`)) .on('error', error => log(`Watcher error: ${error}`)) .on('ready', () => log('Initial scan complete. Ready for changes')) .on('raw', (event, path, details) => { // internal log('Raw event info:', event, path, details); }); // 'add', 'addDir' and 'change' events also receive stat() results as second // argument when available: https://nodejs.org/api/fs.html#fs_class_fs_stats watcher.on('change', (path, stats) => { if (stats) console.log(`File ${path} changed size to ${stats.size}`); }); // Watch new files. watcher.add('new-file'); watcher.add(['new-file-2', 'new-file-3', '**/other-file*']); // Get list of actual paths being watched on the filesystem var watchedPaths = watcher.getWatched(); // Un-watch some files. await watcher.unwatch('new-file*'); // Stop watching. // The method is async! watcher.close().then(() => console.log('closed')); // Full list of options. See below for descriptions. // Do not use this example! chokidar.watch('file', { persistent: true, ignored: '*.txt', ignoreInitial: false, followSymlinks: true, cwd: '.', disableGlobbing: false, usePolling: false, interval: 100, binaryInterval: 300, alwaysStat: false, depth: 99, awaitWriteFinish: { stabilityThreshold: 2000, pollInterval: 100 }, ignorePermissionErrors: false, atomic: true // or a custom 'atomicity delay', in milliseconds (default 100) }); chokidar.watch(paths, [options]) paths (string or array of strings). Paths to files, dirs to be watched recursively, or glob patterns. Note: globs must not contain windows separators (\\), because that's how they work by the standard — you'll need to replace them with forward slashes (/). Note 2: for additional glob documentation, check out low-level library: picomatch. options (object) Options object as defined below: Persistence persistent (default: true). Indicates whether the process should continue to run as long as files are being watched. If set to false when using fsevents to watch, no more events will be emitted after ready, even if the process continues to run. Path filtering ignored (anymatch-compatible definition) Defines files/paths to be ignored. The whole relative or absolute path is tested, not just filename. If a function with two arguments is provided, it gets called twice per path - once with a single argument (the path), second time with two arguments (the path and the fs.Stats object of that path). ignoreInitial (default: false). If set to false then add/addDir events are also emitted for matching paths while instantiating the watching as chokidar discovers these file paths (before the ready event). followSymlinks (default: true). When false, only the symlinks themselves will be watched for changes instead of following the link references and bubbling events through the link's path. cwd (no default). The base directory from which watch paths are to be derived. Paths emitted with events will be relative to this. disableGlobbing (default: false). If set to true then the strings passed to .watch() and .add() are treated as literal path names, even if they look like globs. Performance usePolling (default: false). Whether to use fs.watchFile (backed by polling), or fs.watch. If polling leads to high CPU utilization, consider setting this to false. It is typically necessary to set this to true to successfully watch files over a network, and it may be necessary to successfully watch files in other non-standard situations. Setting to true explicitly on MacOS overrides the useFsEvents default. You may also set the CHOKIDAR_USEPOLLING env variable to true (1) or false (0) in order to override this option. Polling-specific settings (effective when usePolling: true) interval (default: 100). Interval of file system polling, in milliseconds. You may also set the CHOKIDAR_INTERVAL env variable to override this option. binaryInterval (default: 300). Interval of file system polling for binary files. (see list of binary extensions) useFsEvents (default: true on MacOS). Whether to use the fsevents watching interface if available. When set to true explicitly and fsevents is available this supercedes the usePolling setting. When set to false on MacOS, usePolling: true becomes the default. alwaysStat (default: false). If relying upon the fs.Stats object that may get passed with add, addDir, and change events, set this to true to ensure it is provided even in cases where it wasn't already available from the underlying watch events. depth (default: undefined). If set, limits how many levels of subdirectories will be traversed. awaitWriteFinish (default: false). By default, the add event will fire when a file first appears on disk, before the entire file has been written. Furthermore, in some cases some change events will be emitted while the file is being written. In some cases, especially when watching for large files there will be a need to wait for the write operation to finish before responding to a file creation or modification. Setting awaitWriteFinish to true (or a truthy value) will poll file size, holding its add and change events until the size does not change for a configurable amount of time. The appropriate duration setting is heavily dependent on the OS and hardware. For accurate detection this parameter should be relatively high, making file watching much less responsive. Use with caution. options.awaitWriteFinish can be set to an object in order to adjust timing params: awaitWriteFinish.stabilityThreshold (default: 2000). Amount of time in milliseconds for a file size to remain constant before emitting its event. awaitWriteFinish.pollInterval (default: 100). File size polling interval, in milliseconds. Errors ignorePermissionErrors (default: false). Indicates whether to watch files that don't have read permissions if possible. If watching fails due to EPERM or EACCES with this set to true, the errors will be suppressed silently. atomic (default: true if useFsEvents and usePolling are false). Automatically filters out artifacts that occur when using editors that use \"atomic writes\" instead of writing directly to the source file. If a file is re-added within 100 ms of being deleted, Chokidar emits a change event rather than unlink then add. If the default of 100 ms does not work well for you, you can override it by setting atomic to a custom value, in milliseconds. Methods & Events chokidar.watch() produces an instance of FSWatcher. Methods of FSWatcher: .add(path / paths): Add files, directories, or glob patterns for tracking. Takes an array of strings or just one string. .on(event, callback): Listen for an FS event. Available events: add, addDir, change, unlink, unlinkDir, ready, raw, error. Additionally all is available which gets emitted with the underlying event name and path for every event other than ready, raw, and error. raw is internal, use it carefully. .unwatch(path / paths): Stop watching files, directories, or glob patterns. Takes an array of strings or just one string. .close(): async Removes all listeners from watched files. Asynchronous, returns Promise. Use with await to ensure bugs don't happen. .getWatched(): Returns an object representing all the paths on the file system being watched by this FSWatcher instance. The object's keys are all the directories (using absolute paths unless the cwd option was used), and the values are arrays of the names of the items contained in each directory. CLI If you need a CLI interface for your file watching, check out chokidar-cli, allowing you to execute a command on each change, or get a stdio stream of change events. Install Troubleshooting npm WARN optional dep failed, continuing fsevents@n.n.n This message is normal part of how npm handles optional dependencies and is not indicative of a problem. Even if accompanied by other related error messages, Chokidar should function properly. TypeError: fsevents is not a constructor Update chokidar by doing rm -rf node_modules package-lock.json yarn.lock && npm install, or update your dependency that uses chokidar. Chokidar is producing ENOSP error on Linux, like this: bash: cannot set terminal process group (-1): Inappropriate ioctl for device bash: no job control in this shell Error: watch /home/ ENOSPC This means Chokidar ran out of file handles and you'll need to increase their count by executing the following command in Terminal: echo fs.inotify.max_user_watches=524288 | sudo tee -a /etc/sysctl.conf && sudo sysctl -p Changelog For more detailed changelog, see full_changelog.md. v3.5 (Jan 6, 2021): Support for ARM Macs with Apple Silicon. Fixes for deleted symlinks. v3.4 (Apr 26, 2020): Support for directory-based symlinks. Fixes for macos file replacement. v3.3 (Nov 2, 2019): FSWatcher#close() method became async. That fixes IO race conditions related to close method. v3.2 (Oct 1, 2019): Improve Linux RAM usage by 50%. Race condition fixes. Windows glob fixes. Improve stability by using tight range of dependency versions. v3.1 (Sep 16, 2019): dotfiles are no longer filtered out by default. Use ignored option if needed. Improve initial Linux scan time by 50%. v3 (Apr 30, 2019): massive CPU & RAM consumption improvements; reduces deps / package size by a factor of 17x and bumps Node.js requirement to v8.16 and higher. v2 (Dec 29, 2017): Globs are now posix-style-only; without windows support. Tons of bugfixes. v1 (Apr 7, 2015): Glob support, symlink support, tons of bugfixes. Node 0.8+ is supported v0.1 (Apr 20, 2012): Initial release, extracted from Brunch Also Why was chokidar named this way? What's the meaning behind it? Chowkidar is a transliteration of a Hindi word meaning 'watchman, gatekeeper', चौकीदार. This ultimately comes from Sanskrit _ चतुष्क_ (crossway, quadrangle, consisting-of-four). This word is also used in other languages like Urdu as (چوکیدار) which is widely used in Pakistan and India. License MIT (c) Paul Miller (https://paulmillr.com), see LICENSE file."
  },
  "node_modules/clean-stack/node_modules/escape-string-regexp/readme.html": {
    "href": "node_modules/clean-stack/node_modules/escape-string-regexp/readme.html",
    "title": "escape-string-regexp | accouter",
    "keywords": "escape-string-regexp Escape RegExp special characters Install $ npm install escape-string-regexp Usage import escapeStringRegexp from 'escape-string-regexp'; const escapedString = escapeStringRegexp('How much $ for a 🦄?'); //=> 'How much \\\\$ for a 🦄\\\\?' new RegExp(escapedString); You can also use this to escape a string that is inserted into the middle of a regex, for example, into a character class. Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "node_modules/clean-stack/readme.html": {
    "href": "node_modules/clean-stack/readme.html",
    "title": "clean-stack | accouter",
    "keywords": "clean-stack Clean up error stack traces Removes the mostly unhelpful internal Node.js entries. Also works in Electron. Install $ npm install clean-stack Usage import cleanStack from 'clean-stack'; const error = new Error('Missing unicorn'); console.log(error.stack); /* Error: Missing unicorn at Object.<anonymous> (/Users/sindresorhus/dev/clean-stack/unicorn.js:2:15) at Module._compile (module.js:409:26) at Object.Module._extensions..js (module.js:416:10) at Module.load (module.js:343:32) at Function.Module._load (module.js:300:12) at Function.Module.runMain (module.js:441:10) at startup (node.js:139:18) */ console.log(cleanStack(error.stack)); /* Error: Missing unicorn at Object.<anonymous> (/Users/sindresorhus/dev/clean-stack/unicorn.js:2:15) */ API cleanStack(stack, options?) Returns the cleaned stack or undefined if the given stack is undefined. stack Type: string | undefined The stack property of an Error. options Type: object pretty Type: boolean Default: false Prettify the file paths in the stack: /Users/sindresorhus/dev/clean-stack/unicorn.js:2:15 → ~/dev/clean-stack/unicorn.js:2:15 basePath Type: string? Remove the given base path from stack trace file paths, effectively turning absolute paths into relative ones. Example with '/Users/sindresorhus/dev/clean-stack/' as basePath: /Users/sindresorhus/dev/clean-stack/unicorn.js:2:15 → unicorn.js:2:15 Related extract-stack - Extract the actual stack of an error stack-utils - Captures and cleans stack traces"
  },
  "node_modules/cliui/CHANGELOG.html": {
    "href": "node_modules/cliui/CHANGELOG.html",
    "title": "Change Log | accouter",
    "keywords": "Change Log All notable changes to this project will be documented in this file. See standard-version for commit guidelines. 8.0.1 (2022-10-01) Bug Fixes deps: move rollup-plugin-ts to dev deps (#124) (7c8bd6b) 8.0.0 (2022-09-30) ⚠ BREAKING CHANGES deps: drop Node 10 to release CVE-2021-3807 patch (#122) Bug Fixes deps: drop Node 10 to release CVE-2021-3807 patch (#122) (f156571) 7.0.4 (2020-11-08) Bug Fixes deno: import UIOptions from definitions (#97) (f04f343) 7.0.3 (2020-10-16) Bug Fixes exports: node 13.0 and 13.1 require the dotted object form with a string fallback (#93) (eca16fc) 7.0.2 (2020-10-14) Bug Fixes exports: node 13.0-13.6 require a string fallback (#91) (b529d7e) 7.0.1 (2020-08-16) Bug Fixes build: main should be build/index.cjs (dc29a3c) 7.0.0 (2020-08-16) ⚠ BREAKING CHANGES tsc/ESM/Deno support (#82) modernize deps and build (#80) Build System modernize deps and build (#80) (339d08d) Code Refactoring tsc/ESM/Deno support (#82) (4b777a5) 6.0.0 (2019-11-10) ⚠ BREAKING CHANGES update deps, drop Node 6 Code Refactoring update deps, drop Node 6 (62056df) 5.0.0 (2019-04-10) Bug Fixes Update wrap-ansi to fix compatibility with latest versions of chalk. (#60) (7bf79ae) BREAKING CHANGES Drop support for node < 6. 4.1.0 (2018-04-23) Features add resetOutput method (#57) (7246902) 4.0.0 (2017-12-18) Bug Fixes downgrades strip-ansi to version 3.0.1 (#54) (5764c46) set env variable FORCE_COLOR. (#56) (7350e36) Chores drop support for node < 4 (#53) (b105376) Features add fallback for window width (#45) (d064922) BREAKING CHANGES officially drop support for Node < 4 3.2.0 (2016-04-11) Bug Fixes reduces tarball size (acc6c33) Features adds standard-version for release management (ff84e32)"
  },
  "node_modules/cliui/README.html": {
    "href": "node_modules/cliui/README.html",
    "title": "cliui | accouter",
    "keywords": "cliui easily create complex multi-column command-line-interfaces. Example const ui = require('cliui')() ui.div('Usage: $0 [command] [options]') ui.div({ text: 'Options:', padding: [2, 0, 1, 0] }) ui.div( { text: \"-f, --file\", width: 20, padding: [0, 4, 0, 4] }, { text: \"the file to load.\" + chalk.green(\"(if this description is long it wraps).\") , width: 20 }, { text: chalk.red(\"[required]\"), align: 'right' } ) console.log(ui.toString()) Deno/ESM Support As of v7 cliui supports Deno and ESM: import cliui from \"https://deno.land/x/cliui/deno.ts\"; const ui = cliui({}) ui.div('Usage: $0 [command] [options]') ui.div({ text: 'Options:', padding: [2, 0, 1, 0] }) ui.div({ text: \"-f, --file\", width: 20, padding: [0, 4, 0, 4] }) console.log(ui.toString()) Layout DSL cliui exposes a simple layout DSL: If you create a single ui.div, passing a string rather than an object: \\n: characters will be interpreted as new rows. \\t: characters will be interpreted as new columns. \\s: characters will be interpreted as padding. as an example... var ui = require('./')({ width: 60 }) ui.div( 'Usage: node ./bin/foo.js\\n' + ' <regex>\\t provide a regex\\n' + ' <glob>\\t provide a glob\\t [required]' ) console.log(ui.toString()) will output: Usage: node ./bin/foo.js <regex> provide a regex <glob> provide a glob [required] Methods cliui = require('cliui') cliui({width: integer}) Specify the maximum width of the UI being generated. If no width is provided, cliui will try to get the current window's width and use it, and if that doesn't work, width will be set to 80. cliui({wrap: boolean}) Enable or disable the wrapping of text in a column. cliui.div(column, column, column) Create a row with any number of columns, a column can either be a string, or an object with the following options: text: some text to place in the column. width: the width of a column. align: alignment, right or center. padding: [top, right, bottom, left]. border: should a border be placed around the div? cliui.span(column, column, column) Similar to div, except the next row will be appended without a new line being created. cliui.resetOutput() Resets the UI elements of the current cliui instance, maintaining the values set for width and wrap."
  },
  "node_modules/color-convert/CHANGELOG.html": {
    "href": "node_modules/color-convert/CHANGELOG.html",
    "title": "1.0.0 - 2016-01-07 | accouter",
    "keywords": "1.0.0 - 2016-01-07 Removed: unused speed test Added: Automatic routing between previously unsupported conversions (#27) Removed: xxx2xxx() and xxx2xxxRaw() functions (#27) Removed: convert() class (#27) Changed: all functions to lookup dictionary (#27) Changed: ansi to ansi256 (#27) Fixed: argument grouping for functions requiring only one argument (#27) 0.6.0 - 2015-07-23 Added: methods to handle ANSI 16/256 colors: rgb2ansi16 rgb2ansi hsl2ansi16 hsl2ansi hsv2ansi16 hsv2ansi hwb2ansi16 hwb2ansi cmyk2ansi16 cmyk2ansi keyword2ansi16 keyword2ansi ansi162rgb ansi162hsl ansi162hsv ansi162hwb ansi162cmyk ansi162keyword ansi2rgb ansi2hsl ansi2hsv ansi2hwb ansi2cmyk ansi2keyword (#18) 0.5.3 - 2015-06-02 Fixed: hsl2hsv does not return NaN anymore when using [0,0,0] (#15) Check out commit logs for older releases"
  },
  "node_modules/color-convert/README.html": {
    "href": "node_modules/color-convert/README.html",
    "title": "color-convert | accouter",
    "keywords": "color-convert Color-convert is a color conversion library for JavaScript and node. It converts all ways between rgb, hsl, hsv, hwb, cmyk, ansi, ansi16, hex strings, and CSS keywords (will round to closest): var convert = require('color-convert'); convert.rgb.hsl(140, 200, 100); // [96, 48, 59] convert.keyword.rgb('blue'); // [0, 0, 255] var rgbChannels = convert.rgb.channels; // 3 var cmykChannels = convert.cmyk.channels; // 4 var ansiChannels = convert.ansi16.channels; // 1 Install $ npm install color-convert API Simply get the property of the from and to conversion that you're looking for. All functions have a rounded and unrounded variant. By default, return values are rounded. To get the unrounded (raw) results, simply tack on .raw to the function. All 'from' functions have a hidden property called .channels that indicates the number of channels the function expects (not including alpha). var convert = require('color-convert'); // Hex to LAB convert.hex.lab('DEADBF'); // [ 76, 21, -2 ] convert.hex.lab.raw('DEADBF'); // [ 75.56213190997677, 20.653827952644754, -2.290532499330533 ] // RGB to CMYK convert.rgb.cmyk(167, 255, 4); // [ 35, 0, 98, 0 ] convert.rgb.cmyk.raw(167, 255, 4); // [ 34.509803921568626, 0, 98.43137254901961, 0 ] Arrays All functions that accept multiple arguments also support passing an array. Note that this does not apply to functions that convert from a color that only requires one value (e.g. keyword, ansi256, hex, etc.) var convert = require('color-convert'); convert.rgb.hex(123, 45, 67); // '7B2D43' convert.rgb.hex([123, 45, 67]); // '7B2D43' Routing Conversions that don't have an explicitly defined conversion (in conversions.js), but can be converted by means of sub-conversions (e.g. XYZ -> RGB -> CMYK), are automatically routed together. This allows just about any color model supported by color-convert to be converted to any other model, so long as a sub-conversion path exists. This is also true for conversions requiring more than one step in between (e.g. LCH -> LAB -> XYZ -> RGB -> Hex). Keep in mind that extensive conversions may result in a loss of precision, and exist only to be complete. For a list of \"direct\" (single-step) conversions, see conversions.js. Contribute If there is a new model you would like to support, or want to add a direct conversion between two existing models, please send us a pull request. License Copyright © 2011-2016, Heather Arthur and Josh Junon. Licensed under the MIT License."
  },
  "node_modules/color-name/README.html": {
    "href": "node_modules/color-name/README.html",
    "title": "| accouter",
    "keywords": "A JSON with color names and its values. Based on http://dev.w3.org/csswg/css-color/#named-colors. var colors = require('color-name'); colors.red //[255,0,0]"
  },
  "node_modules/colord/CHANGELOG.html": {
    "href": "node_modules/colord/CHANGELOG.html",
    "title": "| accouter",
    "keywords": "2.9.3 Fix types export for TypeScript 4.7 ❤️ @pkishorez 2.9.2 Fix: Add \"package.json\" to exports map 2.9.1 Fix: Make minification lossless Fix: Minify to name only if color is opaque 2.9.0 New plugin: Color string minification 🗜 2.8.0 New delta method to calculate the perceived color difference between two colors ❤️ @EricRovell 2.7.0 Improve mix plugin by adding new tints, tones and shades methods ❤️ @EricRovell 2.6.0 Support \"double split complementary\" color harmony generation ❤️ @EricRovell & @lbragile 2.5.0 New closest option of toName method allows you to find the closest color if there is no exact match 2.4.0 New plugin: Color harmonies generator ❤️ @EricRovell 2.3.0 Add new isEqual method ❤️ @EricRovell 2.2.0 New plugin: CMYK color space ❤️ @EricRovell 2.1.0 Add new hue and rotate methods 2.0.1 Improve the precision of alpha values 2.0.0 Strict string color parsing conforming to the CSS Color Level specifications 1.7.2 Simplify package \"exports\" field to improve different environments support 1.7.1 Parse a color name disregarding the case 1.7.0 New getFormat utility Support HWB color strings (CSS functional notation) Clamp LAB values as defined in CSS Color Level 4 specs 1.6.0 Improvement: You can now use every angle unit supported by CSS (deg, rad, grad, turn) 1.5.0 New utility: Random color generation 1.4.1 Mix colors through CIE LAB color space 1.4.0 New plugin: Color mixing Adjust XYZ, LAB and LCH conversions to the D50 white point (according to the latest CSS specs). 1.3.1 Support modern CSS notations of RGB, HSL and LCH color functions 1.3.0 New plugin: CIE LCH color space 1.2.1 Fix: Do not treat 7-digit hex as a valid color ❤️ @subzey Parser update: Turn NaN input values into valid numbers ❤️ @subzey 1.2.0 New plugin: CIE LAB color space 1.1.1 Make bundle 1% lighter 1.1.0 Add isValid method 1.0 An official production-ready release 0.10.2 Sort named colors dictionary for better compression ❤️ @subzey 0.10.1 Ignore null input in the parsers 0.10 Shorten conversion method names (toRgba to toRgb, etc) 0.9.3 New plugin: HWB color model More accurate HSL and HSV conversions 0.9.2 Names plugin: Support \"transparent\" keyword 0.9.1 Improve package exports 0.9 Add CommonJS exports 0.8 New plugin: a11y (Accessibility) 0.7 New plugin: CIE XYZ color space 0.6.2 20% speed improvement ❤️ @jeetiss 0.6.1 100% code coverage 0.6 Make plugin available in Parcel which doesn't support exports map yet Fix names plugin TS declarations export Documentation 0.5 New plugin: CSS color names 0.4 Make the library ESM-first Add code coverage reports 0.3 Implement Plugin API 0.2 Support 4 and 8 digit Hex 0.1 Basic API"
  },
  "node_modules/colord/LICENSE.html": {
    "href": "node_modules/colord/LICENSE.html",
    "title": "| accouter",
    "keywords": "MIT License Copyright (c) 2020 Vlad Shilov omgovich@ya.ru Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/colord/README.html": {
    "href": "node_modules/colord/README.html",
    "title": "| accouter",
    "keywords": "Colord is a tiny yet powerful tool for high-performance color manipulations and conversions. Features 📦 Small: Just 1.7 KB gzipped (3x+ lighter than color and tinycolor2) 🚀 Fast: 3x+ faster than color and tinycolor2 😍 Simple: Chainable API and familiar patterns 💪 Immutable: No need to worry about data mutations 🛡 Bulletproof: Written in strict TypeScript and has 100% test coverage 🗂 Typed: Ships with types included 🏗 Extendable: Built-in plugin system to add new functionality 📚 CSS-compliant: Strictly follows CSS Color Level specifications 👫 Works everywhere: Supports all browsers and Node.js 💨 Dependency-free Benchmarks Library Operations/sec Size (minified) Size (gzipped) Dependencies Type declarations colord 👑 3,524,989 color 744,263 tinycolor2 971,312 ac-colors 660,722 chroma-js 962,967 The performance results were generated on a MBP 2019, 2,6 GHz Intel Core i7 by running npm run benchmark in the library folder. See tests/benchmark.ts. Getting Started npm i colord import { colord } from \"colord\"; colord(\"#ff0000\").grayscale().alpha(0.25).toRgbString(); // \"rgba(128, 128, 128, 0.25)\" colord(\"rgb(192, 192, 192)\").isLight(); // true colord(\"hsl(0, 50%, 50%)\").darken(0.25).toHex(); // \"#602020\" Supported Color Models Hexadecimal strings (including 3, 4 and 8 digit notations) RGB strings and objects HSL strings and objects HSV objects Color names (via plugin) HWB objects and strings (via plugin) CMYK objects and strings (via plugin) LCH objects and strings (via plugin) LAB objects (via plugin) XYZ objects (via plugin) API Color parsing colord(input) Parses the given input and creates a new Colord instance. String parsing strictly conforms to CSS Color Level Specifications. import { colord } from \"colord\"; // String input examples colord(\"#FFF\"); colord(\"#ffffff\"); colord(\"#ffffffff\"); colord(\"rgb(255, 255, 255)\"); colord(\"rgba(255, 255, 255, 0.5)\"); colord(\"rgba(100% 100% 100% / 50%)\"); colord(\"hsl(90, 100%, 100%)\"); colord(\"hsla(90, 100%, 100%, 0.5)\"); colord(\"hsla(90deg 100% 100% / 50%)\"); colord(\"tomato\"); // requires \"names\" plugin // Object input examples colord({ r: 255, g: 255, b: 255 }); colord({ r: 255, g: 255, b: 255, a: 1 }); colord({ h: 360, s: 100, l: 100 }); colord({ h: 360, s: 100, l: 100, a: 1 }); colord({ h: 360, s: 100, v: 100 }); colord({ h: 360, s: 100, v: 100, a: 1 }); Check out the \"Plugins\" section for more input format examples. getFormat(input) Returns a color model name for the input passed to the function. Uses the same parsing system as colord function. import { getFormat } from \"colord\"; getFormat(\"#aabbcc\"); // \"hex\" getFormat({ r: 13, g: 237, b: 162, a: 0.5 }); // \"rgb\" getFormat(\"hsl(180deg, 50%, 50%)\"); // \"hsl\" getFormat(\"WUT?\"); // undefined Color conversion .toHex() Returns the hexadecimal representation of a color. When the alpha channel value of the color is less than 1, it outputs #rrggbbaa format instead of #rrggbb. colord(\"rgb(0, 255, 0)\").toHex(); // \"#00ff00\" colord({ h: 300, s: 100, l: 50 }).toHex(); // \"#ff00ff\" colord({ r: 255, g: 255, b: 255, a: 0 }).toHex(); // \"#ffffff00\" .toRgb() colord(\"#ff0000\").toRgb(); // { r: 255, g: 0, b: 0, a: 1 } colord({ h: 180, s: 100, l: 50, a: 0.5 }).toRgb(); // { r: 0, g: 255, b: 255, a: 0.5 } .toRgbString() colord(\"#ff0000\").toRgbString(); // \"rgb(255, 0, 0)\" colord({ h: 180, s: 100, l: 50, a: 0.5 }).toRgbString(); // \"rgba(0, 255, 255, 0.5)\" .toHsl() Converts a color to HSL color space and returns an object. colord(\"#ffff00\").toHsl(); // { h: 60, s: 100, l: 50, a: 1 } colord(\"rgba(0, 0, 255, 0.5) \").toHsl(); // { h: 240, s: 100, l: 50, a: 0.5 } .toHslString() Converts a color to HSL color space and expresses it through the functional notation. colord(\"#ffff00\").toHslString(); // \"hsl(60, 100%, 50%)\" colord(\"rgba(0, 0, 255, 0.5)\").toHslString(); // \"hsla(240, 100%, 50%, 0.5)\" .toHsv() Converts a color to HSV color space and returns an object. colord(\"#ffff00\").toHsv(); // { h: 60, s: 100, v: 100, a: 1 } colord(\"rgba(0, 255, 255, 0.5) \").toHsv(); // { h: 180, s: 100, v: 100, a: 1 } .toName(options?) (names plugin) Converts a color to a CSS keyword. Returns undefined if the color is not specified in the specs. import { colord, extend } from \"colord\"; import namesPlugin from \"colord/plugins/names\"; extend([namesPlugin]); colord(\"#ff6347\").toName(); // \"tomato\" colord(\"#00ffff\").toName(); // \"cyan\" colord(\"rgba(0, 0, 0, 0)\").toName(); // \"transparent\" colord(\"#fe0000\").toName(); // undefined (the color is not specified in CSS specs) colord(\"#fe0000\").toName({ closest: true }); // \"red\" (closest color available) .toCmyk() (cmyk plugin) Converts a color to CMYK color space. import { colord, extend } from \"colord\"; import cmykPlugin from \"colord/plugins/cmyk\"; extend([cmykPlugin]); colord(\"#ffffff\").toCmyk(); // { c: 0, m: 0, y: 0, k: 0, a: 1 } colord(\"#555aaa\").toCmyk(); // { c: 50, m: 47, y: 0, k: 33, a: 1 } .toCmykString() (cmyk plugin) Converts a color to color space. Converts a color to CMYK color space and expresses it through the functional notation import { colord, extend } from \"colord\"; import cmykPlugin from \"colord/plugins/cmyk\"; extend([cmykPlugin]); colord(\"#99ffff\").toCmykString(); // \"device-cmyk(40% 0% 0% 0%)\" colord(\"#00336680\").toCmykString(); // \"device-cmyk(100% 50% 0% 60% / 0.5)\" .toHwb() (hwb plugin) Converts a color to HWB (Hue-Whiteness-Blackness) color space. import { colord, extend } from \"colord\"; import hwbPlugin from \"colord/plugins/hwb\"; extend([hwbPlugin]); colord(\"#ffffff\").toHwb(); // { h: 0, w: 100, b: 0, a: 1 } colord(\"#555aaa\").toHwb(); // { h: 236, w: 33, b: 33, a: 1 } .toHwbString() (hwb plugin) Converts a color to HWB (Hue-Whiteness-Blackness) color space and expresses it through the functional notation. import { colord, extend } from \"colord\"; import hwbPlugin from \"colord/plugins/hwb\"; extend([hwbPlugin]); colord(\"#999966\").toHwbString(); // \"hwb(60 40% 40%)\" colord(\"#99ffff\").toHwbString(); // \"hwb(180 60% 0%)\" colord(\"#003366\").alpha(0.5).toHwbString(); // \"hwb(210 0% 60% / 0.5)\" .toLab() (lab plugin) Converts a color to CIE LAB color space. The conversion logic is ported from CSS Color Module Level 4 Specification. import { colord, extend } from \"colord\"; import labPlugin from \"colord/plugins/lab\"; extend([labPlugin]); colord(\"#ffffff\").toLab(); // { l: 100, a: 0, b: 0, alpha: 1 } colord(\"#33221180\").toLab(); // { l: 14.89, a: 5.77, b: 14.41, alpha: 0.5 } .toLch() (lch plugin) Converts a color to CIE LCH color space. The conversion logic is ported from CSS Color Module Level 4 Specification. import { colord, extend } from \"colord\"; import lchPlugin from \"colord/plugins/lch\"; extend([lchPlugin]); colord(\"#ffffff\").toLch(); // { l: 100, c: 0, h: 0, a: 1 } colord(\"#213b0b\").toLch(); // { l: 21.85, c: 31.95, h: 127.77, a: 1 } .toLchString() (lch plugin) Converts a color to CIE LCH color space and expresses it through the functional notation. import { colord, extend } from \"colord\"; import lchPlugin from \"colord/plugins/lch\"; extend([lchPlugin]); colord(\"#ffffff\").toLchString(); // \"lch(100% 0 0)\" colord(\"#213b0b\").alpha(0.5).toLchString(); // \"lch(21.85% 31.95 127.77 / 0.5)\" .toXyz() (xyz plugin) Converts a color to CIE XYZ color space. The conversion logic is ported from CSS Color Module Level 4 Specification. import { colord, extend } from \"colord\"; import xyzPlugin from \"colord/plugins/xyz\"; extend([xyzPlugin]); colord(\"#ffffff\").toXyz(); // { x: 95.047, y: 100, z: 108.883, a: 1 } Color manipulation .alpha(value) Changes the alpha channel value and returns a new Colord instance. colord(\"rgb(0, 0, 0)\").alpha(0.5).toRgbString(); // \"rgba(0, 0, 0, 0.5)\" .invert() Creates a new Colord instance containing an inverted (opposite) version of the color. colord(\"#ffffff\").invert().toHex(); // \"#000000\" colord(\"#aabbcc\").invert().toHex(); // \"#554433\" .saturate(amount = 0.1) Increases the HSL saturation of a color by the given amount. colord(\"#bf4040\").saturate(0.25).toHex(); // \"#df2020\" colord(\"hsl(0, 50%, 50%)\").saturate(0.5).toHslString(); // \"hsl(0, 100%, 50%)\" .desaturate(amount = 0.1) Decreases the HSL saturation of a color by the given amount. colord(\"#df2020\").saturate(0.25).toHex(); // \"#bf4040\" colord(\"hsl(0, 100%, 50%)\").saturate(0.5).toHslString(); // \"hsl(0, 50%, 50%)\" .grayscale() Makes a gray color with the same lightness as a source color. Same as calling desaturate(1). colord(\"#bf4040\").grayscale().toHex(); // \"#808080\" colord(\"hsl(0, 100%, 50%)\").grayscale().toHslString(); // \"hsl(0, 0%, 50%)\" .lighten(amount = 0.1) Increases the HSL lightness of a color by the given amount. colord(\"#000000\").lighten(0.5).toHex(); // \"#808080\" colord(\"#223344\").lighten(0.3).toHex(); // \"#5580aa\" colord(\"hsl(0, 50%, 50%)\").lighten(0.5).toHslString(); // \"hsl(0, 50%, 100%)\" .darken(amount = 0.1) Decreases the HSL lightness of a color by the given amount. colord(\"#ffffff\").darken(0.5).toHex(); // \"#808080\" colord(\"#5580aa\").darken(0.3).toHex(); // \"#223344\" colord(\"hsl(0, 50%, 100%)\").lighten(0.5).toHslString(); // \"hsl(0, 50%, 50%)\" .hue(value) Changes the hue value and returns a new Colord instance. colord(\"hsl(90, 50%, 50%)\").hue(180).toHslString(); // \"hsl(180, 50%, 50%)\" colord(\"hsl(90, 50%, 50%)\").hue(370).toHslString(); // \"hsl(10, 50%, 50%)\" .rotate(amount = 15) Increases the HSL hue value of a color by the given amount. colord(\"hsl(90, 50%, 50%)\").rotate(90).toHslString(); // \"hsl(180, 50%, 50%)\" colord(\"hsl(90, 50%, 50%)\").rotate(-180).toHslString(); // \"hsl(270, 50%, 50%)\" .mix(color2, ratio = 0.5) (mix plugin) Produces a mixture of two colors and returns the result of mixing them (new Colord instance). In contrast to other libraries that perform RGB values mixing, Colord mixes colors through LAB color space. This approach produces better results and doesn't have the drawbacks the legacy way has. → Online demo import { colord, extend } from \"colord\"; import mixPlugin from \"colord/plugins/mix\"; extend([mixPlugin]); colord(\"#ffffff\").mix(\"#000000\").toHex(); // \"#777777\" colord(\"#800080\").mix(\"#dda0dd\").toHex(); // \"#af5cae\" colord(\"#cd853f\").mix(\"#eee8aa\", 0.6).toHex(); // \"#e3c07e\" colord(\"#008080\").mix(\"#808000\", 0.35).toHex(); // \"#50805d\" .tints(count = 5) (mix plugin) Provides functionality to generate tints of a color. Returns an array of Colord instances, including the original color. import { colord, extend } from \"colord\"; import mixPlugin from \"colord/plugins/mix\"; extend([mixPlugin]); const color = colord(\"#ff0000\"); color.tints(3).map((c) => c.toHex()); // [\"#ff0000\", \"#ff9f80\", \"#ffffff\"]; .shades(count = 5) (mix plugin) Provides functionality to generate shades of a color. Returns an array of Colord instances, including the original color. import { colord, extend } from \"colord\"; import mixPlugin from \"colord/plugins/mix\"; extend([mixPlugin]); const color = colord(\"#ff0000\"); color.shades(3).map((c) => c.toHex()); // [\"#ff0000\", \"#7a1b0b\", \"#000000\"]; .tones(count = 5) (mix plugin) Provides functionality to generate tones of a color. Returns an array of Colord instances, including the original color. import { colord, extend } from \"colord\"; import mixPlugin from \"colord/plugins/mix\"; extend([mixPlugin]); const color = colord(\"#ff0000\"); color.tones(3).map((c) => c.toHex()); // [\"#ff0000\", \"#c86147\", \"#808080\"]; .harmonies(type = \"complementary\") (harmonies plugin) Provides functionality to generate harmony colors. Returns an array of Colord instances. import { colord, extend } from \"colord\"; import harmoniesPlugin from \"colord/plugins/harmonies\"; extend([harmoniesPlugin]); const color = colord(\"#ff0000\"); color.harmonies(\"analogous\").map((c) => c.toHex()); // [\"#ff0080\", \"#ff0000\", \"#ff8000\"] color.harmonies(\"complementary\").map((c) => c.toHex()); // [\"#ff0000\", \"#00ffff\"] color.harmonies(\"double-split-complementary\").map((c) => c.toHex()); // [\"#ff0080\", \"#ff0000\", \"#ff8000\", \"#00ff80\", \"#0080ff\"] color.harmonies(\"rectangle\").map((c) => c.toHex()); // [\"#ff0000\", \"#ffff00\", \"#00ffff\", \"#0000ff\"] color.harmonies(\"split-complementary\").map((c) => c.toHex()); // [\"#ff0000\", \"#00ff80\", \"#0080ff\"] color.harmonies(\"tetradic\").map((c) => c.toHex()); // [\"#ff0000\", \"#80ff00\", \"#00ffff\", \"#8000ff\"] color.harmonies(\"triadic\").map((c) => c.toHex()); // [\"#ff0000\", \"#00ff00\", \"#0000ff\"] Color analysis .isValid() Returns a boolean indicating whether or not an input has been parsed successfully. Note: If parsing is unsuccessful, Colord defaults to black (does not throws an error). colord(\"#ffffff\").isValid(); // true colord(\"#wwuutt\").isValid(); // false colord(\"abracadabra\").isValid(); // false colord({ r: 0, g: 0, b: 0 }).isValid(); // true colord({ r: 0, g: 0, v: 0 }).isValid(); // false .isEqual(color2) Determines whether two values are the same color. colord(\"#000000\").isEqual(\"rgb(0, 0, 0)\"); // true colord(\"#000000\").isEqual(\"rgb(255, 255, 255)\"); // false .alpha() colord(\"#ffffff\").alpha(); // 1 colord(\"rgba(50, 100, 150, 0.5)\").alpha(); // 0.5 .hue() colord(\"hsl(90, 50%, 50%)\").hue(); // 90 colord(\"hsl(-10, 50%, 50%)\").hue(); // 350 .brightness() Returns the brightness of a color (from 0 to 1). The calculation logic is modified from Web Content Accessibility Guidelines. colord(\"#000000\").brightness(); // 0 colord(\"#808080\").brightness(); // 0.5 colord(\"#ffffff\").brightness(); // 1 .isLight() Same as calling brightness() >= 0.5. colord(\"#111111\").isLight(); // false colord(\"#aabbcc\").isLight(); // true colord(\"#ffffff\").isLight(); // true .isDark() Same as calling brightness() < 0.5. colord(\"#111111\").isDark(); // true colord(\"#aabbcc\").isDark(); // false colord(\"#ffffff\").isDark(); // false .luminance() (a11y plugin) Returns the relative luminance of a color, normalized to 0 for darkest black and 1 for lightest white as defined by WCAG 2.0. colord(\"#000000\").luminance(); // 0 colord(\"#808080\").luminance(); // 0.22 colord(\"#ccddee\").luminance(); // 0.71 colord(\"#ffffff\").luminance(); // 1 .contrast(color2 = \"#FFF\") (a11y plugin) Calculates a contrast ratio for a color pair. This luminance difference is expressed as a ratio ranging from 1 (e.g. white on white) to 21 (e.g., black on a white). WCAG Accessibility Level AA requires a ratio of at least 4.5 for normal text and 3 for large text. colord(\"#000000\").contrast(); // 21 (black on white) colord(\"#ffffff\").contrast(\"#000000\"); // 21 (white on black) colord(\"#777777\").contrast(); // 4.47 (gray on white) colord(\"#ff0000\").contrast(); // 3.99 (red on white) colord(\"#0000ff\").contrast(\"#ff000\"); // 2.14 (blue on red) .isReadable(color2 = \"#FFF\", options?) (a11y plugin) Checks that a background and text color pair is readable according to WCAG 2.0 Contrast and Color Requirements. colord(\"#000000\").isReadable(); // true (normal black text on white bg conforms to WCAG AA) colord(\"#777777\").isReadable(); // false (normal gray text on white bg conforms to WCAG AA) colord(\"#ffffff\").isReadable(\"#000000\"); // true (normal white text on black bg conforms to WCAG AA) colord(\"#e60000\").isReadable(\"#ffff47\"); // true (normal red text on yellow bg conforms to WCAG AA) colord(\"#e60000\").isReadable(\"#ffff47\", { level: \"AAA\" }); // false (normal red text on yellow bg does not conform to WCAG AAA) colord(\"#e60000\").isReadable(\"#ffff47\", { level: \"AAA\", size: \"large\" }); // true (large red text on yellow bg conforms to WCAG AAA) .delta(color2 = \"#FFF\") (lab plugin) Calculates the perceived color difference between two colors. The difference calculated according to Delta E2000. The return value is 0 if the colors are equal, 1 if they are entirely different. colord(\"#3296fa\").delta(\"#197dc8\"); // 0.099 colord(\"#faf0c8\").delta(\"#ffffff\"); // 0.148 colord(\"#afafaf\").delta(\"#b4b4b4\"); // 0.014 colord(\"#000000\").delta(\"#ffffff\"); // 1 Color utilities random() Returns a new Colord instance with a random color value inside. import { random } from \"colord\"; random().toHex(); // \"#01c8ec\" random().alpha(0.5).toRgb(); // { r: 13, g: 237, b: 162, a: 0.5 } .minify(options?) Converts a color to its shortest string representation. import { colord, extend } from \"colord\"; import minifyPlugin from \"colord/plugins/minify\"; extend([minifyPlugin]); colord(\"black\").minify(); // \"#000\" colord(\"#112233\").minify(); // \"#123\" colord(\"darkgray\").minify(); // \"#a9a9a9\" colord(\"rgba(170,170,170,0.4)\").minify(); // \"hsla(0,0%,67%,.4)\" colord(\"rgba(170,170,170,0.4)\").minify({ alphaHex: true }); // \"#aaa6\" Option Default Description hex true Enable #rrggbb and #rgb notations alphaHex false Enable #rrggbbaa and #rgba notations rgb true Enable rgb() and rgba() functional notations hsl true Enable hsl() and hsla() functional notations name false Enable CSS color keywords. Requires names plugin installed transparent false Enable \"transparent\" color keyword Plugins Colord has a built-in plugin system that allows new features and functionality to be easily added. a11y (Accessibility) 0.38 KB Adds accessibility and color contrast utilities working according to Web Content Accessibility Guidelines 2.0. import { colord, extend } from \"colord\"; import a11yPlugin from \"colord/plugins/a11y\"; extend([a11yPlugin]); colord(\"#000000\").luminance(); // 0 colord(\"#ccddee\").luminance(); // 0.71 colord(\"#ffffff\").luminance(); // 1 colord(\"#000000\").contrast(); // 21 (black on white) colord(\"#ffffff\").contrast(\"#000000\"); // 21 (white on black) colord(\"#0000ff\").contrast(\"#ff000\"); // 2.14 (blue on red) colord(\"#000000\").isReadable(); // true (black on white) colord(\"#ffffff\").isReadable(\"#000000\"); // true (white on black) colord(\"#777777\").isReadable(); // false (gray on white) colord(\"#e60000\").isReadable(\"#ffff47\"); // true (normal red text on yellow bg conforms to WCAG AA) colord(\"#e60000\").isReadable(\"#ffff47\", { level: \"AAA\" }); // false (normal red text on yellow bg does not conform to WCAG AAA) colord(\"#e60000\").isReadable(\"#ffff47\", { level: \"AAA\", size: \"large\" }); // true (large red text on yellow bg conforms to WCAG AAA) cmyk (CMYK color space) 0.6 KB Adds support of CMYK color model. import { colord, extend } from \"colord\"; import cmykPlugin from \"colord/plugins/cmyk\"; extend([cmykPlugin]); colord(\"#ffffff\").toCmyk(); // { c: 0, m: 0, y: 0, k: 0, a: 1 } colord(\"#999966\").toCmykString(); // \"device-cmyk(0% 0% 33% 40%)\" colord({ c: 0, m: 0, y: 0, k: 100, a: 1 }).toHex(); // \"#000000\" colord(\"device-cmyk(0% 61% 72% 0% / 50%)\").toHex(); // \"#ff634780\" harmonies (Color harmonies) 0.15 KB Provides functionality to generate harmony colors. import { colord, extend } from \"colord\"; import harmonies from \"colord/plugins/harmonies\"; extend([harmonies]); const color = colord(\"#ff0000\"); color.harmonies(\"analogous\").map((c) => c.toHex()); // [\"#ff0080\", \"#ff0000\", \"#ff8000\"] color.harmonies(\"complementary\").map((c) => c.toHex()); // [\"#ff0000\", \"#00ffff\"] color.harmonies(\"double-split-complementary\").map((c) => c.toHex()); // [\"#ff0080\", \"#ff0000\", \"#ff8000\", \"#00ff80\", \"#0080ff\"] color.harmonies(\"rectangle\").map((c) => c.toHex()); // [\"#ff0000\", \"#ffff00\", \"#00ffff\", \"#0000ff\"] color.harmonies(\"split-complementary\").map((c) => c.toHex()); // [\"#ff0000\", \"#00ff80\", \"#0080ff\"] color.harmonies(\"tetradic\").map((c) => c.toHex()); // [\"#ff0000\", \"#80ff00\", \"#00ffff\", \"#8000ff\"] color.harmonies(\"triadic\").map((c) => c.toHex()); // [\"#ff0000\", \"#00ff00\", \"#0000ff\"] hwb (HWB color model) 0.8 KB Adds support of Hue-Whiteness-Blackness color model. import { colord, extend } from \"colord\"; import hwbPlugin from \"colord/plugins/hwb\"; extend([hwbPlugin]); colord(\"#999966\").toHwb(); // { h: 60, w: 40, b: 40, a: 1 } colord(\"#003366\").toHwbString(); // \"hwb(210 0% 60%)\" colord({ h: 60, w: 40, b: 40 }).toHex(); // \"#999966\" colord(\"hwb(210 0% 60% / 50%)\").toHex(); // \"#00336680\" lab (CIE LAB color space) 1.4 KB Adds support of CIE LAB color model. The conversion logic is ported from CSS Color Module Level 4 Specification. Also plugin provides .delta method for perceived color difference calculations. import { colord, extend } from \"colord\"; import labPlugin from \"colord/plugins/lab\"; extend([labPlugin]); colord({ l: 53.24, a: 80.09, b: 67.2 }).toHex(); // \"#ff0000\" colord(\"#ffffff\").toLab(); // { l: 100, a: 0, b: 0, alpha: 1 } colord(\"#afafaf\").delta(\"#b4b4b4\"); // 0.014 colord(\"#000000\").delta(\"#ffffff\"); // 1 lch (CIE LCH color space) 1.3 KB Adds support of CIE LCH color space. The conversion logic is ported from CSS Color Module Level 4 Specification. import { colord, extend } from \"colord\"; import lchPlugin from \"colord/plugins/lch\"; extend([lchPlugin]); colord({ l: 100, c: 0, h: 0 }).toHex(); // \"#ffffff\" colord(\"lch(48.25% 30.07 196.38)\").toHex(); // \"#008080\" colord(\"#646464\").toLch(); // { l: 42.37, c: 0, h: 0, a: 1 } colord(\"#646464\").alpha(0.5).toLchString(); // \"lch(42.37% 0 0 / 0.5)\" minify (Color string minification) 0.5 KB A plugin adding color string minification utilities. import { colord, extend } from \"colord\"; import minifyPlugin from \"colord/plugins/minify\"; extend([minifyPlugin]); colord(\"black\").minify(); // \"#000\" colord(\"#112233\").minify(); // \"#123\" colord(\"darkgray\").minify(); // \"#a9a9a9\" colord(\"rgba(170,170,170,0.4)\").minify(); // \"hsla(0,0%,67%,.4)\" colord(\"rgba(170,170,170,0.4)\").minify({ alphaHex: true }); // \"#aaa6\" mix (Color mixing) 0.96 KB A plugin adding color mixing utilities. In contrast to other libraries that perform RGB values mixing, Colord mixes colors through LAB color space. This approach produces better results and doesn't have the drawbacks the legacy way has. → Online demo import { colord, extend } from \"colord\"; import mixPlugin from \"colord/plugins/mix\"; extend([mixPlugin]); colord(\"#ffffff\").mix(\"#000000\").toHex(); // \"#777777\" colord(\"#800080\").mix(\"#dda0dd\").toHex(); // \"#af5cae\" colord(\"#cd853f\").mix(\"#eee8aa\", 0.6).toHex(); // \"#e3c07e\" colord(\"#008080\").mix(\"#808000\", 0.35).toHex(); // \"#50805d\" Also, the plugin provides special mixtures such as tints, shades, and tones: const color = colord(\"#ff0000\"); color.tints(3).map((c) => c.toHex()); // [\"#ff0000\", \"#ff9f80\", \"#ffffff\"]; color.shades(3).map((c) => c.toHex()); // [\"#ff0000\", \"#7a1b0b\", \"#000000\"]; color.tones(3).map((c) => c.toHex()); // [\"#ff0000\", \"#c86147\", \"#808080\"]; names (CSS color keywords) 1.45 KB Provides options to convert a color into a CSS color keyword and vice versa. import { colord, extend } from \"colord\"; import namesPlugin from \"colord/plugins/names\"; extend([namesPlugin]); colord(\"tomato\").toHex(); // \"#ff6347\" colord(\"#00ffff\").toName(); // \"cyan\" colord(\"rgba(0, 0, 0, 0)\").toName(); // \"transparent\" colord(\"#fe0000\").toName(); // undefined (the color is not specified in CSS specs) colord(\"#fe0000\").toName({ closest: true }); // \"red\" (closest color) xyz (CIE XYZ color space) 0.7 KB Adds support of CIE XYZ color model. The conversion logic is ported from CSS Color Module Level 4 Specification. import { colord, extend } from \"colord\"; import xyzPlugin from \"colord/plugins/xyz\"; extend([xyzPlugin]); colord(\"#ffffff\").toXyz(); // { x: 95.047, y: 100, z: 108.883, a: 1 } colord({ x: 0, y: 0, z: 0 }).toHex(); // \"#000000\" Types Colord is written in strict TypeScript and ships with types in the library itself — no need for any other install. We provide everything you need in one tiny package. While not only typing its own functions and variables, Colord can also help you type yours. Depending on the color space you are using, you can also import and use the type that is associated with it. import { RgbColor, RgbaColor, HslColor, HslaColor, HsvColor, HsvaColor } from \"colord\"; const foo: HslColor = { h: 0, s: 0, l: 0 }; const bar: RgbColor = { r: 0, g: 0, v: 0 }; // ERROR Projects using Colord cssnano — the most popular CSS minification tool Resume.io — online resume builder with over 12,000,000 users worldwide Leva — open source extensible GUI panel made for React Qui Max — Vue.js design system and component library and thousands more... Roadmap [x] Parse and convert Hex, RGB(A), HSL(A), HSV(A) [x] Saturate, desaturate, grayscale [x] Trim an input value [x] Clamp input numbers to resolve edge cases (e.g. rgb(256, -1, 999, 2)) [x] brightness, isDark, isLight [x] Set and get alpha [x] Plugin API [x] 4 and 8 digit Hex [x] lighten, darken [x] invert [x] CSS color names (via plugin) [x] A11y and contrast utils (via plugin) [x] XYZ color space (via plugin) [x] HWB color space (via plugin) [x] LAB color space (via plugin) [x] LCH color space (via plugin) [x] Mix colors (via plugin) [x] CMYK color space (via plugin)"
  },
  "node_modules/commander/CHANGELOG.html": {
    "href": "node_modules/commander/CHANGELOG.html",
    "title": "2.20.3 / 2019-10-11 | accouter",
    "keywords": "2.20.3 / 2019-10-11 Support Node.js 0.10 (Revert #1059) Ran \"npm unpublish commander@2.20.2\". There is no 2.20.2. 2.20.1 / 2019-09-29 Improve executable subcommand tracking Update dev dependencies 2.20.0 / 2019-04-02 fix: resolve symbolic links completely when hunting for subcommands (#935) Update index.d.ts (#930) Update Readme.md (#924) Remove --save option as it isn't required anymore (#918) Add link to the license file (#900) Added example of receiving args from options (#858) Added missing semicolon (#882) Add extension to .eslintrc (#876) 2.19.0 / 2018-10-02 Removed newline after Options and Commands headers (#864) Bugfix - Error output (#862) Fix to change default value to string (#856) 2.18.0 / 2018-09-07 Standardize help output (#853) chmod 644 travis.yml (#851) add support for execute typescript subcommand via ts-node (#849) 2.17.1 / 2018-08-07 Fix bug in command emit (#844) 2.17.0 / 2018-08-03 fixed newline output after help information (#833) Fix to emit the action even without command (#778) npm update (#823) 2.16.0 / 2018-06-29 Remove Makefile and test/run (#821) Make 'npm test' run on Windows (#820) Add badge to display install size (#807) chore: cache node_modules (#814) chore: remove Node.js 4 (EOL), add Node.js 10 (#813) fixed typo in readme (#812) Fix types (#804) Update eslint to resolve vulnerabilities in lodash (#799) updated readme with custom event listeners. (#791) fix tests (#794) 2.15.0 / 2018-03-07 Update downloads badge to point to graph of downloads over time instead of duplicating link to npm Arguments description 2.14.1 / 2018-02-07 Fix typing of help function 2.14.0 / 2018-02-05 only register the option:version event once Fixes issue #727: Passing empty string for option on command is set to undefined enable eqeqeq rule resolves #754 add linter configuration to project resolves #560 respect custom name for version option document how to override the version flag document using options per command 2.13.0 / 2018-01-09 Do not print default for --no- remove trailing spaces in command help Update CI's Node.js to LTS and latest version typedefs: Command and Option types added to commander namespace 2.12.2 / 2017-11-28 fix: typings are not shipped 2.12.1 / 2017-11-23 Move @types/node to dev dependency 2.12.0 / 2017-11-22 add attributeName() method to Option objects Documentation updated for options with --no prefix typings: outputHelp takes a string as the first parameter typings: use overloads feat(typings): update to match js api Print default value in option help Fix translation error Fail when using same command and alias (#491) feat(typings): add help callback fix bug when description is add after command with options (#662) Format js code Rename History.md to CHANGELOG.md (#668) feat(typings): add typings to support TypeScript (#646) use current node 2.11.0 / 2017-07-03 Fix help section order and padding (#652) feature: support for signals to subcommands (#632) Fixed #37, --help should not display first (#447) Fix translation errors. (#570) Add package-lock.json Remove engines Upgrade package version Prefix events to prevent conflicts between commands and options (#494) Removing dependency on graceful-readlink Support setting name in #name function and make it chainable Add .vscode directory to .gitignore (Visual Studio Code metadata) Updated link to ruby commander in readme files 2.10.0 / 2017-06-19 Update .travis.yml. drop support for older node.js versions. Fix require arguments in README.md On SemVer you do not start from 0.0.1 Add missing semi colon in readme Add save param to npm install node v6 travis test Update Readme_zh-CN.md Allow literal '--' to be passed-through as an argument Test subcommand alias help link build badge to master branch Support the alias of Git style sub-command added keyword commander for better search result on npm Fix Sub-Subcommands test node.js stable Fixes TypeError when a command has an option called --description Update README.md to make it beginner friendly and elaborate on the difference between angled and square brackets. Add chinese Readme file 2.9.0 / 2015-10-13 Add option isDefault to set default subcommand #415 @Qix- Add callback to allow filtering or post-processing of help text #434 @djulien Fix undefined text in help information close #414 #416 @zhiyelee 2.8.1 / 2015-04-22 Back out support multiline description Close #396 #397 2.8.0 / 2015-04-07 Add process.execArg support, execution args like --harmony will be passed to sub-commands #387 @DigitalIO @zhiyelee Fix bug in Git-style sub-commands #372 @zhiyelee Allow commands to be hidden from help #383 @tonylukasavage When git-style sub-commands are in use, yet none are called, display help #382 @claylo Add ability to specify arguments syntax for top-level command #258 @rrthomas Support multiline descriptions #208 @zxqfox 2.7.1 / 2015-03-11 Revert #347 (fix collisions when option and first arg have same name) which causes a bug in #367. 2.7.0 / 2015-03-09 Fix git-style bug when installed globally. Close #335 #349 @zhiyelee Fix collisions when option and first arg have same name. Close #346 #347 @tonylukasavage Add support for camelCase on opts(). Close #353 @nkzawa Add node.js 0.12 and io.js to travis.yml Allow RegEx options. #337 @palanik Fixes exit code when sub-command failing. Close #260 #332 @pirelenito git-style bin files in $PATH make sense. Close #196 #327 @zhiyelee 2.6.0 / 2014-12-30 added Command#allowUnknownOption method. Close #138 #318 @doozr @zhiyelee Add application description to the help msg. Close #112 @dalssoft 2.5.1 / 2014-12-15 fixed two bugs incurred by variadic arguments. Close #291 @Quentin01 #302 @zhiyelee 2.5.0 / 2014-10-24 add support for variadic arguments. Closes #277 @whitlockjc 2.4.0 / 2014-10-17 fixed a bug on executing the coercion function of subcommands option. Closes #270 added Command.prototype.name to retrieve command name. Closes #264 #266 @tonylukasavage added Command.prototype.opts to retrieve all the options as a simple object of key-value pairs. Closes #262 @tonylukasavage fixed a bug on subcommand name. Closes #248 @jonathandelgado fixed function normalize doesn’t honor option terminator. Closes #216 @abbr 2.3.0 / 2014-07-16 add command alias'. Closes PR #210 fix: Typos. Closes #99 fix: Unused fs module. Closes #217 2.2.0 / 2014-03-29 add passing of previous option value fix: support subcommands on windows. Closes #142 Now the defaultValue passed as the second argument of the coercion function. 2.1.0 / 2013-11-21 add: allow cflag style option params, unit test, fixes #174 2.0.0 / 2013-07-18 remove input methods (.prompt, .confirm, etc) 1.3.2 / 2013-07-18 add support for sub-commands to co-exist with the original command 1.3.1 / 2013-07-18 add quick .runningCommand hack so you can opt-out of other logic when running a sub command 1.3.0 / 2013-07-09 add EACCES error handling fix sub-command --help 1.2.0 / 2013-06-13 allow \"-\" hyphen as an option argument support for RegExp coercion 1.1.1 / 2012-11-20 add more sub-command padding fix .usage() when args are present. Closes #106 1.1.0 / 2012-11-16 add git-style executable subcommand support. Closes #94 1.0.5 / 2012-10-09 fix --name clobbering. Closes #92 fix examples/help. Closes #89 1.0.4 / 2012-09-03 add outputHelp() method. 1.0.3 / 2012-08-30 remove invalid .version() defaulting 1.0.2 / 2012-08-24 add --foo=bar support [arv] fix password on node 0.8.8. Make backward compatible with 0.6 [focusaurus] 1.0.1 / 2012-08-03 fix issue #56 fix tty.setRawMode(mode) was moved to tty.ReadStream#setRawMode() (i.e. process.stdin.setRawMode()) 1.0.0 / 2012-07-05 add support for optional option descriptions add defaulting of .version() to package.json's version 0.6.1 / 2012-06-01 Added: append (yes or no) on confirmation Added: allow node.js v0.7.x 0.6.0 / 2012-04-10 Added .prompt(obj, callback) support. Closes #49 Added default support to .choose(). Closes #41 Fixed the choice example 0.5.1 / 2011-12-20 Fixed password() for recent nodes. Closes #36 0.5.0 / 2011-12-04 Added sub-command option support [itay] 0.4.3 / 2011-12-04 Fixed custom help ordering. Closes #32 0.4.2 / 2011-11-24 Added travis support Fixed: line-buffered input automatically trimmed. Closes #31 0.4.1 / 2011-11-18 Removed listening for \"close\" on --help 0.4.0 / 2011-11-15 Added support for --. Closes #24 0.3.3 / 2011-11-14 Fixed: wait for close event when writing help info [Jerry Hamlet] 0.3.2 / 2011-11-01 Fixed long flag definitions with values [felixge] 0.3.1 / 2011-10-31 Changed --version short flag to -V from -v Changed .version() so it's configurable [felixge] 0.3.0 / 2011-10-31 Added support for long flags only. Closes #18 0.2.1 / 2011-10-24 \"node\": \">= 0.4.x < 0.7.0\". Closes #20 0.2.0 / 2011-09-26 Allow for defaults that are not just boolean. Default peassignment only occurs for --no-*, optional, and required arguments. [Jim Isaacs] 0.1.0 / 2011-08-24 Added support for custom --help output 0.0.5 / 2011-08-18 Changed: when the user enters nothing prompt for password again Fixed issue with passwords beginning with numbers [NuckChorris] 0.0.4 / 2011-08-15 Fixed Commander#args 0.0.3 / 2011-08-15 Added default option value support 0.0.2 / 2011-08-15 Added mask support to Command#password(str[, mask], fn) Added Command#password(str, fn) 0.0.1 / 2010-01-03 Initial release"
  },
  "node_modules/commander/Readme.html": {
    "href": "node_modules/commander/Readme.html",
    "title": "Commander.js | accouter",
    "keywords": "Commander.js The complete solution for node.js command-line interfaces, inspired by Ruby's commander. API documentation Installation $ npm install commander Option parsing Options with commander are defined with the .option() method, also serving as documentation for the options. The example below parses args and options from process.argv, leaving remaining args as the program.args array which were not consumed by options. #!/usr/bin/env node /** * Module dependencies. */ var program = require('commander'); program .version('0.1.0') .option('-p, --peppers', 'Add peppers') .option('-P, --pineapple', 'Add pineapple') .option('-b, --bbq-sauce', 'Add bbq sauce') .option('-c, --cheese [type]', 'Add the specified type of cheese [marble]', 'marble') .parse(process.argv); console.log('you ordered a pizza with:'); if (program.peppers) console.log(' - peppers'); if (program.pineapple) console.log(' - pineapple'); if (program.bbqSauce) console.log(' - bbq'); console.log(' - %s cheese', program.cheese); Short flags may be passed as a single arg, for example -abc is equivalent to -a -b -c. Multi-word options such as \"--template-engine\" are camel-cased, becoming program.templateEngine etc. Note that multi-word options starting with --no prefix negate the boolean value of the following word. For example, --no-sauce sets the value of program.sauce to false. #!/usr/bin/env node /** * Module dependencies. */ var program = require('commander'); program .option('--no-sauce', 'Remove sauce') .parse(process.argv); console.log('you ordered a pizza'); if (program.sauce) console.log(' with sauce'); else console.log(' without sauce'); To get string arguments from options you will need to use angle brackets <> for required inputs or square brackets [] for optional inputs. e.g. .option('-m --myarg [myVar]', 'my super cool description') Then to access the input if it was passed in. e.g. var myInput = program.myarg NOTE: If you pass a argument without using brackets the example above will return true and not the value passed in. Version option Calling the version implicitly adds the -V and --version options to the command. When either of these options is present, the command prints the version number and exits. $ ./examples/pizza -V 0.0.1 If you want your program to respond to the -v option instead of the -V option, simply pass custom flags to the version method using the same syntax as the option method. program .version('0.0.1', '-v, --version') The version flags can be named anything, but the long option is required. Command-specific options You can attach options to a command. #!/usr/bin/env node var program = require('commander'); program .command('rm <dir>') .option('-r, --recursive', 'Remove recursively') .action(function (dir, cmd) { console.log('remove ' + dir + (cmd.recursive ? ' recursively' : '')) }) program.parse(process.argv) A command's options are validated when the command is used. Any unknown options will be reported as an error. However, if an action-based command does not define an action, then the options are not validated. Coercion function range(val) { return val.split('..').map(Number); } function list(val) { return val.split(','); } function collect(val, memo) { memo.push(val); return memo; } function increaseVerbosity(v, total) { return total + 1; } program .version('0.1.0') .usage('[options] <file ...>') .option('-i, --integer <n>', 'An integer argument', parseInt) .option('-f, --float <n>', 'A float argument', parseFloat) .option('-r, --range <a>..<b>', 'A range', range) .option('-l, --list <items>', 'A list', list) .option('-o, --optional [value]', 'An optional value') .option('-c, --collect [value]', 'A repeatable value', collect, []) .option('-v, --verbose', 'A value that can be increased', increaseVerbosity, 0) .parse(process.argv); console.log(' int: %j', program.integer); console.log(' float: %j', program.float); console.log(' optional: %j', program.optional); program.range = program.range || []; console.log(' range: %j..%j', program.range[0], program.range[1]); console.log(' list: %j', program.list); console.log(' collect: %j', program.collect); console.log(' verbosity: %j', program.verbose); console.log(' args: %j', program.args); Regular Expression program .version('0.1.0') .option('-s --size <size>', 'Pizza size', /^(large|medium|small)$/i, 'medium') .option('-d --drink [drink]', 'Drink', /^(coke|pepsi|izze)$/i) .parse(process.argv); console.log(' size: %j', program.size); console.log(' drink: %j', program.drink); Variadic arguments The last argument of a command can be variadic, and only the last argument. To make an argument variadic you have to append ... to the argument name. Here is an example: #!/usr/bin/env node /** * Module dependencies. */ var program = require('commander'); program .version('0.1.0') .command('rmdir <dir> [otherDirs...]') .action(function (dir, otherDirs) { console.log('rmdir %s', dir); if (otherDirs) { otherDirs.forEach(function (oDir) { console.log('rmdir %s', oDir); }); } }); program.parse(process.argv); An Array is used for the value of a variadic argument. This applies to program.args as well as the argument passed to your action as demonstrated above. Specify the argument syntax #!/usr/bin/env node var program = require('commander'); program .version('0.1.0') .arguments('<cmd> [env]') .action(function (cmd, env) { cmdValue = cmd; envValue = env; }); program.parse(process.argv); if (typeof cmdValue === 'undefined') { console.error('no command given!'); process.exit(1); } console.log('command:', cmdValue); console.log('environment:', envValue || \"no environment given\"); Angled brackets (e.g. <cmd>) indicate required input. Square brackets (e.g. [env]) indicate optional input. Git-style sub-commands // file: ./examples/pm var program = require('commander'); program .version('0.1.0') .command('install [name]', 'install one or more packages') .command('search [query]', 'search with optional query') .command('list', 'list packages installed', {isDefault: true}) .parse(process.argv); When .command() is invoked with a description argument, no .action(callback) should be called to handle sub-commands, otherwise there will be an error. This tells commander that you're going to use separate executables for sub-commands, much like git(1) and other popular tools. The commander will try to search the executables in the directory of the entry script (like ./examples/pm) with the name program-command, like pm-install, pm-search. Options can be passed with the call to .command(). Specifying true for opts.noHelp will remove the subcommand from the generated help output. Specifying true for opts.isDefault will run the subcommand if no other subcommand is specified. If the program is designed to be installed globally, make sure the executables have proper modes, like 755. --harmony You can enable --harmony option in two ways: Use #! /usr/bin/env node --harmony in the sub-commands scripts. Note some os version don’t support this pattern. Use the --harmony option when call the command, like node --harmony examples/pm publish. The --harmony option will be preserved when spawning sub-command process. Automated --help The help information is auto-generated based on the information commander already knows about your program, so the following --help info is for free: $ ./examples/pizza --help Usage: pizza [options] An application for pizzas ordering Options: -h, --help output usage information -V, --version output the version number -p, --peppers Add peppers -P, --pineapple Add pineapple -b, --bbq Add bbq sauce -c, --cheese <type> Add the specified type of cheese [marble] -C, --no-cheese You do not want any cheese Custom help You can display arbitrary -h, --help information by listening for \"--help\". Commander will automatically exit once you are done so that the remainder of your program does not execute causing undesired behaviors, for example in the following executable \"stuff\" will not output when --help is used. #!/usr/bin/env node /** * Module dependencies. */ var program = require('commander'); program .version('0.1.0') .option('-f, --foo', 'enable some foo') .option('-b, --bar', 'enable some bar') .option('-B, --baz', 'enable some baz'); // must be before .parse() since // node's emit() is immediate program.on('--help', function(){ console.log('') console.log('Examples:'); console.log(' $ custom-help --help'); console.log(' $ custom-help -h'); }); program.parse(process.argv); console.log('stuff'); Yields the following help output when node script-name.js -h or node script-name.js --help are run: Usage: custom-help [options] Options: -h, --help output usage information -V, --version output the version number -f, --foo enable some foo -b, --bar enable some bar -B, --baz enable some baz Examples: $ custom-help --help $ custom-help -h .outputHelp(cb) Output help information without exiting. Optional callback cb allows post-processing of help text before it is displayed. If you want to display help by default (e.g. if no command was provided), you can use something like: var program = require('commander'); var colors = require('colors'); program .version('0.1.0') .command('getstream [url]', 'get stream URL') .parse(process.argv); if (!process.argv.slice(2).length) { program.outputHelp(make_red); } function make_red(txt) { return colors.red(txt); //display the help text in red on the console } .help(cb) Output help information and exit immediately. Optional callback cb allows post-processing of help text before it is displayed. Custom event listeners You can execute custom actions by listening to command and option events. program.on('option:verbose', function () { process.env.VERBOSE = this.verbose; }); // error on unknown commands program.on('command:*', function () { console.error('Invalid command: %s\\nSee --help for a list of available commands.', program.args.join(' ')); process.exit(1); }); Examples var program = require('commander'); program .version('0.1.0') .option('-C, --chdir <path>', 'change the working directory') .option('-c, --config <path>', 'set config path. defaults to ./deploy.conf') .option('-T, --no-tests', 'ignore test hook'); program .command('setup [env]') .description('run setup commands for all envs') .option(\"-s, --setup_mode [mode]\", \"Which setup mode to use\") .action(function(env, options){ var mode = options.setup_mode || \"normal\"; env = env || 'all'; console.log('setup for %s env(s) with %s mode', env, mode); }); program .command('exec <cmd>') .alias('ex') .description('execute the given remote cmd') .option(\"-e, --exec_mode <mode>\", \"Which exec mode to use\") .action(function(cmd, options){ console.log('exec \"%s\" using %s mode', cmd, options.exec_mode); }).on('--help', function() { console.log(''); console.log('Examples:'); console.log(''); console.log(' $ deploy exec sequential'); console.log(' $ deploy exec async'); }); program .command('*') .action(function(env){ console.log('deploying \"%s\"', env); }); program.parse(process.argv); More Demos can be found in the examples directory. License MIT"
  },
  "node_modules/connect-history-api-fallback/CHANGELOG.html": {
    "href": "node_modules/connect-history-api-fallback/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog v1.6.0 Recommend absolute paths for rewrite targets. Contributed by @helfi92. v1.5.0 Expose the HTTP request object in rewrite rules. Contributed by @VladShcherbin. v1.4.0 The . (DOT) rule should only check the last path element. Contributed by @ntkme. v1.3.0 Allow disabling of the . (DOT) rule via the disableDotRule option. v1.2.0 Support definition of custom HTML Accept header values. Contributed by @cgmartin. v1.1.0 Rewrite rules are now applied before the request URL is checked for dots. Rewrite rules can be defined as functions to have greater control over the dot rule. v1.0.0 This version introduces a fair amount of breaking changes. Specifically, instances of the historyApiFallback need to be created via the exported function. Previously, this was not necessary. Breaking: Support multiple instances of the historyApiFallback middleware with different configurations. Breaking: Loggers are configured per historyApiFallback middleware instance (see README.md). The fallback index HTML file can be configured. Default is /index.html. Additional rewrite rules can be defined via regular expressions."
  },
  "node_modules/connect-history-api-fallback/README.html": {
    "href": "node_modules/connect-history-api-fallback/README.html",
    "title": "connect-history-api-fallback | accouter",
    "keywords": "connect-history-api-fallback Middleware to proxy requests through a specified index page, useful for Single Page Applications that utilise the HTML5 History API. Table of Contents Introduction Usage Options index rewrites verbose htmlAcceptHeaders disableDotRule Introduction Single Page Applications (SPA) typically only utilise one index file that is accessible by web browsers: usually index.html. Navigation in the application is then commonly handled using JavaScript with the help of the HTML5 History API. This results in issues when the user hits the refresh button or is directly accessing a page other than the landing page, e.g. /help or /help/online as the web server bypasses the index file to locate the file at this location. As your application is a SPA, the web server will fail trying to retrieve the file and return a 404 - Not Found message to the user. This tiny middleware addresses some of the issues. Specifically, it will change the requested location to the index you specify (default being /index.html) whenever there is a request which fulfills the following criteria: The request is a GET request which accepts text/html, is not a direct file request, i.e. the requested path does not contain a . (DOT) character and does not match a pattern provided in options.rewrites (see options below) Usage The middleware is available through NPM and can easily be added. npm install --save connect-history-api-fallback Import the library var history = require('connect-history-api-fallback'); Now you only need to add the middleware to your application like so var connect = require('connect'); var app = connect() .use(history()) .listen(3000); Of course you can also use this piece of middleware with express: var express = require('express'); var app = express(); app.use(history()); Options You can optionally pass options to the library when obtaining the middleware var middleware = history({}); index Override the index (default /index.html) history({ index: '/default.html' }); rewrites Override the index when the request url matches a regex pattern. You can either rewrite to a static string or use a function to transform the incoming request. The following will rewrite a request that matches the /\\/soccer/ pattern to /soccer.html. history({ rewrites: [ { from: /\\/soccer/, to: '/soccer.html'} ] }); Alternatively functions can be used to have more control over the rewrite process. For instance, the following listing shows how requests to /libs/jquery/jquery.1.12.0.min.js and the like can be routed to ./bower_components/libs/jquery/jquery.1.12.0.min.js. You can also make use of this if you have an API version in the URL path. history({ rewrites: [ { from: /^\\/libs\\/.*$/, to: function(context) { return '/bower_components' + context.parsedUrl.pathname; } } ] }); The function will always be called with a context object that has the following properties: parsedUrl: Information about the URL as provided by the URL module's url.parse. match: An Array of matched results as provided by String.match(...). request: The HTTP request object. verbose This middleware does not log any information by default. If you wish to activate logging, then you can do so via the verbose option or by specifying a logger function. history({ verbose: true }); Alternatively use your own logger history({ logger: console.log.bind(console) }); htmlAcceptHeaders Override the default Accepts: headers that are queried when matching HTML content requests (Default: ['text/html', '*/*']). history({ htmlAcceptHeaders: ['text/html', 'application/xhtml+xml'] }) disableDotRule Disables the dot rule mentioned above: […] is not a direct file request, i.e. the requested path does not contain a . (DOT) character […] history({ disableDotRule: true })"
  },
  "node_modules/connect/HISTORY.html": {
    "href": "node_modules/connect/HISTORY.html",
    "title": "3.6.6 / 2018-02-14 | accouter",
    "keywords": "3.6.6 / 2018-02-14 deps: finalhandler@1.1.0 Use res.headersSent when available perf: remove array read-past-end 3.6.5 / 2017-09-22 deps: debug@2.6.9 deps: finalhandler@1.0.6 deps: debug@2.6.9 3.6.4 / 2017-09-20 deps: finalhandler@1.0.5 deps: parseurl@~1.3.2 deps: parseurl@~1.3.2 perf: reduce overhead for full URLs perf: unroll the \"fast-path\" RegExp deps: utils-merge@1.0.1 3.6.3 / 2017-08-03 deps: debug@2.6.8 deps: finalhandler@1.0.4 deps: debug@2.6.8 3.6.2 / 2017-05-16 deps: finalhandler@1.0.3 deps: debug@2.6.7 deps: debug@2.6.7 deps: ms@2.0.0 3.6.1 / 2017-04-19 deps: debug@2.6.3 Fix DEBUG_MAX_ARRAY_LENGTH deps: finalhandler@1.0.1 Fix missing </html> in HTML document deps: debug@2.6.3 3.6.0 / 2017-02-17 deps: debug@2.6.1 Allow colors in workers Deprecated DEBUG_FD environment variable set to 3 or higher Fix error when running under React Native Use same color for same namespace deps: ms@0.7.2 deps: finalhandler@1.0.0 Fix exception when err cannot be converted to a string Fully URL-encode the pathname in the 404 Only include the pathname in the 404 message Send complete HTML document Set Content-Security-Policy: default-src 'self' header deps: debug@2.6.1 3.5.1 / 2017-02-12 deps: finalhandler@0.5.1 Fix exception when err.headers is not an object deps: statuses@~1.3.1 perf: hoist regular expressions perf: remove duplicate validation path 3.5.0 / 2016-09-09 deps: finalhandler@0.5.0 Change invalid or non-numeric status code to 500 Overwrite status message to match set status code Prefer err.statusCode if err.status is invalid Set response headers from err.headers object Use statuses instead of http module for status messages 3.4.1 / 2016-01-23 deps: finalhandler@0.4.1 deps: escape-html@~1.0.3 deps: parseurl@~1.3.1 perf: enable strict mode 3.4.0 / 2015-06-18 deps: debug@~2.2.0 deps: ms@0.7.1 deps: finalhandler@0.4.0 Fix a false-positive when unpiping in Node.js 0.8 Support statusCode property on Error objects Use unpipe module for unpiping requests deps: debug@~2.2.0 deps: escape-html@1.0.2 deps: on-finished@~2.3.0 perf: enable strict mode perf: remove argument reassignment perf: enable strict mode perf: remove argument reassignments 3.3.5 / 2015-03-16 deps: debug@~2.1.3 Fix high intensity foreground color for bold deps: ms@0.7.0 deps: finalhandler@0.3.4 deps: debug@~2.1.3 3.3.4 / 2015-01-07 deps: debug@~2.1.1 deps: finalhandler@0.3.3 deps: debug@~2.1.1 deps: on-finished@~2.2.0 3.3.3 / 2014-11-09 Correctly invoke async callback asynchronously 3.3.2 / 2014-10-28 Fix handling of URLs containing :// in the path 3.3.1 / 2014-10-22 deps: finalhandler@0.3.2 deps: on-finished@~2.1.1 3.3.0 / 2014-10-17 deps: debug@~2.1.0 Implement DEBUG_FD env variable support deps: finalhandler@0.3.1 Terminate in progress response only on error Use on-finished to determine request status deps: debug@~2.1.0 3.2.0 / 2014-09-08 deps: debug@~2.0.0 deps: finalhandler@0.2.0 Set X-Content-Type-Options: nosniff header deps: debug@~2.0.0 3.1.1 / 2014-08-10 deps: parseurl@~1.3.0 3.1.0 / 2014-07-22 deps: debug@1.0.4 deps: finalhandler@0.1.0 Respond after request fully read deps: debug@1.0.4 deps: parseurl@~1.2.0 Cache URLs based on original value Remove no-longer-needed URL mis-parse work-around Simplify the \"fast-path\" RegExp perf: reduce executed logic in routing perf: refactor location of try block 3.0.2 / 2014-07-10 deps: debug@1.0.3 Add support for multiple wildcards in namespaces deps: parseurl@~1.1.3 faster parsing of href-only URLs 3.0.1 / 2014-06-19 use finalhandler for final response handling deps: debug@1.0.2 3.0.0 / 2014-05-29 No changes 3.0.0-rc.2 / 2014-05-04 Call error stack even when response has been sent Prevent default 404 handler after response sent dep: debug@0.8.1 encode stack in HTML for default error handler remove proto export 3.0.0-rc.1 / 2014-03-06 move middleware to separate repos remove docs remove node patches remove connect(middleware...) remove the old connect.createServer() method remove various private connect.utils functions drop node.js 0.8 support 2.30.2 / 2015-07-31 deps: body-parser@~1.13.3 deps: type-is@~1.6.6 deps: compression@~1.5.2 deps: accepts@~1.2.12 deps: compressible@~2.0.5 deps: vary@~1.0.1 deps: errorhandler@~1.4.2 deps: accepts@~1.2.12 deps: method-override@~2.3.5 deps: vary@~1.0.1 perf: enable strict mode deps: serve-index@~1.7.2 deps: accepts@~1.2.12 deps: mime-types@~2.1.4 deps: type-is@~1.6.6 deps: mime-types@~2.1.4 deps: vhost@~3.0.1 perf: enable strict mode 2.30.1 / 2015-07-05 deps: body-parser@~1.13.2 deps: iconv-lite@0.4.11 deps: qs@4.0.0 deps: raw-body@~2.1.2 deps: type-is@~1.6.4 deps: compression@~1.5.1 deps: accepts@~1.2.10 deps: compressible@~2.0.4 deps: errorhandler@~1.4.1 deps: accepts@~1.2.10 deps: qs@4.0.0 Fix dropping parameters like hasOwnProperty Fix various parsing edge cases deps: morgan@~1.6.1 deps: basic-auth@~1.0.3 deps: pause@0.1.0 Re-emit events with all original arguments Refactor internals perf: enable strict mode deps: serve-index@~1.7.1 deps: accepts@~1.2.10 deps: mime-types@~2.1.2 deps: type-is@~1.6.4 deps: mime-types@~2.1.2 perf: enable strict mode perf: remove argument reassignment 2.30.0 / 2015-06-18 deps: body-parser@~1.13.1 Add statusCode property on Errors, in addition to status Change type default to application/json for JSON parser Change type default to application/x-www-form-urlencoded for urlencoded parser Provide static require analysis Use the http-errors module to generate errors deps: bytes@2.1.0 deps: iconv-lite@0.4.10 deps: on-finished@~2.3.0 deps: raw-body@~2.1.1 deps: type-is@~1.6.3 perf: enable strict mode perf: remove argument reassignment perf: remove delete call deps: bytes@2.1.0 Slight optimizations Units no longer case sensitive when parsing deps: compression@~1.5.0 Fix return value from .end and .write after end Improve detection of zero-length body without Content-Length deps: accepts@~1.2.9 deps: bytes@2.1.0 deps: compressible@~2.0.3 perf: enable strict mode perf: remove flush reassignment perf: simplify threshold detection deps: cookie@0.1.3 Slight optimizations deps: cookie-parser@~1.3.5 deps: cookie@0.1.3 deps: csurf@~1.8.3 Add sessionKey option deps: cookie@0.1.3 deps: csrf@~3.0.0 deps: errorhandler@~1.4.0 Add charset to the Content-Type header Support statusCode property on Error objects deps: accepts@~1.2.9 deps: escape-html@1.0.2 deps: express-session@~1.11.3 Support an array in secret option for key rotation deps: cookie@0.1.3 deps: crc@3.3.0 deps: debug@~2.2.0 deps: depd@~1.0.1 deps: uid-safe@~2.0.0 deps: finalhandler@0.4.0 Fix a false-positive when unpiping in Node.js 0.8 Support statusCode property on Error objects Use unpipe module for unpiping requests deps: escape-html@1.0.2 deps: on-finished@~2.3.0 perf: enable strict mode perf: remove argument reassignment deps: fresh@0.3.0 Add weak ETag matching support deps: morgan@~1.6.0 Add morgan.compile(format) export Do not color 1xx status codes in dev format Fix response-time token to not include response latency Fix status token incorrectly displaying before response in dev format Fix token return values to be undefined or a string Improve representation of multiple headers in req and res tokens Use res.getHeader in res token deps: basic-auth@~1.0.2 deps: on-finished@~2.3.0 pref: enable strict mode pref: reduce function closure scopes pref: remove dynamic compile on every request for dev format pref: remove an argument reassignment pref: skip function call without skip option deps: serve-favicon@~2.3.0 Send non-chunked response for OPTIONS deps: etag@~1.7.0 deps: fresh@0.3.0 perf: enable strict mode perf: remove argument reassignment perf: remove bitwise operations deps: serve-index@~1.7.0 Accept function value for template option Send non-chunked response for OPTIONS Stat parent directory when necessary Use Date.prototype.toLocaleDateString to format date deps: accepts@~1.2.9 deps: escape-html@1.0.2 deps: mime-types@~2.1.1 perf: enable strict mode perf: remove argument reassignment deps: serve-static@~1.10.0 Add fallthrough option Fix reading options from options prototype Improve the default redirect response headers Malformed URLs now next() instead of 400 deps: escape-html@1.0.2 deps: send@0.13.0 perf: enable strict mode perf: remove argument reassignment deps: type-is@~1.6.3 deps: mime-types@~2.1.1 perf: reduce try block size perf: remove bitwise operations 2.29.2 / 2015-05-14 deps: body-parser@~1.12.4 Slight efficiency improvement when not debugging deps: debug@~2.2.0 deps: depd@~1.0.1 deps: iconv-lite@0.4.8 deps: on-finished@~2.2.1 deps: qs@2.4.2 deps: raw-body@~2.0.1 deps: type-is@~1.6.2 deps: compression@~1.4.4 deps: accepts@~1.2.7 deps: debug@~2.2.0 deps: connect-timeout@~1.6.2 deps: debug@~2.2.0 deps: ms@0.7.1 deps: debug@~2.2.0 deps: ms@0.7.1 deps: depd@~1.0.1 deps: errorhandler@~1.3.6 deps: accepts@~1.2.7 deps: finalhandler@0.3.6 deps: debug@~2.2.0 deps: on-finished@~2.2.1 deps: method-override@~2.3.3 deps: debug@~2.2.0 deps: morgan@~1.5.3 deps: basic-auth@~1.0.1 deps: debug@~2.2.0 deps: depd@~1.0.1 deps: on-finished@~2.2.1 deps: qs@2.4.2 Fix allowing parameters like constructor deps: response-time@~2.3.1 deps: depd@~1.0.1 deps: serve-favicon@~2.2.1 deps: etag@~1.6.0 deps: ms@0.7.1 deps: serve-index@~1.6.4 deps: accepts@~1.2.7 deps: debug@~2.2.0 deps: mime-types@~2.0.11 deps: serve-static@~1.9.3 deps: send@0.12.3 deps: type-is@~1.6.2 deps: mime-types@~2.0.11 2.29.1 / 2015-03-16 deps: body-parser@~1.12.2 deps: debug@~2.1.3 deps: qs@2.4.1 deps: type-is@~1.6.1 deps: compression@~1.4.3 Fix error when code calls res.end(str, encoding) deps: accepts@~1.2.5 deps: debug@~2.1.3 deps: connect-timeout@~1.6.1 deps: debug@~2.1.3 deps: debug@~2.1.3 Fix high intensity foreground color for bold deps: ms@0.7.0 deps: errorhandler@~1.3.5 deps: accepts@~1.2.5 deps: express-session@~1.10.4 deps: debug@~2.1.3 deps: finalhandler@0.3.4 deps: debug@~2.1.3 deps: method-override@~2.3.2 deps: debug@~2.1.3 deps: morgan@~1.5.2 deps: debug@~2.1.3 deps: qs@2.4.1 Fix error when parameter hasOwnProperty is present deps: serve-index@~1.6.3 Properly escape file names in HTML deps: accepts@~1.2.5 deps: debug@~2.1.3 deps: escape-html@1.0.1 deps: mime-types@~2.0.10 deps: serve-static@~1.9.2 deps: send@0.12.2 deps: type-is@~1.6.1 deps: mime-types@~2.0.10 2.29.0 / 2015-02-17 Use content-type to parse Content-Type headers deps: body-parser@~1.12.0 add debug messages accept a function for the type option make internal extended: true depth limit infinity use content-type to parse Content-Type headers deps: iconv-lite@0.4.7 deps: raw-body@1.3.3 deps: type-is@~1.6.0 deps: compression@~1.4.1 Prefer gzip over deflate on the server deps: accepts@~1.2.4 deps: connect-timeout@~1.6.0 deps: http-errors@~1.3.1 deps: cookie-parser@~1.3.4 deps: cookie-signature@1.0.6 deps: cookie-signature@1.0.6 deps: csurf@~1.7.0 Accept CSRF-Token and XSRF-Token request headers Default cookie.path to '/', if using cookies deps: cookie-signature@1.0.6 deps: csrf@~2.0.6 deps: http-errors@~1.3.1 deps: errorhandler@~1.3.4 deps: accepts@~1.2.4 deps: express-session@~1.10.3 deps: cookie-signature@1.0.6 deps: uid-safe@1.1.0 deps: http-errors@~1.3.1 Construct errors using defined constructors from createError Fix error names that are not identifiers Set a meaningful name property on constructed errors deps: response-time@~2.3.0 Add function argument to support recording of response time deps: serve-index@~1.6.2 deps: accepts@~1.2.4 deps: http-errors@~1.3.1 deps: mime-types@~2.0.9 deps: serve-static@~1.9.1 deps: send@0.12.1 deps: type-is@~1.6.0 fix argument reassignment fix false-positives in hasBody Transfer-Encoding check support wildcard for both type and subtype (*/*) deps: mime-types@~2.0.9 2.28.3 / 2015-01-31 deps: compression@~1.3.1 deps: accepts@~1.2.3 deps: compressible@~2.0.2 deps: csurf@~1.6.6 deps: csrf@~2.0.5 deps: errorhandler@~1.3.3 deps: accepts@~1.2.3 deps: express-session@~1.10.2 deps: uid-safe@1.0.3 deps: serve-index@~1.6.1 deps: accepts@~1.2.3 deps: mime-types@~2.0.8 deps: type-is@~1.5.6 deps: mime-types@~2.0.8 2.28.2 / 2015-01-20 deps: body-parser@~1.10.2 deps: iconv-lite@0.4.6 deps: raw-body@1.3.2 deps: serve-static@~1.8.1 Fix redirect loop in Node.js 0.11.14 Fix root path disclosure deps: send@0.11.1 2.28.1 / 2015-01-08 deps: csurf@~1.6.5 deps: csrf@~2.0.4 deps: express-session@~1.10.1 deps: uid-safe@~1.0.2 2.28.0 / 2015-01-05 deps: body-parser@~1.10.1 Make internal extended: true array limit dynamic deps: on-finished@~2.2.0 deps: type-is@~1.5.5 deps: compression@~1.3.0 Export the default filter function for wrapping deps: accepts@~1.2.2 deps: debug@~2.1.1 deps: connect-timeout@~1.5.0 deps: debug@~2.1.1 deps: http-errors@~1.2.8 deps: ms@0.7.0 deps: csurf@~1.6.4 deps: csrf@~2.0.3 deps: http-errors@~1.2.8 deps: debug@~2.1.1 deps: errorhandler@~1.3.2 Add log option Fix heading content to not include stack deps: accepts@~1.2.2 deps: express-session@~1.10.0 Add store.touch interface for session stores Fix MemoryStore expiration with resave: false deps: debug@~2.1.1 deps: finalhandler@0.3.3 deps: debug@~2.1.1 deps: on-finished@~2.2.0 deps: method-override@~2.3.1 deps: debug@~2.1.1 deps: methods@~1.1.1 deps: morgan@~1.5.1 Add multiple date formats clf, iso, and web Deprecate buffer option Fix date format in common and combined formats Fix token arguments to accept values with \" deps: debug@~2.1.1 deps: on-finished@~2.2.0 deps: serve-favicon@~2.2.0 Support query string in the URL deps: etag@~1.5.1 deps: ms@0.7.0 deps: serve-index@~1.6.0 Add link to root directory deps: accepts@~1.2.2 deps: batch@0.5.2 deps: debug@~2.1.1 deps: mime-types@~2.0.7 deps: serve-static@~1.8.0 Fix potential open redirect when mounted at root deps: send@0.11.0 deps: type-is@~1.5.5 deps: mime-types@~2.0.7 2.27.6 / 2014-12-10 deps: serve-index@~1.5.3 deps: accepts@~1.1.4 deps: http-errors@~1.2.8 deps: mime-types@~2.0.4 2.27.5 / 2014-12-10 deps: compression@~1.2.2 Fix .end to only proxy to .end deps: accepts@~1.1.4 deps: express-session@~1.9.3 Fix error when req.sessionID contains a non-string value deps: http-errors@~1.2.8 Fix stack trace from exported function Remove arguments.callee usage deps: serve-index@~1.5.2 Fix icon name background alignment on mobile view deps: type-is@~1.5.4 deps: mime-types@~2.0.4 2.27.4 / 2014-11-23 deps: body-parser@~1.9.3 deps: iconv-lite@0.4.5 deps: qs@2.3.3 deps: raw-body@1.3.1 deps: type-is@~1.5.3 deps: compression@~1.2.1 deps: accepts@~1.1.3 deps: errorhandler@~1.2.3 deps: accepts@~1.1.3 deps: express-session@~1.9.2 deps: crc@3.2.1 deps: qs@2.3.3 Fix arrayLimit behavior deps: serve-favicon@~2.1.7 Avoid errors from enumerables on Object.prototype deps: serve-index@~1.5.1 deps: accepts@~1.1.3 deps: mime-types@~2.0.3 deps: type-is@~1.5.3 deps: mime-types@~2.0.3 2.27.3 / 2014-11-09 Correctly invoke async callback asynchronously deps: csurf@~1.6.3 bump csrf bump http-errors 2.27.2 / 2014-10-28 Fix handling of URLs containing :// in the path deps: body-parser@~1.9.2 deps: qs@2.3.2 deps: qs@2.3.2 Fix parsing of mixed objects and values 2.27.1 / 2014-10-22 deps: body-parser@~1.9.1 deps: on-finished@~2.1.1 deps: qs@2.3.0 deps: type-is@~1.5.2 deps: express-session@~1.9.1 Remove unnecessary empty write call deps: finalhandler@0.3.2 deps: on-finished@~2.1.1 deps: morgan@~1.4.1 deps: on-finished@~2.1.1 deps: qs@2.3.0 Fix parsing of mixed implicit and explicit arrays deps: serve-static@~1.7.1 deps: send@0.10.1 2.27.0 / 2014-10-16 Use http-errors module for creating errors Use utils-merge module for merging objects deps: body-parser@~1.9.0 include the charset in \"unsupported charset\" error message include the encoding in \"unsupported content encoding\" error message deps: depd@~1.0.0 deps: compression@~1.2.0 deps: debug@~2.1.0 deps: connect-timeout@~1.4.0 Create errors with http-errors deps: debug@~2.1.0 deps: debug@~2.1.0 Implement DEBUG_FD env variable support deps: depd@~1.0.0 deps: express-session@~1.9.0 deps: debug@~2.1.0 deps: depd@~1.0.0 deps: finalhandler@0.3.1 Terminate in progress response only on error Use on-finished to determine request status deps: debug@~2.1.0 deps: method-override@~2.3.0 deps: debug@~2.1.0 deps: morgan@~1.4.0 Add debug messages deps: depd@~1.0.0 deps: response-time@~2.2.0 Add header option for custom header name Add suffix option Change digits argument to an options argument deps: depd@~1.0.0 deps: serve-favicon@~2.1.6 deps: etag@~1.5.0 deps: serve-index@~1.5.0 Add dir argument to filter function Add icon for mkv files Create errors with http-errors Fix incorrect 403 on Windows and Node.js 0.11 Lookup icon by mime type for greater icon support Support using tokens multiple times deps: accepts@~1.1.2 deps: debug@~2.1.0 deps: mime-types@~2.0.2 deps: serve-static@~1.7.0 deps: send@0.10.0 2.26.6 / 2014-10-15 deps: compression@~1.1.2 deps: accepts@~1.1.2 deps: compressible@~2.0.1 deps: csurf@~1.6.2 bump http-errors fix cookie name when using cookie: true deps: errorhandler@~1.2.2 deps: accepts@~1.1.2 2.26.5 / 2014-10-08 Fix accepting non-object arguments to logger deps: serve-static@~1.6.4 Fix redirect loop when index file serving disabled 2.26.4 / 2014-10-02 deps: morgan@~1.3.2 Fix req.ip integration when immediate: false deps: type-is@~1.5.2 deps: mime-types@~2.0.2 2.26.3 / 2014-09-24 deps: body-parser@~1.8.4 fix content encoding to be case-insensitive deps: serve-favicon@~2.1.5 deps: etag@~1.4.0 deps: serve-static@~1.6.3 deps: send@0.9.3 2.26.2 / 2014-09-19 deps: body-parser@~1.8.3 deps: qs@2.2.4 deps: qs@2.2.4 Fix issue with object keys starting with numbers truncated 2.26.1 / 2014-09-15 deps: body-parser@~1.8.2 deps: depd@0.4.5 deps: depd@0.4.5 deps: express-session@~1.8.2 Use crc instead of buffer-crc32 for speed deps: depd@0.4.5 deps: morgan@~1.3.1 Remove un-used bytes dependency deps: depd@0.4.5 deps: serve-favicon@~2.1.4 Fix content headers being sent in 304 response deps: etag@~1.3.1 deps: serve-static@~1.6.2 deps: send@0.9.2 2.26.0 / 2014-09-08 deps: body-parser@~1.8.1 add parameterLimit option to urlencoded parser change urlencoded extended array limit to 100 make empty-body-handling consistent between chunked requests respond with 415 when over parameterLimit in urlencoded deps: media-typer@0.3.0 deps: qs@2.2.3 deps: type-is@~1.5.1 deps: compression@~1.1.0 deps: accepts@~1.1.0 deps: compressible@~2.0.0 deps: debug@~2.0.0 deps: connect-timeout@~1.3.0 deps: debug@~2.0.0 deps: cookie-parser@~1.3.3 deps: cookie-signature@1.0.5 deps: cookie-signature@1.0.5 deps: csurf@~1.6.1 add ignoreMethods option bump cookie-signature csrf-tokens -> csrf set code property on CSRF token errors deps: debug@~2.0.0 deps: errorhandler@~1.2.0 Display error using util.inspect if no other representation deps: accepts@~1.1.0 deps: express-session@~1.8.1 Do not resave already-saved session at end of request Prevent session prototype methods from being overwritten deps: cookie-signature@1.0.5 deps: debug@~2.0.0 deps: finalhandler@0.2.0 Set X-Content-Type-Options: nosniff header deps: debug@~2.0.0 deps: fresh@0.2.4 deps: media-typer@0.3.0 Throw error when parameter format invalid on parse deps: method-override@~2.2.0 deps: debug@~2.0.0 deps: morgan@~1.3.0 Assert if format is not a function or string deps: qs@2.2.3 Fix issue where first empty value in array is discarded deps: serve-favicon@~2.1.3 Accept string for maxAge (converted by ms) Use etag to generate ETag header deps: fresh@0.2.4 deps: serve-index@~1.2.1 Add debug messages Resolve relative paths at middleware setup deps: accepts@~1.1.0 deps: serve-static@~1.6.1 Add lastModified option deps: send@0.9.1 deps: type-is@~1.5.1 fix hasbody to be true for content-length: 0 deps: media-typer@0.3.0 deps: mime-types@~2.0.1 deps: vhost@~3.0.0 2.25.10 / 2014-09-04 deps: serve-static@~1.5.4 deps: send@0.8.5 2.25.9 / 2014-08-29 deps: body-parser@~1.6.7 deps: qs@2.2.2 deps: qs@2.2.2 2.25.8 / 2014-08-27 deps: body-parser@~1.6.6 deps: qs@2.2.0 deps: csurf@~1.4.1 deps: qs@2.2.0 Array parsing fix Performance improvements 2.25.7 / 2014-08-18 deps: body-parser@~1.6.5 deps: on-finished@2.1.0 deps: express-session@~1.7.6 Fix exception on res.end(null) calls deps: morgan@~1.2.3 deps: on-finished@2.1.0 deps: serve-static@~1.5.3 deps: send@0.8.3 2.25.6 / 2014-08-14 deps: body-parser@~1.6.4 deps: qs@1.2.2 deps: qs@1.2.2 deps: serve-static@~1.5.2 deps: send@0.8.2 2.25.5 / 2014-08-11 Fix backwards compatibility in logger 2.25.4 / 2014-08-10 Fix query middleware breaking with argument It never really took one in the first place deps: body-parser@~1.6.3 deps: qs@1.2.1 deps: compression@~1.0.11 deps: on-headers@~1.0.0 deps: parseurl@~1.3.0 deps: connect-timeout@~1.2.2 deps: on-headers@~1.0.0 deps: express-session@~1.7.5 Fix parsing original URL deps: on-headers@~1.0.0 deps: parseurl@~1.3.0 deps: method-override@~2.1.3 deps: on-headers@~1.0.0 deps: parseurl@~1.3.0 deps: qs@1.2.1 deps: response-time@~2.0.1 deps: on-headers@~1.0.0 deps: serve-index@~1.1.6 Fix URL parsing deps: serve-static@~1.5.1 Fix parsing of weird req.originalUrl values deps: parseurl@~1.3.0 = deps: utils-merge@1.0.0 2.25.3 / 2014-08-07 deps: multiparty@3.3.2 Fix potential double-callback 2.25.2 / 2014-08-07 deps: body-parser@~1.6.2 deps: qs@1.2.0 deps: qs@1.2.0 Fix parsing array of objects 2.25.1 / 2014-08-06 deps: body-parser@~1.6.1 deps: qs@1.1.0 deps: qs@1.1.0 Accept urlencoded square brackets Accept empty values in implicit array notation 2.25.0 / 2014-08-05 deps: body-parser@~1.6.0 deps: qs@1.0.2 deps: compression@~1.0.10 Fix upper-case Content-Type characters prevent compression deps: compressible@~1.1.1 deps: csurf@~1.4.0 Support changing req.session after csurf middleware Calling res.csrfToken() after req.session.destroy() will now work deps: express-session@~1.7.4 Fix res.end patch to call correct upstream res.write Fix response end delay for non-chunked responses deps: qs@1.0.2 Complete rewrite Limits array length to 20 Limits object depth to 5 Limits parameters to 1,000 deps: serve-static@~1.5.0 Add extensions option deps: send@0.8.1 2.24.3 / 2014-08-04 deps: serve-index@~1.1.5 Fix Content-Length calculation for multi-byte file names deps: accepts@~1.0.7 deps: serve-static@~1.4.4 Fix incorrect 403 on Windows and Node.js 0.11 deps: send@0.7.4 2.24.2 / 2014-07-27 deps: body-parser@~1.5.2 deps: depd@0.4.4 Work-around v8 generating empty stack traces deps: express-session@~1.7.2 deps: morgan@~1.2.2 deps: serve-static@~1.4.2 2.24.1 / 2014-07-26 deps: body-parser@~1.5.1 deps: depd@0.4.3 Fix exception when global Error.stackTraceLimit is too low deps: express-session@~1.7.1 deps: morgan@~1.2.1 deps: serve-index@~1.1.4 deps: serve-static@~1.4.1 2.24.0 / 2014-07-22 deps: body-parser@~1.5.0 deps: depd@0.4.2 deps: iconv-lite@0.4.4 deps: raw-body@1.3.0 deps: type-is@~1.3.2 deps: compression@~1.0.9 Add debug messages deps: accepts@~1.0.7 deps: connect-timeout@~1.2.1 Accept string for time (converted by ms) deps: debug@1.0.4 deps: debug@1.0.4 deps: depd@0.4.2 Add TRACE_DEPRECATION environment variable Remove non-standard grey color from color output Support --no-deprecation argument Support --trace-deprecation argument deps: express-session@~1.7.0 Improve session-ending error handling deps: debug@1.0.4 deps: depd@0.4.2 deps: finalhandler@0.1.0 Respond after request fully read deps: debug@1.0.4 deps: method-override@~2.1.2 deps: debug@1.0.4 deps: parseurl@~1.2.0 deps: morgan@~1.2.0 Add :remote-user token Add combined log format Add common log format Remove non-standard grey color from dev format deps: multiparty@3.3.1 deps: parseurl@~1.2.0 Cache URLs based on original value Remove no-longer-needed URL mis-parse work-around Simplify the \"fast-path\" RegExp deps: serve-static@~1.4.0 Add dotfiles option deps: parseurl@~1.2.0 deps: send@0.7.0 2.23.0 / 2014-07-10 deps: debug@1.0.3 Add support for multiple wildcards in namespaces deps: express-session@~1.6.4 deps: method-override@~2.1.0 add simple debug output deps: methods@1.1.0 deps: parseurl@~1.1.3 deps: parseurl@~1.1.3 faster parsing of href-only URLs deps: serve-static@~1.3.1 deps: parseurl@~1.1.3 2.22.0 / 2014-07-03 deps: csurf@~1.3.0 Fix cookie.signed option to actually sign cookie deps: express-session@~1.6.1 Fix res.end patch to return correct value Fix res.end patch to handle multiple res.end calls Reject cookies with missing signatures deps: multiparty@3.3.0 Always emit close after all parts ended Fix callback hang in node.js 0.8 on errors deps: serve-static@~1.3.0 Accept string for maxAge (converted by ms) Add setHeaders option Include HTML link in redirect response deps: send@0.5.0 2.21.1 / 2014-06-26 deps: cookie-parser@1.3.2 deps: cookie-signature@1.0.4 deps: cookie-signature@1.0.4 fix for timing attacks deps: express-session@~1.5.2 deps: cookie-signature@1.0.4 deps: type-is@~1.3.2 more mime types 2.21.0 / 2014-06-20 deprecate connect(middleware) -- use app.use(middleware) instead deprecate connect.createServer() -- use connect() instead fix res.setHeader() patch to work with get -> append -> set pattern deps: compression@~1.0.8 deps: errorhandler@~1.1.1 deps: express-session@~1.5.0 Deprecate integration with cookie-parser middleware Deprecate looking for secret in req.secret Directly read cookies; cookie-parser no longer required Directly set cookies; res.cookie no longer required Generate session IDs with uid-safe, faster and even less collisions deps: serve-index@~1.1.3 2.20.2 / 2014-06-19 deps: body-parser@1.4.3 deps: type-is@1.3.1 2.20.1 / 2014-06-19 deps: type-is@1.3.1 fix global variable leak 2.20.0 / 2014-06-19 deprecate verify option to json -- use body-parser npm module instead deprecate verify option to urlencoded -- use body-parser npm module instead deprecate things with depd module use finalhandler for final response handling use media-typer to parse content-type for charset deps: body-parser@1.4.2 check accepted charset in content-type (accepts utf-8) check accepted encoding in content-encoding (accepts identity) deprecate urlencoded() without provided extended option lazy-load urlencoded parsers support gzip and deflate bodies set inflate: false to turn off deps: raw-body@1.2.2 deps: type-is@1.3.0 Support all encodings from iconv-lite deps: connect-timeout@1.1.1 deps: debug@1.0.2 deps: cookie-parser@1.3.1 export parsing functions req.cookies and req.signedCookies are now plain objects slightly faster parsing of many cookies deps: csurf@1.2.2 deps: errorhandler@1.1.0 Display error on console formatted like throw Escape HTML in stack trace Escape HTML in title Fix up edge cases with error sent in response Set X-Content-Type-Options: nosniff header Use accepts for negotiation deps: express-session@1.4.0 Add genid option to generate custom session IDs Add saveUninitialized option to control saving uninitialized sessions Add unset option to control unsetting req.session Generate session IDs with rand-token by default; reduce collisions Integrate with express \"trust proxy\" by default deps: buffer-crc32@0.2.3 deps: debug@1.0.2 deps: multiparty@3.2.9 deps: serve-index@1.1.2 deps: batch@0.5.1 deps: type-is@1.3.0 improve type parsing deps: vhost@2.0.0 Accept RegExp object for hostname Provide req.vhost object Support IPv6 literal in Host header 2.19.6 / 2014-06-11 deps: body-parser@1.3.1 deps: type-is@1.2.1 deps: compression@1.0.7 use vary module for better Vary behavior deps: accepts@1.0.3 deps: compressible@1.1.0 deps: debug@1.0.2 deps: serve-index@1.1.1 deps: accepts@1.0.3 deps: serve-static@1.2.3 Do not throw un-catchable error on file open race condition deps: send@0.4.3 2.19.5 / 2014-06-09 deps: csurf@1.2.1 refactor to use csrf-tokens@~1.0.2 deps: debug@1.0.1 deps: serve-static@1.2.2 fix \"event emitter leak\" warnings deps: send@0.4.2 deps: type-is@1.2.1 Switch dependency from mime to mime-types@1.0.0 2.19.4 / 2014-06-05 deps: errorhandler@1.0.2 Pass on errors from reading error files deps: method-override@2.0.2 use vary module for better Vary behavior deps: serve-favicon@2.0.1 Reduce byte size of ETag header 2.19.3 / 2014-06-03 deps: compression@1.0.6 fix listeners for delayed stream creation fix regression for certain stream.pipe(res) situations fix regression when negotiation fails 2.19.2 / 2014-06-03 deps: compression@1.0.4 fix adding Vary when value stored as array fix back-pressure behavior fix length check for res.end 2.19.1 / 2014-06-02 fix deprecated utils.escape 2.19.0 / 2014-06-02 deprecate methodOverride() -- use method-override npm module instead deps: body-parser@1.3.0 add extended option to urlencoded parser deps: method-override@2.0.1 set Vary header deps: methods@1.0.1 deps: multiparty@3.2.8 deps: response-time@2.0.0 add digits argument do not override existing X-Response-Time header timer not subject to clock drift timer resolution down to nanoseconds deps: serve-static@1.2.1 send max-age in Cache-Control in correct format use escape-html for escaping deps: send@0.4.1 2.18.0 / 2014-05-29 deps: compression@1.0.3 deps: serve-index@1.1.0 Fix content negotiation when no Accept header Properly support all HTTP methods Support vanilla node.js http servers Treat ENAMETOOLONG as code 414 Use accepts for negotiation deps: serve-static@1.2.0 Calculate ETag with md5 for reduced collisions Fix wrong behavior when index file matches directory Ignore stream errors after request ends Skip directories in index file search deps: send@0.4.0 2.17.3 / 2014-05-27 deps: express-session@1.2.1 Fix resave such that resave: true works 2.17.2 / 2014-05-27 deps: body-parser@1.2.2 invoke next(err) after request fully read deps: raw-body@1.1.6 deps: method-override@1.0.2 Handle req.body key referencing array or object Handle multiple HTTP headers 2.17.1 / 2014-05-21 fix res.charset appending charset when content-type has one 2.17.0 / 2014-05-20 deps: express-session@1.2.0 Add resave option to control saving unmodified sessions deps: morgan@1.1.1 \"dev\" format will use same tokens as other formats :response-time token is now empty when immediate used :response-time token is now monotonic :response-time token has precision to 1 μs fix :status + immediate output in node.js 0.8 improve buffer option to prevent indefinite event loop holding simplify method to get remote address deps: bytes@1.0.0 deps: serve-index@1.0.3 Fix error from non-statable files in HTML view 2.16.2 / 2014-05-18 fix edge-case in res.appendHeader that would append in wrong order deps: method-override@1.0.1 2.16.1 / 2014-05-17 remove usages of res.headerSent from core 2.16.0 / 2014-05-17 deprecate res.headerSent -- use res.headersSent deprecate res.on(\"header\") -- use on-headers module instead fix connect.version to reflect the actual version json: use body-parser add type option fix repeated limit parsing with every request improve parser speed urlencoded: use body-parser add type option fix repeated limit parsing with every request dep: bytes@1.0.0 add negative support dep: cookie-parser@1.1.0 deps: cookie@0.1.2 dep: csurf@1.2.0 add support for double-submit cookie dep: express-session@1.1.0 Add name option; replacement for key option Use setImmediate in MemoryStore for node.js >= 0.10 2.15.0 / 2014-05-04 Add simple res.cookie support Add res.appendHeader Call error stack even when response has been sent Patch res.headerSent to return Boolean Patch res.headersSent for node.js 0.8 Prevent default 404 handler after response sent dep: compression@1.0.2 support headers given to res.writeHead deps: bytes@0.3.0 deps: negotiator@0.4.3 dep: connect-timeout@1.1.0 Add req.timedout property Add respond option to constructor Clear timer on socket destroy deps: debug@0.8.1 dep: debug@^0.8.0 add enable() method change from stderr to stdout dep: errorhandler@1.0.1 Clean up error CSS Do not respond after headers sent dep: express-session@1.0.4 Remove import of setImmediate Use res.cookie() instead of res.setHeader() deps: cookie@0.1.2 deps: debug@0.8.1 dep: morgan@1.0.1 Make buffer unique per morgan instance deps: bytes@0.3.0 dep: serve-favicon@2.0.0 Accept Buffer of icon as first argument Non-GET and HEAD requests are denied Send valid max-age value Support conditional requests Support max-age=0 Support OPTIONS method Throw if path argument is directory dep: serve-index@1.0.2 Add stylesheet option deps: negotiator@0.4.3 2.14.5 / 2014-04-24 dep: raw-body@1.1.4 allow true as an option deps: bytes@0.3.0 dep: serve-static@1.1.0 Accept options directly to send module deps: send@0.3.0 2.14.4 / 2014-04-07 dep: bytes@0.3.0 added terabyte support dep: csurf@1.1.0 add constant-time string compare dep: serve-static@1.0.4 Resolve relative paths at middleware setup Use parseurl to parse the URL from request fix node.js 0.8 compatibility with memory session 2.14.3 / 2014-03-18 dep: static-favicon@1.0.2 Fixed content of default icon 2.14.2 / 2014-03-11 dep: static-favicon@1.0.1 Fixed path to default icon 2.14.1 / 2014-03-06 dep: fresh@0.2.2 no real changes dep: serve-index@1.0.1 deps: negotiator@0.4.2 dep: serve-static@1.0.2 deps: send@0.2.0 2.14.0 / 2014-03-05 basicAuth: use basic-auth-connect cookieParser: use cookie-parser compress: use compression csrf: use csurf dep: cookie-signature@1.0.3 directory: use serve-index errorHandler: use errorhandler favicon: use static-favicon logger: use morgan methodOverride: use method-override responseTime: use response-time session: use express-session static: use serve-static timeout: use connect-timeout vhost: use vhost 2.13.1 / 2014-03-05 cookieSession: compare full value rather than crc32 deps: raw-body@1.1.3 2.13.0 / 2014-02-14 fix typo in memory store warning #974 @rvagg compress: use compressible directory: add template option #990 @gottaloveit @Earl-Brown csrf: prevent deprecated warning with old sessions 2.12.0 / 2013-12-10 bump qs directory: sort folders before files directory: add folder icons directory: de-duplicate icons, details/mobile views #968 @simov errorHandler: end default 404 handler with a newline #972 @rlidwka session: remove long cookie expire check #870 @undoZen 2.11.2 / 2013-12-01 bump raw-body 2.11.1 / 2013-11-27 bump raw-body errorHandler: use res.setHeader() instead of res.writeHead() #949 @lo1tuma 2.11.0 / 2013-10-29 update bytes update uid2 update negotiator sessions: add rolling session option #944 @ilmeo sessions: property set cookies when given FQDN cookieSessions: properly set cookies when given FQDN #948 @bmancini55 proto: fix FQDN mounting when multiple handlers #945 @bmancini55 2.10.1 / 2013-10-23 fixed; fixed a bug with static middleware at root and trailing slashes #942 (@dougwilson) 2.10.0 / 2013-10-22 fixed: set headers written by writeHead before emitting 'header' fixed: mounted path should ignore querystrings on FQDNs #940 (@dougwilson) fixed: parsing protocol-relative URLs with @ as pathnames #938 (@dougwilson) fixed: fix static directory redirect for mount's root #937 (@dougwilson) fixed: setting set-cookie header when mixing arrays and strings #893 (@anuj123) bodyParser: optional verify function for urlencoded and json parsers for signing request bodies compress: compress checks content-length to check threshold compress: expose res.flush() for flushing responses cookieParser: pass options into node-cookie #803 (@cauldrath) errorHandler: replace \\ns with <br/>s in error handler 2.9.2 / 2013-10-18 warn about multiparty and limit middleware deprecation for v3 fix fully qualified domain name mounting. #920 (@dougwilson) directory: Fix potential security issue with serving files outside the root. #929 (@dougwilson) logger: store IP at beginning in case socket prematurely closes #930 (@dougwilson) 2.9.1 / 2013-10-15 update multiparty compress: Set vary header only if Content-Type passes filter #904 directory: Fix directory middleware URI escaping #917 (@dougwilson) directory: Fix directory seperators for Windows #914 (@dougwilson) directory: Keep query string intact during directory redirect #913 (@dougwilson) directory: Fix paths in links #730 (@JacksonTian) errorHandler: Don't escape text/plain as HTML #875 (@johan) logger: Write '0' instead of '-' when response time is zero #910 (@dougwilson) logger: Log even when connections are aborted #760 (@dylanahsmith) methodOverride: Check req.body is an object #907 (@kbjr) multipart: Add .type back to file parts for backwards compatibility #912 (@dougwilson) multipart: Allow passing options to the Multiparty constructor #902 (@niftylettuce) 2.9.0 / 2013-09-07 multipart: add docs regarding tmpfiles multipart: add .name back to file parts multipart: use multiparty instead of formidable 2.8.8 / 2013-09-02 csrf: change to math.random() salt and remove csrfToken() callback 2.8.7 / 2013-08-28 csrf: prevent salt generation on every request, and add async req.csrfToken(fn) 2.8.6 / 2013-08-28 csrf: refactor to use HMAC tokens (BREACH attack) compress: add compression of SVG and common font files by default. 2.8.5 / 2013-08-11 add: compress Dart source files by default update fresh 2.8.4 / 2013-07-08 update send 2.8.3 / 2013-07-04 add a name back to static middleware (\"staticMiddleware\") fix .hasBody() utility to require transfer-encoding or content-length 2.8.2 / 2013-07-03 update send update cookie dep. add better debug() for middleware add whitelisting of supported methods to methodOverride() 2.8.1 / 2013-06-27 fix: escape req.method in 404 response 2.8.0 / 2013-06-26 add threshold option to compress() to prevent compression of small responses add support for vendor JSON mime types in json() add X-Forwarded-Proto initial https proxy support change static redirect to 303 change octal escape sequences for strict mode change: replace utils.uid() with uid2 lib remove other \"static\" function name. Fixes #794 fix: hasBody() should return false if Content-Length: 0 2.7.11 / 2013-06-02 update send 2.7.10 / 2013-05-21 update qs update formidable fix: write/end to noop() when request aborted 2.7.9 / 2013-05-07 update qs drop support for node < v0.8 2.7.8 / 2013-05-03 update qs 2.7.7 / 2013-04-29 update qs dependency remove \"static\" function name. Closes #794 update node-formidable update buffer-crc32 2.7.6 / 2013-04-15 revert cookie signature which was creating session race conditions 2.7.5 / 2013-04-12 update cookie-signature limit: do not consume request in node 0.10.x 2.7.4 / 2013-04-01 session: add long expires check and prevent excess set-cookie session: add console.error() of session#save() errors 2.7.3 / 2013-02-19 add name to compress middleware add appending Accept-Encoding to Vary when set but missing add tests for csrf middleware add 'next' support for connect() server handler change utils.uid() to return url-safe chars. Closes #753 fix treating '.' as a regexp in vhost() fix duplicate bytes dep in package.json. Closes #743 fix #733 - parse x-forwarded-proto in a more generally compatibly way revert \"add support for next(status[, msg])\"; makes composition hard 2.7.2 / 2013-01-04 add support for next(status[, msg]) back add utf-8 meta tag to support foreign characters in filenames/directories change timeout() 408 to 503 replace 'node-crc' with 'buffer-crc32', fixes licensing fix directory.html IE support 2.7.1 / 2012-12-05 add directory() tests add support for bodyParser to ignore Content-Type if no body is present (jquery primarily does this poorely) fix errorHandler signature 2.7.0 / 2012-11-13 add support for leading JSON whitespace add logging of req.ip when present add basicAuth support for :-delimited string update cookie module. Closes #688 2.6.2 / 2012-11-01 add debug() for disconnected session store fix session regeneration bug. Closes #681 2.6.1 / 2012-10-25 add passing of connect.timeout() errors to next() replace signature utils with cookie-signature module 2.6.0 / 2012-10-09 add defer option to multipart() [Blake Miner] fix mount path case sensitivity. Closes #663 fix default of ascii encoding from logger(), now utf8. Closes #293 2.5.0 / 2012-09-27 add err.status = 400 to multipart() errors add double-encoding protection to compress(). Closes #659 add graceful handling cookie parsing errors [shtylman] fix typo X-Response-time to X-Response-Time 2.4.6 / 2012-09-18 update qs 2.4.5 / 2012-09-03 add session store \"connect\" / \"disconnect\" support [louischatriot] fix :url log token 2.4.4 / 2012-08-21 fix static() pause regression from \"send\" integration 2.4.3 / 2012-08-07 fix .write() encoding for zlib inconstancy. Closes #561 2.4.2 / 2012-07-25 remove limit default from urlencoded() remove limit default from json() remove limit default from multipart() fix cookieSession() clear cookie path / domain bug. Closes #636 2.4.1 / 2012-07-24 fix options mutation in static() 2.4.0 / 2012-07-23 add connect.timeout() add GET / HEAD check to directory(). Closes #634 add \"pause\" util dep update send dep for normalization bug 2.3.9 / 2012-07-16 add more descriptive invalid json error message update send dep for root normalization regression fix staticCache fresh dep 2.3.8 / 2012-07-12 fix connect.static() 404 regression, pass next(). Closes #629 2.3.7 / 2012-07-05 add json() utf-8 illustration test. Closes #621 add \"send\" dependency change connect.static() internals to use \"send\" fix session() req.session generation with pathname mismatch fix cookieSession() req.session generation with pathname mismatch fix mime export. Closes #618 2.3.6 / 2012-07-03 Fixed cookieSession() with cookieParser() secret regression. Closes #602 Fixed set-cookie header fields on cookie.path mismatch. Closes #615 2.3.5 / 2012-06-28 Remove logger() mount check Fixed staticCache() dont cache responses with set-cookie. Closes #607 Fixed staticCache() when Cookie is present 2.3.4 / 2012-06-22 Added err.buf to urlencoded() and json() Update cookie to 0.0.4. Closes #604 Fixed: only send 304 if original response in 2xx or 304 [timkuijsten] 2.3.3 / 2012-06-11 Added ETags back to static() [timkuijsten] Replaced utils.parseRange() with range-parser module Replaced utils.parseBytes() with bytes module Replaced utils.modified() with fresh module Fixed cookieSession() regression with invalid cookie signing [shtylman] 2.3.2 / 2012-06-08 expose mime module Update crc dep (which bundled nodeunit) 2.3.1 / 2012-06-06 Added secret option to cookieSession middleware [shtylman] Added secret option to session middleware [shtylman] Added req.remoteUser back to basicAuth() as alias of req.user Performance: improve signed cookie parsing Update cookie dependency [shtylman] 2.3.0 / 2012-05-20 Added limit option to json() Added limit option to urlencoded() Added limit option to multipart() Fixed: remove socket error event listener on callback Fixed ENOTDIR error on static middleware 2.2.2 / 2012-05-07 Added support to csrf middle for pre-flight CORS requests Updated engines to allow newer version of node Removed duplicate repo prop. Closes #560 2.2.1 / 2012-04-28 Fixed static() redirect when mounted. Closes #554 2.2.0 / 2012-04-25 Added make benchmark Perf: memoize url parsing (~20% increase) Fixed connect(fn, fn2, ...). Closes #549 2.1.3 / 2012-04-20 Added optional json() reviver function to be passed to JSON.parse [jed] Fixed: emit drain in compress middleware [nsabovic] 2.1.2 / 2012-04-11 Fixed cookieParser() req.cookies regression 2.1.1 / 2012-04-11 Fixed session() browser-session length cookies & examples Fixed: make query() \"self-aware\" [jed] 2.1.0 / 2012-04-05 Added debug() calls to .use() (DEBUG=connect:displatcher) Added urlencoded() support for GET Added json() support for GET. Closes #497 Added strict option to json() Changed: session() only set-cookie when modified Removed Session#lastAccess property. Closes #399 2.0.3 / 2012-03-20 Added: cookieSession() only sets cookie on change. Closes #442 Added connect:dispatcher debug() probes 2.0.2 / 2012-03-04 Added test for ENAMETOOLONG now that node is fixed Fixed static() index \"/\" check on windows. Closes #498 Fixed Content-Range behaviour to match RFC2616 [matthiasdg / visionmedia] 2.0.1 / 2012-02-29 Added test coverage for vhost() middleware Changed cookieParser() signed cookie support to use SHA-2 [senotrusov] Fixed static() Range: respond with 416 when unsatisfiable Fixed vhost() middleware. Closes #494 2.0.0 / 2011-10-05 Added cookieSession() middleware for cookie-only sessions Added compress() middleware for gzip / deflate support Added session() \"proxy\" setting to trust X-Forwarded-Proto Added json() middleware to parse \"application/json\" Added urlencoded() middleware to parse \"application/x-www-form-urlencoded\" Added multipart() middleware to parse \"multipart/form-data\" Added cookieParser(secret) support so anything using this middleware may access signed cookies Added signed cookie support to cookieParser() Added support for JSON-serialized cookies to cookieParser() Added err.status support in Connect's default end-point Added X-Cache MISS / HIT to staticCache() Added public res.headerSent checking nodes res._headerSent until node does Changed basicAuth() req.remoteUser to req.user Changed: default session() to a browser-session cookie. Closes #475 Changed: no longer lowercase cookie names Changed bodyParser() to use json(), urlencoded(), and multipart() Changed: errorHandler() is now a development-only middleware Changed middleware to next() errors when possible so applications can unify logging / handling Removed http[s].Server inheritance, now just a function, making it easy to have an app providing both http and https Removed .createServer() (use connect()) Removed secret option from session(), use cookieParser(secret) Removed connect.session.ignore array support Removed router() middleware. Closes #262 Fixed: set-cookie only once for browser-session cookies Fixed FQDN support. dont add leading \"/\" Fixed 404 XSS attack vector. Closes #473 Fixed HEAD support for 404s and 500s generated by Connect's end-point 1.8.5 / 2011-12-22 Fixed: actually allow empty body for json 1.8.4 / 2011-12-22 Changed: allow empty body for json/urlencoded requests. Backport for #443 1.8.3 / 2011-12-16 Fixed static() index.html support on windows 1.8.2 / 2011-12-03 Fixed potential security issue, store files in req.files. Closes #431 [reported by dobesv] 1.8.1 / 2011-11-21 Added nesting support for multipart/form-data [jackyz] 1.8.0 / 2011-11-17 Added multipart/form-data support to bodyParser() using formidable 1.7.3 / 2011-11-11 Fixed req.body, always default to {} Fixed HEAD support for 404s and 500s 1.7.2 / 2011-10-24 \"node\": \">= 0.4.1 < 0.7.0\" Added static() redirect option. Closes #398 Changed limit(): respond with 413 when content-length exceeds the limit Removed socket error listener in static(). Closes #389 Fixed staticCache() Age header field Fixed race condition causing errors reported in #329. 1.7.1 / 2011-09-12 Added: make Store inherit from EventEmitter Added session Store#load(sess, fn) to fetch a Session instance Added backpressure support to staticCache() Changed res.socket.destroy() to req.socket.destroy() 1.7.0 / 2011-08-31 Added staticCache() middleware, a memory cache for static() Added public res.headerSent checking nodes res._headerSent (remove when node adds this) Changed: ignore error handling middleware when header is sent Changed: dispatcher errors after header is sent destroy the sock 1.6.4 / 2011-08-26 Revert \"Added double-next reporting\" 1.6.3 / 2011-08-26 Added double-next() reporting Added immediate option to logger(). Closes #321 Dependency qs >= 0.3.1 1.6.2 / 2011-08-11 Fixed connect.static() null byte vulnerability Fixed connect.directory() null byte vulnerability Changed: 301 redirect in static() to postfix \"/\" on directory. Closes #289 1.6.1 / 2011-08-03 Added: allow retval == null from logger callback to ignore line Added getOnly option to connect.static.send() Added response \"header\" event allowing augmentation Added X-CSRF-Token header field check Changed dep qs >= 0.3.0 Changed: persist csrf token. Closes #322 Changed: sort directory middleware files alphabetically 1.6.0 / 2011-07-10 Added :response-time to \"dev\" logger format Added simple csrf() middleware. Closes #315 Fixed res._headers logger regression. Closes #318 Removed support for multiple middleware being passed to .use() 1.5.2 / 2011-07-06 Added filter function option to directory() [David Rio Deiros] Changed: re-write of the logger() middleware, with extensible tokens and formats Changed: static.send() \"..\" in path without root considered malicious Fixed quotes in docs. Closes #312 Fixed urls when mounting directory(), use originalUrl [Daniel Dickison] 1.5.1 / 2011-06-20 Added malicious path check to directory() middleware Added utils.forbidden(res) Added connect.query() middleware 1.5.0 / 2011-06-20 Added connect.directory() middleware for serving directory listings 1.4.6 / 2011-06-18 Fixed connect.static() root with .. Fixed connect.static() EBADF 1.4.5 / 2011-06-17 Fixed EBADF in connect.static(). Closes #297 1.4.4 / 2011-06-16 Changed connect.static() to check resolved dirname. Closes #294 1.4.3 / 2011-06-06 Fixed fd leak in connect.static() when the socket is closed Fixed; bodyParser() ignoring GET/HEAD. Closes #285 1.4.2 / 2011-05-27 Changed to devDependencies Fixed stream creation on static() HEAD request. [Andreas Lind Petersen] Fixed Win32 support for static() Fixed monkey-patch issue. Closes #261 1.4.1 / 2011-05-08 Added \"hidden\" option to static(). ignores hidden files by default. Closes * Added; expose connect.static.mime.define(). Closes #251 Fixed errorHandler middleware for missing stack traces. [aseemk] #274 1.4.0 / 2011-04-25 Added route-middleware next('route') support to jump passed the route itself Added Content-Length support to limit() Added route-specific middleware support (used to be in express) Changed; refactored duplicate session logic Changed; prevent redefining store.generate per request Fixed; static() does not set Content-Type when explicitly set [nateps] Fixed escape errorHandler() {error} contents NOTE: router will be removed in 2.0 1.3.0 / 2011-04-06 Added router.remove(path[, method]) to remove a route 1.2.3 / 2011-04-05 Fixed basicAuth realm issue when passing strings. Closes #253 1.2.2 / 2011-04-05 Added basicAuth(username, password) support Added errorHandler.title defaulting to \"Connect\" Changed errorHandler css 1.2.1 / 2011-03-30 Fixed logger() https remoteAddress logging [Alexander Simmerl] 1.2.0 / 2011-03-30 Added router.lookup(path[, method]) Added router.match(url[, method]) Added basicAuth async support. Closes #223 1.1.5 / 2011-03-27 Added; allow logger() callback function to return an empty string to ignore logging Fixed; utilizing mime.charsets.lookup() for static(). Closes 245 1.1.4 / 2011-03-23 Added logger() support for format function Fixed logger() to support mess of writeHead()/progressive api for node 0.4.x 1.1.3 / 2011-03-21 Changed; limit() now calls req.destroy() 1.1.2 / 2011-03-21 Added request \"limit\" event to limit() middleware Changed; limit() middleware will next(err) on failure 1.1.1 / 2011-03-18 Fixed session middleware for HTTPS. Closes #241 [reported by mt502] 1.1.0 / 2011-03-17 Added Session#reload(fn) 1.0.6 / 2011-03-09 Fixed res.setHeader() patch, preserve casing 1.0.5 / 2011-03-09 Fixed; logger() using req.originalUrl instead of req.url 1.0.4 / 2011-03-09 Added res.charset Added conditional sessions example Added support for session.ignore to be replaced. Closes #227 Fixed Cache-Control delimiters. Closes #228 1.0.3 / 2011-03-03 Fixed; static.send() invokes callback with connection error 1.0.2 / 2011-03-02 Fixed exported connect function Fixed package.json; node \">= 0.4.1 < 0.5.0\" 1.0.1 / 2011-03-02 Added Session#save(fn). Closes #213 Added callback support to connect.static.send() for express Added connect.static.send() \"path\" option Fixed content-type in static() for index.html 1.0.0 / 2011-03-01 Added stack, message, and dump errorHandler option aliases Added req.originalMethod to methodOverride Added favicon() maxAge option support Added connect() alternative to connect.createServer() Added new documentation Added Range support to static() Added HTTPS support Rewrote session middleware. The session API now allows for session-specific cookies, so you may alter each individually. Click to view the new session api. Added middleware self-awareness. This helps prevent middleware breakage when used within mounted servers. For example cookieParser() will not parse cookies more than once even when within a mounted server. Added new examples in the ./examples directory Added limit() middleware Added profiler() middleware Added responseTime() middleware Renamed staticProvider to static Renamed bodyDecoder to bodyParser Renamed cookieDecoder to cookieParser Fixed ETag quotes. [reported by papandreou] Fixed If-None-Match comma-delimited ETag support. [reported by papandreou] Fixed; only set req.originalUrl once. Closes #124 Fixed symlink support for static(). Closes #123 0.5.10 / 2011-02-14 Fixed SID space issue. Closes #196 Fixed; proxy res.end() to commit session data Fixed directory traversal attack in staticProvider. Closes #198 0.5.9 / 2011-02-09 qs >= 0.0.4 0.5.8 / 2011-02-04 Added qs dependency Fixed router race-condition causing possible failure when next()ing to one or more routes with parallel requests 0.5.7 / 2011-02-01 Added onvhost() call so Express (and others) can know when they are Revert \"Added stylus support\" (use the middleware which ships with stylus) Removed custom Server#listen() to allow regular http.Server#listen() args to work properly Fixed long standing router issue (#83) that causes '.' to be disallowed within named placeholders in routes [Andreas Lind Petersen] Fixed utils.uid() length error [Jxck] mounted 0.5.6 / 2011-01-23 Added stylus support to compiler favicon.js cleanup compiler.js cleanup bodyDecoder.js cleanup 0.5.5 / 2011-01-13 Changed; using sha256 HMAC instead of md5. [Paul Querna] Changed; generated a longer random UID, without time influence. [Paul Querna] Fixed; session middleware throws when secret is not present. [Paul Querna] 0.5.4 / 2011-01-07 Added; throw when router path or callback is missing Fixed; next(err) on cookie parse exception instead of ignoring Revert \"Added utils.pathname(), memoized url.parse(str).pathname\" 0.5.3 / 2011-01-05 Added docs/api.html Added utils.pathname(), memoized url.parse(str).pathname Fixed session.id issue. Closes #183 Changed; Defaulting staticProvider maxAge to 0 not 1 year. Closes #179 Removed bad outdated docs, we need something new / automated eventually 0.5.2 / 2010-12-28 Added default OPTIONS support to router middleware 0.5.1 / 2010-12-28 Added req.session.id mirroring req.sessionID Refactored router, exposing connect.router.methods Exclude non-lib files from npm Removed imposed headers X-Powered-By, Server, etc 0.5.0 / 2010-12-06 Added ./index.js Added route segment precondition support and example Added named capture group support to router 0.4.0 / 2010-11-29 Added basicAuth middleware Added more HTTP methods to the router middleware 0.3.0 / 2010-07-21 Added staticGzip middleware Added connect.utils to expose utils Added connect.session.Session Added connect.session.Store Added connect.session.MemoryStore Added connect.middleware to expose the middleware getters Added buffer option to logger for performance increase Added favicon middleware for serving your own favicon or the connect default Added option support to staticProvider, can now pass root and lifetime. Added; mounted Server instances now have the route property exposed for reflection Added support for callback as first arg to Server#use() Added support for next(true) in router to bypass match attempts Added Server#listen() host support Added Server#route when Server#use() is called with a route on a Server instance Added methodOverride X-HTTP-Method-Override support Refactored session internals, adds secret option Renamed lifetime option to maxAge in staticProvider Removed connect(1), it is now spark(1) Removed connect(1) dependency on examples, they can all now run with node(1) Remove a typo that was leaking a global. Removed Object.prototype forEach() and map() methods Removed a few utils not used Removed connect.createApp() Removed res.simpleBody() Removed format middleware Removed flash middleware Removed redirect middleware Removed jsonrpc middleware, use visionmedia/connect-jsonrpc Removed pubsub middleware Removed need for params.{captures,splat} in router middleware, params is an array Changed; compiler no longer 404s Changed; router signature now matches connect middleware signature Fixed a require in session for default MemoryStore Fixed nasty request body bug in router. Closes #54 Fixed less support in compiler Fixed bug preventing proper bubbling of exceptions in mounted servers Fixed bug in Server#use() preventing Server instances as the first arg Fixed ENOENT special case, is now treated as any other exception Fixed spark env support 0.2.1 / 2010-07-09 Added support for router next() to continue calling matched routes Added mime type for cache.manifest files. Changed compiler middleware to use async require Changed session api, stores now only require #get(), and #set() Fixed cacheManifest by adding utils.find() back 0.2.0 / 2010-07-01 Added calls to Session() casts the given object as a Session instance Added passing of next() to router callbacks. Closes #46 Changed; MemoryStore#destroy() removes req.session Changed res.redirect(\"back\") to default to \"/\" when Referr?er is not present Fixed staticProvider urlencoded paths issue. Closes #47 Fixed staticProvider middleware responding to GET requests Fixed jsonrpc middleware Accept header check. Closes #43 Fixed logger format option Fixed typo in compiler middleware preventing the dest option from working 0.1.0 / 2010-06-25 Revamped the api, view the Connect documentation for more info (hover on the right for menu) Added extended api docs Added docs for several more middleware layers Added connect.Server#use() Added compiler middleware which provides arbitrary static compilation Added req.originalUrl Removed blog example Removed sass middleware (use compiler) Removed less middleware (use compiler) Renamed middleware to be camelcase, body-decoder is now bodyDecoder etc. Fixed req.url mutation bug when matching connect.Server#use() routes Fixed mkdir -p implementation used in bin/connect. Closes #39 Fixed bug in bodyDecoder throwing exceptions on request empty bodies make install installing lib to $LIB_PREFIX aka $HOME/.node_libraries 0.0.6 / 2010-06-22 Added static middleware usage example Added support for regular expressions as paths for router Added util.merge() Increased performance of static by ~ 200 rps Renamed the rest middleware to router Changed rest api to accept a callback function Removed router middleware Removed proto.js, only Object#forEach() remains 0.0.5 / 2010-06-21 Added Server#use() which contains the Layer normalization logic Added documentation for several middleware Added several new examples Added less middleware Added repl middleware Added vhost middleware Added flash middleware Added cookie middleware Added session middleware Added utils.htmlEscape() Added utils.base64Decode() Added utils.base64Encode() Added utils.uid() Added bin/connect app path and --config path support for .js suffix, although optional. Closes #26 Moved mime code to utils.mime, ex utils.mime.types, and utils.mime.type() Renamed req.redirect() to res.redirect(). Closes #29 Fixed sass 404 on ENOENT Fixed +new Date duplication. Closes #24 0.0.4 / 2010-06-16 Added workerPidfile() to bin/connect Added --workers support to bin/connect stop and status commands Added redirect middleware Added better --config support to bin/connect. All flags can be utilized Added auto-detection of ./config.js Added config example Added net.Server support to bin/connect Writing worker pids relative to env.pidfile s/parseQuery/parse/g Fixed npm support 0.0.3 / 2010-06-16 Fixed node dependency in package.json, now \">= 0.1.98-0\" to support HEAD 0.0.2 / 2010-06-15 Added -V, --version to bin/connect Added utils.parseCookie() Added utils.serializeCookie() Added utils.toBoolean() Added sass middleware Added cookie middleware Added format middleware Added lint middleware Added rest middleware Added ./package.json (npm install connect) Added handleError() support Added process.connectEnv Added custom log format support to log middleware Added arbitrary env variable support to bin/connect (ext: --logFormat \":method :url\") Added -w, --workers to bin/connect Added bin/connect support for --user NAME and --group NAME Fixed url re-writing support 0.0.1 / 2010-06-03 Initial release"
  },
  "node_modules/connect/README.html": {
    "href": "node_modules/connect/README.html",
    "title": "Connect | accouter",
    "keywords": "Connect Connect is an extensible HTTP server framework for node using \"plugins\" known as middleware. var connect = require('connect'); var http = require('http'); var app = connect(); // gzip/deflate outgoing responses var compression = require('compression'); app.use(compression()); // store session state in browser cookie var cookieSession = require('cookie-session'); app.use(cookieSession({ keys: ['secret1', 'secret2'] })); // parse urlencoded request bodies into req.body var bodyParser = require('body-parser'); app.use(bodyParser.urlencoded({extended: false})); // respond to all requests app.use(function(req, res){ res.end('Hello from Connect!\\n'); }); //create node.js http server and listen on port http.createServer(app).listen(3000); Getting Started Connect is a simple framework to glue together various \"middleware\" to handle requests. Install Connect $ npm install connect Create an app The main component is a Connect \"app\". This will store all the middleware added and is, itself, a function. var app = connect(); Use middleware The core of Connect is \"using\" middleware. Middleware are added as a \"stack\" where incoming requests will execute each middleware one-by-one until a middleware does not call next() within it. app.use(function middleware1(req, res, next) { // middleware 1 next(); }); app.use(function middleware2(req, res, next) { // middleware 2 next(); }); Mount middleware The .use() method also takes an optional path string that is matched against the beginning of the incoming request URL. This allows for basic routing. app.use('/foo', function fooMiddleware(req, res, next) { // req.url starts with \"/foo\" next(); }); app.use('/bar', function barMiddleware(req, res, next) { // req.url starts with \"/bar\" next(); }); Error middleware There are special cases of \"error-handling\" middleware. There are middleware where the function takes exactly 4 arguments. When a middleware passes an error to next, the app will proceed to look for the error middleware that was declared after that middleware and invoke it, skipping any error middleware above that middleware and any non-error middleware below. // regular middleware app.use(function (req, res, next) { // i had an error next(new Error('boom!')); }); // error middleware for errors that occurred in middleware // declared before this app.use(function onerror(err, req, res, next) { // an error occurred! }); Create a server from the app The last step is to actually use the Connect app in a server. The .listen() method is a convenience to start a HTTP server (and is identical to the http.Server's listen method in the version of Node.js you are running). var server = app.listen(port); The app itself is really just a function with three arguments, so it can also be handed to .createServer() in Node.js. var server = http.createServer(app); Middleware These middleware and libraries are officially supported by the Connect/Express team: body-parser - previous bodyParser, json, and urlencoded. You may also be interested in: body co-body raw-body compression - previously compress connect-timeout - previously timeout cookie-parser - previously cookieParser cookie-session - previously cookieSession csurf - previously csrf errorhandler - previously error-handler express-session - previously session method-override - previously method-override morgan - previously logger response-time - previously response-time serve-favicon - previously favicon serve-index - previously directory serve-static - previously static vhost - previously vhost Most of these are exact ports of their Connect 2.x equivalents. The primary exception is cookie-session. Some middleware previously included with Connect are no longer supported by the Connect/Express team, are replaced by an alternative module, or should be superseded by a better module. Use one of these alternatives instead: cookieParser cookies and keygrip limit raw-body multipart connect-multiparty connect-busboy query qs staticCache st connect-static Checkout http-framework for many other compatible middleware! API The Connect API is very minimalist, enough to create an app and add a chain of middleware. When the connect module is required, a function is returned that will construct a new app when called. // require module var connect = require('connect') // create app var app = connect() app(req, res[, next]) The app itself is a function. This is just an alias to app.handle. app.handle(req, res[, out]) Calling the function will run the middleware stack against the given Node.js http request (req) and response (res) objects. An optional function out can be provided that will be called if the request (or error) was not handled by the middleware stack. app.listen([...]) Start the app listening for requests. This method will internally create a Node.js HTTP server and call .listen() on it. This is an alias to the server.listen() method in the version of Node.js running, so consult the Node.js documentation for all the different variations. The most common signature is app.listen(port). app.use(fn) Use a function on the app, where the function represents a middleware. The function will be invoked for every request in the order that app.use is called. The function is called with three arguments: app.use(function (req, res, next) { // req is the Node.js http request object // res is the Node.js http response object // next is a function to call to invoke the next middleware }) In addition to a plan function, the fn argument can also be a Node.js HTTP server instance or another Connect app instance. app.use(route, fn) Use a function on the app, where the function represents a middleware. The function will be invoked for every request in which the URL (req.url property) starts with the given route string in the order that app.use is called. The function is called with three arguments: app.use('/foo', function (req, res, next) { // req is the Node.js http request object // res is the Node.js http response object // next is a function to call to invoke the next middleware }) In addition to a plan function, the fn argument can also be a Node.js HTTP server instance or another Connect app instance. The route is always terminated at a path separator (/) or a dot (.) character. This means the given routes /foo/ and /foo are the same and both will match requests with the URLs /foo, /foo/, /foo/bar, and /foo.bar, but not match a request with the URL /foobar. The route is matched in a case-insensitive manor. In order to make middleware easier to write to be agnostic of the route, when the fn is invoked, the req.url will be altered to remove the route part (and the original will be available as req.originalUrl). For example, if fn is used at the route /foo, the request for /foo/bar will invoke fn with req.url === '/bar' and req.originalUrl === '/foo/bar'. Running Tests npm install npm test People The Connect project would not be the same without all the people involved. The original author of Connect is TJ Holowaychuk The current lead maintainer is Douglas Christopher Wilson List of all contributors Node Compatibility Connect < 1.x - node 0.2 Connect 1.x - node 0.4 Connect < 2.8 - node 0.6 Connect >= 2.8 < 3 - node 0.8 Connect >= 3 - node 0.10, 0.12, 4.x, 5.x, 6.x, 7.x, 8.x; io.js 1.x, 2.x, 3.x License MIT"
  },
  "node_modules/connect/SECURITY.html": {
    "href": "node_modules/connect/SECURITY.html",
    "title": "Security Policies and Procedures | accouter",
    "keywords": "Security Policies and Procedures This document outlines security procedures and general policies for the Connect project. Reporting a Bug Disclosure Policy Comments on this Policy Reporting a Bug The Connect team and community take all security bugs in Connect seriously. Thank you for improving the security of Connect. We appreciate your efforts and responsible disclosure and will make every effort to acknowledge your contributions. Report security bugs by emailing the lead maintainer in the README.md file. The lead maintainer will acknowledge your email within 48 hours, and will send a more detailed response within 48 hours indicating the next steps in handling your report. After the initial reply to your report, the security team will endeavor to keep you informed of the progress towards a fix and full announcement, and may ask for additional information or guidance. Report security bugs in third-party modules to the person or team maintaining the module. You can also report a vulnerability through the Node Security Project. Disclosure Policy When the security team receives a security bug report, they will assign it to a primary handler. This person will coordinate the fix and release process, involving the following steps: Confirm the problem and determine the affected versions. Audit code to find any potential similar problems. Prepare fixes for all releases still under maintenance. These fixes will be released as fast as possible to npm. Comments on this Policy If you have suggestions on how this process could be improved please submit a pull request."
  },
  "node_modules/cookie/HISTORY.html": {
    "href": "node_modules/cookie/HISTORY.html",
    "title": "0.4.2 / 2022-02-02 | accouter",
    "keywords": "0.4.2 / 2022-02-02 pref: read value only when assigning in parse pref: remove unnecessary regexp in parse 0.4.1 / 2020-04-21 Fix maxAge option to reject invalid values 0.4.0 / 2019-05-15 Add SameSite=None support 0.3.1 / 2016-05-26 Fix sameSite: true to work with draft-7 clients true now sends SameSite=Strict instead of SameSite 0.3.0 / 2016-05-26 Add sameSite option Replaces firstPartyOnly option, never implemented by browsers Improve error message when encode is not a function Improve error message when expires is not a Date 0.2.4 / 2016-05-20 perf: enable strict mode perf: use for loop in parse perf: use string concatination for serialization 0.2.3 / 2015-10-25 Fix cookie Max-Age to never be a floating point number 0.2.2 / 2015-09-17 Fix regression when setting empty cookie value Ease the new restriction, which is just basic header-level validation Fix typo in invalid value errors 0.2.1 / 2015-09-17 Throw on invalid values provided to serialize Ensures the resulting string is a valid HTTP header value 0.2.0 / 2015-08-13 Add firstPartyOnly option Throw better error for invalid argument to parse perf: hoist regular expression 0.1.5 / 2015-09-17 Fix regression when setting empty cookie value Ease the new restriction, which is just basic header-level validation Fix typo in invalid value errors 0.1.4 / 2015-09-17 Throw better error for invalid argument to parse Throw on invalid values provided to serialize Ensures the resulting string is a valid HTTP header value 0.1.3 / 2015-05-19 Reduce the scope of try-catch deopt Remove argument reassignments 0.1.2 / 2014-04-16 Remove unnecessary files from npm package 0.1.1 / 2014-02-23 Fix bad parse when cookie value contained a comma Fix support for maxAge of 0 0.1.0 / 2013-05-01 Add decode option Add encode option 0.0.6 / 2013-04-08 Ignore cookie parts missing = 0.0.5 / 2012-10-29 Return raw cookie value if value unescape errors 0.0.4 / 2012-06-21 Use encode/decodeURIComponent for cookie encoding/decoding Improve server/client interoperability 0.0.3 / 2012-06-06 Only escape special characters per the cookie RFC 0.0.2 / 2012-06-01 Fix maxAge option to not throw error 0.0.1 / 2012-05-28 Add more tests 0.0.0 / 2012-05-28 Initial release"
  },
  "node_modules/cookie/README.html": {
    "href": "node_modules/cookie/README.html",
    "title": "cookie | accouter",
    "keywords": "cookie Basic HTTP cookie parser and serializer for HTTP servers. Installation This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install cookie API var cookie = require('cookie'); cookie.parse(str, options) Parse an HTTP Cookie header string and returning an object of all cookie name-value pairs. The str argument is the string representing a Cookie header value and options is an optional object containing additional parsing options. var cookies = cookie.parse('foo=bar; equation=E%3Dmc%5E2'); // { foo: 'bar', equation: 'E=mc^2' } Options cookie.parse accepts these properties in the options object. decode Specifies a function that will be used to decode a cookie's value. Since the value of a cookie has a limited character set (and must be a simple string), this function can be used to decode a previously-encoded cookie value into a JavaScript string or other object. The default function is the global decodeURIComponent, which will decode any URL-encoded sequences into their byte representations. note if an error is thrown from this function, the original, non-decoded cookie value will be returned as the cookie's value. cookie.serialize(name, value, options) Serialize a cookie name-value pair into a Set-Cookie header string. The name argument is the name for the cookie, the value argument is the value to set the cookie to, and the options argument is an optional object containing additional serialization options. var setCookie = cookie.serialize('foo', 'bar'); // foo=bar Options cookie.serialize accepts these properties in the options object. domain Specifies the value for the Domain Set-Cookie attribute. By default, no domain is set, and most clients will consider the cookie to apply to only the current domain. encode Specifies a function that will be used to encode a cookie's value. Since value of a cookie has a limited character set (and must be a simple string), this function can be used to encode a value into a string suited for a cookie's value. The default function is the global encodeURIComponent, which will encode a JavaScript string into UTF-8 byte sequences and then URL-encode any that fall outside of the cookie range. expires Specifies the Date object to be the value for the Expires Set-Cookie attribute. By default, no expiration is set, and most clients will consider this a \"non-persistent cookie\" and will delete it on a condition like exiting a web browser application. note the cookie storage model specification states that if both expires and maxAge are set, then maxAge takes precedence, but it is possible not all clients by obey this, so if both are set, they should point to the same date and time. httpOnly Specifies the boolean value for the HttpOnly Set-Cookie attribute. When truthy, the HttpOnly attribute is set, otherwise it is not. By default, the HttpOnly attribute is not set. note be careful when setting this to true, as compliant clients will not allow client-side JavaScript to see the cookie in document.cookie. maxAge Specifies the number (in seconds) to be the value for the Max-Age Set-Cookie attribute. The given number will be converted to an integer by rounding down. By default, no maximum age is set. note the cookie storage model specification states that if both expires and maxAge are set, then maxAge takes precedence, but it is possible not all clients by obey this, so if both are set, they should point to the same date and time. path Specifies the value for the Path Set-Cookie attribute. By default, the path is considered the \"default path\". sameSite Specifies the boolean or string to be the value for the SameSite Set-Cookie attribute. true will set the SameSite attribute to Strict for strict same site enforcement. false will not set the SameSite attribute. 'lax' will set the SameSite attribute to Lax for lax same site enforcement. 'none' will set the SameSite attribute to None for an explicit cross-site cookie. 'strict' will set the SameSite attribute to Strict for strict same site enforcement. More information about the different enforcement levels can be found in the specification. note This is an attribute that has not yet been fully standardized, and may change in the future. This also means many clients may ignore this attribute until they understand it. secure Specifies the boolean value for the Secure Set-Cookie attribute. When truthy, the Secure attribute is set, otherwise it is not. By default, the Secure attribute is not set. note be careful when setting this to true, as compliant clients will not send the cookie back to the server in the future if the browser does not have an HTTPS connection. Example The following example uses this module in conjunction with the Node.js core HTTP server to prompt a user for their name and display it back on future visits. var cookie = require('cookie'); var escapeHtml = require('escape-html'); var http = require('http'); var url = require('url'); function onRequest(req, res) { // Parse the query string var query = url.parse(req.url, true, true).query; if (query && query.name) { // Set a new cookie with the name res.setHeader('Set-Cookie', cookie.serialize('name', String(query.name), { httpOnly: true, maxAge: 60 * 60 * 24 * 7 // 1 week })); // Redirect back after setting cookie res.statusCode = 302; res.setHeader('Location', req.headers.referer || '/'); res.end(); return; } // Parse the cookies on the request var cookies = cookie.parse(req.headers.cookie || ''); // Get the visitor name set in the cookie var name = cookies.name; res.setHeader('Content-Type', 'text/html; charset=UTF-8'); if (name) { res.write('<p>Welcome back, <b>' + escapeHtml(name) + '</b>!</p>'); } else { res.write('<p>Hello, new visitor!</p>'); } res.write('<form method=\"GET\">'); res.write('<input placeholder=\"enter your name\" name=\"name\"> <input type=\"submit\" value=\"Set Name\">'); res.end('</form>'); } http.createServer(onRequest).listen(3000); Testing $ npm test Benchmark $ npm run bench > cookie@0.4.1 bench > node benchmark/index.js node@16.13.1 v8@9.4.146.24-node.14 uv@1.42.0 zlib@1.2.11 brotli@1.0.9 ares@1.18.1 modules@93 nghttp2@1.45.1 napi@8 llhttp@6.0.4 openssl@1.1.1l+quic cldr@39.0 icu@69.1 tz@2021a unicode@13.0 ngtcp2@0.1.0-DEV nghttp3@0.1.0-DEV > node benchmark/parse-top.js cookie.parse - top sites 15 tests completed. parse accounts.google.com x 504,358 ops/sec ±6.55% (171 runs sampled) parse apple.com x 1,369,991 ops/sec ±0.84% (189 runs sampled) parse cloudflare.com x 360,669 ops/sec ±3.75% (182 runs sampled) parse docs.google.com x 521,496 ops/sec ±4.90% (180 runs sampled) parse drive.google.com x 553,514 ops/sec ±0.59% (189 runs sampled) parse en.wikipedia.org x 286,052 ops/sec ±0.62% (188 runs sampled) parse linkedin.com x 178,817 ops/sec ±0.61% (192 runs sampled) parse maps.google.com x 284,585 ops/sec ±0.68% (188 runs sampled) parse microsoft.com x 161,230 ops/sec ±0.56% (192 runs sampled) parse play.google.com x 352,144 ops/sec ±1.01% (181 runs sampled) parse plus.google.com x 275,204 ops/sec ±7.78% (156 runs sampled) parse support.google.com x 339,493 ops/sec ±1.02% (191 runs sampled) parse www.google.com x 286,110 ops/sec ±0.90% (191 runs sampled) parse youtu.be x 548,557 ops/sec ±0.60% (184 runs sampled) parse youtube.com x 545,293 ops/sec ±0.65% (191 runs sampled) > node benchmark/parse.js cookie.parse - generic 6 tests completed. simple x 1,266,646 ops/sec ±0.65% (191 runs sampled) decode x 838,413 ops/sec ±0.60% (191 runs sampled) unquote x 877,820 ops/sec ±0.72% (189 runs sampled) duplicates x 516,680 ops/sec ±0.61% (191 runs sampled) 10 cookies x 156,874 ops/sec ±0.52% (189 runs sampled) 100 cookies x 14,663 ops/sec ±0.53% (191 runs sampled) References RFC 6265: HTTP State Management Mechanism Same-site Cookies License MIT"
  },
  "node_modules/cors/CONTRIBUTING.html": {
    "href": "node_modules/cors/CONTRIBUTING.html",
    "title": "contributing to cors | accouter",
    "keywords": "contributing to cors CORS is a node.js package for providing a connect/express middleware that can be used to enable CORS with various options. Learn more about the project in the README. The CORS Spec http://www.w3.org/TR/cors/ Pull Requests Welcome Include 'use strict'; in every javascript file. 2 space indentation. Please run the testing steps below before submitting. Testing $ npm install $ npm test Interactive Testing Harness http://node-cors-client.herokuapp.com Related git repositories: https://github.com/TroyGoode/node-cors-server https://github.com/TroyGoode/node-cors-client License MIT License"
  },
  "node_modules/cors/HISTORY.html": {
    "href": "node_modules/cors/HISTORY.html",
    "title": "2.8.5 / 2018-11-04 | accouter",
    "keywords": "2.8.5 / 2018-11-04 Fix setting maxAge option to 0 2.8.4 / 2017-07-12 Work-around Safari bug in default pre-flight response 2.8.3 / 2017-03-29 Fix error when options delegate missing methods option 2.8.2 / 2017-03-28 Fix error when frozen options are passed Send \"Vary: Origin\" when using regular expressions Send \"Vary: Access-Control-Request-Headers\" when dynamic allowedHeaders 2.8.1 / 2016-09-08 This release only changed documentation. 2.8.0 / 2016-08-23 Add optionsSuccessStatus option 2.7.2 / 2016-08-23 Fix error when Node.js running in strict mode 2.7.1 / 2015-05-28 Move module into expressjs organization 2.7.0 / 2015-05-28 Allow array of matching condition as origin option Allow regular expression as origin option 2.6.1 / 2015-05-28 Update license in package.json 2.6.0 / 2015-04-27 Add preflightContinue option Fix \"Vary: Origin\" header added for \"*\""
  },
  "node_modules/cors/README.html": {
    "href": "node_modules/cors/README.html",
    "title": "cors | accouter",
    "keywords": "cors CORS is a node.js package for providing a Connect/Express middleware that can be used to enable CORS with various options. Follow me (@troygoode) on Twitter! Installation Usage Simple Usage Enable CORS for a Single Route Configuring CORS Configuring CORS Asynchronously Enabling CORS Pre-Flight Configuration Options Demo License Author Installation This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install cors Usage Simple Usage (Enable All CORS Requests) var express = require('express') var cors = require('cors') var app = express() app.use(cors()) app.get('/products/:id', function (req, res, next) { res.json({msg: 'This is CORS-enabled for all origins!'}) }) app.listen(80, function () { console.log('CORS-enabled web server listening on port 80') }) Enable CORS for a Single Route var express = require('express') var cors = require('cors') var app = express() app.get('/products/:id', cors(), function (req, res, next) { res.json({msg: 'This is CORS-enabled for a Single Route'}) }) app.listen(80, function () { console.log('CORS-enabled web server listening on port 80') }) Configuring CORS var express = require('express') var cors = require('cors') var app = express() var corsOptions = { origin: 'http://example.com', optionsSuccessStatus: 200 // some legacy browsers (IE11, various SmartTVs) choke on 204 } app.get('/products/:id', cors(corsOptions), function (req, res, next) { res.json({msg: 'This is CORS-enabled for only example.com.'}) }) app.listen(80, function () { console.log('CORS-enabled web server listening on port 80') }) Configuring CORS w/ Dynamic Origin var express = require('express') var cors = require('cors') var app = express() var whitelist = ['http://example1.com', 'http://example2.com'] var corsOptions = { origin: function (origin, callback) { if (whitelist.indexOf(origin) !== -1) { callback(null, true) } else { callback(new Error('Not allowed by CORS')) } } } app.get('/products/:id', cors(corsOptions), function (req, res, next) { res.json({msg: 'This is CORS-enabled for a whitelisted domain.'}) }) app.listen(80, function () { console.log('CORS-enabled web server listening on port 80') }) If you do not want to block REST tools or server-to-server requests, add a !origin check in the origin function like so: var corsOptions = { origin: function (origin, callback) { if (whitelist.indexOf(origin) !== -1 || !origin) { callback(null, true) } else { callback(new Error('Not allowed by CORS')) } } } Enabling CORS Pre-Flight Certain CORS requests are considered 'complex' and require an initial OPTIONS request (called the \"pre-flight request\"). An example of a 'complex' CORS request is one that uses an HTTP verb other than GET/HEAD/POST (such as DELETE) or that uses custom headers. To enable pre-flighting, you must add a new OPTIONS handler for the route you want to support: var express = require('express') var cors = require('cors') var app = express() app.options('/products/:id', cors()) // enable pre-flight request for DELETE request app.del('/products/:id', cors(), function (req, res, next) { res.json({msg: 'This is CORS-enabled for all origins!'}) }) app.listen(80, function () { console.log('CORS-enabled web server listening on port 80') }) You can also enable pre-flight across-the-board like so: app.options('*', cors()) // include before other routes Configuring CORS Asynchronously var express = require('express') var cors = require('cors') var app = express() var whitelist = ['http://example1.com', 'http://example2.com'] var corsOptionsDelegate = function (req, callback) { var corsOptions; if (whitelist.indexOf(req.header('Origin')) !== -1) { corsOptions = { origin: true } // reflect (enable) the requested origin in the CORS response } else { corsOptions = { origin: false } // disable CORS for this request } callback(null, corsOptions) // callback expects two parameters: error and options } app.get('/products/:id', cors(corsOptionsDelegate), function (req, res, next) { res.json({msg: 'This is CORS-enabled for a whitelisted domain.'}) }) app.listen(80, function () { console.log('CORS-enabled web server listening on port 80') }) Configuration Options origin: Configures the Access-Control-Allow-Origin CORS header. Possible values: Boolean - set origin to true to reflect the request origin, as defined by req.header('Origin'), or set it to false to disable CORS. String - set origin to a specific origin. For example if you set it to \"http://example.com\" only requests from \"http://example.com\" will be allowed. RegExp - set origin to a regular expression pattern which will be used to test the request origin. If it's a match, the request origin will be reflected. For example the pattern /example\\.com$/ will reflect any request that is coming from an origin ending with \"example.com\". Array - set origin to an array of valid origins. Each origin can be a String or a RegExp. For example [\"http://example1.com\", /\\.example2\\.com$/] will accept any request from \"http://example1.com\" or from a subdomain of \"example2.com\". Function - set origin to a function implementing some custom logic. The function takes the request origin as the first parameter and a callback (which expects the signature err [object], allow [bool]) as the second. methods: Configures the Access-Control-Allow-Methods CORS header. Expects a comma-delimited string (ex: 'GET,PUT,POST') or an array (ex: ['GET', 'PUT', 'POST']). allowedHeaders: Configures the Access-Control-Allow-Headers CORS header. Expects a comma-delimited string (ex: 'Content-Type,Authorization') or an array (ex: ['Content-Type', 'Authorization']). If not specified, defaults to reflecting the headers specified in the request's Access-Control-Request-Headers header. exposedHeaders: Configures the Access-Control-Expose-Headers CORS header. Expects a comma-delimited string (ex: 'Content-Range,X-Content-Range') or an array (ex: ['Content-Range', 'X-Content-Range']). If not specified, no custom headers are exposed. credentials: Configures the Access-Control-Allow-Credentials CORS header. Set to true to pass the header, otherwise it is omitted. maxAge: Configures the Access-Control-Max-Age CORS header. Set to an integer to pass the header, otherwise it is omitted. preflightContinue: Pass the CORS preflight response to the next handler. optionsSuccessStatus: Provides a status code to use for successful OPTIONS requests, since some legacy browsers (IE11, various SmartTVs) choke on 204. The default configuration is the equivalent of: { \"origin\": \"*\", \"methods\": \"GET,HEAD,PUT,PATCH,POST,DELETE\", \"preflightContinue\": false, \"optionsSuccessStatus\": 204 } For details on the effect of each CORS header, read this article on HTML5 Rocks. Demo A demo that illustrates CORS working (and not working) using jQuery is available here: http://node-cors-client.herokuapp.com/ Code for that demo can be found here: Client: https://github.com/TroyGoode/node-cors-client Server: https://github.com/TroyGoode/node-cors-server License MIT License Author Troy Goode (troygoode@gmail.com)"
  },
  "node_modules/cp-file/readme.html": {
    "href": "node_modules/cp-file/readme.html",
    "title": "cp-file | accouter",
    "keywords": "cp-file Copy a file Highlights Fast by using streams in the async version and fs.copyFileSync() in the synchronous version. Resilient by using graceful-fs. User-friendly by creating non-existent destination directories for you. Can be safe by turning off overwriting. Preserves file mode, but not ownership. User-friendly errors. Install npm install cp-file Usage import {copyFile} from 'cp-file'; await copyFile('source/unicorn.png', 'destination/unicorn.png'); console.log('File copied'); API copyFile(source, destination, options?) Returns a Promise that resolves when the file is copied. copyFileSync(source, destination, options?) source Type: string The file you want to copy. destination Type: string Where you want the file copied. options Type: object overwrite Type: boolean Default: true Overwrite existing destination file. cwd Type: string Default: process.cwd() The working directory to find source files. The source and destination path are relative to this. directoryMode Type: number Default: 0o777 Permissions for created directories. It has no effect on Windows. onProgress Type: (progress: ProgressData) => void The given function is called whenever there is measurable progress. Only available when using the async method. ProgressData { sourcePath: string, destinationPath: string, size: number, writtenBytes: number, percent: number } sourcePath and destinationPath are absolute paths. size and writtenBytes are in bytes. percent is a value between 0 and 1. Notes For empty files, the onProgress callback function is emitted only once. import {copyFile} from 'cp-file'; await copyFile(source, destination, { onProgress: progress => { // … } }); Related cpy - Copy files cpy-cli - Copy files on the command-line move-file - Move a file make-dir - Make a directory and its parents if needed"
  },
  "node_modules/cpy-cli/readme.html": {
    "href": "node_modules/cpy-cli/readme.html",
    "title": "cpy-cli | accouter",
    "keywords": "cpy-cli Copy files Why Fast by using streams. Resilient by using graceful-fs. User-friendly by accepting globs and creating non-existant destination directories. User-friendly error messages. Install npm install --global cpy-cli Usage $ cpy --help Usage $ cpy <source …> <destination> Options --no-overwrite Don't overwrite the destination --cwd=<dir> Working directory for files --rename=<filename> Rename all <source> filenames to <filename>. Supports string templates. --dot Allow patterns to match entries that begin with a period (.) --flat Flatten directory structure. All copied files will be put in the same directory. --concurrency Number of files being copied concurrently <source> can contain globs if quoted Examples Copy all .png files in src folder into dist except src/goat.png $ cpy 'src/*.png' '!src/goat.png' dist Copy all files inside src folder into dist and preserve path structure $ cpy . '../dist/' --cwd=src Copy all .png files in the src folder to dist and prefix the image filenames $ cpy 'src/*.png' dist --cwd=src --rename=hi-{{basename}} Related cpy - API for this module"
  },
  "node_modules/cpy/readme.html": {
    "href": "node_modules/cpy/readme.html",
    "title": "cpy | accouter",
    "keywords": "cpy Copy files Why Fast by using streams. Resilient by using graceful-fs. User-friendly by accepting globs and creating non-existent destination directories. User-friendly error messages. Progress reporting. Install npm install cpy Usage import cpy from 'cpy'; await cpy([ 'source/*.png', // Copy all .png files '!source/goat.png', // Ignore goat.png ], 'destination'); // Copy node_modules to destination/node_modules await cpy('node_modules', 'destination'); // Copy node_modules content to destination await cpy('node_modules/**', 'destination'); // Copy node_modules structure but skip all files except package.json files await cpy('node_modules/**/*.json', 'destination'); // Copy all png files into destination without keeping directory structure await cpy('**/*.png', 'destination', {flat: true}); console.log('Files copied!'); API cpy(source, destination, options?) Returns a Promise<string[]> with the destination file paths. source Type: string | string[] Files to copy. If any of the files do not exist, an error will be thrown (does not apply to globs). destination Type: string Destination directory. options Type: object Options are passed to globby. In addition, you can specify the below options. cwd Type: string Default: process.cwd() Working directory to find source files. overwrite Type: boolean Default: true Overwrite existing files. flat Type: boolean Default: false Flatten directory structure. All copied files will be put in the same directory. import cpy from 'cpy'; await cpy('src/**/*.js', 'destination', { flat: true }); rename Type: string | Function Filename or function returning a filename used to rename every file in source. import cpy from 'cpy'; await cpy('foo.js', 'destination', { // The `basename` is the filename with extension. rename: basename => `prefix-${basename}` }); await cpy('foo.js', 'destination', { rename: 'new-name' }); concurrency Type: number Default: (os.cpus().length || 1) * 2 Number of files being copied concurrently. ignoreJunk Type: boolean Default: true Ignores junk files. filter Type: Function Function to filter files to copy. Receives a source file object as the first argument. Return true to include, false to exclude. You can also return a Promise that resolves to true or false. import cpy from 'cpy'; await cpy('foo', 'destination', { filter: file => file.extension !== 'nocopy' }); Source file object path Type: string Example: '/tmp/dir/foo.js' Resolved path to the file. relativePath Type: string Example: 'dir/foo.js' if cwd was '/tmp' Relative path to the file from cwd. name Type: string Example: 'foo.js' Filename with extension. nameWithoutExtension Type: string Example: 'foo' Filename without extension. extension Type: string Example: 'js' File extension. Progress reporting cpy.on('progress', handler) handler(progress) Type: Function progress { completedFiles: number, totalFiles: number, completedSize: number, percent: number, sourcePath: string, destinationPath: string, } completedSize is in bytes percent is a value between 0 and 1 sourcePath is the absolute source path of the current file being copied. destinationPath is The absolute destination path of the current file being copied. Note that the .on() method is available only right after the initial cpy call, so make sure you add a handler before awaiting the promise: import cpy from 'cpy'; await cpy(source, destination).on('progress', progress => { // … }); Related cpy-cli - CLI for this module cp-file - Copy a single file move-file - Move a file make-dir - Make a directory and its parents if needed"
  },
  "node_modules/cross-spawn/CHANGELOG.html": {
    "href": "node_modules/cross-spawn/CHANGELOG.html",
    "title": "Change Log | accouter",
    "keywords": "Change Log All notable changes to this project will be documented in this file. See standard-version for commit guidelines. 6.0.5 (2018-03-02) Bug Fixes avoid using deprecated Buffer constructor (#94) (d5770df), closes /nodejs.org/api/deprecations.html#deprecations_dep0005 6.0.4 (2018-01-31) Bug Fixes fix paths being incorrectly normalized on unix (06ee3c6), closes #90 6.0.3 (2018-01-23) 6.0.2 (2018-01-23) 6.0.1 (2018-01-23) 6.0.0 (2018-01-23) Bug Fixes fix certain arguments not being correctly escaped or causing batch syntax error (900cf10), closes #82 #51 fix commands as posix relatixe paths not working correctly, e.g.: ./my-command (900cf10) fix options argument being mutated (900cf10) fix commands resolution when PATH was actually Path (900cf10) Features improve compliance with node's ENOENT errors (900cf10) improve detection of node's shell option support (900cf10) Chores upgrade tooling upgrate project to es6 (node v4) BREAKING CHANGES remove support for older nodejs versions, only node >= 4 is supported 5.1.0 (2017-02-26) Bug Fixes fix options.shell support for NodeJS v4.8 5.0.1 (2016-11-04) Bug Fixes fix options.shell support for NodeJS v7 5.0.0 (2016-10-30) Features add support for options.shell improve parsing of shebangs by using shebang-command module Chores refactor some code to make it more clear update README caveats"
  },
  "node_modules/cross-spawn/README.html": {
    "href": "node_modules/cross-spawn/README.html",
    "title": "cross-spawn | accouter",
    "keywords": "cross-spawn A cross platform solution to node's spawn and spawnSync. Installation $ npm install cross-spawn Why Node has issues when using spawn on Windows: It ignores PATHEXT It does not support shebangs Has problems running commands with spaces Has problems running commands with posix relative paths (e.g.: ./my-folder/my-executable) Has an issue with command shims (files in node_modules/.bin/), where arguments with quotes and parenthesis would result in invalid syntax error No options.shell support on node <v4.8 All these issues are handled correctly by cross-spawn. There are some known modules, such as win-spawn, that try to solve this but they are either broken or provide faulty escaping of shell arguments. Usage Exactly the same way as node's spawn or spawnSync, so it's a drop in replacement. const spawn = require('cross-spawn'); // Spawn NPM asynchronously const child = spawn('npm', ['list', '-g', '-depth', '0'], { stdio: 'inherit' }); // Spawn NPM synchronously const result = spawn.sync('npm', ['list', '-g', '-depth', '0'], { stdio: 'inherit' }); Caveats Using options.shell as an alternative to cross-spawn Starting from node v4.8, spawn has a shell option that allows you run commands from within a shell. This new option solves the PATHEXT issue but: It's not supported in node <v4.8 You must manually escape the command and arguments which is very error prone, specially when passing user input There are a lot of other unresolved issues from the Why section that you must take into account If you are using the shell option to spawn a command in a cross platform way, consider using cross-spawn instead. You have been warned. options.shell support While cross-spawn adds support for options.shell in node <v4.8, all of its enhancements are disabled. This mimics the Node.js behavior. More specifically, the command and its arguments will not be automatically escaped nor shebang support will be offered. This is by design because if you are using options.shell you are probably targeting a specific platform anyway and you don't want things to get into your way. Shebangs support While cross-spawn handles shebangs on Windows, its support is limited. More specifically, it just supports #!/usr/bin/env <program> where <program> must not contain any arguments. If you would like to have the shebang support improved, feel free to contribute via a pull-request. Remember to always test your code on Windows! Tests $ npm test $ npm test -- --watch during development License Released under the MIT License."
  },
  "node_modules/cross-spawn/node_modules/semver/README.html": {
    "href": "node_modules/cross-spawn/node_modules/semver/README.html",
    "title": "semver(1) -- The semantic versioner for npm | accouter",
    "keywords": "semver(1) -- The semantic versioner for npm Install npm install --save semver Usage As a node module: const semver = require('semver') semver.valid('1.2.3') // '1.2.3' semver.valid('a.b.c') // null semver.clean(' =v1.2.3 ') // '1.2.3' semver.satisfies('1.2.3', '1.x || >=2.5.0 || 5.0.0 - 7.2.3') // true semver.gt('1.2.3', '9.8.7') // false semver.lt('1.2.3', '9.8.7') // true semver.minVersion('>=1.0.0') // '1.0.0' semver.valid(semver.coerce('v2')) // '2.0.0' semver.valid(semver.coerce('42.6.7.9.3-alpha')) // '42.6.7' As a command-line utility: $ semver -h A JavaScript implementation of the https://semver.org/ specification Copyright Isaac Z. Schlueter Usage: semver [options] <version> [<version> [...]] Prints valid versions sorted by SemVer precedence Options: -r --range <range> Print versions that match the specified range. -i --increment [<level>] Increment a version by the specified level. Level can be one of: major, minor, patch, premajor, preminor, prepatch, or prerelease. Default level is 'patch'. Only one version may be specified. --preid <identifier> Identifier to be used to prefix premajor, preminor, prepatch or prerelease version increments. -l --loose Interpret versions and ranges loosely -p --include-prerelease Always include prerelease versions in range matching -c --coerce Coerce a string into SemVer if possible (does not imply --loose) Program exits successfully if any valid version satisfies all supplied ranges, and prints all satisfying versions. If no satisfying versions are found, then exits failure. Versions are printed in ascending order, so supplying multiple versions to the utility will just sort them. Versions A \"version\" is described by the v2.0.0 specification found at https://semver.org/. A leading \"=\" or \"v\" character is stripped off and ignored. Ranges A version range is a set of comparators which specify versions that satisfy the range. A comparator is composed of an operator and a version. The set of primitive operators is: < Less than <= Less than or equal to > Greater than >= Greater than or equal to = Equal. If no operator is specified, then equality is assumed, so this operator is optional, but MAY be included. For example, the comparator >=1.2.7 would match the versions 1.2.7, 1.2.8, 2.5.3, and 1.3.9, but not the versions 1.2.6 or 1.1.0. Comparators can be joined by whitespace to form a comparator set, which is satisfied by the intersection of all of the comparators it includes. A range is composed of one or more comparator sets, joined by ||. A version matches a range if and only if every comparator in at least one of the ||-separated comparator sets is satisfied by the version. For example, the range >=1.2.7 <1.3.0 would match the versions 1.2.7, 1.2.8, and 1.2.99, but not the versions 1.2.6, 1.3.0, or 1.1.0. The range 1.2.7 || >=1.2.9 <2.0.0 would match the versions 1.2.7, 1.2.9, and 1.4.6, but not the versions 1.2.8 or 2.0.0. Prerelease Tags If a version has a prerelease tag (for example, 1.2.3-alpha.3) then it will only be allowed to satisfy comparator sets if at least one comparator with the same [major, minor, patch] tuple also has a prerelease tag. For example, the range >1.2.3-alpha.3 would be allowed to match the version 1.2.3-alpha.7, but it would not be satisfied by 3.4.5-alpha.9, even though 3.4.5-alpha.9 is technically \"greater than\" 1.2.3-alpha.3 according to the SemVer sort rules. The version range only accepts prerelease tags on the 1.2.3 version. The version 3.4.5 would satisfy the range, because it does not have a prerelease flag, and 3.4.5 is greater than 1.2.3-alpha.7. The purpose for this behavior is twofold. First, prerelease versions frequently are updated very quickly, and contain many breaking changes that are (by the author's design) not yet fit for public consumption. Therefore, by default, they are excluded from range matching semantics. Second, a user who has opted into using a prerelease version has clearly indicated the intent to use that specific set of alpha/beta/rc versions. By including a prerelease tag in the range, the user is indicating that they are aware of the risk. However, it is still not appropriate to assume that they have opted into taking a similar risk on the next set of prerelease versions. Note that this behavior can be suppressed (treating all prerelease versions as if they were normal versions, for the purpose of range matching) by setting the includePrerelease flag on the options object to any functions that do range matching. Prerelease Identifiers The method .inc takes an additional identifier string argument that will append the value of the string as a prerelease identifier: semver.inc('1.2.3', 'prerelease', 'beta') // '1.2.4-beta.0' command-line example: $ semver 1.2.3 -i prerelease --preid beta 1.2.4-beta.0 Which then can be used to increment further: $ semver 1.2.4-beta.0 -i prerelease 1.2.4-beta.1 Advanced Range Syntax Advanced range syntax desugars to primitive comparators in deterministic ways. Advanced ranges may be combined in the same way as primitive comparators using white space or ||. Hyphen Ranges X.Y.Z - A.B.C Specifies an inclusive set. 1.2.3 - 2.3.4 := >=1.2.3 <=2.3.4 If a partial version is provided as the first version in the inclusive range, then the missing pieces are replaced with zeroes. 1.2 - 2.3.4 := >=1.2.0 <=2.3.4 If a partial version is provided as the second version in the inclusive range, then all versions that start with the supplied parts of the tuple are accepted, but nothing that would be greater than the provided tuple parts. 1.2.3 - 2.3 := >=1.2.3 <2.4.0 1.2.3 - 2 := >=1.2.3 <3.0.0 X-Ranges 1.2.x 1.X 1.2.* * Any of X, x, or * may be used to \"stand in\" for one of the numeric values in the [major, minor, patch] tuple. * := >=0.0.0 (Any version satisfies) 1.x := >=1.0.0 <2.0.0 (Matching major version) 1.2.x := >=1.2.0 <1.3.0 (Matching major and minor versions) A partial version range is treated as an X-Range, so the special character is in fact optional. \"\" (empty string) := * := >=0.0.0 1 := 1.x.x := >=1.0.0 <2.0.0 1.2 := 1.2.x := >=1.2.0 <1.3.0 Tilde Ranges ~1.2.3 ~1.2 ~1 Allows patch-level changes if a minor version is specified on the comparator. Allows minor-level changes if not. ~1.2.3 := >=1.2.3 <1.(2+1).0 := >=1.2.3 <1.3.0 ~1.2 := >=1.2.0 <1.(2+1).0 := >=1.2.0 <1.3.0 (Same as 1.2.x) ~1 := >=1.0.0 <(1+1).0.0 := >=1.0.0 <2.0.0 (Same as 1.x) ~0.2.3 := >=0.2.3 <0.(2+1).0 := >=0.2.3 <0.3.0 ~0.2 := >=0.2.0 <0.(2+1).0 := >=0.2.0 <0.3.0 (Same as 0.2.x) ~0 := >=0.0.0 <(0+1).0.0 := >=0.0.0 <1.0.0 (Same as 0.x) ~1.2.3-beta.2 := >=1.2.3-beta.2 <1.3.0 Note that prereleases in the 1.2.3 version will be allowed, if they are greater than or equal to beta.2. So, 1.2.3-beta.4 would be allowed, but 1.2.4-beta.2 would not, because it is a prerelease of a different [major, minor, patch] tuple. Caret Ranges ^1.2.3 ^0.2.5 ^0.0.4 Allows changes that do not modify the left-most non-zero digit in the [major, minor, patch] tuple. In other words, this allows patch and minor updates for versions 1.0.0 and above, patch updates for versions 0.X >=0.1.0, and no updates for versions 0.0.X. Many authors treat a 0.x version as if the x were the major \"breaking-change\" indicator. Caret ranges are ideal when an author may make breaking changes between 0.2.4 and 0.3.0 releases, which is a common practice. However, it presumes that there will not be breaking changes between 0.2.4 and 0.2.5. It allows for changes that are presumed to be additive (but non-breaking), according to commonly observed practices. ^1.2.3 := >=1.2.3 <2.0.0 ^0.2.3 := >=0.2.3 <0.3.0 ^0.0.3 := >=0.0.3 <0.0.4 ^1.2.3-beta.2 := >=1.2.3-beta.2 <2.0.0 Note that prereleases in the 1.2.3 version will be allowed, if they are greater than or equal to beta.2. So, 1.2.3-beta.4 would be allowed, but 1.2.4-beta.2 would not, because it is a prerelease of a different [major, minor, patch] tuple. ^0.0.3-beta := >=0.0.3-beta <0.0.4 Note that prereleases in the 0.0.3 version only will be allowed, if they are greater than or equal to beta. So, 0.0.3-pr.2 would be allowed. When parsing caret ranges, a missing patch value desugars to the number 0, but will allow flexibility within that value, even if the major and minor versions are both 0. ^1.2.x := >=1.2.0 <2.0.0 ^0.0.x := >=0.0.0 <0.1.0 ^0.0 := >=0.0.0 <0.1.0 A missing minor and patch values will desugar to zero, but also allow flexibility within those values, even if the major version is zero. ^1.x := >=1.0.0 <2.0.0 ^0.x := >=0.0.0 <1.0.0 Range Grammar Putting all this together, here is a Backus-Naur grammar for ranges, for the benefit of parser authors: range-set ::= range ( logical-or range ) * logical-or ::= ( ' ' ) * '||' ( ' ' ) * range ::= hyphen | simple ( ' ' simple ) * | '' hyphen ::= partial ' - ' partial simple ::= primitive | partial | tilde | caret primitive ::= ( '<' | '>' | '>=' | '<=' | '=' ) partial partial ::= xr ( '.' xr ( '.' xr qualifier ? )? )? xr ::= 'x' | 'X' | '*' | nr nr ::= '0' | ['1'-'9'] ( ['0'-'9'] ) * tilde ::= '~' partial caret ::= '^' partial qualifier ::= ( '-' pre )? ( '+' build )? pre ::= parts build ::= parts parts ::= part ( '.' part ) * part ::= nr | [-0-9A-Za-z]+ Functions All methods and classes take a final options object argument. All options in this object are false by default. The options supported are: loose Be more forgiving about not-quite-valid semver strings. (Any resulting output will always be 100% strict compliant, of course.) For backwards compatibility reasons, if the options argument is a boolean value instead of an object, it is interpreted to be the loose param. includePrerelease Set to suppress the default behavior of excluding prerelease tagged versions from ranges unless they are explicitly opted into. Strict-mode Comparators and Ranges will be strict about the SemVer strings that they parse. valid(v): Return the parsed version, or null if it's not valid. inc(v, release): Return the version incremented by the release type (major, premajor, minor, preminor, patch, prepatch, or prerelease), or null if it's not valid premajor in one call will bump the version up to the next major version and down to a prerelease of that major version. preminor, and prepatch work the same way. If called from a non-prerelease version, the prerelease will work the same as prepatch. It increments the patch version, then makes a prerelease. If the input version is already a prerelease it simply increments it. prerelease(v): Returns an array of prerelease components, or null if none exist. Example: prerelease('1.2.3-alpha.1') -> ['alpha', 1] major(v): Return the major version number. minor(v): Return the minor version number. patch(v): Return the patch version number. intersects(r1, r2, loose): Return true if the two supplied ranges or comparators intersect. parse(v): Attempt to parse a string as a semantic version, returning either a SemVer object or null. Comparison gt(v1, v2): v1 > v2 gte(v1, v2): v1 >= v2 lt(v1, v2): v1 < v2 lte(v1, v2): v1 <= v2 eq(v1, v2): v1 == v2 This is true if they're logically equivalent, even if they're not the exact same string. You already know how to compare strings. neq(v1, v2): v1 != v2 The opposite of eq. cmp(v1, comparator, v2): Pass in a comparison string, and it'll call the corresponding function above. \"===\" and \"!==\" do simple string comparison, but are included for completeness. Throws if an invalid comparison string is provided. compare(v1, v2): Return 0 if v1 == v2, or 1 if v1 is greater, or -1 if v2 is greater. Sorts in ascending order if passed to Array.sort(). rcompare(v1, v2): The reverse of compare. Sorts an array of versions in descending order when passed to Array.sort(). diff(v1, v2): Returns difference between two versions by the release type (major, premajor, minor, preminor, patch, prepatch, or prerelease), or null if the versions are the same. Comparators intersects(comparator): Return true if the comparators intersect Ranges validRange(range): Return the valid range or null if it's not valid satisfies(version, range): Return true if the version satisfies the range. maxSatisfying(versions, range): Return the highest version in the list that satisfies the range, or null if none of them do. minSatisfying(versions, range): Return the lowest version in the list that satisfies the range, or null if none of them do. minVersion(range): Return the lowest version that can possibly match the given range. gtr(version, range): Return true if version is greater than all the versions possible in the range. ltr(version, range): Return true if version is less than all the versions possible in the range. outside(version, range, hilo): Return true if the version is outside the bounds of the range in either the high or low direction. The hilo argument must be either the string '>' or '<'. (This is the function called by gtr and ltr.) intersects(range): Return true if any of the ranges comparators intersect Note that, since ranges may be non-contiguous, a version might not be greater than a range, less than a range, or satisfy a range! For example, the range 1.2 <1.2.9 || >2.0.0 would have a hole from 1.2.9 until 2.0.0, so the version 1.2.10 would not be greater than the range (because 2.0.1 satisfies, which is higher), nor less than the range (since 1.2.8 satisfies, which is lower), and it also does not satisfy the range. If you want to know if a version satisfies or does not satisfy a range, use the satisfies(version, range) function. Coercion coerce(version): Coerces a string to semver if possible This aims to provide a very forgiving translation of a non-semver string to semver. It looks for the first digit in a string, and consumes all remaining characters which satisfy at least a partial semver (e.g., 1, 1.2, 1.2.3) up to the max permitted length (256 characters). Longer versions are simply truncated (4.6.3.9.2-alpha2 becomes 4.6.3). All surrounding text is simply ignored (v3.4 replaces v3.3.1 becomes 3.4.0). Only text which lacks digits will fail coercion (version one is not valid). The maximum length for any semver component considered for coercion is 16 characters; longer components will be ignored (10000000000000000.4.7.4 becomes 4.7.4). The maximum value for any semver component is Number.MAX_SAFE_INTEGER || (2**53 - 1); higher value components are invalid (9999999999999999.4.7.4 is likely invalid)."
  },
  "node_modules/css-declaration-sorter/license.html": {
    "href": "node_modules/css-declaration-sorter/license.html",
    "title": "| accouter",
    "keywords": "ISC License Copyright (c) Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies. THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE."
  },
  "node_modules/css-declaration-sorter/readme.html": {
    "href": "node_modules/css-declaration-sorter/readme.html",
    "title": "CSS Declaration Sorter | accouter",
    "keywords": "CSS Declaration Sorter A Node.js module and PostCSS plugin to sort CSS, SCSS or Less declarations based on their property names. Ensuring styling is organized, more consistent and in order... The goal of this package is to sort the source code of a project in the build process or to decrease the distributed CSS gzipped size. Check out the Prettier plugin for usage with a variety of file formats. Niceness Up-to-date CSS properties fetched from the MDN Compatibility Data project. Choose your wanted order or provide your own. Nested rules sorting support. SCSS and Less support when combined with either postcss-scss or postcss-less. Thought-out sorting orders out of the box, approved by their authors. Alphabetical example Input: body { display: block; animation: none; color: #C55; border: 0; } Output: body { animation: none; border: 0; color: #C55; display: block; } Built-in sorting orders Alphabetical alphabetical Default, order in a simple alphabetical manner from a - z. SMACSS smacss Order from most important, flow affecting properties, to least important properties. Box Border Background Text Other Concentric CSS concentric-css Order properties applying outside the box model, moving inward to intrinsic changes. Positioning Visibility Box model Dimensions Text Usage Following the PostCSS plugin guidelines, this package depends on PostCSS as a peer dependency: npm install postcss css-declaration-sorter --save-dev CLI This module does not include its own CLI but works with the official PostCSS CLI. To use the examples below, the postcss-cli package is a required dependency. Piping out result from file: postcss input.css --use css-declaration-sorter | cat Sorting multiple files by overwriting: postcss *.css --use css-declaration-sorter --replace --no-map Sorting all files in a directory with SCSS syntax using postcss-scss by overwriting: postcss ./src/**/*.scss --syntax postcss-scss --use css-declaration-sorter --replace --no-map Sorting all files in the directory with SCSS syntax and SMACSS order by overwriting, using package.json configuration: \"postcss\": { \"syntax\": \"postcss-scss\", \"map\": false, \"plugins\": { \"css-declaration-sorter\": { \"order\": \"smacss\" } } } postcss ./src/**/*.scss --replace --config package.json Vanilla JS import postcss from 'postcss'; import { cssDeclarationSorter } from 'css-declaration-sorter'; postcss([cssDeclarationSorter({ order: 'smacss' })]) .process('a { color: hyperblue; display: block; }', { from: undefined }) .then(result => console.log( result.css === 'a { display: block; color: hyperblue; }' )); View more usage examples in combination with other tools. API cssDeclarationSorter({ order, keepOverrides }) order Type: string or function Default: alphabetical Options: alphabetical, smacss, concentric-css Provide the name of one of the built-in sort orders or a comparison function that is passed to (Array.sort). This function receives two declaration names and is expected to return -1, 0 or 1 depending on the wanted order. keepOverrides Type: Boolean Default: false To prevent breaking legacy CSS where shorthand declarations override longhand declarations (also taking into account vendor prefixes) this option can enabled. For example animation-name: some; animation: greeting; will be kept in this order when keepOverrides is true."
  },
  "node_modules/css-select/README.html": {
    "href": "node_modules/css-select/README.html",
    "title": "css-select | accouter",
    "keywords": "css-select A CSS selector compiler and engine What? As a compiler, css-select turns CSS selectors into functions that tests if elements match them. As an engine, css-select looks through a DOM tree, searching for elements. Elements are tested \"from the top\", similar to how browsers execute CSS selectors. In its default configuration, css-select queries the DOM structure of the domhandler module (also known as htmlparser2 DOM). To query alternative DOM structures, see Options below. Features: 🔬 Full implementation of CSS3 selectors, as well as most CSS4 selectors 🧪 Partial implementation of jQuery/Sizzle extensions (see cheerio-select for the remaining selectors) 🧑‍🔬 High test coverage, including the full test suites from Sizzle, Qwery and NWMatcher and . 🥼 Reliably great performance Why? Most CSS engines written in JavaScript execute selectors left-to-right. That means thet execute every component of the selector in order, from left to right. As an example: For the selector a b, these engines will first query for a elements, then search these for b elements. (That's the approach of eg. Sizzle, Qwery and NWMatcher.) While this works, it has some downsides: Children of as will be checked multiple times; first, to check if they are also as, then, for every superior a once, if they are bs. Using Big O notation, that would be O(n^(k+1)), where k is the number of descendant selectors (that's the space in the example above). The far more efficient approach is to first look for b elements, then check if they have superior a elements: Using big O notation again, that would be O(n). That's called right-to-left execution. And that's what css-select does – and why it's quite performant. How does it work? By building a stack of functions. Wait, what? Okay, so let's suppose we want to compile the selector a b, for right-to-left execution. We start by parsing the selector. This turns the selector into an array of the building blocks. That's what the css-what module is for, if you want to have a look. Anyway, after parsing, we end up with an array like this one: [ { type: \"tag\", name: \"a\" }, { type: \"descendant\" }, { type: \"tag\", name: \"b\" }, ]; (Actually, this array is wrapped in another array, but that's another story, involving commas in selectors.) Now that we know the meaning of every part of the selector, we can compile it. That is where things become interesting. The basic idea is to turn every part of the selector into a function, which takes an element as its only argument. The function checks whether a passed element matches its part of the selector: If it does, the element is passed to the next function representing the next part of the selector. That function does the same. If an element is accepted by all parts of the selector, it matches the selector and double rainbow ALL THE WAY. As said before, we want to do right-to-left execution with all the big O improvements. That means elements are passed from the rightmost part of the selector (b in our example) to the leftmost (which would be c of course a). For traversals, such as the descendant operating the space between a and b, we walk up the DOM tree, starting from the element passed as argument. //TODO: More in-depth description. Implementation details. Build a spaceship. API const CSSselect = require(\"css-select\"); Note: css-select throws errors when invalid selectors are passed to it. This is done to aid with writing css selectors, but can be unexpected when processing arbitrary strings. CSSselect.selectAll(query, elems, options) Queries elems, returns an array containing all matches. query can be either a CSS selector or a function. elems can be either an array of elements, or a single element. If it is an element, its children will be queried. options is described below. Aliases: default export, CSSselect.iterate(query, elems). CSSselect.compile(query, options) Compiles the query, returns a function. CSSselect.is(elem, query, options) Tests whether or not an element is matched by query. query can be either a CSS selector or a function. CSSselect.selectOne(query, elems, options) Arguments are the same as for CSSselect.selectAll(query, elems). Only returns the first match, or null if there was no match. Options All options are optional. xmlMode: When enabled, tag names will be case-sensitive. Default: false. rootFunc: The last function in the stack, will be called with the last element that's looked at. adapter: The adapter to use when interacting with the backing DOM structure. By default it uses the domutils module. context: The context of the current query. Used to limit the scope of searches. Can be matched directly using the :scope pseudo-class. relativeSelector: By default, selectors are relative to the context, which means that no parent elements of the context will be matched. (Eg. a b c with context b will never give any results.) If relativeSelector is set to false, selectors won't be absolutized and selectors can test for parent elements outside of the context. cacheResults: Allow css-select to cache results for some selectors, sometimes greatly improving querying performance. Disable this if your document can change in between queries with the same compiled selector. Default: true. pseudos: A map of pseudo-class names to functions or strings. Custom Adapters A custom adapter must match the interface described here. You may want to have a look at domutils to see the default implementation, or at css-select-browser-adapter for an implementation backed by the DOM. Supported selectors As defined by CSS 4 and / or jQuery. Selector lists (,) Universal (*) Type (<tagname>) Descendant ( ) Child (>) Parent (<) Adjacent sibling (+) General sibling (~) Attribute ([attr=foo]), with supported comparisons: [attr] (existential) = ~= |= *= ^= $= != i and s can be added after the comparison to make the comparison case-insensitive or case-sensitive (eg. [attr=foo i]). If neither is supplied, css-select will follow the HTML spec's case-sensitivity rules. Pseudos: :not :contains :icontains (case-insensitive version of :contains) :has :root :empty :parent :first-child, :last-child, :first-of-type, :last-of-type :only-of-type, :only-child :nth-child, :nth-last-child, :nth-of-type, :nth-last-of-type, :link, :any-link :visited, :hover, :active (these depend on optional Adapter methods, so these will only match elements if implemented in Adapter) :selected, :checked :enabled, :disabled :required, :optional :header, :button, :input, :text, :checkbox, :file, :password, :reset, :radio etc. :is, plus its legacy alias :matches :scope (uses the context from the passed options) License: BSD-2-Clause Security contact information To report a security vulnerability, please use the Tidelift security contact. Tidelift will coordinate the fix and disclosure. css-select for enterprise Available as part of the Tidelift Subscription The maintainers of css-select and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more."
  },
  "node_modules/css-tree/README.html": {
    "href": "node_modules/css-tree/README.html",
    "title": "CSSTree | accouter",
    "keywords": "CSSTree CSSTree is a tool set for CSS: fast detailed parser (CSS → AST), walker (AST traversal), generator (AST → CSS) and lexer (validation and matching) based on specs and browser implementations. The main goal is to be efficient and W3C spec compliant, with focus on CSS analyzing and source-to-source transforming tasks. Features Detailed parsing with an adjustable level of detail By default CSSTree parses CSS as detailed as possible, i.e. each single logical part is representing with its own AST node (see AST format for all possible node types). The parsing detail level can be changed through parser options, for example, you can disable parsing of selectors or declaration values for component parts. Tolerant to errors by design Parser behaves as spec says: \"When errors occur in CSS, the parser attempts to recover gracefully, throwing away only the minimum amount of content before returning to parsing as normal\". The only thing the parser departs from the specification is that it doesn't throw away bad content, but wraps it in a special node type (Raw) that allows processing it later. Fast and efficient CSSTree is created with focus on performance and effective memory consumption. Therefore it's one of the fastest CSS parsers at the moment. Syntax validation The build-in lexer can test CSS against syntaxes defined by W3C. CSSTree uses mdn/data as a basis for lexer's dictionaries and extends it with vendor specific and legacy syntaxes. Lexer can only check the declaration values currently, but this feature will be extended to other parts of the CSS in the future. Projects using CSSTree Svelte – Cybernetically enhanced web apps SVGO – Node.js tool for optimizing SVG files CSSO – CSS minifier with structural optimizations NativeScript – NativeScript empowers you to access native APIs from JavaScript directly react-native-svg – SVG library for React Native, React Native Web, and plain React web projects penthouse – Critical Path CSS Generator Bit – Bit is the platform for collaborating on components and more... Documentation AST format Parsing CSS → AST parse(source[, options]) Serialization AST → CSS generate(ast[, options]) AST traversal walk(ast, options) find(ast, fn) findLast(ast, fn) findAll(ast, fn) Util functions Value encoding & decoding property(name) keyword(name) ident string url AST transforming clone(ast) fromPlainObject(object) toPlainObject(ast) Value Definition Syntax parse(source) walk(node, options, context) generate(node, options) AST format Tools AST Explorer – explore CSSTree AST format with zero setup CSS syntax reference CSS syntax validator Related projects csstree-validator – NPM package to validate CSS stylelint-csstree-validator – plugin for stylelint to validate CSS Grunt plugin Gulp plugin Sublime plugin VS Code plugin Atom plugin Usage Install with npm: npm install css-tree Basic usage: import * as csstree from 'css-tree'; // parse CSS to AST const ast = csstree.parse('.example { world: \"!\" }'); // traverse AST and modify it csstree.walk(ast, (node) => { if (node.type === 'ClassSelector' && node.name === 'example') { node.name = 'hello'; } }); // generate CSS from AST console.log(csstree.generate(ast)); // .hello{world:\"!\"} Syntax matching: // parse CSS to AST as a declaration value const ast = csstree.parse('red 1px solid', { context: 'value' }); // match to syntax of `border` property const matchResult = csstree.lexer.matchProperty('border', ast); // check first value node is a <color> console.log(matchResult.isType(ast.children.first, 'color')); // true // get a type list matched to a node console.log(matchResult.getTrace(ast.children.first)); // [ { type: 'Property', name: 'border' }, // { type: 'Type', name: 'color' }, // { type: 'Type', name: 'named-color' }, // { type: 'Keyword', name: 'red' } ] Exports Is it possible to import just a needed part of library like a parser or a walker. That's might useful for loading time or bundle size optimisations. import * as tokenizer from 'css-tree/tokenizer'; import * as parser from 'css-tree/parser'; import * as walker from 'css-tree/walker'; import * as lexer from 'css-tree/lexer'; import * as definitionSyntax from 'css-tree/definition-syntax'; import * as data from 'css-tree/definition-syntax-data'; import * as dataPatch from 'css-tree/definition-syntax-data-patch'; import * as utils from 'css-tree/utils'; Using in a browser Bundles are available for use in a browser: dist/csstree.js – minified IIFE with csstree as global <script src=\"node_modules/css-tree/dist/csstree.js\"></script> <script> csstree.parse('.example { color: green }'); </script> dist/csstree.esm.js – minified ES module <script type=\"module\"> import { parse } from 'node_modules/css-tree/dist/csstree.esm.js' parse('.example { color: green }'); </script> One of CDN services like unpkg or jsDelivr can be used. By default (for short path) a ESM version is exposing. For IIFE version a full path to a bundle should be specified: <!-- ESM --> <script type=\"module\"> import * as csstree from 'https://cdn.jsdelivr.net/npm/css-tree'; import * as csstree from 'https://unpkg.com/css-tree'; </script> <!-- IIFE with an export to global --> <script src=\"https://cdn.jsdelivr.net/npm/css-tree/dist/csstree.js\"></script> <script src=\"https://unpkg.com/css-tree/dist/csstree.js\"></script> Top level API License MIT"
  },
  "node_modules/css-what/readme.html": {
    "href": "node_modules/css-what/readme.html",
    "title": "css-what | accouter",
    "keywords": "css-what A CSS selector parser. Example import * as CSSwhat from \"css-what\"; CSSwhat.parse(\"foo[bar]:baz\") ~> [ [ { type: \"tag\", name: \"foo\" }, { type: \"attribute\", name: \"bar\", action: \"exists\", value: \"\", ignoreCase: null }, { type: \"pseudo\", name: \"baz\", data: null } ] ] API CSSwhat.parse(selector) - Parses selector. The function returns a two-dimensional array. The first array represents selectors separated by commas (eg. sub1, sub2), the second contains the relevant tokens for that selector. Possible token types are: name properties example output tag name div { type: 'tag', name: 'div' } universal - * { type: 'universal' } pseudo name, data :name(data) { type: 'pseudo', name: 'name', data: 'data' } pseudo name, data :name { type: 'pseudo', name: 'name', data: null } pseudo-element name ::name { type: 'pseudo-element', name: 'name' } attribute name, action, value, ignoreCase [attr] { type: 'attribute', name: 'attr', action: 'exists', value: '', ignoreCase: false } attribute name, action, value, ignoreCase [attr=val] { type: 'attribute', name: 'attr', action: 'equals', value: 'val', ignoreCase: false } attribute name, action, value, ignoreCase [attr^=val] { type: 'attribute', name: 'attr', action: 'start', value: 'val', ignoreCase: false } attribute name, action, value, ignoreCase [attr$=val] { type: 'attribute', name: 'attr', action: 'end', value: 'val', ignoreCase: false } child - > { type: 'child' } parent - < { type: 'parent' } sibling - ~ { type: 'sibling' } adjacent - + { type: 'adjacent' } descendant - { type: 'descendant' } column-combinator - \\|\\| { type: 'column-combinator' } CSSwhat.stringify(selector) - Turns selector back into a string. License: BSD-2-Clause Security contact information To report a security vulnerability, please use the Tidelift security contact. Tidelift will coordinate the fix and disclosure. css-what for enterprise Available as part of the Tidelift Subscription The maintainers of css-what and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more."
  },
  "node_modules/cssesc/README.html": {
    "href": "node_modules/cssesc/README.html",
    "title": "cssesc | accouter",
    "keywords": "cssesc A JavaScript library for escaping CSS strings and identifiers while generating the shortest possible ASCII-only output. This is a JavaScript library for escaping text for use in CSS strings or identifiers while generating the shortest possible valid ASCII-only output. Here’s an online demo. A polyfill for the CSSOM CSS.escape() method is available in a separate repository. (In comparison, cssesc is much more powerful.) Feel free to fork if you see possible improvements! Installation Via npm: npm install cssesc In a browser: <script src=\"cssesc.js\"></script> In Node.js: const cssesc = require('cssesc'); In Ruby using the ruby-cssesc wrapper gem: gem install ruby-cssesc require 'ruby-cssesc' CSSEsc.escape('I ♥ Ruby', is_identifier: true) In Sass using sassy-escape: gem install sassy-escape body { content: escape('I ♥ Sass', $is-identifier: true); } API cssesc(value, options) This function takes a value and returns an escaped version of the value where any characters that are not printable ASCII symbols are escaped using the shortest possible (but valid) escape sequences for use in CSS strings or identifiers. cssesc('Ich ♥ Bücher'); // → 'Ich \\\\2665 B\\\\FC cher' cssesc('foo 𝌆 bar'); // → 'foo \\\\1D306 bar' By default, cssesc returns a string that can be used as part of a CSS string. If the target is a CSS identifier rather than a CSS string, use the isIdentifier: true setting (see below). The optional options argument accepts an object with the following options: isIdentifier The default value for the isIdentifier option is false. This means that the input text will be escaped for use in a CSS string literal. If you want to use the result as a CSS identifier instead (in a selector, for example), set this option to true. cssesc('123a2b'); // → '123a2b' cssesc('123a2b', { 'isIdentifier': true }); // → '\\\\31 23a2b' quotes The default value for the quotes option is 'single'. This means that any occurences of ' in the input text will be escaped as \\', so that the output can be used in a CSS string literal wrapped in single quotes. cssesc('Lorem ipsum \"dolor\" sit \\'amet\\' etc.'); // → 'Lorem ipsum \"dolor\" sit \\\\\\'amet\\\\\\' etc.' // → \"Lorem ipsum \\\"dolor\\\" sit \\\\'amet\\\\' etc.\" cssesc('Lorem ipsum \"dolor\" sit \\'amet\\' etc.', { 'quotes': 'single' }); // → 'Lorem ipsum \"dolor\" sit \\\\\\'amet\\\\\\' etc.' // → \"Lorem ipsum \\\"dolor\\\" sit \\\\'amet\\\\' etc.\" If you want to use the output as part of a CSS string literal wrapped in double quotes, set the quotes option to 'double'. cssesc('Lorem ipsum \"dolor\" sit \\'amet\\' etc.', { 'quotes': 'double' }); // → 'Lorem ipsum \\\\\"dolor\\\\\" sit \\'amet\\' etc.' // → \"Lorem ipsum \\\\\\\"dolor\\\\\\\" sit 'amet' etc.\" wrap The wrap option takes a boolean value (true or false), and defaults to false (disabled). When enabled, the output will be a valid CSS string literal wrapped in quotes. The type of quotes can be specified through the quotes setting. cssesc('Lorem ipsum \"dolor\" sit \\'amet\\' etc.', { 'quotes': 'single', 'wrap': true }); // → '\\'Lorem ipsum \"dolor\" sit \\\\\\'amet\\\\\\' etc.\\'' // → \"\\'Lorem ipsum \\\"dolor\\\" sit \\\\\\'amet\\\\\\' etc.\\'\" cssesc('Lorem ipsum \"dolor\" sit \\'amet\\' etc.', { 'quotes': 'double', 'wrap': true }); // → '\"Lorem ipsum \\\\\"dolor\\\\\" sit \\'amet\\' etc.\"' // → \"\\\"Lorem ipsum \\\\\\\"dolor\\\\\\\" sit \\'amet\\' etc.\\\"\" escapeEverything The escapeEverything option takes a boolean value (true or false), and defaults to false (disabled). When enabled, all the symbols in the output will be escaped, even printable ASCII symbols. cssesc('lolwat\"foo\\'bar', { 'escapeEverything': true }); // → '\\\\6C\\\\6F\\\\6C\\\\77\\\\61\\\\74\\\\\"\\\\66\\\\6F\\\\6F\\\\\\'\\\\62\\\\61\\\\72' // → \"\\\\6C\\\\6F\\\\6C\\\\77\\\\61\\\\74\\\\\\\"\\\\66\\\\6F\\\\6F\\\\'\\\\62\\\\61\\\\72\" Overriding the default options globally The global default settings can be overridden by modifying the css.options object. This saves you from passing in an options object for every call to encode if you want to use the non-default setting. // Read the global default setting for `escapeEverything`: cssesc.options.escapeEverything; // → `false` by default // Override the global default setting for `escapeEverything`: cssesc.options.escapeEverything = true; // Using the global default setting for `escapeEverything`, which is now `true`: cssesc('foo © bar ≠ baz 𝌆 qux'); // → '\\\\66\\\\6F\\\\6F\\\\ \\\\A9\\\\ \\\\62\\\\61\\\\72\\\\ \\\\2260\\\\ \\\\62\\\\61\\\\7A\\\\ \\\\1D306\\\\ \\\\71\\\\75\\\\78' cssesc.version A string representing the semantic version number. Using the cssesc binary To use the cssesc binary in your shell, simply install cssesc globally using npm: npm install -g cssesc After that you will be able to escape text for use in CSS strings or identifiers from the command line: $ cssesc 'föo ♥ bår 𝌆 baz' f\\F6o \\2665 b\\E5r \\1D306 baz If the output needs to be a CSS identifier rather than part of a string literal, use the -i/--identifier option: $ cssesc --identifier 'föo ♥ bår 𝌆 baz' f\\F6o\\ \\2665\\ b\\E5r\\ \\1D306\\ baz See cssesc --help for the full list of options. Support This library supports the Node.js and browser versions mentioned in .babelrc. For a version that supports a wider variety of legacy browsers and environments out-of-the-box, see v0.1.0. Author Mathias Bynens License This library is available under the MIT license."
  },
  "node_modules/cssnano-preset-default/README.html": {
    "href": "node_modules/cssnano-preset-default/README.html",
    "title": "cssnano-preset-default | accouter",
    "keywords": "cssnano-preset-default Safe defaults for cssnano which require minimal configuration. Table of Contents Overview Usage Install Configuration Plugins css-declaration-sorter (external) cssnano-utils postcss-calc (external) postcss-colormin postcss-convert-values postcss-discard-comments postcss-discard-duplicates postcss-discard-empty postcss-discard-overridden postcss-merge-longhand postcss-merge-rules postcss-minify-font-values postcss-minify-gradients postcss-minify-params postcss-minify-selectors postcss-normalize-charset postcss-normalize-display-values postcss-normalize-positions postcss-normalize-repeat-style postcss-normalize-string postcss-normalize-timing-functions postcss-normalize-unicode postcss-normalize-url postcss-normalize-whitespace postcss-ordered-values postcss-reduce-initial postcss-reduce-transforms postcss-svgo postcss-unique-selectors Contributors License Overview This default preset for cssnano only includes transforms that make no assumptions about your CSS other than what is passed in. In previous iterations of cssnano, assumptions were made about your CSS which caused output to look different in certain use cases, but not others. These transforms have been moved from the defaults to other presets, to make this preset require only minimal configuration. Usage Install Note that this preset comes bundled with cssnano by default, so you don't need to install it separately. Configuration If you would like to use the default configuration, then you don't need to add anything to your package.json. But should you wish to customise this, you can pass an array with the second parameter as the options object to use. For example, to remove all comments: { \"name\": \"awesome-application\", + \"cssnano\": { + \"preset\": [ + \"default\", + {\"discardComments\": {\"removeAll\": true}} + ] + } } Depending on your usage, the JSON configuration might not work for you, such as in cases where you would like to use options with customisable function parameters. For this use case, we recommend a cssnano.config.js at the same location as your package.json. You can then load a preset and export it with your custom parameters: const defaultPreset = require('cssnano-preset-default'); module.exports = defaultPreset({ discardComments: { remove: (comment) => comment[0] === '@', }, }); Note that you may wish to publish your own preset to npm for reusability, should it differ a lot from this one. This is highly encouraged! Plugins css-declaration-sorter (external) Sorts CSS declarations fast and automatically in a certain order. This plugin is loaded with the following configuration: { keepOverrides: true } cssnano-utils Utility methods used by cssnano postcss-calc (external) PostCSS plugin to reduce calc() This plugin is loaded with its default configuration. postcss-colormin Minify colors in your CSS files with PostCSS. This plugin is loaded with its default configuration. postcss-convert-values Convert values with PostCSS (e.g. ms -> s) This plugin is loaded with the following configuration: { length: false; } postcss-discard-comments Discard comments in your CSS files with PostCSS. This plugin is loaded with its default configuration. postcss-discard-duplicates Discard duplicate rules in your CSS files with PostCSS. This plugin is loaded with its default configuration. postcss-discard-empty Discard empty rules and values with PostCSS. This plugin is loaded with its default configuration. postcss-discard-overridden PostCSS plugin to discard overridden @keyframes or @counter-style. This plugin is loaded with its default configuration. postcss-merge-longhand Merge longhand properties into shorthand with PostCSS. This plugin is loaded with its default configuration. postcss-merge-rules Merge CSS rules with PostCSS. This plugin is loaded with its default configuration. postcss-minify-font-values Minify font declarations with PostCSS This plugin is loaded with its default configuration. postcss-minify-gradients Minify gradient parameters with PostCSS. This plugin is loaded with its default configuration. postcss-minify-params Minify at-rule params with PostCSS This plugin is loaded with its default configuration. postcss-minify-selectors Minify selectors with PostCSS. This plugin is loaded with its default configuration. postcss-normalize-charset Add necessary or remove extra charset with PostCSS This plugin is loaded with the following configuration: { add: false; } postcss-normalize-display-values Normalize multiple value display syntaxes into single values. This plugin is loaded with its default configuration. postcss-normalize-positions Normalize keyword values for position into length values. This plugin is loaded with its default configuration. postcss-normalize-repeat-style Convert two value syntax for repeat-style into one value. This plugin is loaded with its default configuration. postcss-normalize-string Normalize wrapping quotes for CSS string literals. This plugin is loaded with its default configuration. postcss-normalize-timing-functions Normalize CSS animation/transition timing functions. This plugin is loaded with its default configuration. postcss-normalize-unicode Normalize unicode-range descriptors, and can convert to wildcard ranges. This plugin is loaded with its default configuration. postcss-normalize-url Normalize URLs with PostCSS This plugin is loaded with its default configuration. postcss-normalize-whitespace Trim whitespace inside and around CSS rules & declarations. This plugin is loaded with its default configuration. postcss-ordered-values Ensure values are ordered consistently in your CSS. This plugin is loaded with its default configuration. postcss-reduce-initial Reduce initial definitions to the actual initial value, where possible. This plugin is loaded with its default configuration. postcss-reduce-transforms Reduce transform functions with PostCSS. This plugin is loaded with its default configuration. postcss-svgo Optimise inline SVG with PostCSS. This plugin is loaded with its default configuration. postcss-unique-selectors Ensure CSS selectors are unique. This plugin is loaded with its default configuration. Contributors See CONTRIBUTORS.md. License MIT © Ben Briggs"
  },
  "node_modules/cssnano-utils/README.html": {
    "href": "node_modules/cssnano-utils/README.html",
    "title": "cssnano-utils | accouter",
    "keywords": "cssnano-utils Utility methods and plugin for cssnano projects List of methods and plugin(s) utility methods description rawCache Postcss plugin to manage the raw value formatting for generated AST nodes getArguments Get a list of arguments, separated by a comma. sameParent Check that two PostCSS nodes share the same parent. Contributors See CONTRIBUTORS.md."
  },
  "node_modules/cssnano/README.html": {
    "href": "node_modules/cssnano/README.html",
    "title": "cssnano | accouter",
    "keywords": "cssnano For documentation, please see the following links: Repository: https://github.com/cssnano/cssnano Website: http://cssnano.github.io/cssnano"
  },
  "node_modules/csso/README.html": {
    "href": "node_modules/csso/README.html",
    "title": "| accouter",
    "keywords": "CSSO (CSS Optimizer) is a CSS minifier. It performs three sort of transformations: cleaning (removing redundants), compression (replacement for the shorter forms) and restructuring (merge of declarations, rules and so on). As a result an output CSS becomes much smaller in size. Install npm install csso Usage import { minify } from 'csso'; // CommonJS is also supported // const { minify } = require('csso'); const minifiedCss = minify('.test { color: #ff0000; }').css; console.log(minifiedCss); // .test{color:red} Bundles are also available for use in a browser: dist/csso.js – minified IIFE with csso as global <script src=\"node_modules/csso/dist/csso.js\"></script> <script> csso.minify('.example { color: green }'); </script> dist/csso.esm.js – minified ES module <script type=\"module\"> import { minify } from 'node_modules/csso/dist/csso.esm.js' minify('.example { color: green }'); </script> One of CDN services like unpkg or jsDelivr can be used. By default (for short path) a ESM version is exposing. For IIFE version a full path to a bundle should be specified: <!-- ESM --> <script type=\"module\"> import * as csstree from 'https://cdn.jsdelivr.net/npm/csso'; import * as csstree from 'https://unpkg.com/csso'; </script> <!-- IIFE with an export to global --> <script src=\"https://cdn.jsdelivr.net/npm/csso/dist/csso.js\"></script> <script src=\"https://unpkg.com/csso/dist/csso.js\"></script> CSSO is based on CSSTree to parse CSS into AST, AST traversal and to generate AST back to CSS. All CSSTree API is available behind syntax field extended with compress() method. You may minify CSS step by step: import { syntax } from 'csso'; const ast = syntax.parse('.test { color: #ff0000; }'); const compressedAst = syntax.compress(ast).ast; const minifiedCss = syntax.generate(compressedAst); console.log(minifiedCss); // .test{color:red} Also syntax can be imported using csso/syntax entry point: import { parse, compress, generate } from 'csso/syntax'; const ast = parse('.test { color: #ff0000; }'); const compressedAst = compress(ast).ast; const minifiedCss = generate(compressedAst); console.log(minifiedCss); // .test{color:red} Warning: CSSO doesn't guarantee API behind a syntax field as well as AST format. Both might be changed with changes in CSSTree. If you rely heavily on syntax API, a better option might be to use CSSTree directly. Related projects Web interface csso-cli – command line interface gulp-csso – Gulp plugin grunt-csso – Grunt plugin broccoli-csso – Broccoli plugin postcss-csso – PostCSS plugin csso-loader – webpack loader csso-webpack-plugin – webpack plugin CSSO Visual Studio Code plugin vscode-csso - Visual Studio Code plugin atom-csso - Atom plugin Sublime-csso - Sublime plugin API minify(source[, options]) minifyBlock(source[, options]) syntax.compress(ast[, options]) Source maps Usage data White list filtering Black list filtering Scopes minify(source[, options]) Minify source CSS passed as String. const result = csso.minify('.test { color: #ff0000; }', { restructure: false, // don't change CSS structure, i.e. don't merge declarations, rulesets etc debug: true // show additional debug information: // true or number from 1 to 3 (greater number - more details) }); console.log(result.css); // > .test{color:red} Returns an object with properties: css String – resulting CSS map Object – instance of SourceMapGenerator or null Options: sourceMap Type: Boolean Default: false Generate a source map when true. filename Type: String Default: '<unknown>' Filename of input CSS, uses for source map generation. debug Type: Boolean Default: false Output debug information to stderr. beforeCompress Type: function(ast, options) or Array<function(ast, options)> or null Default: null Called right after parse is run. afterCompress Type: function(compressResult, options) or Array<function(compressResult, options)> or null Default: null Called right after syntax.compress() is run. Other options are the same as for syntax.compress() function. minifyBlock(source[, options]) The same as minify() but for list of declarations. Usually it's a style attribute value. const result = csso.minifyBlock('color: rgba(255, 0, 0, 1); color: #ff0000'); console.log(result.css); // > color:red syntax.compress(ast[, options]) Does the main task – compress an AST. This is CSSO's extension in CSSTree syntax API. NOTE: syntax.compress() performs AST compression by transforming input AST by default (since AST cloning is expensive and needed in rare cases). Use clone option with truthy value in case you want to keep input AST untouched. Returns an object with properties: ast Object – resulting AST Options: restructure Type: Boolean Default: true Disable or enable a structure optimisations. forceMediaMerge Type: Boolean Default: false Enables merging of @media rules with the same media query by splitted by other rules. The optimisation is unsafe in general, but should work fine in most cases. Use it on your own risk. clone Type: Boolean Default: false Transform a copy of input AST if true. Useful in case of AST reuse. comments Type: String or Boolean Default: true Specify what comments to leave: 'exclamation' or true – leave all exclamation comments (i.e. /*! .. */) 'first-exclamation' – remove every comment except first one false – remove all comments usage Type: Object or null Default: null Usage data for advanced optimisations (see Usage data for details) logger Type: Function or null Default: null Function to track every step of transformation. Source maps To get a source map set true for sourceMap option. Additianaly filename option can be passed to specify source file. When sourceMap option is true, map field of result object will contain a SourceMapGenerator instance. This object can be mixed with another source map or translated to string. const csso = require('csso'); const css = fs.readFileSync('path/to/my.css', 'utf8'); const result = csso.minify(css, { filename: 'path/to/my.css', // will be added to source map as reference to source file sourceMap: true // generate source map }); console.log(result); // { css: '...minified...', map: SourceMapGenerator {} } console.log(result.map.toString()); // '{ .. source map content .. }' Example of generating source map with respect of source map from input CSS: import { SourceMapConsumer } from 'source-map'; import * as csso from 'csso'; const inputFile = 'path/to/my.css'; const input = fs.readFileSync(inputFile, 'utf8'); const inputMap = input.match(/\\/\\*# sourceMappingURL=(\\S+)\\s*\\*\\/\\s*$/); const output = csso.minify(input, { filename: inputFile, sourceMap: true }); // apply input source map to output if (inputMap) { output.map.applySourceMap( new SourceMapConsumer(inputMap[1]), inputFile ) } // result CSS with source map console.log( output.css + '/*# sourceMappingURL=data:application/json;base64,' + Buffer.from(output.map.toString()).toString('base64') + ' */' ); Usage data CSSO can use data about how CSS is used in a markup for better compression. File with this data (JSON) can be set using usage option. Usage data may contain following sections: blacklist – a set of black lists (see Black list filtering) tags – white list of tags ids – white list of ids classes – white list of classes scopes – groups of classes which never used with classes from other groups on the same element All sections are optional. Value of tags, ids and classes should be an array of a string, value of scopes should be an array of arrays of strings. Other values are ignoring. White list filtering tags, ids and classes are using on clean stage to filter selectors that contain something not in the lists. Selectors are filtering only by those kind of simple selector which white list is specified. For example, if only tags list is specified then type selectors are checking, and if all type selectors in selector present in list or selector has no any type selector it isn't filter. ids and classes are case sensitive, tags – is not. Input CSS: * { color: green; } ul, ol, li { color: blue; } UL.foo, span.bar { color: red; } Usage data: { \"tags\": [\"ul\", \"LI\"] } Resulting CSS: *{color:green}ul,li{color:blue}ul.foo{color:red} Filtering performs for nested selectors too. :not() pseudos content is ignoring since the result of matching is unpredictable. Example for the same usage data as above: :nth-child(2n of ul, ol) { color: red } :nth-child(3n + 1 of img) { color: yellow } :not(div, ol, ul) { color: green } :has(:matches(ul, ol), ul, ol) { color: blue } Turns into: :nth-child(2n of ul){color:red}:not(div,ol,ul){color:green}:has(:matches(ul),ul){color:blue} Black list filtering Black list filtering performs the same as white list filtering, but filters things that mentioned in the lists. blacklist can contain the lists tags, ids and classes. Black list has a higher priority, so when something mentioned in the white list and in the black list then white list occurrence is ignoring. The :not() pseudos content ignoring as well. * { color: green; } ul, ol, li { color: blue; } UL.foo, li.bar { color: red; } Usage data: { \"blacklist\": { \"tags\": [\"ul\"] }, \"tags\": [\"ul\", \"LI\"] } Resulting CSS: *{color:green}li{color:blue}li.bar{color:red} Scopes Scopes is designed for CSS scope isolation solutions such as css-modules. Scopes are similar to namespaces and define lists of class names that exclusively used on some markup. This information allows the optimizer to move rules more agressive. Since it assumes selectors from different scopes don't match for the same element. This can improve rule merging. Suppose we have a file: .module1-foo { color: red; } .module1-bar { font-size: 1.5em; background: yellow; } .module2-baz { color: red; } .module2-qux { font-size: 1.5em; background: yellow; width: 50px; } It can be assumed that first two rules are never used with the second two on the same markup. But we can't say that for sure without a markup review. The optimizer doesn't know it either and will perform safe transformations only. The result will be the same as input but with no spaces and some semicolons: .module1-foo{color:red}.module1-bar{font-size:1.5em;background:#ff0}.module2-baz{color:red}.module2-qux{font-size:1.5em;background:#ff0;width:50px} With usage data CSSO can produce better output. If follow usage data is provided: { \"scopes\": [ [\"module1-foo\", \"module1-bar\"], [\"module2-baz\", \"module2-qux\"] ] } The result will be (29 bytes extra saving): .module1-foo,.module2-baz{color:red}.module1-bar,.module2-qux{font-size:1.5em;background:#ff0}.module2-qux{width:50px} If class name isn't mentioned in the scopes it belongs to default scope. scopes data doesn't affect classes whitelist. If class name mentioned in scopes but missed in classes (both sections are specified) it will be filtered. Note that class name can't be set for several scopes. Also a selector can't have class names from different scopes. In both cases an exception will thrown. Currently the optimizer doesn't care about changing order safety for out-of-bounds selectors (i.e. selectors that match to elements without class name, e.g. .scope div or .scope ~ :last-child). It assumes that scoped CSS modules doesn't relay on it's order. It may be fix in future if to be an issue."
  },
  "node_modules/csso/node_modules/css-tree/README.html": {
    "href": "node_modules/csso/node_modules/css-tree/README.html",
    "title": "CSSTree | accouter",
    "keywords": "CSSTree CSSTree is a tool set for CSS: fast detailed parser (CSS → AST), walker (AST traversal), generator (AST → CSS) and lexer (validation and matching) based on specs and browser implementations. The main goal is to be efficient and W3C spec compliant, with focus on CSS analyzing and source-to-source transforming tasks. Features Detailed parsing with an adjustable level of detail By default CSSTree parses CSS as detailed as possible, i.e. each single logical part is representing with its own AST node (see AST format for all possible node types). The parsing detail level can be changed through parser options, for example, you can disable parsing of selectors or declaration values for component parts. Tolerant to errors by design Parser behaves as spec says: \"When errors occur in CSS, the parser attempts to recover gracefully, throwing away only the minimum amount of content before returning to parsing as normal\". The only thing the parser departs from the specification is that it doesn't throw away bad content, but wraps it in a special node type (Raw) that allows processing it later. Fast and efficient CSSTree is created with focus on performance and effective memory consumption. Therefore it's one of the fastest CSS parsers at the moment. Syntax validation The build-in lexer can test CSS against syntaxes defined by W3C. CSSTree uses mdn/data as a basis for lexer's dictionaries and extends it with vendor specific and legacy syntaxes. Lexer can only check the declaration values currently, but this feature will be extended to other parts of the CSS in the future. Projects using CSSTree Svelte – Cybernetically enhanced web apps SVGO – Node.js tool for optimizing SVG files CSSO – CSS minifier with structural optimizations NativeScript – NativeScript empowers you to access native APIs from JavaScript directly react-native-svg – SVG library for React Native, React Native Web, and plain React web projects penthouse – Critical Path CSS Generator Bit – Bit is the platform for collaborating on components and more... Documentation AST format Parsing CSS → AST parse(source[, options]) Serialization AST → CSS generate(ast[, options]) AST traversal walk(ast, options) find(ast, fn) findLast(ast, fn) findAll(ast, fn) Util functions Value encoding & decoding property(name) keyword(name) ident string url AST transforming clone(ast) fromPlainObject(object) toPlainObject(ast) Value Definition Syntax parse(source) walk(node, options, context) generate(node, options) AST format Tools AST Explorer – explore CSSTree AST format with zero setup CSS syntax reference CSS syntax validator Related projects csstree-validator – NPM package to validate CSS stylelint-csstree-validator – plugin for stylelint to validate CSS Grunt plugin Gulp plugin Sublime plugin VS Code plugin Atom plugin Usage Install with npm: npm install css-tree Basic usage: import * as csstree from 'css-tree'; // parse CSS to AST const ast = csstree.parse('.example { world: \"!\" }'); // traverse AST and modify it csstree.walk(ast, (node) => { if (node.type === 'ClassSelector' && node.name === 'example') { node.name = 'hello'; } }); // generate CSS from AST console.log(csstree.generate(ast)); // .hello{world:\"!\"} Syntax matching: // parse CSS to AST as a declaration value const ast = csstree.parse('red 1px solid', { context: 'value' }); // match to syntax of `border` property const matchResult = csstree.lexer.matchProperty('border', ast); // check first value node is a <color> console.log(matchResult.isType(ast.children.first, 'color')); // true // get a type list matched to a node console.log(matchResult.getTrace(ast.children.first)); // [ { type: 'Property', name: 'border' }, // { type: 'Type', name: 'color' }, // { type: 'Type', name: 'named-color' }, // { type: 'Keyword', name: 'red' } ] Exports Is it possible to import just a needed part of library like a parser or a walker. That's might useful for loading time or bundle size optimisations. import * as tokenizer from 'css-tree/tokenizer'; import * as parser from 'css-tree/parser'; import * as walker from 'css-tree/walker'; import * as lexer from 'css-tree/lexer'; import * as definitionSyntax from 'css-tree/definition-syntax'; import * as data from 'css-tree/definition-syntax-data'; import * as dataPatch from 'css-tree/definition-syntax-data-patch'; import * as utils from 'css-tree/utils'; Using in a browser Bundles are available for use in a browser: dist/csstree.js – minified IIFE with csstree as global <script src=\"node_modules/css-tree/dist/csstree.js\"></script> <script> csstree.parse('.example { color: green }'); </script> dist/csstree.esm.js – minified ES module <script type=\"module\"> import { parse } from 'node_modules/css-tree/dist/csstree.esm.js' parse('.example { color: green }'); </script> One of CDN services like unpkg or jsDelivr can be used. By default (for short path) a ESM version is exposing. For IIFE version a full path to a bundle should be specified: <!-- ESM --> <script type=\"module\"> import * as csstree from 'https://cdn.jsdelivr.net/npm/css-tree'; import * as csstree from 'https://unpkg.com/css-tree'; </script> <!-- IIFE with an export to global --> <script src=\"https://cdn.jsdelivr.net/npm/css-tree/dist/csstree.js\"></script> <script src=\"https://unpkg.com/css-tree/dist/csstree.js\"></script> Top level API License MIT"
  },
  "node_modules/csso/node_modules/mdn-data/CHANGELOG.html": {
    "href": "node_modules/csso/node_modules/mdn-data/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog 2.0.28 (2022-07-12) Bug Fixes css: correct two syntax examples in selectors (#589) (91ab33a) 2.0.27 (2022-02-24) Miscellaneous Chores release (a99ae2e) 2.0.26 (2022-01-19) Miscellaneous Chores release 2.0.26 (8b1045d) 2.0.25 (2021-12-21) Bug Fixes change branch reference to main (a473261) remove old clashing workflow (af9a18c) Miscellaneous Chores release 2.0.25 (db5a54b) release 2.0.25 (0f453ee) 2.0.24 (2021-12-17) Miscellaneous Chores release 2.0.24 (4d00c38) 2.0.24 (2021-12-15) Miscellaneous Chores release 2.0.24 (abff6ff)"
  },
  "node_modules/csso/node_modules/mdn-data/README.html": {
    "href": "node_modules/csso/node_modules/mdn-data/README.html",
    "title": "MDN data | accouter",
    "keywords": "MDN data https://github.com/mdn/data Maintained by the MDN team at Mozilla. This repository contains general data for Web technologies. This data is used in MDN documentation, to build information boxes or sidebar navigation. External tools have started to make use of this data as well. For example, the CSSTree CSS parser. Repository contents There's a top-level directory for each broad area covered: for example, api and css. Inside each of these directories is one or more JSON files containing the data. api Contains data about Web APIs: API inheritance (interface inheritance and mixin implementations) css Contains data about: CSS at-rules CSS properties CSS selectors CSS syntaxes CSS types CSS units Read more about CSS data and the format of the files. l10n The l10n folder contains localization strings that are used in the various json files throughout this repository. Problems? If you find a problem, please file an issue. Contributing We're very happy to accept contributions to this data. Please familiarize yourself with the schema for the data you're editing, and send us a pull request. See also the Contributing file for more information. See also https://github.com/mdn/browser-compat-data for compatibility data for Web technologies"
  },
  "node_modules/csso/node_modules/mdn-data/css/readme.html": {
    "href": "node_modules/csso/node_modules/mdn-data/css/readme.html",
    "title": "MDN CSS data | accouter",
    "keywords": "MDN CSS data This folder contains data about the different features of the CSS language. Different types of CSS data The CSS data is split into these parts: at-rules: data | schema | docs properties: data | schema | docs selectors: data | schema | docs syntaxes: data | schema | docs types: data | schema | docs units: data | schema | docs"
  },
  "node_modules/data-view-buffer/CHANGELOG.html": {
    "href": "node_modules/data-view-buffer/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.1 - 2024-02-06 Commits [Refactor] use es-errors, so things that only need those do not need get-intrinsic 675f588 [Deps] update call-bind, get-intrinsic e6eb209 v1.0.0 - 2024-02-02 Commits Initial implementation, tests, readme, types 2e1382b Initial commit 1eb7dc4 npm init d9e3d47 Only apps should have lockfiles 116b60b"
  },
  "node_modules/data-view-buffer/README.html": {
    "href": "node_modules/data-view-buffer/README.html",
    "title": "data-view-buffer | accouter",
    "keywords": "data-view-buffer Get the ArrayBuffer out of a DataView, robustly. This will work in node <= 0.10 and < 0.11.4, where there's no prototype accessor, only a nonconfigurable own property. It will also work in modern engines where DataView.prototype.buffer has been deleted after this module has loaded. Example const dataViewBuffer = require('data-view-buffer'); const assert = require('assert'); const ab = new ArrayBuffer(0); const dv = new DataView(ab); assert.equal(dataViewBuffer(dv), ab); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/data-view-byte-length/CHANGELOG.html": {
    "href": "node_modules/data-view-byte-length/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.1 - 2024-03-08 Commits [types] use shared tsconfig 0d5873c [Dev Deps] update @arethetypeswrong/cli, tape 13c1eaf [patch] fix function name a061e7b [Deps] update call-bind 6603851 v1.0.0 - 2024-03-04 Commits Initial implementation, tests, readme, types 79ad058 Initial commit 1a11313 npm init aac0108 Only apps should have lockfiles cdf1a15"
  },
  "node_modules/data-view-byte-length/README.html": {
    "href": "node_modules/data-view-byte-length/README.html",
    "title": "data-view-byte-length | accouter",
    "keywords": "data-view-byte-length Get the byteLength out of a DataView, robustly. This will work in node <= 0.10 and < 0.11.4, where there's no prototype accessor, only a nonconfigurable own property. It will also work in modern engines where DataView.prototype.byteLength has been deleted after this module has loaded. Example const dataViewByteLength = require('data-view-byte-length'); const assert = require('assert'); const ab = new ArrayBuffer(42); const dv = new DataView(ab); assert.equal(dataViewByteLength(dv), 42); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/data-view-byte-offset/CHANGELOG.html": {
    "href": "node_modules/data-view-byte-offset/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.0 - 2024-03-04 Commits Initial implementation, tests, readme, types 8b94518 Initial commit aee2acc npm init 10a21a4 Only apps should have lockfiles f6cfa3e"
  },
  "node_modules/data-view-byte-offset/README.html": {
    "href": "node_modules/data-view-byte-offset/README.html",
    "title": "data-view-byte-offset | accouter",
    "keywords": "data-view-byte-offset Get the byteOffset out of a DataView, robustly. This will work in node <= 0.10 and < 0.11.4, where there's no prototype accessor, only a nonconfigurable own property. It will also work in modern engines where DataView.prototype.byteOffset has been deleted after this module has loaded. Example const dataViewByteOffset = require('data-view-byte-offset'); const assert = require('assert'); const ab = new ArrayBuffer(42); const dv = new DataView(ab, 2); assert.equal(dataViewByteOffset(dv), 2); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/debug/CHANGELOG.html": {
    "href": "node_modules/debug/CHANGELOG.html",
    "title": "2.6.9 / 2017-09-22 | accouter",
    "keywords": "2.6.9 / 2017-09-22 remove ReDoS regexp in %o formatter (#504) 2.6.8 / 2017-05-18 Fix: Check for undefined on browser globals (#462, @marbemac) 2.6.7 / 2017-05-16 Fix: Update ms to 2.0.0 to fix regular expression denial of service vulnerability (#458, @hubdotcom) Fix: Inline extend function in node implementation (#452, @dougwilson) Docs: Fix typo (#455, @msasad) 2.6.5 / 2017-04-27 Fix: null reference check on window.documentElement.style.WebkitAppearance (#447, @thebigredgeek) Misc: clean up browser reference checks (#447, @thebigredgeek) Misc: add npm-debug.log to .gitignore (@thebigredgeek) 2.6.4 / 2017-04-20 Fix: bug that would occure if process.env.DEBUG is a non-string value. (#444, @LucianBuzzo) Chore: ignore bower.json in npm installations. (#437, @joaovieira) Misc: update \"ms\" to v0.7.3 (@tootallnate) 2.6.3 / 2017-03-13 Fix: Electron reference to process.env.DEBUG (#431, @paulcbetts) Docs: Changelog fix (@thebigredgeek) 2.6.2 / 2017-03-10 Fix: DEBUG_MAX_ARRAY_LENGTH (#420, @slavaGanzin) Docs: Add backers and sponsors from Open Collective (#422, @piamancini) Docs: Add Slackin invite badge (@tootallnate) 2.6.1 / 2017-02-10 Fix: Module's export default syntax fix for IE8 Expected identifier error Fix: Whitelist DEBUG_FD for values 1 and 2 only (#415, @pi0) Fix: IE8 \"Expected identifier\" error (#414, @vgoma) Fix: Namespaces would not disable once enabled (#409, @musikov) 2.6.0 / 2016-12-28 Fix: added better null pointer checks for browser useColors (@thebigredgeek) Improvement: removed explicit window.debug export (#404, @tootallnate) Improvement: deprecated DEBUG_FD environment variable (#405, @tootallnate) 2.5.2 / 2016-12-25 Fix: reference error on window within webworkers (#393, @KlausTrainer) Docs: fixed README typo (#391, @lurch) Docs: added notice about v3 api discussion (@thebigredgeek) 2.5.1 / 2016-12-20 Fix: babel-core compatibility 2.5.0 / 2016-12-20 Fix: wrong reference in bower file (@thebigredgeek) Fix: webworker compatibility (@thebigredgeek) Fix: output formatting issue (#388, @kribblo) Fix: babel-loader compatibility (#383, @escwald) Misc: removed built asset from repo and publications (@thebigredgeek) Misc: moved source files to /src (#378, @yamikuronue) Test: added karma integration and replaced babel with browserify for browser tests (#378, @yamikuronue) Test: coveralls integration (#378, @yamikuronue) Docs: simplified language in the opening paragraph (#373, @yamikuronue) 2.4.5 / 2016-12-17 Fix: navigator undefined in Rhino (#376, @jochenberger) Fix: custom log function (#379, @hsiliev) Improvement: bit of cleanup + linting fixes (@thebigredgeek) Improvement: rm non-maintainted dist/ dir (#375, @freewil) Docs: simplified language in the opening paragraph. (#373, @yamikuronue) 2.4.4 / 2016-12-14 Fix: work around debug being loaded in preload scripts for electron (#368, @paulcbetts) 2.4.3 / 2016-12-14 Fix: navigation.userAgent error for react native (#364, @escwald) 2.4.2 / 2016-12-14 Fix: browser colors (#367, @tootallnate) Misc: travis ci integration (@thebigredgeek) Misc: added linting and testing boilerplate with sanity check (@thebigredgeek) 2.4.1 / 2016-12-13 Fix: typo that broke the package (#356) 2.4.0 / 2016-12-13 Fix: bower.json references unbuilt src entry point (#342, @justmatt) Fix: revert \"handle regex special characters\" (@tootallnate) Feature: configurable util.inspect()`options for NodeJS (#327, @tootallnate) Feature: %O`(big O) pretty-prints objects (#322, @tootallnate) Improvement: allow colors in workers (#335, @botverse) Improvement: use same color for same namespace. (#338, @lchenay) 2.3.3 / 2016-11-09 Fix: Catch JSON.stringify() errors (#195, Jovan Alleyne) Fix: Returning localStorage saved values (#331, Levi Thomason) Improvement: Don't create an empty object when no process (Nathan Rajlich) 2.3.2 / 2016-11-09 Fix: be super-safe in index.js as well (@TooTallNate) Fix: should check whether process exists (Tom Newby) 2.3.1 / 2016-11-09 Fix: Added electron compatibility (#324, @paulcbetts) Improvement: Added performance optimizations (@tootallnate) Readme: Corrected PowerShell environment variable example (#252, @gimre) Misc: Removed yarn lock file from source control (#321, @fengmk2) 2.3.0 / 2016-11-07 Fix: Consistent placement of ms diff at end of output (#215, @gorangajic) Fix: Escaping of regex special characters in namespace strings (#250, @zacronos) Fix: Fixed bug causing crash on react-native (#282, @vkarpov15) Feature: Enabled ES6+ compatible import via default export (#212 @bucaran) Feature: Added %O formatter to reflect Chrome's console.log capability (#279, @oncletom) Package: Update \"ms\" to 0.7.2 (#315, @DevSide) Package: removed superfluous version property from bower.json (#207 @kkirsche) Readme: fix USE_COLORS to DEBUG_COLORS Readme: Doc fixes for format string sugar (#269, @mlucool) Readme: Updated docs for DEBUG_FD and DEBUG_COLORS environment variables (#232, @mattlyons0) Readme: doc fixes for PowerShell (#271 #243, @exoticknight @unreadable) Readme: better docs for browser support (#224, @matthewmueller) Tooling: Added yarn integration for development (#317, @thebigredgeek) Misc: Renamed History.md to CHANGELOG.md (@thebigredgeek) Misc: Added license file (#226 #274, @CantemoInternal @sdaitzman) Misc: Updated contributors (@thebigredgeek) 2.2.0 / 2015-05-09 package: update \"ms\" to v0.7.1 (#202, @dougwilson) README: add logging to file example (#193, @DanielOchoa) README: fixed a typo (#191, @amir-s) browser: expose storage (#190, @stephenmathieson) Makefile: add a distclean target (#189, @stephenmathieson) 2.1.3 / 2015-03-13 Updated stdout/stderr example (#186) Updated example/stdout.js to match debug current behaviour Renamed example/stderr.js to stdout.js Update Readme.md (#184) replace high intensity foreground color for bold (#182, #183) 2.1.2 / 2015-03-01 dist: recompile update \"ms\" to v0.7.0 package: update \"browserify\" to v9.0.3 component: fix \"ms.js\" repo location changed bower package name updated documentation about using debug in a browser fix: security error on safari (#167, #168, @yields) 2.1.1 / 2014-12-29 browser: use typeof to check for console existence browser: check for console.log truthiness (fix IE 8/9) browser: add support for Chrome apps Readme: added Windows usage remarks Add bower.json to properly support bower install 2.1.0 / 2014-10-15 node: implement DEBUG_FD env variable support package: update \"browserify\" to v6.1.0 package: add \"license\" field to package.json (#135, @panuhorsmalahti) 2.0.0 / 2014-09-01 package: update \"browserify\" to v5.11.0 node: use stderr rather than stdout for logging (#29, @stephenmathieson) 1.0.4 / 2014-07-15 dist: recompile example: remove console.info() log usage example: add \"Content-Type\" UTF-8 header to browser example browser: place %c marker after the space character browser: reset the \"content\" color via color: inherit browser: add colors support for Firefox >= v31 debug: prefer an instance log() function over the global one (#119) Readme: update documentation about styled console logs for FF v31 (#116, @wryk) 1.0.3 / 2014-07-09 Add support for multiple wildcards in namespaces (#122, @seegno) browser: fix lint 1.0.2 / 2014-06-10 browser: update color palette (#113, @gscottolson) common: make console logging function configurable (#108, @timoxley) node: fix %o colors on old node <= 0.8.x Makefile: find node path using shell/which (#109, @timoxley) 1.0.1 / 2014-06-06 browser: use removeItem() to clear localStorage browser, node: don't set DEBUG if namespaces is undefined (#107, @leedm777) package: add \"contributors\" section node: fix comment typo README: list authors 1.0.0 / 2014-06-04 make ms diff be global, not be scope debug: ignore empty strings in enable() node: make DEBUG_COLORS able to disable coloring *: export the colors array npmignore: don't publish the dist dir Makefile: refactor to use browserify package: add \"browserify\" as a dev dependency Readme: add Web Inspector Colors section node: reset terminal color for the debug content node: map \"%o\" to util.inspect() browser: map \"%j\" to JSON.stringify() debug: add custom \"formatters\" debug: use \"ms\" module for humanizing the diff Readme: add \"bash\" syntax highlighting browser: add Firebug color support browser: add colors for WebKit browsers node: apply log to console rewrite: abstract common logic for Node & browsers add .jshintrc file 0.8.1 / 2014-04-14 package: re-add the \"component\" section 0.8.0 / 2014-03-30 add enable() method for nodejs. Closes #27 change from stderr to stdout remove unnecessary index.js file 0.7.4 / 2013-11-13 remove \"browserify\" key from package.json (fixes something in browserify) 0.7.3 / 2013-10-30 fix: catch localStorage security error when cookies are blocked (Chrome) add debug(err) support. Closes #46 add .browser prop to package.json. Closes #42 0.7.2 / 2013-02-06 fix package.json fix: Mobile Safari (private mode) is broken with debug fix: Use unicode to send escape character to shell instead of octal to work with strict mode javascript 0.7.1 / 2013-02-05 add repository URL to package.json add DEBUG_COLORED to force colored output add browserify support fix component. Closes #24 0.7.0 / 2012-05-04 Added .component to package.json Added debug.component.js build 0.6.0 / 2012-03-16 Added support for \"-\" prefix in DEBUG [Vinay Pulim] Added .enabled flag to the node version [TooTallNate] 0.5.0 / 2012-02-02 Added: humanize diffs. Closes #8 Added debug.disable() to the CS variant Removed padding. Closes #10 Fixed: persist client-side variant again. Closes #9 0.4.0 / 2012-02-01 Added browser variant support for older browsers [TooTallNate] Added debug.enable('project:*') to browser variant [TooTallNate] Added padding to diff (moved it to the right) 0.3.0 / 2012-01-26 Added millisecond diff when isatty, otherwise UTC string 0.2.0 / 2012-01-22 Added wildcard support 0.1.0 / 2011-12-02 Added: remove colors unless stderr isatty [TooTallNate] 0.0.1 / 2010-01-03 Initial release"
  },
  "node_modules/debug/README.html": {
    "href": "node_modules/debug/README.html",
    "title": "debug | accouter",
    "keywords": "debug A tiny node.js debugging utility modelled after node core's debugging technique. Discussion around the V3 API is under way here Installation $ npm install debug Usage debug exposes a function; simply pass this function the name of your module, and it will return a decorated version of console.error for you to pass debug statements to. This will allow you to toggle the debug output for different parts of your module as well as the module as a whole. Example app.js: var debug = require('debug')('http') , http = require('http') , name = 'My App'; // fake app debug('booting %s', name); http.createServer(function(req, res){ debug(req.method + ' ' + req.url); res.end('hello\\n'); }).listen(3000, function(){ debug('listening'); }); // fake worker of some kind require('./worker'); Example worker.js: var debug = require('debug')('worker'); setInterval(function(){ debug('doing some work'); }, 1000); The DEBUG environment variable is then used to enable these based on space or comma-delimited names. Here are some examples: Windows note On Windows the environment variable is set using the set command. set DEBUG=*,-not_this Note that PowerShell uses different syntax to set environment variables. $env:DEBUG = \"*,-not_this\" Then, run the program to be debugged as usual. Millisecond diff When actively developing an application it can be useful to see when the time spent between one debug() call and the next. Suppose for example you invoke debug() before requesting a resource, and after as well, the \"+NNNms\" will show you how much time was spent between calls. When stdout is not a TTY, Date#toUTCString() is used, making it more useful for logging the debug information as shown below: Conventions If you're using this in one or more of your libraries, you should use the name of your library so that developers may toggle debugging as desired without guessing names. If you have more than one debuggers you should prefix them with your library name and use \":\" to separate features. For example \"bodyParser\" from Connect would then be \"connect:bodyParser\". Wildcards The * character may be used as a wildcard. Suppose for example your library has debuggers named \"connect:bodyParser\", \"connect:compress\", \"connect:session\", instead of listing all three with DEBUG=connect:bodyParser,connect:compress,connect:session, you may simply do DEBUG=connect:*, or to run everything using this module simply use DEBUG=*. You can also exclude specific debuggers by prefixing them with a \"-\" character. For example, DEBUG=*,-connect:* would include all debuggers except those starting with \"connect:\". Environment Variables When running through Node.js, you can set a few environment variables that will change the behavior of the debug logging: Name Purpose DEBUG Enables/disables specific debugging namespaces. DEBUG_COLORS Whether or not to use colors in the debug output. DEBUG_DEPTH Object inspection depth. DEBUG_SHOW_HIDDEN Shows hidden properties on inspected objects. Note: The environment variables beginning with DEBUG_ end up being converted into an Options object that gets used with %o/%O formatters. See the Node.js documentation for util.inspect() for the complete list. Formatters Debug uses printf-style formatting. Below are the officially supported formatters: Formatter Representation %O Pretty-print an Object on multiple lines. %o Pretty-print an Object all on a single line. %s String. %d Number (both integer and float). %j JSON. Replaced with the string '[Circular]' if the argument contains circular references. %% Single percent sign ('%'). This does not consume an argument. Custom formatters You can add custom formatters by extending the debug.formatters object. For example, if you wanted to add support for rendering a Buffer as hex with %h, you could do something like: const createDebug = require('debug') createDebug.formatters.h = (v) => { return v.toString('hex') } // …elsewhere const debug = createDebug('foo') debug('this is hex: %h', new Buffer('hello world')) // foo this is hex: 68656c6c6f20776f726c6421 +0ms Browser support You can build a browser-ready script using browserify, or just use the browserify-as-a-service build, if you don't want to build it yourself. Debug's enable state is currently persisted by localStorage. Consider the situation shown below where you have worker:a and worker:b, and wish to debug both. You can enable this using localStorage.debug: localStorage.debug = 'worker:*' And then refresh the page. a = debug('worker:a'); b = debug('worker:b'); setInterval(function(){ a('doing some work'); }, 1000); setInterval(function(){ b('doing some work'); }, 1200); Web Inspector Colors Colors are also enabled on \"Web Inspectors\" that understand the %c formatting option. These are WebKit web inspectors, Firefox (since version 31) and the Firebug plugin for Firefox (any version). Colored output looks something like: Output streams By default debug will log to stderr, however this can be configured per-namespace by overriding the log method: Example stdout.js: var debug = require('debug'); var error = debug('app:error'); // by default stderr is used error('goes to stderr!'); var log = debug('app:log'); // set this namespace to log via console.log log.log = console.log.bind(console); // don't forget to bind to console! log('goes to stdout'); error('still goes to stderr!'); // set all output to go via console.info // overrides all per-namespace log settings debug.log = console.info.bind(console); error('now goes to stdout via console.info'); log('still goes to stdout, but via console.info now'); Authors TJ Holowaychuk Nathan Rajlich Andrew Rhyne Backers Support us with a monthly donation and help us continue our activities. [Become a backer] Sponsors Become a sponsor and get your logo on our README on Github with a link to your site. [Become a sponsor] License (The MIT License) Copyright (c) 2014-2016 TJ Holowaychuk <tj@vision-media.ca&gt; Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/decamelize/readme.html": {
    "href": "node_modules/decamelize/readme.html",
    "title": "decamelize | accouter",
    "keywords": "decamelize Convert a camelized string into a lowercased one with a custom separator Example: unicornRainbow → unicorn_rainbow Install $ npm install decamelize Usage const decamelize = require('decamelize'); decamelize('unicornRainbow'); //=> 'unicorn_rainbow' decamelize('unicornRainbow', '-'); //=> 'unicorn-rainbow' API decamelize(input, separator?) input Type: string separator Type: string Default: '_' Related See camelcase for the inverse. Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "node_modules/define-data-property/CHANGELOG.html": {
    "href": "node_modules/define-data-property/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.1.4 - 2024-02-13 Commits [Refactor] use es-define-property 90f2f4c [Dev Deps] update @types/object.getownpropertydescriptors cd929d9 v1.1.3 - 2024-02-12 Commits [types] hand-write d.ts instead of emitting it 0cbc988 [meta] simplify exports 690781e [Dev Deps] update hasown; clean up DT packages 6cdfd1c [actions] cleanup 3142bc6 [meta] add funding 8474423 [Deps] update get-intrinsic 3e9be00 v1.1.2 - 2024-02-05 Commits [Dev Deps] update @types packages, object-inspect, tape, typescript df41bf8 [Dev Deps] update DT packages, aud, npmignore, tape, typescript [fab0e4e`](https://github.com/ljharb/define-data-property/commit/fab0e4ec709ee02b79f42d6db3ee5f26e0a34b8a) [Dev Deps] use hasown instead of has aa51ef9 [Refactor] use es-errors, so things that only need those do not need get-intrinsic d89be50 [Deps] update has-property-descriptors 7af887c [Deps] update get-intrinsic bb8728e v1.1.1 - 2023-10-12 Commits [Tests] fix tests in ES3 engines 5c6920e [Dev Deps] update @types/es-value-fixtures, @types/for-each, @types/gopd, @types/has-property-descriptors, tape, typescript 7d82dfc [Fix] IE 8 has a broken Object.defineProperty 0672e1a [meta] emit types on prepack 73acb1f [Dev Deps] update tape, typescript 9489a77 v1.1.0 - 2023-09-13 Commits [New] add loose arg 155235a [New] allow null to be passed for the non* args 7d2fa5f v1.0.1 - 2023-09-12 Commits [meta] add TS types 43d763c [Dev Deps] update @types/tape, typescript f444985 [meta] add safe-publish-latest, 172bb10 v1.0.0 - 2023-09-12 Commits Initial implementation, tests, readme 5b43d6b Initial commit 35e577a npm init 82a0a04 Only apps should have lockfiles 96df244 [meta] use npmignore to autogenerate an npmignore file a87ff18"
  },
  "node_modules/define-data-property/README.html": {
    "href": "node_modules/define-data-property/README.html",
    "title": "define-data-property | accouter",
    "keywords": "define-data-property Define a data property on an object. Will fall back to assignment in an engine without descriptors. The three non* argument can also be passed null, which will use the existing state if available. The loose argument will mean that if you attempt to set a non-normal data property, in an environment without descriptor support, it will fall back to normal assignment. Usage var defineDataProperty = require('define-data-property'); var assert = require('assert'); var obj = {}; defineDataProperty(obj, 'key', 'value'); defineDataProperty( obj, 'key2', 'value', true, // nonEnumerable, optional false, // nonWritable, optional true, // nonConfigurable, optional false // loose, optional ); assert.deepEqual( Object.getOwnPropertyDescriptors(obj), { key: { configurable: true, enumerable: true, value: 'value', writable: true, }, key2: { configurable: false, enumerable: false, value: 'value', writable: true, }, } );"
  },
  "node_modules/define-properties/CHANGELOG.html": {
    "href": "node_modules/define-properties/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.2.1 - 2023-09-12 Commits [Refactor] use define-data-property e7782a7 [actions] use reusable rebase action cd249c3 [Dev Deps] update @ljharb/eslint-config, aud, tape 8205f97 v1.2.0 - 2023-02-10 Commits [New] if the predicate is boolean true, it compares the existing value with === as the predicate d8dd6fc [meta] add auto-changelog 7ebe2b0 [meta] use npmignore to autogenerate an npmignore file 647478a [Dev Deps] update @ljharb/eslint-config, aud, tape e620d70 [Dev Deps] update aud, tape f1e5072 [actions] update checkout action 628b3af 1.1.4 / 2022-04-14 [Refactor] use has-property-descriptors [readme] add github actions/codecov badges [Docs] fix header parsing; remove testling [Deps] update object-keys [meta] use prepublishOnly script for npm 7+ [meta] add funding field; create FUNDING.yml [actions] add \"Allow Edits\" workflow; automatic rebasing / merge commit blocking [actions] reuse common workflows [actions] update codecov uploader [actions] use node/install instead of node/run; use codecov action [Tests] migrate tests to Github Actions [Tests] run nyc on all tests; use tape runner [Tests] use shared travis-ci config [Tests] use npx aud instead of nsp or npm audit with hoops [Tests] remove jscs [Dev Deps] update eslint, @ljharb/eslint-config, safe-publish-latest, tape; add aud, safe-publish-latest 1.1.3 / 2018-08-14 [Refactor] use a for loop instead of foreach to make for smaller bundle sizes [Robustness] cache Array.prototype.concat and Object.defineProperty [Deps] update object-keys [Dev Deps] update eslint, @ljharb/eslint-config, nsp, tape, jscs; remove unused eccheck script + dep [Tests] use pretest/posttest for linting/security [Tests] fix npm upgrades on older nodes 1.1.2 / 2015-10-14 [Docs] Switch from vb.teelaun.ch to versionbadg.es for the npm version badge SVG [Deps] Update object-keys [Dev Deps] update jscs, tape, eslint, @ljharb/eslint-config, nsp [Tests] up to io.js v3.3, node v4.2 1.1.1 / 2015-07-21 [Deps] Update object-keys [Dev Deps] Update tape, eslint [Tests] Test on io.js v2.4 1.1.0 / 2015-07-01 [New] Add support for symbol-valued properties. [Dev Deps] Update nsp, eslint [Tests] Test up to io.js v2.3 1.0.3 / 2015-05-30 Using a more reliable check for supported property descriptors. 1.0.2 / 2015-05-23 Test up to io.js v2.0 Update tape, jscs, nsp, eslint, object-keys, editorconfig-tools, covert 1.0.1 / 2015-01-06 Update object-keys to fix ES3 support 1.0.0 / 2015-01-04 v1.0.0"
  },
  "node_modules/define-properties/README.html": {
    "href": "node_modules/define-properties/README.html",
    "title": "define-properties | accouter",
    "keywords": "define-properties Define multiple non-enumerable properties at once. Uses Object.defineProperty when available; falls back to standard assignment in older engines. Existing properties are not overridden. Accepts a map of property names to a predicate that, when true, force-overrides. Example var define = require('define-properties'); var assert = require('assert'); var obj = define({ a: 1, b: 2 }, { a: 10, b: 20, c: 30 }); assert(obj.a === 1); assert(obj.b === 2); assert(obj.c === 30); if (define.supportsDescriptors) { assert.deepEqual(Object.keys(obj), ['a', 'b']); assert.deepEqual(Object.getOwnPropertyDescriptor(obj, 'c'), { configurable: true, enumerable: false, value: 30, writable: false }); } Then, with predicates: var define = require('define-properties'); var assert = require('assert'); var obj = define({ a: 1, b: 2, c: 3 }, { a: 10, b: 20, c: 30 }, { a: function () { return false; }, b: function () { return true; } }); assert(obj.a === 1); assert(obj.b === 20); assert(obj.c === 3); if (define.supportsDescriptors) { assert.deepEqual(Object.keys(obj), ['a', 'c']); assert.deepEqual(Object.getOwnPropertyDescriptor(obj, 'b'), { configurable: true, enumerable: false, value: 20, writable: false }); } Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/depd/History.html": {
    "href": "node_modules/depd/History.html",
    "title": "2.0.0 / 2018-10-26 | accouter",
    "keywords": "2.0.0 / 2018-10-26 Drop support for Node.js 0.6 Replace internal eval usage with Function constructor Use instance methods on process to check for listeners 1.1.2 / 2018-01-11 perf: remove argument reassignment Support Node.js 0.6 to 9.x 1.1.1 / 2017-07-27 Remove unnecessary Buffer loading Support Node.js 0.6 to 8.x 1.1.0 / 2015-09-14 Enable strict mode in more places Support io.js 3.x Support io.js 2.x Support web browser loading Requires bundler like Browserify or webpack 1.0.1 / 2015-04-07 Fix TypeErrors when under 'use strict' code Fix useless type name on auto-generated messages Support io.js 1.x Support Node.js 0.12 1.0.0 / 2014-09-17 No changes 0.4.5 / 2014-09-09 Improve call speed to functions using the function wrapper Support Node.js 0.6 0.4.4 / 2014-07-27 Work-around v8 generating empty stack traces 0.4.3 / 2014-07-26 Fix exception when global Error.stackTraceLimit is too low 0.4.2 / 2014-07-19 Correct call site for wrapped functions and properties 0.4.1 / 2014-07-19 Improve automatic message generation for function properties 0.4.0 / 2014-07-19 Add TRACE_DEPRECATION environment variable Remove non-standard grey color from color output Support --no-deprecation argument Support --trace-deprecation argument Support deprecate.property(fn, prop, message) 0.3.0 / 2014-06-16 Add NO_DEPRECATION environment variable 0.2.0 / 2014-06-15 Add deprecate.property(obj, prop, message) Remove supports-color dependency for node.js 0.8 0.1.0 / 2014-06-15 Add deprecate.function(fn, message) Add process.on('deprecation', fn) emitter Automatically generate message when omitted from deprecate() 0.0.1 / 2014-06-15 Fix warning for dynamic calls at singe call site 0.0.0 / 2014-06-15 Initial implementation"
  },
  "node_modules/depd/Readme.html": {
    "href": "node_modules/depd/Readme.html",
    "title": "depd | accouter",
    "keywords": "depd Deprecate all the things With great modules comes great responsibility; mark things deprecated! Install This module is installed directly using npm: $ npm install depd This module can also be bundled with systems like Browserify or webpack, though by default this module will alter it's API to no longer display or track deprecations. API var deprecate = require('depd')('my-module') This library allows you to display deprecation messages to your users. This library goes above and beyond with deprecation warnings by introspection of the call stack (but only the bits that it is interested in). Instead of just warning on the first invocation of a deprecated function and never again, this module will warn on the first invocation of a deprecated function per unique call site, making it ideal to alert users of all deprecated uses across the code base, rather than just whatever happens to execute first. The deprecation warnings from this module also include the file and line information for the call into the module that the deprecated function was in. NOTE this library has a similar interface to the debug module, and this module uses the calling file to get the boundary for the call stacks, so you should always create a new deprecate object in each file and not within some central file. depd(namespace) Create a new deprecate function that uses the given namespace name in the messages and will display the call site prior to the stack entering the file this function was called from. It is highly suggested you use the name of your module as the namespace. deprecate(message) Call this function from deprecated code to display a deprecation message. This message will appear once per unique caller site. Caller site is the first call site in the stack in a different file from the caller of this function. If the message is omitted, a message is generated for you based on the site of the deprecate() call and will display the name of the function called, similar to the name displayed in a stack trace. deprecate.function(fn, message) Call this function to wrap a given function in a deprecation message on any call to the function. An optional message can be supplied to provide a custom message. deprecate.property(obj, prop, message) Call this function to wrap a given property on object in a deprecation message on any accessing or setting of the property. An optional message can be supplied to provide a custom message. The method must be called on the object where the property belongs (not inherited from the prototype). If the property is a data descriptor, it will be converted to an accessor descriptor in order to display the deprecation message. process.on('deprecation', fn) This module will allow easy capturing of deprecation errors by emitting the errors as the type \"deprecation\" on the global process. If there are no listeners for this type, the errors are written to STDERR as normal, but if there are any listeners, nothing will be written to STDERR and instead only emitted. From there, you can write the errors in a different format or to a logging source. The error represents the deprecation and is emitted only once with the same rules as writing to STDERR. The error has the following properties: message - This is the message given by the library name - This is always 'DeprecationError' namespace - This is the namespace the deprecation came from stack - This is the stack of the call to the deprecated thing Example error.stack output: DeprecationError: my-cool-module deprecated oldfunction at Object.<anonymous> ([eval]-wrapper:6:22) at Module._compile (module.js:456:26) at evalScript (node.js:532:25) at startup (node.js:80:7) at node.js:902:3 process.env.NO_DEPRECATION As a user of modules that are deprecated, the environment variable NO_DEPRECATION is provided as a quick solution to silencing deprecation warnings from being output. The format of this is similar to that of DEBUG: $ NO_DEPRECATION=my-module,othermod node app.js This will suppress deprecations from being output for \"my-module\" and \"othermod\". The value is a list of comma-separated namespaces. To suppress every warning across all namespaces, use the value * for a namespace. Providing the argument --no-deprecation to the node executable will suppress all deprecations (only available in Node.js 0.8 or higher). NOTE This will not suppress the deperecations given to any \"deprecation\" event listeners, just the output to STDERR. process.env.TRACE_DEPRECATION As a user of modules that are deprecated, the environment variable TRACE_DEPRECATION is provided as a solution to getting more detailed location information in deprecation warnings by including the entire stack trace. The format of this is the same as NO_DEPRECATION: $ TRACE_DEPRECATION=my-module,othermod node app.js This will include stack traces for deprecations being output for \"my-module\" and \"othermod\". The value is a list of comma-separated namespaces. To trace every warning across all namespaces, use the value * for a namespace. Providing the argument --trace-deprecation to the node executable will trace all deprecations (only available in Node.js 0.8 or higher). NOTE This will not trace the deperecations silenced by NO_DEPRECATION. Display When a user calls a function in your library that you mark deprecated, they will see the following written to STDERR (in the given colors, similar colors and layout to the debug module): bright cyan bright yellow | | reset cyan | | | | ▼ ▼ ▼ ▼ my-cool-module deprecated oldfunction [eval]-wrapper:6:22 ▲ ▲ ▲ ▲ | | | | namespace | | location of mycoolmod.oldfunction() call | deprecation message the word \"deprecated\" If the user redirects their STDERR to a file or somewhere that does not support colors, they see (similar layout to the debug module): Sun, 15 Jun 2014 05:21:37 GMT my-cool-module deprecated oldfunction at [eval]-wrapper:6:22 ▲ ▲ ▲ ▲ ▲ | | | | | timestamp of message namespace | | location of mycoolmod.oldfunction() call | deprecation message the word \"deprecated\" Examples Deprecating all calls to a function This will display a deprecated message about \"oldfunction\" being deprecated from \"my-module\" on STDERR. var deprecate = require('depd')('my-cool-module') // message automatically derived from function name // Object.oldfunction exports.oldfunction = deprecate.function(function oldfunction () { // all calls to function are deprecated }) // specific message exports.oldfunction = deprecate.function(function () { // all calls to function are deprecated }, 'oldfunction') Conditionally deprecating a function call This will display a deprecated message about \"weirdfunction\" being deprecated from \"my-module\" on STDERR when called with less than 2 arguments. var deprecate = require('depd')('my-cool-module') exports.weirdfunction = function () { if (arguments.length < 2) { // calls with 0 or 1 args are deprecated deprecate('weirdfunction args < 2') } } When calling deprecate as a function, the warning is counted per call site within your own module, so you can display different deprecations depending on different situations and the users will still get all the warnings: var deprecate = require('depd')('my-cool-module') exports.weirdfunction = function () { if (arguments.length < 2) { // calls with 0 or 1 args are deprecated deprecate('weirdfunction args < 2') } else if (typeof arguments[0] !== 'string') { // calls with non-string first argument are deprecated deprecate('weirdfunction non-string first arg') } } Deprecating property access This will display a deprecated message about \"oldprop\" being deprecated from \"my-module\" on STDERR when accessed. A deprecation will be displayed when setting the value and when getting the value. var deprecate = require('depd')('my-cool-module') exports.oldprop = 'something' // message automatically derives from property name deprecate.property(exports, 'oldprop') // explicit message deprecate.property(exports, 'oldprop', 'oldprop >= 0.10') License MIT"
  },
  "node_modules/dependency-graph/CHANGELOG.html": {
    "href": "node_modules/dependency-graph/CHANGELOG.html",
    "title": "Dependency Graph Changelog | accouter",
    "keywords": "Dependency Graph Changelog 0.11.0 (March 5, 2021) Add entryNodes method that returns the nodes that nothing depends on - thanks amcdnl! 0.10.0 (January 9, 2021) Add directDependenciesOf and directDependantsOf methods for retrieving direct dependency information. (Fixes #40) Add aliases dependentsOf and directDependentsOf. 0.9.0 (February 10, 2020) Rewrite the topological sort DFS to be more efficient (and work!) on large graphs. No longer uses recursion to avoid stack overflows with large/deep graphs No longer is accidentally O(N^2) (thanks willtennien for pointing this out!) 0.8.1 (December 3, 2019) Ensure all nodes are included in overallOrder when cycles are allowed. (Fixes #33) 0.8.0 (December 11, 2018) Add a DepGraphCycleError with cyclePath property - thanks jhugman! 0.7.2 (August 30, 2018) Make constructor parameter optional in Typescript definition. (Fixes #26) 0.7.1 (June 5, 2018) Fix Typescript definition to include the new constructor arguments added in 0.7.0 - thanks tbranyen! 0.7.0 (January 17, 2018) Allow circular dependencies by passing in {circular: true} into the constructor - thanks tbranyen! 0.6.0 (October 22, 2017) Add a size method that will return the number of nodes in the graph. Add a clone method that will clone the graph. Any custom node data will only be shallow-copied. (Fixes #14) 0.5.2 (October 22, 2017) Add missing parameter in TypeScript definition. (Fixes #19) 0.5.1 (October 7, 2017) Now exposes Typescript type definition - thanks vangorra! 0.5.0 (April 26, 2016) Add optional data parameter for the addNode method. (Fixes #12) Add methods getNodeData and setNodeData to manipulate the data associated with a node name. (Fixes #12) Change the hasNode method to be able to cope with falsy node data. (Fixes #12) 0.4.1 (Sept 3, 2015) Check all nodes for potential cycles when calculating overall order. (Fixes #8) 0.4.0 (Aug 1, 2015) Better error messages When a cycle is detected, the error message will now include the cycle in it. E.g Dependency Cycle Found: a -> b -> c -> a (Fixes #7) When calling addDependency if one of the nodes does not exist, the error will say which one it was (instead of saying that \"one\" of the two nodes did not exist and making you manually determine which one) Calling overallOrder on an empty graph will no longer throw an error about a dependency cycle. It will return an empty array. 0.3.0 (July 24, 2015) Fix issue where if you call addNode twice with the same name, it would clear all edges for that node. Now it will do nothing if a node with the specified name already exists. (Fixes #3) 0.2.1 (July 3, 2015) Fixed removeNode leaving references in outgoingEdges and reference to non-existent var edges - thanks juhoha! (Fixes #2) 0.2.0 (May 1, 2015) Removed dependency on Underscore - thanks myndzi! (Fixes #1) 0.1.0 (May 18, 2013) Initial Release - extracted out of asset-smasher"
  },
  "node_modules/dependency-graph/README.html": {
    "href": "node_modules/dependency-graph/README.html",
    "title": "Dependency Graph | accouter",
    "keywords": "Dependency Graph Simple dependency graph Overview This is a simple dependency graph useful for determining the order to do a list of things that depend on certain items being done before they are. To use, npm install dependency-graph and then require('dependency-graph').DepGraph API DepGraph Nodes in the graph are just simple strings with optional data associated with them. addNode(name, data) - add a node in the graph with optional data. If data is not given, name will be used as data removeNode(name) - remove a node from the graph hasNode(name) - check if a node exists in the graph size() - return the number of nodes in the graph getNodeData(name) - get the data associated with a node (will throw an Error if the node does not exist) setNodeData(name, data) - set the data for an existing node (will throw an Error if the node does not exist) addDependency(from, to) - add a dependency between two nodes (will throw an Error if one of the nodes does not exist) removeDependency(from, to) - remove a dependency between two nodes clone() - return a clone of the graph. Any data attached to the nodes will only be shallow-copied dependenciesOf(name, leavesOnly) - get an array containing the nodes that the specified node depends on (transitively). If leavesOnly is true, only nodes that do not depend on any other nodes will be returned in the array. dependantsOf(name, leavesOnly) (aliased as dependentsOf) - get an array containing the nodes that depend on the specified node (transitively). If leavesOnly is true, only nodes that do not have any dependants will be returned in the array. directDependenciesOf(name) - get an array containing the direct dependencies of the specified node directDependantsOf(name) (aliased as directDependentsOf) - get an array containing the nodes that directly depend on the specified node overallOrder(leavesOnly) - construct the overall processing order for the dependency graph. If leavesOnly is true, only nodes that do not depend on any other nodes will be returned. entryNodes() - array of nodes that have no dependants (i.e. nothing depends on them). Dependency Cycles are detected when running dependenciesOf, dependantsOf, and overallOrder and if one is found, a DepGraphCycleError will be thrown that includes what the cycle was in the message as well as the cyclePath property: e.g. Dependency Cycle Found: a -> b -> c -> a. If you wish to silence this error, pass circular: true when instantiating DepGraph (more below). Examples var DepGraph = require('dependency-graph').DepGraph; var graph = new DepGraph(); graph.addNode('a'); graph.addNode('b'); graph.addNode('c'); graph.size() // 3 graph.addDependency('a', 'b'); graph.addDependency('b', 'c'); graph.dependenciesOf('a'); // ['c', 'b'] graph.dependenciesOf('b'); // ['c'] graph.dependantsOf('c'); // ['a', 'b'] graph.overallOrder(); // ['c', 'b', 'a'] graph.overallOrder(true); // ['c'] graph.entryNodes(); // ['a'] graph.addNode('d', 'data'); graph.getNodeData('d'); // 'data' graph.setNodeData('d', 'newData'); graph.getNodeData('d'); // 'newData' var circularGraph = new DepGraph({ circular: true }); circularGraph.addNode('a'); circularGraph.addNode('b'); circularGraph.addNode('c'); circularGraph.addNode('d'); circularGraph.addDependency('a', 'b'); circularGraph.addDependency('b', 'c'); // b depends on c circularGraph.addDependency('c', 'a'); // c depends on a, which depends on b circularGraph.addDependency('d', 'a'); circularGraph.dependenciesOf('b'); // ['a', 'c'] circularGraph.overallOrder(); // ['c', 'b', 'a', 'd']"
  },
  "node_modules/destroy/README.html": {
    "href": "node_modules/destroy/README.html",
    "title": "Destroy | accouter",
    "keywords": "Destroy Destroy a stream. This module is meant to ensure a stream gets destroyed, handling different APIs and Node.js bugs. API var destroy = require('destroy') destroy(stream) Destroy the given stream. In most cases, this is identical to a simple stream.destroy() call. The rules are as follows for a given stream: If the stream is an instance of ReadStream, then call stream.destroy() and add a listener to the open event to call stream.close() if it is fired. This is for a Node.js bug that will leak a file descriptor if .destroy() is called before open. If the stream is not an instance of Stream, then nothing happens. If the stream has a .destroy() method, then call it. The function returns the stream passed in as the argument. Example var destroy = require('destroy') var fs = require('fs') var stream = fs.createReadStream('package.json') // ... and later destroy(stream)"
  },
  "node_modules/dev-ip/README.html": {
    "href": "node_modules/dev-ip/README.html",
    "title": "dev-ip | accouter",
    "keywords": "dev-ip Find a suitable IP host to view local websites on. Command line Install it globally to use on the command line: sudo npm install -g dev-ip then run: dev-ip \"http://192.168.1.46\" In your project npm install dev-ip var devip = require('dev-ip'); devip(); // \"192.168.1.76\" or false if nothing found (ie, offline user) Contributing In lieu of a formal styleguide, take care to maintain the existing coding style. Add unit tests for any new or changed functionality. Run lint & tests with gulp. Release History (Nothing yet) License Copyright (c) 2013 Shane Osbourne Licensed under the MIT license."
  },
  "node_modules/diff-sequences/README.html": {
    "href": "node_modules/diff-sequences/README.html",
    "title": "diff-sequences | accouter",
    "keywords": "diff-sequences Compare items in two sequences to find a longest common subsequence. The items not in common are the items to delete or insert in a shortest edit script. To maximize flexibility and minimize memory, you write callback functions as configuration: Input function isCommon(aIndex, bIndex) compares items at indexes in the sequences and returns a truthy/falsey value. This package might call your function more than once for some pairs of indexes. Because your function encapsulates comparison, this package can compare items according to === operator, Object.is method, or other criterion. Because your function encapsulates sequences, this package can find differences in arrays, strings, or other data. Output function foundSubsequence(nCommon, aCommon, bCommon) receives the number of adjacent items and starting indexes of each common subsequence. If sequences do not have common items, then this package does not call your function. If N is the sum of lengths of sequences and L is length of a longest common subsequence, then D = N – 2L is the number of differences in the corresponding shortest edit script. An O(ND) Difference Algorithm and Its Variations by Eugene W. Myers is fast when sequences have few differences. This package implements the linear space variation with optimizations so it is fast even when sequences have many differences. Usage To add this package as a dependency of a project, do either of the following: npm install diff-sequences yarn add diff-sequences To use diff as the name of the default export from this package, do either of the following: var diff = require('diff-sequences').default; // CommonJS modules import diff from 'diff-sequences'; // ECMAScript modules Call diff with the lengths of sequences and your callback functions: const a = ['a', 'b', 'c', 'a', 'b', 'b', 'a']; const b = ['c', 'b', 'a', 'b', 'a', 'c']; function isCommon(aIndex, bIndex) { return a[aIndex] === b[bIndex]; } function foundSubsequence(nCommon, aCommon, bCommon) { // see examples } diff(a.length, b.length, isCommon, foundSubsequence); Example of longest common subsequence Some sequences (for example, a and b in the example of usage) have more than one longest common subsequence. This package finds the following common items: comparisons of common items values output arguments a[2] === b[0] 'c' foundSubsequence(1, 2, 0) a[4] === b[1] 'b' foundSubsequence(1, 4, 1) a[5] === b[3] && a[6] === b[4] 'b', 'a' foundSubsequence(2, 5, 3) The “edit graph” analogy in the Myers paper shows the following common items: comparisons of common items values a[2] === b[0] 'c' a[3] === b[2] && a[4] === b[3] 'a', 'b' a[6] === b[4] 'a' Various packages which implement the Myers algorithm will always agree on the length of a longest common subsequence, but might sometimes disagree on which items are in it. Example of callback functions to count common items // Return length of longest common subsequence according to === operator. function countCommonItems(a, b) { let n = 0; function isCommon(aIndex, bIndex) { return a[aIndex] === b[bIndex]; } function foundSubsequence(nCommon) { n += nCommon; } diff(a.length, b.length, isCommon, foundSubsequence); return n; } const commonLength = countCommonItems( ['a', 'b', 'c', 'a', 'b', 'b', 'a'], ['c', 'b', 'a', 'b', 'a', 'c'], ); category of items expression value in common commonLength 4 to delete from a a.length - commonLength 3 to insert from b b.length - commonLength 2 If the length difference b.length - a.length is: negative: its absolute value is the minimum number of items to delete from a positive: it is the minimum number of items to insert from b zero: there is an equal number of items to delete from a and insert from b non-zero: there is an equal number of additional items to delete from a and insert from b In this example, 6 - 7 is: negative: 1 is the minimum number of items to delete from a non-zero: 2 is the number of additional items to delete from a and insert from b Example of callback functions to find common items // Return array of items in longest common subsequence according to Object.is method. const findCommonItems = (a, b) => { const array = []; diff( a.length, b.length, (aIndex, bIndex) => Object.is(a[aIndex], b[bIndex]), (nCommon, aCommon) => { for (; nCommon !== 0; nCommon -= 1, aCommon += 1) { array.push(a[aCommon]); } }, ); return array; }; const commonItems = findCommonItems( ['a', 'b', 'c', 'a', 'b', 'b', 'a'], ['c', 'b', 'a', 'b', 'a', 'c'], ); i commonItems[i] aIndex 0 'c' 2 1 'b' 4 2 'b' 5 3 'a' 6 Example of callback functions to diff index intervals Instead of slicing array-like objects, you can adjust indexes in your callback functions. // Diff index intervals that are half open [start, end) like array slice method. const diffIndexIntervals = (a, aStart, aEnd, b, bStart, bEnd) => { // Validate: 0 <= aStart and aStart <= aEnd and aEnd <= a.length // Validate: 0 <= bStart and bStart <= bEnd and bEnd <= b.length diff( aEnd - aStart, bEnd - bStart, (aIndex, bIndex) => Object.is(a[aStart + aIndex], b[bStart + bIndex]), (nCommon, aCommon, bCommon) => { // aStart + aCommon, bStart + bCommon }, ); // After the last common subsequence, do any remaining work. }; Example of callback functions to emulate diff command Linux or Unix has a diff command to compare files line by line. Its output is a shortest edit script: change adjacent lines from the first file to lines from the second file delete lines from the first file append or insert lines from the second file // Given zero-based half-open range [start, end) of array indexes, // return one-based closed range [start + 1, end] as string. const getRange = (start, end) => start + 1 === end ? `${start + 1}` : `${start + 1},${end}`; // Given index intervals of lines to delete or insert, or both, or neither, // push formatted diff lines onto array. const pushDelIns = (aLines, aIndex, aEnd, bLines, bIndex, bEnd, array) => { const deleteLines = aIndex !== aEnd; const insertLines = bIndex !== bEnd; const changeLines = deleteLines && insertLines; if (changeLines) { array.push(`${getRange(aIndex, aEnd)}c${getRange(bIndex, bEnd)}`); } else if (deleteLines) { array.push(`${getRange(aIndex, aEnd)}d${String(bIndex)}`); } else if (insertLines) { array.push(`${String(aIndex)}a${getRange(bIndex, bEnd)}`); } else { return; } for (; aIndex !== aEnd; aIndex += 1) { array.push(`< ${aLines[aIndex]}`); // delete is less than } if (changeLines) { array.push('---'); } for (; bIndex !== bEnd; bIndex += 1) { array.push(`> ${bLines[bIndex]}`); // insert is greater than } }; // Given content of two files, return emulated output of diff utility. const findShortestEditScript = (a, b) => { const aLines = a.split('\\n'); const bLines = b.split('\\n'); const aLength = aLines.length; const bLength = bLines.length; const isCommon = (aIndex, bIndex) => aLines[aIndex] === bLines[bIndex]; let aIndex = 0; let bIndex = 0; const array = []; const foundSubsequence = (nCommon, aCommon, bCommon) => { pushDelIns(aLines, aIndex, aCommon, bLines, bIndex, bCommon, array); aIndex = aCommon + nCommon; // number of lines compared in a bIndex = bCommon + nCommon; // number of lines compared in b }; diff(aLength, bLength, isCommon, foundSubsequence); // After the last common subsequence, push remaining change lines. pushDelIns(aLines, aIndex, aLength, bLines, bIndex, bLength, array); return array.length === 0 ? '' : `${array.join('\\n')}\\n`; }; Example of callback functions to format diff lines Here is simplified code to format changed and unchanged lines in expected and received values after a test fails in Jest: // Format diff with minus or plus for change lines and space for common lines. const formatDiffLines = (a, b) => { // Jest depends on pretty-format package to serialize objects as strings. // Unindented for comparison to avoid distracting differences: const aLinesUn = format(a, {indent: 0 /*, other options*/}).split('\\n'); const bLinesUn = format(b, {indent: 0 /*, other options*/}).split('\\n'); // Indented to display changed and unchanged lines: const aLinesIn = format(a, {indent: 2 /*, other options*/}).split('\\n'); const bLinesIn = format(b, {indent: 2 /*, other options*/}).split('\\n'); const aLength = aLinesIn.length; // Validate: aLinesUn.length === aLength const bLength = bLinesIn.length; // Validate: bLinesUn.length === bLength const isCommon = (aIndex, bIndex) => aLinesUn[aIndex] === bLinesUn[bIndex]; // Only because the GitHub Flavored Markdown doc collapses adjacent spaces, // this example code and the following table represent spaces as middle dots. let aIndex = 0; let bIndex = 0; const array = []; const foundSubsequence = (nCommon, aCommon, bCommon) => { for (; aIndex !== aCommon; aIndex += 1) { array.push(`-·${aLinesIn[aIndex]}`); // delete is minus } for (; bIndex !== bCommon; bIndex += 1) { array.push(`+·${bLinesIn[bIndex]}`); // insert is plus } for (; nCommon !== 0; nCommon -= 1, aIndex += 1, bIndex += 1) { // For common lines, received indentation seems more intuitive. array.push(`··${bLinesIn[bIndex]}`); // common is space } }; diff(aLength, bLength, isCommon, foundSubsequence); // After the last common subsequence, push remaining change lines. for (; aIndex !== aLength; aIndex += 1) { array.push(`-·${aLinesIn[aIndex]}`); } for (; bIndex !== bLength; bIndex += 1) { array.push(`+·${bLinesIn[bIndex]}`); } return array; }; const expected = { searching: '', sorting: { ascending: true, fieldKey: 'what', }, }; const received = { searching: '', sorting: [ { descending: false, fieldKey: 'what', }, ], }; const diffLines = formatDiffLines(expected, received); If N is the sum of lengths of sequences and L is length of a longest common subsequence, then N – L is length of an array of diff lines. In this example, N is 7 + 9, L is 5, and N – L is 11. i diffLines[i] aIndex bIndex 0 '··Object {' 0 0 1 '····\"searching\": \"\",' 1 1 2 '-···\"sorting\": Object {' 2 3 '-·····\"ascending\": true,' 3 4 '+·····\"sorting\": Array [' 2 5 '+·······Object {' 3 6 '+·········\"descending\": false,' 4 7 '··········\"fieldKey\": \"what\",' 4 5 8 '········},' 5 6 9 '+·····],' 7 10 '··}' 6 8 Example of callback functions to find diff items Here is simplified code to find changed and unchanged substrings within adjacent changed lines in expected and received values after a test fails in Jest: // Return diff items for strings (compatible with diff-match-patch package). const findDiffItems = (a, b) => { const isCommon = (aIndex, bIndex) => a[aIndex] === b[bIndex]; let aIndex = 0; let bIndex = 0; const array = []; const foundSubsequence = (nCommon, aCommon, bCommon) => { if (aIndex !== aCommon) { array.push([-1, a.slice(aIndex, aCommon)]); // delete is -1 } if (bIndex !== bCommon) { array.push([1, b.slice(bIndex, bCommon)]); // insert is 1 } aIndex = aCommon + nCommon; // number of characters compared in a bIndex = bCommon + nCommon; // number of characters compared in b array.push([0, a.slice(aCommon, aIndex)]); // common is 0 }; diff(a.length, b.length, isCommon, foundSubsequence); // After the last common subsequence, push remaining change items. if (aIndex !== a.length) { array.push([-1, a.slice(aIndex)]); } if (bIndex !== b.length) { array.push([1, b.slice(bIndex)]); } return array; }; const expectedDeleted = ['\"sorting\": Object {', '\"ascending\": true,'].join( '\\n', ); const receivedInserted = [ '\"sorting\": Array [', 'Object {', '\"descending\": false,', ].join('\\n'); const diffItems = findDiffItems(expectedDeleted, receivedInserted); i diffItems[i][0] diffItems[i][1] 0 0 '\"sorting\": ' 1 1 'Array [\\n' 2 0 'Object {\\n\"' 3 -1 'a' 4 1 'de' 5 0 'scending\": ' 6 -1 'tru' 7 1 'fals' 8 0 'e,' The length difference b.length - a.length is equal to the sum of diffItems[i][0] values times diffItems[i][1] lengths. In this example, the difference 48 - 38 is equal to the sum 10. category of diff item [0] [1] lengths subtotal in common 0 11 + 10 + 11 + 2 0 to delete from a –1 1 + 3 -4 to insert from b 1 8 + 2 + 4 14 Instead of formatting the changed substrings with escape codes for colors in the foundSubsequence function to save memory, this example spends memory to gain flexibility before formatting, so a separate heuristic algorithm might modify the generic array of diff items to show changes more clearly: i diffItems[i][0] diffItems[i][1] 6 -1 'true' 7 1 'false' 8 0 ',' For expected and received strings of serialized data, the result of finding changed lines, and then finding changed substrings within adjacent changed lines (as in the preceding two examples) sometimes displays the changes in a more intuitive way than the result of finding changed substrings, and then splitting them into changed and unchanged lines."
  },
  "node_modules/diff/CONTRIBUTING.html": {
    "href": "node_modules/diff/CONTRIBUTING.html",
    "title": "How to Contribute | accouter",
    "keywords": "How to Contribute Pull Requests We also accept pull requests! Generally we like to see pull requests that Maintain the existing code style Are focused on a single change (i.e. avoid large refactoring or style adjustments in untouched code if not the primary goal of the pull request) Have good commit messages Have tests Don't decrease the current code coverage (see coverage/lcov-report/index.html) Building npm install npm test The npm test -- dev implements watching for tests within Node and karma start may be used for manual testing in browsers. If you notice any problems, please report them to the GitHub issue tracker at http://github.com/kpdecker/jsdiff/issues. Releasing JsDiff utilizes the release yeoman generator to perform most release tasks. A full release may be completed with the following: yo release npm publish"
  },
  "node_modules/diff/README.html": {
    "href": "node_modules/diff/README.html",
    "title": "jsdiff | accouter",
    "keywords": "jsdiff A javascript text differencing implementation. Based on the algorithm proposed in \"An O(ND) Difference Algorithm and its Variations\" (Myers, 1986). Installation npm install diff --save API Diff.diffChars(oldStr, newStr[, options]) - diffs two blocks of text, comparing character by character. Returns a list of change objects (See below). Options ignoreCase: true to ignore casing difference. Defaults to false. Diff.diffWords(oldStr, newStr[, options]) - diffs two blocks of text, comparing word by word, ignoring whitespace. Returns a list of change objects (See below). Options ignoreCase: Same as in diffChars. Diff.diffWordsWithSpace(oldStr, newStr[, options]) - diffs two blocks of text, comparing word by word, treating whitespace as significant. Returns a list of change objects (See below). Diff.diffLines(oldStr, newStr[, options]) - diffs two blocks of text, comparing line by line. Options ignoreWhitespace: true to ignore leading and trailing whitespace. This is the same as diffTrimmedLines newlineIsToken: true to treat newline characters as separate tokens. This allows for changes to the newline structure to occur independently of the line content and to be treated as such. In general this is the more human friendly form of diffLines and diffLines is better suited for patches and other computer friendly output. Returns a list of change objects (See below). Diff.diffTrimmedLines(oldStr, newStr[, options]) - diffs two blocks of text, comparing line by line, ignoring leading and trailing whitespace. Returns a list of change objects (See below). Diff.diffSentences(oldStr, newStr[, options]) - diffs two blocks of text, comparing sentence by sentence. Returns a list of change objects (See below). Diff.diffCss(oldStr, newStr[, options]) - diffs two blocks of text, comparing CSS tokens. Returns a list of change objects (See below). Diff.diffJson(oldObj, newObj[, options]) - diffs two JSON objects, comparing the fields defined on each. The order of fields, etc does not matter in this comparison. Returns a list of change objects (See below). Diff.diffArrays(oldArr, newArr[, options]) - diffs two arrays, comparing each item for strict equality (===). Options comparator: function(left, right) for custom equality checks Returns a list of change objects (See below). Diff.createTwoFilesPatch(oldFileName, newFileName, oldStr, newStr, oldHeader, newHeader) - creates a unified diff patch. Parameters: oldFileName : String to be output in the filename section of the patch for the removals newFileName : String to be output in the filename section of the patch for the additions oldStr : Original string value newStr : New string value oldHeader : Additional information to include in the old file header newHeader : Additional information to include in the new file header options : An object with options. Currently, only context is supported and describes how many lines of context should be included. Diff.createPatch(fileName, oldStr, newStr, oldHeader, newHeader) - creates a unified diff patch. Just like Diff.createTwoFilesPatch, but with oldFileName being equal to newFileName. Diff.structuredPatch(oldFileName, newFileName, oldStr, newStr, oldHeader, newHeader, options) - returns an object with an array of hunk objects. This method is similar to createTwoFilesPatch, but returns a data structure suitable for further processing. Parameters are the same as createTwoFilesPatch. The data structure returned may look like this: { oldFileName: 'oldfile', newFileName: 'newfile', oldHeader: 'header1', newHeader: 'header2', hunks: [{ oldStart: 1, oldLines: 3, newStart: 1, newLines: 3, lines: [' line2', ' line3', '-line4', '+line5', '\\\\ No newline at end of file'], }] } Diff.applyPatch(source, patch[, options]) - applies a unified diff patch. Return a string containing new version of provided data. patch may be a string diff or the output from the parsePatch or structuredPatch methods. The optional options object may have the following keys: fuzzFactor: Number of lines that are allowed to differ before rejecting a patch. Defaults to 0. compareLine(lineNumber, line, operation, patchContent): Callback used to compare to given lines to determine if they should be considered equal when patching. Defaults to strict equality but may be overridden to provide fuzzier comparison. Should return false if the lines should be rejected. Diff.applyPatches(patch, options) - applies one or more patches. This method will iterate over the contents of the patch and apply to data provided through callbacks. The general flow for each patch index is: options.loadFile(index, callback) is called. The caller should then load the contents of the file and then pass that to the callback(err, data) callback. Passing an err will terminate further patch execution. options.patched(index, content, callback) is called once the patch has been applied. content will be the return value from applyPatch. When it's ready, the caller should call callback(err) callback. Passing an err will terminate further patch execution. Once all patches have been applied or an error occurs, the options.complete(err) callback is made. Diff.parsePatch(diffStr) - Parses a patch into structured data Return a JSON object representation of the a patch, suitable for use with the applyPatch method. This parses to the same structure returned by Diff.structuredPatch. convertChangesToXML(changes) - converts a list of changes to a serialized XML format All methods above which accept the optional callback method will run in sync mode when that parameter is omitted and in async mode when supplied. This allows for larger diffs without blocking the event loop. This may be passed either directly as the final parameter or as the callback field in the options object. Change Objects Many of the methods above return change objects. These objects consist of the following fields: value: Text content added: True if the value was inserted into the new string removed: True if the value was removed from the old string Note that some cases may omit a particular flag field. Comparison on the flag fields should always be done in a truthy or falsy manner. Examples Basic example in Node require('colors'); const Diff = require('diff'); const one = 'beep boop'; const other = 'beep boob blah'; const diff = Diff.diffChars(one, other); diff.forEach((part) => { // green for additions, red for deletions // grey for common parts const color = part.added ? 'green' : part.removed ? 'red' : 'grey'; process.stderr.write(part.value[color]); }); console.log(); Running the above program should yield Basic example in a web page <pre id=\"display\"></pre> <script src=\"diff.js\"></script> <script> const one = 'beep boop', other = 'beep boob blah', color = ''; let span = null; const diff = Diff.diffChars(one, other), display = document.getElementById('display'), fragment = document.createDocumentFragment(); diff.forEach((part) => { // green for additions, red for deletions // grey for common parts const color = part.added ? 'green' : part.removed ? 'red' : 'grey'; span = document.createElement('span'); span.style.color = color; span.appendChild(document .createTextNode(part.value)); fragment.appendChild(span); }); display.appendChild(fragment); </script> Open the above .html file in a browser and you should see Full online demo Compatibility jsdiff supports all ES3 environments with some known issues on IE8 and below. Under these browsers some diff algorithms such as word diff and others may fail due to lack of support for capturing groups in the split operation. License See LICENSE."
  },
  "node_modules/diff/release-notes.html": {
    "href": "node_modules/diff/release-notes.html",
    "title": "Release Notes | accouter",
    "keywords": "Release Notes Development Commits v5.0.0 Breaking: UMD export renamed from JsDiff to Diff. Breaking: Newlines separated into separate tokens for word diff. Breaking: Unified diffs now match \"quirks\" Commits v4.0.1 - January 6th, 2019 Fix main reference path - b826104 Commits v4.0.0 - January 5th, 2019 #94 - Missing \"No newline at end of file\" when comparing two texts that do not end in newlines (@federicotdn) #227 - Licence #199 - Import statement for jsdiff #159 - applyPatch affecting wrong line number with with new lines #8 - A new state \"replace\" Drop ie9 from karma targets - 79c31bd Upgrade deps. Convert from webpack to rollup - 2c1a29c Make ()[]\"' as word boundaries between each other - f27b899 jsdiff: Replaced phantomJS by chrome - ec3114e Add yarn.lock to .npmignore - 29466d8 Compatibility notes: Bower and Component packages no longer supported Commits v3.5.0 - March 4th, 2018 Omit redundant slice in join method of diffArrays - 1023590 Support patches with empty lines - fb0f208 Accept a custom JSON replacer function for JSON diffing - 69c7f0a Optimize parch header parser - 2aec429 Fix typos - e89c832 Commits v3.4.0 - October 7th, 2017 #183 - Feature request: ability to specify a custom equality checker for diffArrays #173 - Bug: diffArrays gives wrong result on array of booleans #158 - diffArrays will not compare the empty string in array? comparator for custom equality checks - 30e141e count oldLines and newLines when there are conflicts - 53bf384 Fix: diffArrays can compare falsey items - 9e24284 Docs: Replace grunt with npm test - 00e2f94 Commits v3.3.1 - September 3rd, 2017 #141 - Cannot apply patch because my file delimiter is \"/r/n\" instead of \"/n\" #192 - Fix: Bad merge when adding new files (#189) correct spelling mistake - 21fa478 Commits v3.3.0 - July 5th, 2017 #114 - /patch/merge not exported Gracefully accept invalid newStart in hunks, same as patch(1) does. - d8a3635 Use regex rather than starts/ends with for parsePatch - 6cab62c Add browser flag - e64f674 refactor: simplified code a bit more - 8f8e0f2 refactor: simplified code a bit - b094a6f fix: some corrections re ignoreCase option - 3c78fd0 ignoreCase option - 3cbfbb5 Sanitize filename while parsing patches - 2fe8129 Added better installation methods - aced50b Simple export of functionality - 8690f31 Commits v3.2.0 - December 26th, 2016 #156 - Add undefinedReplacement option to diffJson (@ewnd9) #154 - Add examples and images to .npmignore. (@wtgtybhertgeghgtwtg) #153 - feat(structuredPatch): Pass options to diffLines (@Kiougar) Commits v3.1.0 - November 27th, 2016 #146 - JsDiff.diffArrays to compare arrays (@wvanderdeijl) #144 - Split file using all possible line delimiter instead of hard-coded \"/n\" and join lines back using the original delimiters (@soulbeing) Commits v3.0.1 - October 9th, 2016 #139 - Make README.md look nicer in npmjs.com (@takenspc) #135 - parsePatch combines patches from multiple files into a single IUniDiff when there is no \"Index\" line (@ramya-rao-a) #124 - IE7/IE8 failure since 2.0.0 (@boneskull) Commits v3.0.0 - August 23rd, 2016 #130 - Add callback argument to applyPatches patched option (@piranna) #120 - Correctly handle file names containing spaces (@adius) #119 - Do single reflow (@wifiextender) #117 - Make more usable with long strings. (@abnbgist) Compatibility notes: applyPatches patch callback now is async and requires the callback be called to continue operation Commits v2.2.3 - May 31st, 2016 #118 - Add a fix for applying 0-length destination patches (@chaaz) #115 - Fixed grammar in README (@krizalys) #113 - fix typo (@vmazare) Commits v2.2.2 - March 13th, 2016 #102 - diffJson with dates, returns empty curly braces (@dr-dimitru) #97 - Whitespaces & diffWords (@faiwer) #92 - Fixes typo in the readme (@bg451) Commits v2.2.1 - November 12th, 2015 #89 - add in display selector to readme (@FranDias) #88 - Split diffs based on file headers instead of 'Index:' metadata (@piranna) Commits v2.2.0 - October 29th, 2015 #80 - Fix a typo: applyPath -> applyPatch (@fluxxu) #83 - Add basic fuzzy matching to applyPatch (@piranna) Commits v2.2.0 - October 29th, 2015 #80 - Fix a typo: applyPath -> applyPatch (@fluxxu) #83 - Add basic fuzzy matching to applyPatch (@piranna) Commits v2.1.3 - September 30th, 2015 #78 - fix: error throwing when apply patch to empty string (@21paradox) Commits v2.1.2 - September 23rd, 2015 #76 - diff headers give error (@piranna) Commits v2.1.1 - September 9th, 2015 #73 - Is applyPatches() exposed in the API? (@davidparsson) Commits v2.1.0 - August 27th, 2015 #72 - Consider using options object API for flag permutations (@kpdecker) #70 - diffWords treats \\n at the end as significant whitespace (@nesQuick) #69 - Missing count (@wfalkwallace) #68 - diffLines seems broken (@wfalkwallace) #60 - Support multiple diff hunks (@piranna) #54 - Feature Request: 3-way merge (@mog422) #42 - Fuzz factor for applyPatch (@stuartpb) Move whitespace ignore out of equals method - 542063c Include source maps in babel output - 7f7ab21 Merge diff/line and diff/patch implementations - 1597705 Drop map utility method - 1ddc939 Documentation for parsePatch and applyPatches - 27c4b77 Compatibility notes: The undocumented ignoreWhitespace flag has been removed from the Diff equality check directly. This implementation may be copied to diff utilities if dependencies existed on this functionality. Commits v2.0.2 - August 8th, 2015 #67 - cannot require from npm module in node (@commenthol) Convert to chai since we don’t support IE8 - a96bbad Commits v2.0.1 - August 7th, 2015 Add release build at proper step - 57542fd Commits v2.0.0 - August 7th, 2015 #66 - Add karma and sauce tests (@kpdecker) #65 - Create component repository for bower (@kpdecker) #64 - Automatically call removeEmpty for all tokenizer calls (@kpdecker) #62 - Allow access to structured object representation of patch data (@bittrance) #61 - Use svg instead of png to get better image quality (@PeterDaveHello) #29 - word tokenizer works only for 7 bit ascii (@plasmagunman) Compatibility notes: this.removeEmpty is now called automatically for all instances. If this is not desired, this may be overridden on a per instance basis. The library has been refactored to use some ES6 features. The external APIs should remain the same, but bower projects that directly referenced the repository will now have to point to the components/jsdiff repository. Commits v1.4.0 - May 6th, 2015 #57 - createPatch -> applyPatch failed. (@mog422) #56 - Two files patch (@rgeissert) #14 - Flip added and removed order? (@jakesandlund) Commits v1.3.2 - March 30th, 2015 #53 - Updated README.MD with Bower installation instructions (@ofbriggs) #49 - Cannot read property 'oldlines' of undefined (@nwtn) #44 - invalid-meta jsdiff is missing \"main\" entry in bower.json Commits v1.3.1 - March 13th, 2015 #52 - Fix for #51 Wrong result of JsDiff.diffLines (@felicienfrancois) Commits v1.3.0 - March 2nd, 2015 #47 - Adding Diff Trimmed Lines (@JamesGould123) Commits v1.2.2 - January 26th, 2015 #45 - Fix AMD module loading (@pedrocarrico) #43 - added a bower file (@nbrustein) Commits v1.2.1 - December 26th, 2014 #41 - change condition of using node export system. (@ironhee) Commits v1.2.0 - November 29th, 2014 #37 - Add support for sentences. (@vmariano) #28 - Implemented diffJson (@papandreou) #27 - Slow to execute over diffs with a large number of changes (@termi) Allow for optional async diffing - 19385b9 Fix diffChars implementation - eaa44ed Commits v1.1.0 - November 25th, 2014 #33 - AMD and global exports (@ovcharik) #32 - Add support for component (@vmariano) #31 - Don't rely on Array.prototype.map (@papandreou) Commits v1.0.8 - December 22nd, 2013 #24 - Handle windows newlines on non windows machines. (@benogle) #23 - Prettied up the API formatting a little, and added basic node and web examples (@airportyh) Commits v1.0.7 - September 11th, 2013 #22 - Added variant of WordDiff that doesn't ignore whitespace differences (@papandreou Add 0.10 to travis tests - 243a526 Commits v1.0.6 - August 30th, 2013 #19 - Explicitly define contents of npm package (@sindresorhus Commits"
  },
  "node_modules/dir-glob/readme.html": {
    "href": "node_modules/dir-glob/readme.html",
    "title": "dir-glob | accouter",
    "keywords": "dir-glob Convert directories to glob compatible strings Install $ npm install dir-glob Usage const dirGlob = require('dir-glob'); (async () => { console.log(await dirGlob(['index.js', 'test.js', 'fixtures'])); //=> ['index.js', 'test.js', 'fixtures/**'] console.log(await dirGlob(['index.js', 'inner_folder'], {cwd: 'fixtures'})); //=> ['index.js', 'inner_folder/**'] console.log(await dirGlob(['lib/**', 'fixtures'], { files: ['test', 'unicorn'] extensions: ['js'] })); //=> ['lib/**', 'fixtures/**/test.js', 'fixtures/**/unicorn.js'] console.log(await dirGlob(['lib/**', 'fixtures'], { files: ['test', 'unicorn', '*.jsx'], extensions: ['js', 'png'] })); //=> ['lib/**', 'fixtures/**/test.{js,png}', 'fixtures/**/unicorn.{js,png}', 'fixtures/**/*.jsx'] })(); API dirGlob(input, options?) Returns a Promise<string[]> with globs. dirGlob.sync(input, options?) Returns a string[] with globs. input Type: string | string[] Paths. options Type: object extensions Type: string[] Append extensions to the end of your globs. files Type: string[] Only glob for certain files. cwd Type: string[] Test in specific directory."
  },
  "node_modules/dom-serializer/README.html": {
    "href": "node_modules/dom-serializer/README.html",
    "title": "dom-serializer | accouter",
    "keywords": "dom-serializer Renders a domhandler DOM node or an array of domhandler DOM nodes to a string. import render from \"dom-serializer\"; // OR const render = require(\"dom-serializer\").default; API render ▸ render(node: Node | Node[], options?: Options): string Renders a DOM node or an array of DOM nodes to a string. Can be thought of as the equivalent of the outerHTML of the passed node(s). Parameters: Name Type Default value Description node Node | Node[] - Node to be rendered. options DomSerializerOptions {} Changes serialization behavior Returns: string Options encodeEntities • Optional decodeEntities: boolean | \"utf8\" Encode characters that are either reserved in HTML or XML. If xmlMode is true or the value not 'utf8', characters outside of the utf8 range will be encoded as well. default decodeEntities decodeEntities • Optional decodeEntities: boolean Option inherited from parsing; will be used as the default value for encodeEntities. default true emptyAttrs • Optional emptyAttrs: boolean Print an empty attribute's value. default xmlMode example With emptyAttrs: false: <input checked> example With emptyAttrs: true: <input checked=\"\"> selfClosingTags • Optional selfClosingTags: boolean Print self-closing tags for tags without contents. default xmlMode example With selfClosingTags: false: <foo></foo> example With selfClosingTags: true: <foo /> xmlMode • Optional xmlMode: boolean | \"foreign\" Treat the input as an XML document; enables the emptyAttrs and selfClosingTags options. If the value is \"foreign\", it will try to correct mixed-case attribute names. default false Ecosystem Name Description htmlparser2 Fast & forgiving HTML/XML parser domhandler Handler for htmlparser2 that turns documents into a DOM domutils Utilities for working with domhandler's DOM css-select CSS selector engine, compatible with domhandler's DOM cheerio The jQuery API for domhandler's DOM dom-serializer Serializer for domhandler's DOM LICENSE: MIT"
  },
  "node_modules/domelementtype/readme.html": {
    "href": "node_modules/domelementtype/readme.html",
    "title": "| accouter",
    "keywords": "All the types of nodes in htmlparser2's DOM."
  },
  "node_modules/domhandler/readme.html": {
    "href": "node_modules/domhandler/readme.html",
    "title": "domhandler | accouter",
    "keywords": "domhandler The DOM handler creates a tree containing all nodes of a page. The tree can be manipulated using the domutils or cheerio libraries and rendered using dom-serializer . Usage const handler = new DomHandler([ <func> callback(err, dom), ] [ <obj> options ]); // const parser = new Parser(handler[, options]); Available options are described below. Example const { Parser } = require(\"htmlparser2\"); const { DomHandler } = require(\"domhandler\"); const rawHtml = \"Xyz <script language= javascript>var foo = '<<bar>>';</script><!--<!-- Waah! -- -->\"; const handler = new DomHandler((error, dom) => { if (error) { // Handle error } else { // Parsing completed, do something console.log(dom); } }); const parser = new Parser(handler); parser.write(rawHtml); parser.end(); Output: [ { data: \"Xyz \", type: \"text\", }, { type: \"script\", name: \"script\", attribs: { language: \"javascript\", }, children: [ { data: \"var foo = '<bar>';<\", type: \"text\", }, ], }, { data: \"<!-- Waah! -- \", type: \"comment\", }, ]; Option: withStartIndices Add a startIndex property to nodes. When the parser is used in a non-streaming fashion, startIndex is an integer indicating the position of the start of the node in the document. The default value is false. Option: withEndIndices Add an endIndex property to nodes. When the parser is used in a non-streaming fashion, endIndex is an integer indicating the position of the end of the node in the document. The default value is false. License: BSD-2-Clause Security contact information To report a security vulnerability, please use the Tidelift security contact. Tidelift will coordinate the fix and disclosure. domhandler for enterprise Available as part of the Tidelift Subscription The maintainers of domhandler and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more."
  },
  "node_modules/domutils/readme.html": {
    "href": "node_modules/domutils/readme.html",
    "title": "domutils | accouter",
    "keywords": "domutils Utilities for working with htmlparser2's DOM. All functions are exported as a single module. Look through the docs to see what is available. Ecosystem Name Description htmlparser2 Fast & forgiving HTML/XML parser domhandler Handler for htmlparser2 that turns documents into a DOM domutils Utilities for working with domhandler's DOM css-select CSS selector engine, compatible with domhandler's DOM cheerio The jQuery API for domhandler's DOM dom-serializer Serializer for domhandler's DOM License: BSD-2-Clause Security contact information To report a security vulnerability, please use the Tidelift security contact. Tidelift will coordinate the fix and disclosure. domutils for enterprise Available as part of the Tidelift Subscription The maintainers of domutils and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more."
  },
  "node_modules/eastasianwidth/README.html": {
    "href": "node_modules/eastasianwidth/README.html",
    "title": "East Asian Width | accouter",
    "keywords": "East Asian Width Get East Asian Width from a character. 'F'(Fullwidth), 'H'(Halfwidth), 'W'(Wide), 'Na'(Narrow), 'A'(Ambiguous) or 'N'(Natural). Original Code is 東アジアの文字幅 (East Asian Width) の判定 - 中途. Install $ npm install eastasianwidth Usage var eaw = require('eastasianwidth'); console.log(eaw.eastAsianWidth('￦')) // 'F' console.log(eaw.eastAsianWidth('｡')) // 'H' console.log(eaw.eastAsianWidth('뀀')) // 'W' console.log(eaw.eastAsianWidth('a')) // 'Na' console.log(eaw.eastAsianWidth('①')) // 'A' console.log(eaw.eastAsianWidth('ف')) // 'N' console.log(eaw.characterLength('￦')) // 2 console.log(eaw.characterLength('｡')) // 1 console.log(eaw.characterLength('뀀')) // 2 console.log(eaw.characterLength('a')) // 1 console.log(eaw.characterLength('①')) // 2 console.log(eaw.characterLength('ف')) // 1 console.log(eaw.length('あいうえお')) // 10 console.log(eaw.length('abcdefg')) // 7 console.log(eaw.length('￠￦｡ￜㄅ뀀¢⟭a⊙①بف')) // 19"
  },
  "node_modules/easy-extender/README.html": {
    "href": "node_modules/easy-extender/README.html",
    "title": "| accouter",
    "keywords": "##easy-extender Plugin + hooks system extracted from BrowserSync for general use."
  },
  "node_modules/eazy-logger/README.html": {
    "href": "node_modules/eazy-logger/README.html",
    "title": "| accouter",
    "keywords": "##eazy-logger tFunk + String Substitution ##Install $ npm install eazy-logger --save ##Usage var logger = require(\"eazy-logger\").Logger({ prefix: \"{blue:[}{magenta:easy-logger}{blue:] }\", useLevelPrefixes: true }); /** * Standard loggers + prefixes */ logger.debug(\"Debugging Msg\"); logger.info(\"Info statement\"); logger.warn(\"A little warning with string %s\", \"substitution\"); logger.error(\"an error occurred in file: {red:%s}\", \"/users/awesomedev/file.js\"); /** * Use string substitution + colours */ logger.log(\"error\", \"Use {green:built-in} %s\", \"String substitution\"); /** * Set an option for the next log statement only */ logger.setOnce(\"useLevelPrefixes\", true).warn(\"Use {green:built-in} %s\", \"String substitution\");"
  },
  "node_modules/ee-first/README.html": {
    "href": "node_modules/ee-first/README.html",
    "title": "EE First | accouter",
    "keywords": "EE First Get the first event in a set of event emitters and event pairs, then clean up after itself. Install $ npm install ee-first API var first = require('ee-first') first(arr, listener) Invoke listener on the first event from the list specified in arr. arr is an array of arrays, with each array in the format [ee, ...event]. listener will be called only once, the first time any of the given events are emitted. If error is one of the listened events, then if that fires first, the listener will be given the err argument. The listener is invoked as listener(err, ee, event, args), where err is the first argument emitted from an error event, if applicable; ee is the event emitter that fired; event is the string event name that fired; and args is an array of the arguments that were emitted on the event. var ee1 = new EventEmitter() var ee2 = new EventEmitter() first([ [ee1, 'close', 'end', 'error'], [ee2, 'error'] ], function (err, ee, event, args) { // listener invoked }) .cancel() The group of listeners can be cancelled before being invoked and have all the event listeners removed from the underlying event emitters. var thunk = first([ [ee1, 'close', 'end', 'error'], [ee2, 'error'] ], function (err, ee, event, args) { // listener invoked }) // cancel and clean up thunk.cancel()"
  },
  "node_modules/electron-to-chromium/README.html": {
    "href": "node_modules/electron-to-chromium/README.html",
    "title": "Electron-to-Chromium | accouter",
    "keywords": "Made by @kilianvalkhof Other projects: 💻 Polypane - Develop responsive websites and apps twice as fast on multiple screens at once 🖌️ Superposition - Kickstart your design system by extracting design tokens from your website 🗒️ FromScratch - A smart but simple autosaving scratchpad Electron-to-Chromium This repository provides a mapping of Electron versions to the Chromium version that it uses. This package is used in Browserslist, so you can use e.g. electron >= 1.4 in Autoprefixer, Stylelint, babel-preset-env and eslint-plugin-compat. Supported by: Install Install using npm install electron-to-chromium. Usage To include Electron-to-Chromium, require it: var e2c = require('electron-to-chromium'); Properties The Electron-to-Chromium object has 4 properties to use: versions An object of key-value pairs with a major Electron version as the key, and the corresponding major Chromium version as the value. var versions = e2c.versions; console.log(versions['1.4']); // returns \"53\" fullVersions An object of key-value pairs with a Electron version as the key, and the corresponding full Chromium version as the value. var versions = e2c.fullVersions; console.log(versions['1.4.11']); // returns \"53.0.2785.143\" chromiumVersions An object of key-value pairs with a major Chromium version as the key, and the corresponding major Electron version as the value. var versions = e2c.chromiumVersions; console.log(versions['54']); // returns \"1.4\" fullChromiumVersions An object of key-value pairs with a Chromium version as the key, and an array of the corresponding major Electron versions as the value. var versions = e2c.fullChromiumVersions; console.log(versions['54.0.2840.101']); // returns [\"1.5.1\", \"1.5.0\"] Functions electronToChromium(query) Arguments: Query: string or number, required. A major or full Electron version. A function that returns the corresponding Chromium version for a given Electron function. Returns a string. If you provide it with a major Electron version, it will return a major Chromium version: var chromeVersion = e2c.electronToChromium('1.4'); // chromeVersion is \"53\" If you provide it with a full Electron version, it will return the full Chromium version. var chromeVersion = e2c.electronToChromium('1.4.11'); // chromeVersion is \"53.0.2785.143\" If a query does not match a Chromium version, it will return undefined. var chromeVersion = e2c.electronToChromium('9000'); // chromeVersion is undefined chromiumToElectron(query) Arguments: Query: string or number, required. A major or full Chromium version. Returns a string with the corresponding Electron version for a given Chromium query. If you provide it with a major Chromium version, it will return a major Electron version: var electronVersion = e2c.chromiumToElectron('54'); // electronVersion is \"1.4\" If you provide it with a full Chrome version, it will return an array of full Electron versions. var electronVersions = e2c.chromiumToElectron('56.0.2924.87'); // electronVersions is [\"1.6.3\", \"1.6.2\", \"1.6.1\", \"1.6.0\"] If a query does not match an Electron version, it will return undefined. var electronVersion = e2c.chromiumToElectron('10'); // electronVersion is undefined electronToBrowserList(query) DEPRECATED Arguments: Query: string or number, required. A major Electron version. Deprecated: Browserlist already includes electron-to-chromium. A function that returns a Browserslist query that matches the given major Electron version. Returns a string. If you provide it with a major Electron version, it will return a Browserlist query string that matches the Chromium capabilities: var query = e2c.electronToBrowserList('1.4'); // query is \"Chrome >= 53\" If a query does not match a Chromium version, it will return undefined. var query = e2c.electronToBrowserList('9000'); // query is undefined Importing just versions, fullVersions, chromiumVersions and fullChromiumVersions All lists can be imported on their own, if file size is a concern. versions var versions = require('electron-to-chromium/versions'); fullVersions var fullVersions = require('electron-to-chromium/full-versions'); chromiumVersions var chromiumVersions = require('electron-to-chromium/chromium-versions'); fullChromiumVersions var fullChromiumVersions = require('electron-to-chromium/full-chromium-versions'); Updating This package will be updated with each new Electron release. To update the list, run npm run build.js. Requires internet access as it downloads from the canonical list of Electron versions. To verify correct behaviour, run npm test. License"
  },
  "node_modules/emoji-regex/README.html": {
    "href": "node_modules/emoji-regex/README.html",
    "title": "emoji-regex | accouter",
    "keywords": "emoji-regex emoji-regex offers a regular expression to match all emoji symbols (including textual representations of emoji) as per the Unicode Standard. This repository contains a script that generates this regular expression based on the data from Unicode v12. Because of this, the regular expression can easily be updated whenever new emoji are added to the Unicode standard. Installation Via npm: npm install emoji-regex In Node.js: const emojiRegex = require('emoji-regex'); // Note: because the regular expression has the global flag set, this module // exports a function that returns the regex rather than exporting the regular // expression itself, to make it impossible to (accidentally) mutate the // original regular expression. const text = ` \\u{231A}: ⌚ default emoji presentation character (Emoji_Presentation) \\u{2194}\\u{FE0F}: ↔️ default text presentation character rendered as emoji \\u{1F469}: 👩 emoji modifier base (Emoji_Modifier_Base) \\u{1F469}\\u{1F3FF}: 👩🏿 emoji modifier base followed by a modifier `; const regex = emojiRegex(); let match; while (match = regex.exec(text)) { const emoji = match[0]; console.log(`Matched sequence ${ emoji } — code points: ${ [...emoji].length }`); } Console output: Matched sequence ⌚ — code points: 1 Matched sequence ⌚ — code points: 1 Matched sequence ↔️ — code points: 2 Matched sequence ↔️ — code points: 2 Matched sequence 👩 — code points: 1 Matched sequence 👩 — code points: 1 Matched sequence 👩🏿 — code points: 2 Matched sequence 👩🏿 — code points: 2 To match emoji in their textual representation as well (i.e. emoji that are not Emoji_Presentation symbols and that aren’t forced to render as emoji by a variation selector), require the other regex: const emojiRegex = require('emoji-regex/text.js'); Additionally, in environments which support ES2015 Unicode escapes, you may require ES2015-style versions of the regexes: const emojiRegex = require('emoji-regex/es2015/index.js'); const emojiRegexText = require('emoji-regex/es2015/text.js'); Author Mathias Bynens License emoji-regex is available under the MIT license."
  },
  "node_modules/encodeurl/HISTORY.html": {
    "href": "node_modules/encodeurl/HISTORY.html",
    "title": "1.0.2 / 2018-01-21 | accouter",
    "keywords": "1.0.2 / 2018-01-21 Fix encoding % as last character 1.0.1 / 2016-06-09 Fix encoding unpaired surrogates at start/end of string 1.0.0 / 2016-06-08 Initial release"
  },
  "node_modules/encodeurl/README.html": {
    "href": "node_modules/encodeurl/README.html",
    "title": "encodeurl | accouter",
    "keywords": "encodeurl Encode a URL to a percent-encoded form, excluding already-encoded sequences Installation This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install encodeurl API var encodeUrl = require('encodeurl') encodeUrl(url) Encode a URL to a percent-encoded form, excluding already-encoded sequences. This function will take an already-encoded URL and encode all the non-URL code points (as UTF-8 byte sequences). This function will not encode the \"%\" character unless it is not part of a valid sequence (%20 will be left as-is, but %foo will be encoded as %25foo). This encode is meant to be \"safe\" and does not throw errors. It will try as hard as it can to properly encode the given URL, including replacing any raw, unpaired surrogate pairs with the Unicode replacement character prior to encoding. This function is similar to the intrinsic function encodeURI, except it will not encode the % character if that is part of a valid sequence, will not encode [ and ] (for IPv6 hostnames) and will replace raw, unpaired surrogate pairs with the Unicode replacement character (instead of throwing). Examples Encode a URL containing user-controled data var encodeUrl = require('encodeurl') var escapeHtml = require('escape-html') http.createServer(function onRequest (req, res) { // get encoded form of inbound url var url = encodeUrl(req.url) // create html message var body = '<p>Location ' + escapeHtml(url) + ' not found</p>' // send a 404 res.statusCode = 404 res.setHeader('Content-Type', 'text/html; charset=UTF-8') res.setHeader('Content-Length', String(Buffer.byteLength(body, 'utf-8'))) res.end(body, 'utf-8') }) Encode a URL for use in a header field var encodeUrl = require('encodeurl') var escapeHtml = require('escape-html') var url = require('url') http.createServer(function onRequest (req, res) { // parse inbound url var href = url.parse(req) // set new host for redirect href.host = 'localhost' href.protocol = 'https:' href.slashes = true // create location header var location = encodeUrl(url.format(href)) // create html message var body = '<p>Redirecting to new site: ' + escapeHtml(location) + '</p>' // send a 301 res.statusCode = 301 res.setHeader('Content-Type', 'text/html; charset=UTF-8') res.setHeader('Content-Length', String(Buffer.byteLength(body, 'utf-8'))) res.setHeader('Location', location) res.end(body, 'utf-8') }) Testing $ npm test $ npm run lint References RFC 3986: Uniform Resource Identifier (URI): Generic Syntax WHATWG URL Living Standard License MIT"
  },
  "node_modules/engine.io-client/README.html": {
    "href": "node_modules/engine.io-client/README.html",
    "title": "Engine.IO client | accouter",
    "keywords": "Engine.IO client This is the client for Engine.IO, the implementation of transport-based cross-browser/cross-device bi-directional communication layer for Socket.IO. How to use Standalone You can find an engine.io.js file in this repository, which is a standalone build you can use as follows: <script src=\"/path/to/engine.io.js\"></script> <script> // eio = Socket const socket = eio('ws://localhost'); socket.on('open', () => { socket.on('message', (data) => {}); socket.on('close', () => {}); }); </script> With browserify Engine.IO is a commonjs module, which means you can include it by using require on the browser and package using browserify: install the client package $ npm install engine.io-client write your app code const { Socket } = require('engine.io-client'); const socket = new Socket('ws://localhost'); socket.on('open', () => { socket.on('message', (data) => {}); socket.on('close', () => {}); }); build your app bundle $ browserify app.js > bundle.js include on your page <script src=\"/path/to/bundle.js\"></script> Sending and receiving binary <script src=\"/path/to/engine.io.js\"></script> <script> const socket = eio('ws://localhost/'); socket.binaryType = 'blob'; socket.on('open', () => { socket.send(new Int8Array(5)); socket.on('message', (blob) => {}); socket.on('close', () => {}); }); </script> Node.JS Add engine.io-client to your package.json and then: const { Socket } = require('engine.io-client'); const socket = new Socket('ws://localhost'); socket.on('open', () => { socket.on('message', (data) => {}); socket.on('close', () => {}); }); Node.js with certificates const opts = { key: fs.readFileSync('test/fixtures/client.key'), cert: fs.readFileSync('test/fixtures/client.crt'), ca: fs.readFileSync('test/fixtures/ca.crt') }; const { Socket } = require('engine.io-client'); const socket = new Socket('ws://localhost', opts); socket.on('open', () => { socket.on('message', (data) => {}); socket.on('close', () => {}); }); Node.js with extraHeaders const opts = { extraHeaders: { 'X-Custom-Header-For-My-Project': 'my-secret-access-token', 'Cookie': 'user_session=NI2JlCKF90aE0sJZD9ZzujtdsUqNYSBYxzlTsvdSUe35ZzdtVRGqYFr0kdGxbfc5gUOkR9RGp20GVKza; path=/; expires=Tue, 07-Apr-2015 18:18:08 GMT; secure; HttpOnly' } }; const { Socket } = require('engine.io-client'); const socket = new Socket('ws://localhost', opts); socket.on('open', () => { socket.on('message', (data) => {}); socket.on('close', () => {}); }); In the browser, the WebSocket object does not support additional headers. In case you want to add some headers as part of some authentication mechanism, you can use the transportOptions attribute. Please note that in this case the headers won't be sent in the WebSocket upgrade request. // WILL NOT WORK in the browser const socket = new Socket('http://localhost', { extraHeaders: { 'X-Custom-Header-For-My-Project': 'will not be sent' } }); // WILL NOT WORK const socket = new Socket('http://localhost', { transports: ['websocket'], // polling is disabled transportOptions: { polling: { extraHeaders: { 'X-Custom-Header-For-My-Project': 'will not be sent' } } } }); // WILL WORK const socket = new Socket('http://localhost', { transports: ['polling', 'websocket'], transportOptions: { polling: { extraHeaders: { 'X-Custom-Header-For-My-Project': 'will be used' } } } }); Features Lightweight Runs on browser and node.js seamlessly Transports are independent of Engine Easy to debug Easy to unit test Runs inside HTML5 WebWorker Can send and receive binary data Receives as ArrayBuffer or Blob when in browser, and Buffer or ArrayBuffer in Node When XHR2 or WebSockets are used, binary is emitted directly. Otherwise binary is encoded into base64 strings, and decoded when binary types are supported. With browsers that don't support ArrayBuffer, an object { base64: true, data: dataAsBase64String } is emitted on the message event. API Socket The client class. Mixes in Emitter. Exposed as eio in the browser standalone build. Properties protocol (Number): protocol revision number binaryType (String) : can be set to 'arraybuffer' or 'blob' in browsers, and buffer or arraybuffer in Node. Blob is only used in browser if it's supported. Events open Fired upon successful connection. message Fired when data is received from the server. Arguments String | ArrayBuffer: utf-8 encoded data or ArrayBuffer containing binary data close Fired upon disconnection. In compliance with the WebSocket API spec, this event may be fired even if the open event does not occur (i.e. due to connection error or close()). error Fired when an error occurs. flush Fired upon completing a buffer flush drain Fired after drain event of transport if writeBuffer is empty upgradeError Fired if an error occurs with a transport we're trying to upgrade to. upgrade Fired upon upgrade success, after the new transport is set ping Fired upon receiving a ping packet. pong Fired upon flushing a pong packet (ie: actual packet write out) Methods constructor Initializes the client Parameters String uri Object: optional, options object Options agent (http.Agent): http.Agent to use, defaults to false (NodeJS only) upgrade (Boolean): defaults to true, whether the client should try to upgrade the transport from long-polling to something better. forceBase64 (Boolean): forces base 64 encoding for polling transport even when XHR2 responseType is available and WebSocket even if the used standard supports binary. withCredentials (Boolean): defaults to false, whether to include credentials (cookies, authorization headers, TLS client certificates, etc.) with cross-origin XHR polling requests. timestampRequests (Boolean): whether to add the timestamp with each transport request. Note: polling requests are always stamped unless this option is explicitly set to false (false) timestampParam (String): timestamp parameter (t) path (String): path to connect to, default is /engine.io transports (Array): a list of transports to try (in order). Defaults to ['polling', 'websocket', 'webtransport']. Engine always attempts to connect directly with the first one, provided the feature detection test for it passes. transportOptions (Object): hash of options, indexed by transport name, overriding the common options for the given transport rememberUpgrade (Boolean): defaults to false. If true and if the previous websocket connection to the server succeeded, the connection attempt will bypass the normal upgrade process and will initially try websocket. A connection attempt following a transport error will use the normal upgrade process. It is recommended you turn this on only when using SSL/TLS connections, or if you know that your network does not block websockets. pfx (String|Buffer): Certificate, Private key and CA certificates to use for SSL. Can be used in Node.js client environment to manually specify certificate information. key (String): Private key to use for SSL. Can be used in Node.js client environment to manually specify certificate information. passphrase (String): A string of passphrase for the private key or pfx. Can be used in Node.js client environment to manually specify certificate information. cert (String): Public x509 certificate to use. Can be used in Node.js client environment to manually specify certificate information. ca (String|Array): An authority certificate or array of authority certificates to check the remote host against.. Can be used in Node.js client environment to manually specify certificate information. ciphers (String): A string describing the ciphers to use or exclude. Consult the cipher format list for details on the format. Can be used in Node.js client environment to manually specify certificate information. rejectUnauthorized (Boolean): If true, the server certificate is verified against the list of supplied CAs. An 'error' event is emitted if verification fails. Verification happens at the connection level, before the HTTP request is sent. Can be used in Node.js client environment to manually specify certificate information. perMessageDeflate (Object|Boolean): parameters of the WebSocket permessage-deflate extension (see ws module api docs). Set to false to disable. (true) threshold (Number): data is compressed only if the byte size is above this value. This option is ignored on the browser. (1024) extraHeaders (Object): Headers that will be passed for each request to the server (via xhr-polling and via websockets). These values then can be used during handshake or for special proxies. Can only be used in Node.js client environment. onlyBinaryUpgrades (Boolean): whether transport upgrades should be restricted to transports supporting binary data (false) forceNode (Boolean): Uses NodeJS implementation for websockets - even if there is a native Browser-Websocket available, which is preferred by default over the NodeJS implementation. (This is useful when using hybrid platforms like nw.js or electron) (false, NodeJS only) localAddress (String): the local IP address to connect to autoUnref (Boolean): whether the transport should be unref'd upon creation. This calls unref on the underlying timers and sockets so that the program is allowed to exit if they are the only timers/sockets in the event system (Node.js only) useNativeTimers (Boolean): Whether to always use the native timeouts. This allows the client to reconnect when the native timeout functions are overridden, such as when mock clocks are installed with @sinonjs/fake-timers. Polling-only options requestTimeout (Number): Timeout for xhr-polling requests in milliseconds (0) Websocket-only options protocols (Array): a list of subprotocols (see MDN reference) closeOnBeforeunload (Boolean): whether to silently close the connection when the beforeunload event is emitted in the browser (defaults to false) send Sends a message to the server Parameters String | ArrayBuffer | ArrayBufferView | Blob: data to send Object: optional, options object Function: optional, callback upon drain Options compress (Boolean): whether to compress sending data. This option is ignored and forced to be true on the browser. (true) close Disconnects the client. Transport The transport class. Private. Inherits from EventEmitter. Events poll: emitted by polling transports upon starting a new request pollComplete: emitted by polling transports upon completing a request drain: emitted by polling transports upon a buffer drain Tests engine.io-client is used to test engine. Running the engine.io test suite ensures the client works and vice-versa. Browser tests are run using zuul. You can run the tests locally using the following command. ./node_modules/.bin/zuul --local 8080 -- test/index.js Additionally, engine.io-client has a standalone test suite you can run with make test which will run node.js and browser tests. You must have zuul setup with a saucelabs account. Support The support channels for engine.io-client are the same as socket.io: irc.freenode.net #socket.io Google Groups Website Development To contribute patches, run tests or benchmarks, make sure to clone the repository: git clone git://github.com/socketio/engine.io-client.git Then: cd engine.io-client npm install See the Tests section above for how to run tests before submitting any patches. License MIT - Copyright (c) 2014 Automattic, Inc."
  },
  "node_modules/engine.io-client/node_modules/debug/README.html": {
    "href": "node_modules/engine.io-client/node_modules/debug/README.html",
    "title": "debug | accouter",
    "keywords": "debug A tiny JavaScript debugging utility modelled after Node.js core's debugging technique. Works in Node.js and web browsers. Installation $ npm install debug Usage debug exposes a function; simply pass this function the name of your module, and it will return a decorated version of console.error for you to pass debug statements to. This will allow you to toggle the debug output for different parts of your module as well as the module as a whole. Example app.js: var debug = require('debug')('http') , http = require('http') , name = 'My App'; // fake app debug('booting %o', name); http.createServer(function(req, res){ debug(req.method + ' ' + req.url); res.end('hello\\n'); }).listen(3000, function(){ debug('listening'); }); // fake worker of some kind require('./worker'); Example worker.js: var a = require('debug')('worker:a') , b = require('debug')('worker:b'); function work() { a('doing lots of uninteresting work'); setTimeout(work, Math.random() * 1000); } work(); function workb() { b('doing some work'); setTimeout(workb, Math.random() * 2000); } workb(); The DEBUG environment variable is then used to enable these based on space or comma-delimited names. Here are some examples: Windows command prompt notes CMD On Windows the environment variable is set using the set command. set DEBUG=*,-not_this Example: set DEBUG=* & node app.js PowerShell (VS Code default) PowerShell uses different syntax to set environment variables. $env:DEBUG = \"*,-not_this\" Example: $env:DEBUG='app';node app.js Then, run the program to be debugged as usual. npm script example: \"windowsDebug\": \"@powershell -Command $env:DEBUG='*';node app.js\", Namespace Colors Every debug instance has a color generated for it based on its namespace name. This helps when visually parsing the debug output to identify which debug instance a debug line belongs to. Node.js In Node.js, colors are enabled when stderr is a TTY. You also should install the supports-color module alongside debug, otherwise debug will only use a small handful of basic colors. Web Browser Colors are also enabled on \"Web Inspectors\" that understand the %c formatting option. These are WebKit web inspectors, Firefox (since version 31) and the Firebug plugin for Firefox (any version). Millisecond diff When actively developing an application it can be useful to see when the time spent between one debug() call and the next. Suppose for example you invoke debug() before requesting a resource, and after as well, the \"+NNNms\" will show you how much time was spent between calls. When stdout is not a TTY, Date#toISOString() is used, making it more useful for logging the debug information as shown below: Conventions If you're using this in one or more of your libraries, you should use the name of your library so that developers may toggle debugging as desired without guessing names. If you have more than one debuggers you should prefix them with your library name and use \":\" to separate features. For example \"bodyParser\" from Connect would then be \"connect:bodyParser\". If you append a \"*\" to the end of your name, it will always be enabled regardless of the setting of the DEBUG environment variable. You can then use it for normal output as well as debug output. Wildcards The * character may be used as a wildcard. Suppose for example your library has debuggers named \"connect:bodyParser\", \"connect:compress\", \"connect:session\", instead of listing all three with DEBUG=connect:bodyParser,connect:compress,connect:session, you may simply do DEBUG=connect:*, or to run everything using this module simply use DEBUG=*. You can also exclude specific debuggers by prefixing them with a \"-\" character. For example, DEBUG=*,-connect:* would include all debuggers except those starting with \"connect:\". Environment Variables When running through Node.js, you can set a few environment variables that will change the behavior of the debug logging: Name Purpose DEBUG Enables/disables specific debugging namespaces. DEBUG_HIDE_DATE Hide date from debug output (non-TTY). DEBUG_COLORS Whether or not to use colors in the debug output. DEBUG_DEPTH Object inspection depth. DEBUG_SHOW_HIDDEN Shows hidden properties on inspected objects. Note: The environment variables beginning with DEBUG_ end up being converted into an Options object that gets used with %o/%O formatters. See the Node.js documentation for util.inspect() for the complete list. Formatters Debug uses printf-style formatting. Below are the officially supported formatters: Formatter Representation %O Pretty-print an Object on multiple lines. %o Pretty-print an Object all on a single line. %s String. %d Number (both integer and float). %j JSON. Replaced with the string '[Circular]' if the argument contains circular references. %% Single percent sign ('%'). This does not consume an argument. Custom formatters You can add custom formatters by extending the debug.formatters object. For example, if you wanted to add support for rendering a Buffer as hex with %h, you could do something like: const createDebug = require('debug') createDebug.formatters.h = (v) => { return v.toString('hex') } // …elsewhere const debug = createDebug('foo') debug('this is hex: %h', new Buffer('hello world')) // foo this is hex: 68656c6c6f20776f726c6421 +0ms Browser Support You can build a browser-ready script using browserify, or just use the browserify-as-a-service build, if you don't want to build it yourself. Debug's enable state is currently persisted by localStorage. Consider the situation shown below where you have worker:a and worker:b, and wish to debug both. You can enable this using localStorage.debug: localStorage.debug = 'worker:*' And then refresh the page. a = debug('worker:a'); b = debug('worker:b'); setInterval(function(){ a('doing some work'); }, 1000); setInterval(function(){ b('doing some work'); }, 1200); In Chromium-based web browsers (e.g. Brave, Chrome, and Electron), the JavaScript console will—by default—only show messages logged by debug if the \"Verbose\" log level is enabled. Output streams By default debug will log to stderr, however this can be configured per-namespace by overriding the log method: Example stdout.js: var debug = require('debug'); var error = debug('app:error'); // by default stderr is used error('goes to stderr!'); var log = debug('app:log'); // set this namespace to log via console.log log.log = console.log.bind(console); // don't forget to bind to console! log('goes to stdout'); error('still goes to stderr!'); // set all output to go via console.info // overrides all per-namespace log settings debug.log = console.info.bind(console); error('now goes to stdout via console.info'); log('still goes to stdout, but via console.info now'); Extend You can simply extend debugger const log = require('debug')('auth'); //creates new debug instance with extended namespace const logSign = log.extend('sign'); const logLogin = log.extend('login'); log('hello'); // auth hello logSign('hello'); //auth:sign hello logLogin('hello'); //auth:login hello Set dynamically You can also enable debug dynamically by calling the enable() method : let debug = require('debug'); console.log(1, debug.enabled('test')); debug.enable('test'); console.log(2, debug.enabled('test')); debug.disable(); console.log(3, debug.enabled('test')); print : 1 false 2 true 3 false Usage : enable(namespaces) namespaces can include modes separated by a colon and wildcards. Note that calling enable() completely overrides previously set DEBUG variable : $ DEBUG=foo node -e 'var dbg = require(\"debug\"); dbg.enable(\"bar\"); console.log(dbg.enabled(\"foo\"))' => false disable() Will disable all namespaces. The functions returns the namespaces currently enabled (and skipped). This can be useful if you want to disable debugging temporarily without knowing what was enabled to begin with. For example: let debug = require('debug'); debug.enable('foo:*,-foo:bar'); let namespaces = debug.disable(); debug.enable(namespaces); Note: There is no guarantee that the string will be identical to the initial enable string, but semantically they will be identical. Checking whether a debug target is enabled After you've created a debug instance, you can determine whether or not it is enabled by checking the enabled property: const debug = require('debug')('http'); if (debug.enabled) { // do stuff... } You can also manually toggle this property to force the debug instance to be enabled or disabled. Usage in child processes Due to the way debug detects if the output is a TTY or not, colors are not shown in child processes when stderr is piped. A solution is to pass the DEBUG_COLORS=1 environment variable to the child process. For example: worker = fork(WORKER_WRAP_PATH, [workerPath], { stdio: [ /* stdin: */ 0, /* stdout: */ 'pipe', /* stderr: */ 'pipe', 'ipc', ], env: Object.assign({}, process.env, { DEBUG_COLORS: 1 // without this settings, colors won't be shown }), }); worker.stderr.pipe(process.stderr, { end: false }); Authors TJ Holowaychuk Nathan Rajlich Andrew Rhyne Josh Junon Backers Support us with a monthly donation and help us continue our activities. [Become a backer] Sponsors Become a sponsor and get your logo on our README on Github with a link to your site. [Become a sponsor] License (The MIT License) Copyright (c) 2014-2017 TJ Holowaychuk <tj@vision-media.ca&gt; Copyright (c) 2018-2021 Josh Junon Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/engine.io-client/node_modules/ms/license.html": {
    "href": "node_modules/engine.io-client/node_modules/ms/license.html",
    "title": "| accouter",
    "keywords": "The MIT License (MIT) Copyright (c) 2016 Zeit, Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/engine.io-client/node_modules/ms/readme.html": {
    "href": "node_modules/engine.io-client/node_modules/ms/readme.html",
    "title": "ms | accouter",
    "keywords": "ms Use this package to easily convert various time formats to milliseconds. Examples ms('2 days') // 172800000 ms('1d') // 86400000 ms('10h') // 36000000 ms('2.5 hrs') // 9000000 ms('2h') // 7200000 ms('1m') // 60000 ms('5s') // 5000 ms('1y') // 31557600000 ms('100') // 100 ms('-3 days') // -259200000 ms('-1h') // -3600000 ms('-200') // -200 Convert from Milliseconds ms(60000) // \"1m\" ms(2 * 60000) // \"2m\" ms(-3 * 60000) // \"-3m\" ms(ms('10 hours')) // \"10h\" Time Format Written-Out ms(60000, { long: true }) // \"1 minute\" ms(2 * 60000, { long: true }) // \"2 minutes\" ms(-3 * 60000, { long: true }) // \"-3 minutes\" ms(ms('10 hours'), { long: true }) // \"10 hours\" Features Works both in Node.js and in the browser If a number is supplied to ms, a string with a unit is returned If a string that contains the number is supplied, it returns it as a number (e.g.: it returns 100 for '100') If you pass a string with a number and a valid unit, the number of equivalent milliseconds is returned Related Packages ms.macro - Run ms as a macro at build-time. Caught a Bug? Fork this repository to your own GitHub account and then clone it to your local device Link the package to the global module directory: npm link Within the module you want to test your local development instance of ms, just link it to the dependencies: npm link ms. Instead of the default one from npm, Node.js will now use your clone of ms! As always, you can run the tests using: npm test"
  },
  "node_modules/engine.io-parser/Readme.html": {
    "href": "node_modules/engine.io-parser/Readme.html",
    "title": "engine.io-parser | accouter",
    "keywords": "engine.io-parser This is the JavaScript parser for the engine.io protocol encoding, shared by both engine.io-client and engine.io. How to use Standalone The parser can encode/decode packets, payloads, and payloads as binary with the following methods: encodePacket, decodePacket, encodePayload, decodePayload. Example: const parser = require(\"engine.io-parser\"); const data = Buffer.from([ 1, 2, 3, 4 ]); parser.encodePacket({ type: \"message\", data }, encoded => { const decodedData = parser.decodePacket(encoded); // decodedData === data }); With browserify Engine.IO Parser is a commonjs module, which means you can include it by using require on the browser and package using browserify: install the parser package npm install engine.io-parser write your app code const parser = require(\"engine.io-parser\"); const testBuffer = new Int8Array(10); for (let i = 0; i < testBuffer.length; i++) testBuffer[i] = i; const packets = [{ type: \"message\", data: testBuffer.buffer }, { type: \"message\", data: \"hello\" }]; parser.encodePayload(packets, encoded => { parser.decodePayload(encoded, (packet, index, total) => { const isLast = index + 1 == total; if (!isLast) { const buffer = new Int8Array(packet.data); // testBuffer } else { const message = packet.data; // \"hello\" } }); }); build your app bundle $ browserify app.js > bundle.js include on your page <script src=\"/path/to/bundle.js\"></script> Features Runs on browser and node.js seamlessly Runs inside HTML5 WebWorker Can encode and decode packets Encodes from/to ArrayBuffer or Blob when in browser, and Buffer or ArrayBuffer in Node API Note: cb(type) means the type is a callback function that contains a parameter of type type when called. Node encodePacket Encodes a packet. Parameters Object: the packet to encode, has type and data. data: can be a String, Number, Buffer, ArrayBuffer Boolean: binary support Function: callback, returns the encoded packet (cb(String)) decodePacket Decodes a packet. Data also available as an ArrayBuffer if requested. Returns data as String or (Blob on browser, ArrayBuffer on Node) Parameters String | ArrayBuffer: the packet to decode, has type and data String: optional, the binary type encodePayload Encodes multiple messages (payload). If any contents are binary, they will be encoded as base64 strings. Base64 encoded strings are marked with a b before the length specifier Parameters Array: an array of packets Function: callback, returns the encoded payload (cb(String)) decodePayload Decodes data when a payload is maybe expected. Possible binary contents are decoded from their base64 representation. Parameters String: the payload Function: callback, returns (cb(Object: packet, Number:packet index, Number:packet total)) Tests Standalone tests can be run with npm test which will run the node.js tests. Browser tests are run using zuul. (You must have zuul setup with a saucelabs account.) You can run the tests locally using the following command: npm run test:browser Support The support channels for engine.io-parser are the same as socket.io: irc.freenode.net #socket.io Github Discussions Website Development To contribute patches, run tests or benchmarks, make sure to clone the repository: git clone git://github.com/socketio/engine.io-parser.git Then: cd engine.io-parser npm ci See the Tests section above for how to run tests before submitting any patches. License MIT"
  },
  "node_modules/engine.io/README.html": {
    "href": "node_modules/engine.io/README.html",
    "title": "Engine.IO: the realtime engine | accouter",
    "keywords": "Engine.IO: the realtime engine Engine.IO is the implementation of transport-based cross-browser/cross-device bi-directional communication layer for Socket.IO. How to use Server (A) Listening on a port const engine = require('engine.io'); const server = engine.listen(80); server.on('connection', socket => { socket.send('utf 8 string'); socket.send(Buffer.from([0, 1, 2, 3, 4, 5])); // binary data }); (B) Intercepting requests for a http.Server const engine = require('engine.io'); const http = require('http').createServer().listen(3000); const server = engine.attach(http); server.on('connection', socket => { socket.on('message', data => { }); socket.on('close', () => { }); }); (C) Passing in requests const engine = require('engine.io'); const server = new engine.Server(); server.on('connection', socket => { socket.send('hi'); }); // … httpServer.on('upgrade', (req, socket, head) => { server.handleUpgrade(req, socket, head); }); httpServer.on('request', (req, res) => { server.handleRequest(req, res); }); Client <script src=\"/path/to/engine.io.js\"></script> <script> const socket = new eio.Socket('ws://localhost/'); socket.on('open', () => { socket.on('message', data => {}); socket.on('close', () => {}); }); </script> For more information on the client refer to the engine-client repository. What features does it have? Maximum reliability. Connections are established even in the presence of: proxies and load balancers. personal firewall and antivirus software. for more information refer to Goals and Architecture sections Minimal client size aided by: lazy loading of flash transports. lack of redundant transports. Scalable load balancer friendly Future proof 100% Node.JS core style No API sugar (left for higher level projects) API Server Top-level These are exposed by require('engine.io'): Events flush Called when a socket buffer is being flushed. Arguments Socket: socket being flushed Array: write buffer drain Called when a socket buffer is drained Arguments Socket: socket being flushed Properties protocol (Number): protocol revision number Server: Server class constructor Socket: Socket class constructor Transport (Function): transport constructor transports (Object): map of available transports Methods () Returns a new Server instance. If the first argument is an http.Server then the new Server instance will be attached to it. Otherwise, the arguments are passed directly to the Server constructor. Parameters http.Server: optional, server to attach to. Object: optional, options object (see Server#constructor api docs below) The following are identical ways to instantiate a server and then attach it. const httpServer; // previously created with `http.createServer();` from node.js api. // create a server first, and then attach const eioServer = require('engine.io').Server(); eioServer.attach(httpServer); // or call the module as a function to get `Server` const eioServer = require('engine.io')(); eioServer.attach(httpServer); // immediately attach const eioServer = require('engine.io')(httpServer); // with custom options const eioServer = require('engine.io')(httpServer, { maxHttpBufferSize: 1e3 }); listen Creates an http.Server which listens on the given port and attaches WS to it. It returns 501 Not Implemented for regular http requests. Parameters Number: port to listen on. Object: optional, options object Function: callback for listen. Options All options from Server.attach method, documented below. Additionally See Server constructor below for options you can pass for creating the new Server Returns Server const engine = require('engine.io'); const server = engine.listen(3000, { pingTimeout: 2000, pingInterval: 10000 }); server.on('connection', /* ... */); attach Captures upgrade requests for a http.Server. In other words, makes a regular http.Server WebSocket-compatible. Parameters http.Server: server to attach to. Object: optional, options object Options All options from Server.attach method, documented below. Additionally See Server constructor below for options you can pass for creating the new Server Returns Server a new Server instance. const engine = require('engine.io'); const httpServer = require('http').createServer().listen(3000); const server = engine.attach(httpServer, { wsEngine: require('eiows').Server // requires having eiows as dependency }); server.on('connection', /* ... */); Server The main server/manager. Inherits from EventEmitter. Events connection Fired when a new connection is established. Arguments Socket: a Socket object initial_headers Fired on the first request of the connection, before writing the response headers Arguments headers (Object): a hash of headers req (http.IncomingMessage): the request headers Fired on the all requests of the connection, before writing the response headers Arguments headers (Object): a hash of headers req (http.IncomingMessage): the request connection_error Fired when an error occurs when establishing the connection. Arguments error: an object with following properties: req (http.IncomingMessage): the request that was dropped code (Number): one of Server.errors message (string): one of Server.errorMessages context (Object): extra info about the error Code Message 0 \"Transport unknown\" 1 \"Session ID unknown\" 2 \"Bad handshake method\" 3 \"Bad request\" 4 \"Forbidden\" 5 \"Unsupported protocol version\" Properties Important: if you plan to use Engine.IO in a scalable way, please keep in mind the properties below will only reflect the clients connected to a single process. clients (Object): hash of connected clients by id. clientsCount (Number): number of connected clients. Methods constructor Initializes the server Parameters Object: optional, options object Options pingTimeout (Number): how many ms without a pong packet to consider the connection closed (20000) pingInterval (Number): how many ms before sending a new ping packet (25000) upgradeTimeout (Number): how many ms before an uncompleted transport upgrade is cancelled (10000) maxHttpBufferSize (Number): how many bytes or characters a message can be, before closing the session (to avoid DoS). Default value is 1E6. allowRequest (Function): A function that receives a given handshake or upgrade request as its first parameter, and can decide whether to continue or not. The second argument is a function that needs to be called with the decided information: fn(err, success), where success is a boolean value where false means that the request is rejected, and err is an error code. transports (<Array> String): transports to allow connections to (['polling', 'websocket']) allowUpgrades (Boolean): whether to allow transport upgrades (true) perMessageDeflate (Object|Boolean): parameters of the WebSocket permessage-deflate extension (see ws module api docs). Set to true to enable. (defaults to false) threshold (Number): data is compressed only if the byte size is above this value (1024) httpCompression (Object|Boolean): parameters of the http compression for the polling transports (see zlib api docs). Set to false to disable. (true) threshold (Number): data is compressed only if the byte size is above this value (1024) cookie (Object|Boolean): configuration of the cookie that contains the client sid to send as part of handshake response headers. This cookie might be used for sticky-session. Defaults to not sending any cookie (false). See here for all supported options. wsEngine (Function): what WebSocket server implementation to use. Specified module must conform to the ws interface (see ws module api docs). Default value is ws. An alternative c++ addon is also available by installing eiows module. cors (Object): the options that will be forwarded to the cors module. See there for all available options. Defaults to no CORS allowed. initialPacket (Object): an optional packet which will be concatenated to the handshake packet emitted by Engine.IO. allowEIO3 (Boolean): whether to support v3 Engine.IO clients (defaults to false) close Closes all clients Returns Server for chaining handleRequest Called internally when a Engine request is intercepted. Parameters http.IncomingMessage: a node request object http.ServerResponse: a node response object Returns Server for chaining handleUpgrade Called internally when a Engine ws upgrade is intercepted. Parameters (same as upgrade event) http.IncomingMessage: a node request object net.Stream: TCP socket for the request Buffer: legacy tail bytes Returns Server for chaining attach Attach this Server instance to an http.Server Captures upgrade requests for a http.Server. In other words, makes a regular http.Server WebSocket-compatible. Parameters http.Server: server to attach to. Object: optional, options object Options path (String): name of the path to capture (/engine.io). destroyUpgrade (Boolean): destroy unhandled upgrade requests (true) destroyUpgradeTimeout (Number): milliseconds after which unhandled requests are ended (1000) generateId Generate a socket id. Overwrite this method to generate your custom socket id. Parameters http.IncomingMessage: a node request object Returns A socket id for connected client. Socket A representation of a client. Inherits from EventEmitter. Events close Fired when the client is disconnected. Arguments String: reason for closing Object: description object (optional) message Fired when the client sends a message. Arguments String or Buffer: Unicode string or Buffer with binary contents error Fired when an error occurs. Arguments Error: error object upgrading Fired when the client starts the upgrade to a better transport like WebSocket. Arguments Object: the transport upgrade Fired when the client completes the upgrade to a better transport like WebSocket. Arguments Object: the transport flush Called when the write buffer is being flushed. Arguments Array: write buffer drain Called when the write buffer is drained packet Called when a socket received a packet (message, ping) Arguments type: packet type data: packet data (if type is message) packetCreate Called before a socket sends a packet (message, ping) Arguments type: packet type data: packet data (if type is message) heartbeat Called when ping or pong packed is received (depends of client version) Properties id (String): unique identifier server (Server): engine parent reference request (http.IncomingMessage): request that originated the Socket upgraded (Boolean): whether the transport has been upgraded readyState (String): opening|open|closing|closed transport (Transport): transport reference Methods send: Sends a message, performing message = toString(arguments[0]) unless sending binary data, which is sent as is. Parameters String | Buffer | ArrayBuffer | ArrayBufferView: a string or any object implementing toString(), with outgoing data, or a Buffer or ArrayBuffer with binary data. Also any ArrayBufferView can be sent as is. Object: optional, options object Function: optional, a callback executed when the message gets flushed out by the transport Options compress (Boolean): whether to compress sending data. This option might be ignored and forced to be true when using polling. (true) Returns Socket for chaining close Disconnects the client Returns Socket for chaining Client Exposed in the eio global namespace (in the browser), or by require('engine.io-client') (in Node.JS). For the client API refer to the engine-client repository. Debug / logging Engine.IO is powered by debug. In order to see all the debug output, run your app with the environment variable DEBUG including the desired scope. To see the output from all of Engine.IO's debugging scopes you can use: DEBUG=engine* node myapp Transports polling: XHR / JSONP polling transport. websocket: WebSocket transport. Plugins engine.io-conflation: Makes conflation and aggregation of messages straightforward. Support The support channels for engine.io are the same as socket.io: irc.freenode.net #socket.io Google Groups Website Development To contribute patches, run tests or benchmarks, make sure to clone the repository: git clone git://github.com/LearnBoost/engine.io.git Then: cd engine.io npm install Tests Tests run with npm test. It runs the server tests that are aided by the usage of engine.io-client. Make sure npm install is run first. Goals The main goal of Engine is ensuring the most reliable realtime communication. Unlike the previous Socket.IO core, it always establishes a long-polling connection first, then tries to upgrade to better transports that are \"tested\" on the side. During the lifetime of the Socket.IO projects, we've found countless drawbacks to relying on HTML5 WebSocket or Flash Socket as the first connection mechanisms. Both are clearly the right way of establishing a bidirectional communication, with HTML5 WebSocket being the way of the future. However, to answer most business needs, alternative traditional HTTP 1.1 mechanisms are just as good as delivering the same solution. WebSocket based connections have two fundamental benefits: Better server performance A: Load balancers Load balancing a long polling connection poses a serious architectural nightmare since requests can come from any number of open sockets by the user agent, but they all need to be routed to the process and computer that owns the Engine connection. This negatively impacts RAM and CPU usage. B: Network traffic WebSocket is designed around the premise that each message frame has to be surrounded by the least amount of data. In HTTP 1.1 transports, each message frame is surrounded by HTTP headers and chunked encoding frames. If you try to send the message \"Hello world\" with xhr-polling, the message ultimately becomes larger than if you were to send it with WebSocket. C: Lightweight parser As an effect of B, the server has to do a lot more work to parse the network data and figure out the message when traditional HTTP requests are used (as in long polling). This means that another advantage of WebSocket is less server CPU usage. Better user experience Due to the reasons stated in point 1, the most important effect of being able to establish a WebSocket connection is raw data transfer speed, which translates in some cases in better user experience. Applications with heavy realtime interaction (such as games) will benefit greatly, whereas applications like realtime chat (Gmail/Facebook), newsfeeds (Facebook) or timelines (Twitter) will have negligible user experience improvements. Having said this, attempting to establish a WebSocket connection directly so far has proven problematic: Proxies Many corporate proxies block WebSocket traffic. Personal firewall and antivirus software As a result of our research, we've found that at least 3 personal security applications block WebSocket traffic. Cloud application platforms Platforms like Heroku or No.de have had trouble keeping up with the fast-paced nature of the evolution of the WebSocket protocol. Applications therefore end up inevitably using long polling, but the seamless installation experience of Socket.IO we strive for (\"require() it and it just works\") disappears. Some of these problems have solutions. In the case of proxies and personal programs, however, the solutions many times involve upgrading software. Experience has shown that relying on client software upgrades to deliver a business solution is fruitless: the very existence of this project has to do with a fragmented panorama of user agent distribution, with clients connecting with latest versions of the most modern user agents (Chrome, Firefox and Safari), but others with versions as low as IE 5.5. From the user perspective, an unsuccessful WebSocket connection can translate in up to at least 10 seconds of waiting for the realtime application to begin exchanging data. This perceptively hurts user experience. To summarize, Engine focuses on reliability and user experience first, marginal potential UX improvements and increased server performance second. Engine is the result of all the lessons learned with WebSocket in the wild. Architecture The main premise of Engine, and the core of its existence, is the ability to swap transports on the fly. A connection starts as xhr-polling, but it can switch to WebSocket. The central problem this poses is: how do we switch transports without losing messages? Engine only switches from polling to another transport in between polling cycles. Since the server closes the connection after a certain timeout when there's no activity, and the polling transport implementation buffers messages in between connections, this ensures no message loss and optimal performance. Another benefit of this design is that we workaround almost all the limitations of Flash Socket, such as slow connection times, increased file size (we can safely lazy load it without hurting user experience), etc. FAQ Can I use engine without Socket.IO ? Absolutely. Although the recommended framework for building realtime applications is Socket.IO, since it provides fundamental features for real-world applications such as multiplexing, reconnection support, etc. Engine is to Socket.IO what Connect is to Express. An essential piece for building realtime frameworks, but something you probably won't be using for building actual applications. Does the server serve the client? No. The main reason is that Engine is meant to be bundled with frameworks. Socket.IO includes Engine, therefore serving two clients is not necessary. If you use Socket.IO, including <script src=\"/socket.io/socket.io.js\"> has you covered. Can I implement Engine in other languages? Absolutely. The engine.io-protocol repository contains the most up-to-date description of the specification at all times. License (The MIT License) Copyright (c) 2014 Guillermo Rauch <guillermo@learnboost.com&gt; Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/engine.io/node_modules/debug/README.html": {
    "href": "node_modules/engine.io/node_modules/debug/README.html",
    "title": "debug | accouter",
    "keywords": "debug A tiny JavaScript debugging utility modelled after Node.js core's debugging technique. Works in Node.js and web browsers. Installation $ npm install debug Usage debug exposes a function; simply pass this function the name of your module, and it will return a decorated version of console.error for you to pass debug statements to. This will allow you to toggle the debug output for different parts of your module as well as the module as a whole. Example app.js: var debug = require('debug')('http') , http = require('http') , name = 'My App'; // fake app debug('booting %o', name); http.createServer(function(req, res){ debug(req.method + ' ' + req.url); res.end('hello\\n'); }).listen(3000, function(){ debug('listening'); }); // fake worker of some kind require('./worker'); Example worker.js: var a = require('debug')('worker:a') , b = require('debug')('worker:b'); function work() { a('doing lots of uninteresting work'); setTimeout(work, Math.random() * 1000); } work(); function workb() { b('doing some work'); setTimeout(workb, Math.random() * 2000); } workb(); The DEBUG environment variable is then used to enable these based on space or comma-delimited names. Here are some examples: Windows command prompt notes CMD On Windows the environment variable is set using the set command. set DEBUG=*,-not_this Example: set DEBUG=* & node app.js PowerShell (VS Code default) PowerShell uses different syntax to set environment variables. $env:DEBUG = \"*,-not_this\" Example: $env:DEBUG='app';node app.js Then, run the program to be debugged as usual. npm script example: \"windowsDebug\": \"@powershell -Command $env:DEBUG='*';node app.js\", Namespace Colors Every debug instance has a color generated for it based on its namespace name. This helps when visually parsing the debug output to identify which debug instance a debug line belongs to. Node.js In Node.js, colors are enabled when stderr is a TTY. You also should install the supports-color module alongside debug, otherwise debug will only use a small handful of basic colors. Web Browser Colors are also enabled on \"Web Inspectors\" that understand the %c formatting option. These are WebKit web inspectors, Firefox (since version 31) and the Firebug plugin for Firefox (any version). Millisecond diff When actively developing an application it can be useful to see when the time spent between one debug() call and the next. Suppose for example you invoke debug() before requesting a resource, and after as well, the \"+NNNms\" will show you how much time was spent between calls. When stdout is not a TTY, Date#toISOString() is used, making it more useful for logging the debug information as shown below: Conventions If you're using this in one or more of your libraries, you should use the name of your library so that developers may toggle debugging as desired without guessing names. If you have more than one debuggers you should prefix them with your library name and use \":\" to separate features. For example \"bodyParser\" from Connect would then be \"connect:bodyParser\". If you append a \"*\" to the end of your name, it will always be enabled regardless of the setting of the DEBUG environment variable. You can then use it for normal output as well as debug output. Wildcards The * character may be used as a wildcard. Suppose for example your library has debuggers named \"connect:bodyParser\", \"connect:compress\", \"connect:session\", instead of listing all three with DEBUG=connect:bodyParser,connect:compress,connect:session, you may simply do DEBUG=connect:*, or to run everything using this module simply use DEBUG=*. You can also exclude specific debuggers by prefixing them with a \"-\" character. For example, DEBUG=*,-connect:* would include all debuggers except those starting with \"connect:\". Environment Variables When running through Node.js, you can set a few environment variables that will change the behavior of the debug logging: Name Purpose DEBUG Enables/disables specific debugging namespaces. DEBUG_HIDE_DATE Hide date from debug output (non-TTY). DEBUG_COLORS Whether or not to use colors in the debug output. DEBUG_DEPTH Object inspection depth. DEBUG_SHOW_HIDDEN Shows hidden properties on inspected objects. Note: The environment variables beginning with DEBUG_ end up being converted into an Options object that gets used with %o/%O formatters. See the Node.js documentation for util.inspect() for the complete list. Formatters Debug uses printf-style formatting. Below are the officially supported formatters: Formatter Representation %O Pretty-print an Object on multiple lines. %o Pretty-print an Object all on a single line. %s String. %d Number (both integer and float). %j JSON. Replaced with the string '[Circular]' if the argument contains circular references. %% Single percent sign ('%'). This does not consume an argument. Custom formatters You can add custom formatters by extending the debug.formatters object. For example, if you wanted to add support for rendering a Buffer as hex with %h, you could do something like: const createDebug = require('debug') createDebug.formatters.h = (v) => { return v.toString('hex') } // …elsewhere const debug = createDebug('foo') debug('this is hex: %h', new Buffer('hello world')) // foo this is hex: 68656c6c6f20776f726c6421 +0ms Browser Support You can build a browser-ready script using browserify, or just use the browserify-as-a-service build, if you don't want to build it yourself. Debug's enable state is currently persisted by localStorage. Consider the situation shown below where you have worker:a and worker:b, and wish to debug both. You can enable this using localStorage.debug: localStorage.debug = 'worker:*' And then refresh the page. a = debug('worker:a'); b = debug('worker:b'); setInterval(function(){ a('doing some work'); }, 1000); setInterval(function(){ b('doing some work'); }, 1200); In Chromium-based web browsers (e.g. Brave, Chrome, and Electron), the JavaScript console will—by default—only show messages logged by debug if the \"Verbose\" log level is enabled. Output streams By default debug will log to stderr, however this can be configured per-namespace by overriding the log method: Example stdout.js: var debug = require('debug'); var error = debug('app:error'); // by default stderr is used error('goes to stderr!'); var log = debug('app:log'); // set this namespace to log via console.log log.log = console.log.bind(console); // don't forget to bind to console! log('goes to stdout'); error('still goes to stderr!'); // set all output to go via console.info // overrides all per-namespace log settings debug.log = console.info.bind(console); error('now goes to stdout via console.info'); log('still goes to stdout, but via console.info now'); Extend You can simply extend debugger const log = require('debug')('auth'); //creates new debug instance with extended namespace const logSign = log.extend('sign'); const logLogin = log.extend('login'); log('hello'); // auth hello logSign('hello'); //auth:sign hello logLogin('hello'); //auth:login hello Set dynamically You can also enable debug dynamically by calling the enable() method : let debug = require('debug'); console.log(1, debug.enabled('test')); debug.enable('test'); console.log(2, debug.enabled('test')); debug.disable(); console.log(3, debug.enabled('test')); print : 1 false 2 true 3 false Usage : enable(namespaces) namespaces can include modes separated by a colon and wildcards. Note that calling enable() completely overrides previously set DEBUG variable : $ DEBUG=foo node -e 'var dbg = require(\"debug\"); dbg.enable(\"bar\"); console.log(dbg.enabled(\"foo\"))' => false disable() Will disable all namespaces. The functions returns the namespaces currently enabled (and skipped). This can be useful if you want to disable debugging temporarily without knowing what was enabled to begin with. For example: let debug = require('debug'); debug.enable('foo:*,-foo:bar'); let namespaces = debug.disable(); debug.enable(namespaces); Note: There is no guarantee that the string will be identical to the initial enable string, but semantically they will be identical. Checking whether a debug target is enabled After you've created a debug instance, you can determine whether or not it is enabled by checking the enabled property: const debug = require('debug')('http'); if (debug.enabled) { // do stuff... } You can also manually toggle this property to force the debug instance to be enabled or disabled. Usage in child processes Due to the way debug detects if the output is a TTY or not, colors are not shown in child processes when stderr is piped. A solution is to pass the DEBUG_COLORS=1 environment variable to the child process. For example: worker = fork(WORKER_WRAP_PATH, [workerPath], { stdio: [ /* stdin: */ 0, /* stdout: */ 'pipe', /* stderr: */ 'pipe', 'ipc', ], env: Object.assign({}, process.env, { DEBUG_COLORS: 1 // without this settings, colors won't be shown }), }); worker.stderr.pipe(process.stderr, { end: false }); Authors TJ Holowaychuk Nathan Rajlich Andrew Rhyne Josh Junon Backers Support us with a monthly donation and help us continue our activities. [Become a backer] Sponsors Become a sponsor and get your logo on our README on Github with a link to your site. [Become a sponsor] License (The MIT License) Copyright (c) 2014-2017 TJ Holowaychuk <tj@vision-media.ca&gt; Copyright (c) 2018-2021 Josh Junon Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/engine.io/node_modules/ms/license.html": {
    "href": "node_modules/engine.io/node_modules/ms/license.html",
    "title": "| accouter",
    "keywords": "The MIT License (MIT) Copyright (c) 2016 Zeit, Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/engine.io/node_modules/ms/readme.html": {
    "href": "node_modules/engine.io/node_modules/ms/readme.html",
    "title": "ms | accouter",
    "keywords": "ms Use this package to easily convert various time formats to milliseconds. Examples ms('2 days') // 172800000 ms('1d') // 86400000 ms('10h') // 36000000 ms('2.5 hrs') // 9000000 ms('2h') // 7200000 ms('1m') // 60000 ms('5s') // 5000 ms('1y') // 31557600000 ms('100') // 100 ms('-3 days') // -259200000 ms('-1h') // -3600000 ms('-200') // -200 Convert from Milliseconds ms(60000) // \"1m\" ms(2 * 60000) // \"2m\" ms(-3 * 60000) // \"-3m\" ms(ms('10 hours')) // \"10h\" Time Format Written-Out ms(60000, { long: true }) // \"1 minute\" ms(2 * 60000, { long: true }) // \"2 minutes\" ms(-3 * 60000, { long: true }) // \"-3 minutes\" ms(ms('10 hours'), { long: true }) // \"10 hours\" Features Works both in Node.js and in the browser If a number is supplied to ms, a string with a unit is returned If a string that contains the number is supplied, it returns it as a number (e.g.: it returns 100 for '100') If you pass a string with a number and a valid unit, the number of equivalent milliseconds is returned Related Packages ms.macro - Run ms as a macro at build-time. Caught a Bug? Fork this repository to your own GitHub account and then clone it to your local device Link the package to the global module directory: npm link Within the module you want to test your local development instance of ms, just link it to the dependencies: npm link ms. Instead of the default one from npm, Node.js will now use your clone of ms! As always, you can run the tests using: npm test"
  },
  "node_modules/entities/readme.html": {
    "href": "node_modules/entities/readme.html",
    "title": "entities | accouter",
    "keywords": "entities Encode & decode HTML & XML entities with ease & speed. Features 😇 Tried and true: entities is used by many popular libraries; eg. htmlparser2, the official AWS SDK and commonmark use it to process HTML entities. ⚡️ Fast: entities is the fastest library for decoding HTML entities (as of April 2022); see performance. 🎛 Configurable: Get an output tailored for your needs. You are fine with UTF8? That'll save you some bytes. Prefer to only have ASCII characters? We can do that as well! How to… …install entities npm install entities …use entities const entities = require(\"entities\"); // Encoding entities.escapeUTF8(\"&#38; ü\"); // \"&amp;#38; ü\" entities.encodeXML(\"&#38; ü\"); // \"&amp;#38; &#xfc;\" entities.encodeHTML(\"&#38; ü\"); // \"&amp;&num;38&semi; &uuml;\" // Decoding entities.decodeXML(\"asdf &amp; &#xFF; &#xFC; &apos;\"); // \"asdf & ÿ ü '\" entities.decodeHTML(\"asdf &amp; &yuml; &uuml; &apos;\"); // \"asdf & ÿ ü '\" Performance This is how entities compares to other libraries on a very basic benchmark (see scripts/benchmark.ts, for 10,000,000 iterations; lower is better): Library Version decode perf encode perf escape perf entities 3.0.1 1.418s 6.786s 2.196s html-entities 2.3.2 2.530s 6.829s 2.415s he 1.2.0 5.800s 24.237s 3.624s parse-entities 3.0.0 9.660s N/A N/A FAQ What methods should I actually use to encode my documents? If your target supports UTF-8, the escapeUTF8 method is going to be your best choice. Otherwise, use either encodeHTML or encodeXML based on whether you're dealing with an HTML or an XML document. You can have a look at the options for the encode and decode methods to see everything you can configure. When should I use strict decoding? When strict decoding, entities not terminated with a semicolon will be ignored. This is helpful for decoding entities in legacy environments. Why should I use entities instead of alternative modules? As of April 2022, entities is a bit faster than other modules. Still, this is not a very differentiated space and other modules can catch up. More importantly, you might already have entities in your dependency graph (as a dependency of eg. cheerio, or htmlparser2), and including it directly might not even increase your bundle size. The same is true for other entity libraries, so have a look through your node_modules directory! Does entities support tree shaking? Yes! entities ships as both a CommonJS and a ES module. Note that for best results, you should not use the encode and decode functions, as they wrap around a number of other functions, all of which will remain in the bundle. Instead, use the functions that you need directly. Acknowledgements This library wouldn't be possible without the work of these individuals. Thanks to @mathiasbynens for his explanations about character encodings, and his library he, which was one of the inspirations for entities @inikulin for his work on optimized tries for decoding HTML entities for the parse5 project @mdevils for taking on the challenge of producing a quick entity library with his html-entities library. entities would be quite a bit slower if there wasn't any competition. Right now entities is on top, but we'll see how long that lasts! License: BSD-2-Clause Security contact information To report a security vulnerability, please use the Tidelift security contact. Tidelift will coordinate the fix and disclosure. entities for enterprise Available as part of the Tidelift Subscription The maintainers of entities and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more."
  },
  "node_modules/error-ex/README.html": {
    "href": "node_modules/error-ex/README.html",
    "title": "node-error-ex | accouter",
    "keywords": "node-error-ex Easily subclass and customize new Error types Examples To include in your project: var errorEx = require('error-ex'); To create an error message type with a specific name (note, that ErrorFn.name will not reflect this): var JSONError = errorEx('JSONError'); var err = new JSONError('error'); err.name; //-> JSONError throw err; //-> JSONError: error To add a stack line: var JSONError = errorEx('JSONError', {fileName: errorEx.line('in %s')}); var err = new JSONError('error') err.fileName = '/a/b/c/foo.json'; throw err; //-> (line 2)-> in /a/b/c/foo.json To append to the error message: var JSONError = errorEx('JSONError', {fileName: errorEx.append('in %s')}); var err = new JSONError('error'); err.fileName = '/a/b/c/foo.json'; throw err; //-> JSONError: error in /a/b/c/foo.json API errorEx([name], [properties]) Creates a new ErrorEx error type name: the name of the new type (appears in the error message upon throw; defaults to Error.name) properties: if supplied, used as a key/value dictionary of properties to use when building up the stack message. Keys are property names that are looked up on the error message, and then passed to function values. line: if specified and is a function, return value is added as a stack entry (error-ex will indent for you). Passed the property value given the key. stack: if specified and is a function, passed the value of the property using the key, and the raw stack lines as a second argument. Takes no return value (but the stack can be modified directly). message: if specified and is a function, return value is used as new .message value upon get. Passed the property value of the property named by key, and the existing message is passed as the second argument as an array of lines (suitable for multi-line messages). Returns a constructor (Function) that can be used just like the regular Error constructor. var errorEx = require('error-ex'); var BasicError = errorEx(); var NamedError = errorEx('NamedError'); // -- var AdvancedError = errorEx('AdvancedError', { foo: { line: function (value, stack) { if (value) { return 'bar ' + value; } return null; } } } var err = new AdvancedError('hello, world'); err.foo = 'baz'; throw err; /* AdvancedError: hello, world bar baz at tryReadme() (readme.js:20:1) */ errorEx.line(str) Creates a stack line using a delimiter This is a helper function. It is to be used in lieu of writing a value object for properties values. str: The string to create Use the delimiter %s to specify where in the string the value should go var errorEx = require('error-ex'); var FileError = errorEx('FileError', {fileName: errorEx.line('in %s')}); var err = new FileError('problem reading file'); err.fileName = '/a/b/c/d/foo.js'; throw err; /* FileError: problem reading file in /a/b/c/d/foo.js at tryReadme() (readme.js:7:1) */ errorEx.append(str) Appends to the error.message string This is a helper function. It is to be used in lieu of writing a value object for properties values. str: The string to append Use the delimiter %s to specify where in the string the value should go var errorEx = require('error-ex'); var SyntaxError = errorEx('SyntaxError', {fileName: errorEx.append('in %s')}); var err = new SyntaxError('improper indentation'); err.fileName = '/a/b/c/d/foo.js'; throw err; /* SyntaxError: improper indentation in /a/b/c/d/foo.js at tryReadme() (readme.js:7:1) */ License Licensed under the MIT License. You can find a copy of it in LICENSE."
  },
  "node_modules/es-abstract/CHANGELOG.html": {
    "href": "node_modules/es-abstract/CHANGELOG.html",
    "title": "1.23.3 / 2024-03-29 | accouter",
    "keywords": "1.23.3 / 2024-03-29 [Fix] ES2024: StringPad, StringPaddingBuiltinsImpl: prefer uppercase spec enums [Fix] helpers/bytesAsInteger: avoid a crash in node 10.4 - 10.8 [Fix] ES5: CheckObjectCoercible: restore optMessage optional arg [Refactor] ES2022+: update TimeString to use ToZeroPaddedDecimalString [Robustness] use cached copies of builtins [Deps] update string.prototype.trimstart, typed-array-length [Dev Deps] update array.from, array.prototype.filter, array.prototype.indexof, object.fromentries, safe-bigint 1.23.2 / 2024-03-17 [Fix] records/regexp-record: add optional [[UnicodeSets]] boolean field [Fix] ES2024+: AddValueToKeyedGroup: avoid adding matched values twice [Fix] ES5: CheckObjectCoercible: use the right function name [Fix] ES2024+: AddEntriesFromIterable, GetIterator, GroupBy: properly capitalize spec enums [Deps] update string.prototype.trim, string.prototype.trimend [Tests] increase coverage 1.23.1 / 2024-03-16 [Refactor] use es-object-atoms [Deps] update hasown, which-typed-array, data-view-byte-length, safe-array-concat [Dev Deps] update diff 1.23.0 / 2024-03-04 [New] add ES2024 [New] ES2015+: add InternalizeJSONProperty [New] ES2015+: add IntegerIndexedElement{Get,Set} [New] ES2018+: add TimeZoneString [New] ES2022+: add DefineMethodProperty [New] ES2023: add DefaultTimeZone [Fix] ES2023+: SetTypedArrayFrom{TypedArray,ArrayLike}: match engine reality [Fix] ES2024+: GetViewByteLength, IsViewOutOfBounds: support engines with only own DV properties [Tests] use safe-bigint 1.22.5 / 2024-02-28 [Fix] ES2015+: DetachArrayBuffer: node v21.0.0+ structuredClone throws with an already-detached ArrayBuffer [Fix] helpers/assertRecord: partial revert of 87c340d2; unintentional breaking change [patch] records: fix indentation, improve object checks [Refactor] extract TA tables to separate files [meta] extract \"list spackled files\" to separate run-script [Deps] update available-typed-arrays, es-set-tostringtag, has-proto, is-negative-zero, is-shared-array-buffer, typed-array-buffer, typed-array-byte-length, typed-array-byte-offset, typed-array-length [Dev Deps] update available-regexp-flags, tape [Dev Deps] pin jackspeak and glob, since v2.1.2+ and v10.3.8+ respectively depend on npm aliases, which kill the install process in npm < 6 [Tests] use define-{accessor,data}-property [Tests] fix some test cases [Tests] use safeBigInt for Z() pattern to handle node 10.4 - 10.8 1.22.4 / 2024-02-13 [Fix] ES2017+: IsDetachedBuffer: properly allow SABs [Fix] ES2022+: ToBigInt: properly throw on an unparseable string [Fix] ES2015+: ValidateTypedArray: proper detachment check and return value [Fix] ES2022+: GetSubstitution: match updated semantics [Refactor] prefer typeof over Type(), except for Object, where possible [Refactor] use es-errors instead of get-intrinsic where possible [Refactor] use es-define-property [Refactor] records: extract predicates to individual files [Refactor] ES2015+: Canonicalize, WordCharacters: use explicit .json extension for imports [Deps] update array-buffer-byte-length, arraybuffer.prototype.slice, available-typed-arrays, call-bind, es-set-tostringtag, get-intrinsic, get-symbol-description, has-proper ty-descriptors, has-property-descriptors, hasown, internal-slot, is-array-buffer, is-typed-array, object.assign, regexp.prototype.flags, safe-array-concat, safe-regex-test, typed-array-buffer, which-typed-array [eslint] remove unused overrides [Tests] increase/fix coverage [Dev Deps] update aud, npmignore, mock-property, tape 1.22.3 / 2023-10-20 [Fix] ES2015+: GetSubstitution: accept undefined instead of a hole [Refactor] use hasown instead of has [Deps] update call-bind, get-intrinsic, object-inspect, which-typed-array [Dev Deps] update function-bind, is-core-module, mock-property, tape 1.22.2 / 2023-09-14 [Fix] ES2015+: NewPromiseCapability: use AOs from the current year, not 2022 [Refactor] ES2021+: SetTypedArrayFromArrayLike: use IsBigIntElementType [Refactor] properly name helpers/typedArrayConstructors [Refactor] simplify helpers [Deps] update arraybuffer.prototype.slice, function.prototype.name, is-typed-array, regexp.prototype.flags, safe-array-concat, string.prototype.trim, string.prototype.trimend, string.prototype.trimstart, which-typed-array [actions] update actions [Tests] run SES tests on more node versions [Dev Deps] update @unicode/unicode-15.0.0, array.from, array.prototype.filter, array.prototype.flatmap, array.prototype.indexof, is-core-module, object.fromentries, ses, tape 1.22.1 / 2023-07-15 [Deps] add missing safe-array-concat dep 1.22.0 / 2023-07-15 [New] add ES2023 [New] ES2021+: add SetTypedArrayFromArrayLike, SetTypedArrayFromTypedArray [New] ES2021+: add CloneArrayBuffer [New] ES2020+: add IsValidIntegerIndex [New] ES2015+: add GetValueFromBuffer, SetValueInBuffer [New] ES2016+: add TypedArrayCreate, TypedArraySpeciesCreate [New] ES2015+: add IsWordChar [New] ES2017+ add WordCharacters [New] ES2015+: add Canonicalize [New] ES2015+: add NewPromiseCapability [Fix] ES2017+: NumberToRawBytes, NumericToRawBytes: reimplement Float64, fix integer scenarios [Refactor] add helpers/isLineTerminator [Refactor] add isInteger helper, and use it [Refactor] extract isStringOrHole to a helper [Refactor] ES2017+: RawBytesToNumber, RawBytesToNumeric: extract common code to helpers [Refactor] make a MAX_VALUE helper [Tests] fix RawBytesToNumeric tests in node v10.4-10.8 [Tests] fix buffer test cases in node v10.4-v10.8 1.21.3 / 2023-07-12 [Fix] ES2017+: RawBytesToNumber, RawBytesToNumeric: properly handle some scenarios [Fix] ES2015+: GetV: the receiver is V, not O [Fix] ES2017+: RawBytesToNumber, RawBytesToNumeric: fix exponent calculation for Float64, improve tests [Fix] ES2017+: RawBytesToNumber, RawBytesToNumeric: fix logic, improve tests [Fix] ES2019+: thisTimeValue: fix spackling [Robustness] ES2017+: NumberToRawBytes, NumericToRawBytes: use SameValue instead of Object.is [Refactor] ES2021+: ValidateAtomicAccess: use typed-array-byte-offset [Refactor] ES2019+: AddEntriesFromIterable: use ThrowCompletion [patch] ES2015+: ObjectDefineProperties: satisfy TODO [patch] ES2015+: GetV: improve error message [patch] fix spec URLs [Deps] update get-intrinsic, regexp.prototype.flags, which-typed-array [actions] fix permissions [Tests] add buffer test case fixtures + tests [Tests] skip test that modifies the env in SES [Tests] fix regex flags tests for node 20 [Dev Deps] update @ljharb/eslint-config, aud, available-regexp-flags, is-core-module, tape 1.21.2 / 2023-03-12 [Fix] ES2015+: CreateDataProperty: use OrdinaryDefineOwnProperty [Fix] ES2015+: CreateDataProperty: use OrdinaryDefineOwnProperty [Fix] ES2015+: GetPrototypeFromConstructor: add missing assertion that intrinsicDefaultProto is an object [Fix] ES2015+: IsDetachedBuffer: ensure a nullish error does not crash [Fix] ES2015+: ToDateString: properly handle time values that aren’t \"now\" [Fix] ES2015+: ToUint8Clamp: avoid an extra observable ToNumber [Fix] ES2015+: GetMethod: when funcis not callable andP` is a symbol, avoid the wrong TypeError [Fix] ES2020+: ToBigInt: properly throw on anything besides string, bigint, boolean [Fix] ES2021+: SplitMatch: instead of false, return 'not-matched' [Fix] helpers/assertRecord: handle nullish input [Fix] helpers/isFullyPopulatedPropertyDescriptor: handle primitive inputs [Robustness] ES5: ToNumber: avoid relying on runtime .test and .replace [Refactor] ES2015: mark IsDataDescriptor and IsAccessorDescriptor as spackled [Refactor] ES2015+: IsDetachedBuffer: use array-buffer-byte-length package [Refactor] ES2015+: OrdinaryHasInstance: rely on falsiness [Refactor] ES2016+: CreateListFromArrayLike: hoist default element types to module level [Refactor] ES2022+: StringToNumber, ToNumber: use string.prototype.trim [patch] ES2022+: IsLessThan: fix a comment [patch] ES2022+: TypedArrayElementSize, TypedArrayElementType: throw a SyntaxError with an unknown TA type [patch] ES2022+: IsLessThan: fix a comment [patch] ES2020+: thisBigIntValue: throw a SyntaxError, not TypeError, for unsupported features [patch] helpers/getIteratorMethod: String is always available [patch] fix commented spec URLs [patch] omit % for callBound [meta] fix spec URLs [meta] fix spackle metadata, comments [Deps] update get-intrinsic, internal-slot, is-array-buffer, object-inspect [Deps] move function-bind to dev deps [Tests] String.fromCharCode takes numbers, not strings [Tests] use makeIteratorRecord helper [Tests] increase coverage [Tests] fix tests that throw a sentinel [Dev Deps] update array.from, available-regexp-flags, tape 1.21.1 / 2023-01-10 [Fix] move available-typed-arrays to runtime deps [Fix] ES2021+: NumberToBigInt: throw the proper error on an env without BigInts [Fix] ES2018+: CreateAsyncFromSyncIterator: properly check next method args length [Fix] ES2020-ES2021: Abstract Relational Comparison: handle BigInts properly [Fix] ES2022+: StringToBigInt: invalid BigInts should be undefined, not NaN as in previous years [Fix] helpers/isFinite: properly handle BigInt values [Fix] ES2020+: CreateListFromArrayLike: accept BigInts [Fix] ES2019+: AsyncFromSyncIteratorContinuation: throw a SyntaxError when > 1 arg is passed [patch] ES2020+: GetIterator: use SyntaxError for intentionally unsupported [patch] ES2015+: GetPrototypeFromContructor: use SyntaxError for intentionally unsupported [patch] ES2022+: StringToNumber: fix non-string assertion failure message [Deps] update es-set-tostringtag, is-array-buffer [Tests] increase coverage [Tests] exclude coverage from files that have been replaced by an extracted package 1.21.0 / 2023-01-04 [New] ES2015+: add IsDetachedBuffer [New] ES2015+: add DetachArrayBuffer [New] ES2020+: add NumericToRawBytes [New] ES2017 - ES2019: add NumberToRawBytes [New] ES2020+: add RawBytesToNumeric [New] ES2017-ES2019: add RawBytesToNumber [New] ES2017+: add ValidateAtomicAccess [New] ES2021+: add ValidateIntegerTypedArray [New] ES2015+: add ValidateTypedArray [New] ES2015+: add GetGlobalObject [New] ES2022+: add TypedArrayElementSize, TypedArrayElementType [New] ES2015+: add max, min [New] helpers/assertRecord: add predicates for PromiseCapability and AsyncGeneratorRequest Records [New] ES2018+: add AsyncIteratorClose [New] ES2015+: IteratorClose: also accept a Completion Record instance instead of a completion thunk [New] ES2015+ (CompletionRecord, NormalCompletion), ES2018+ (ThrowCompletion): add new AOs [New] ES2015+ (ObjectCreate) and ES2020+ (OrdinaryObjectCreate): use internal-slot to support additional slots [New] ES2018+: add CreateAsyncFromSyncIterator [patch] ES2015+: GetMethod: better failure message [Refactor] use es-set-tostringtag package [Refactor] use has-proto package [Deps] update has-proto, es-set-tostringtag, internal-slot [meta] fix spackle script to git add after all writing is done [meta] autogenerate esX entry points [meta] use a leading slash in gitattributes for proper spackle matching [Tests] fix comments on missing AOs [Tests] filter out host-defined AOs [Dev Deps] update @ljharb/eslint-config, aud 1.20.5 / 2022-12-07 [Fix] ES2020+: floor: make it work with BigInts as well [Refactor] use gopd [Tests] add mod helper tests (#147) [Deps] update string.prototype.trimend, string.prototype.trimstart [Dev Deps] update array.prototype.filter, array.prototype.flatmap, array.prototype.indexof, object.fromentries 1.20.4 / 2022-10-06 [Fix] ES2021+: values that truncate to -0 in ToIntegerOrInfinity (#146) [Deps] update is-callable 1.20.3 / 2022-09-22 [Refactor] extract regex tester to safe-regex-test package [Deps] update get-intrinsic, is-callable [Dev Deps] update aud, tape 1.20.2 / 2022-09-01 [Fix] ES2020+: SameValueNonNumeric: properly throw on BigInt values [Deps] update object.assign, get-intrinsic, object-inspect [Dev Deps] update array.prototype.indexof, diff, es-value-fixtures, tape [meta] spackle: always mkdirp new files to be written [Tests] fix vscode auto-const from 8fc256d 1.20.1 / 2022-05-16 [Fix] thisTimeValue: use getTime, not valueOf, to get the time value [Refactor] create IsArray helper [Deps] update regexp.prototype.flags [Dev Deps] use for-each instead of foreach 1.20.0 / 2022-05-05 [New] add ES2022 [New] ES2015+: add ObjectDefineProperties [Refactor] create fromPropertyDescriptor helper [Refactor] use has-property-descriptors [Deps] update string.prototype.trimend, string.prototype.trimstart, unbox-primitive [meta] use npmignore to autogenerate an npmignore file [Dev Deps] update es-value-fixtures, has-bigints, functions-have-names [Tests] copy GetIntrinsic tests over from get-intrinsic 1.19.5 / 2022-04-13 [Fix] DefineOwnProperty: FF 4-22 throws an exception when defining length of an array [Dev Deps] update @ljharb/eslint-config 1.19.4 / 2022-04-12 [Fix] ES2015+: CreateDataProperty: a nonwritable but configurable property is still converted to a data property 1.19.3 / 2022-04-11 [Fix] ES2015+: GetIterator, IterableToArrayLike: in Symbol-less envs, handle boxed string objects [Robustness] use exec instead of test, since the latter observably looks up exec [Deps] update is-shared-array-buffer [actions] restrict permissions [Dev Deps] update tape [Tests] add test coverage [Tests] avoid a bug in node v4.0 with bound function names 1.19.2 / 2022-03-28 [Fix] ES2018+: EnumerableOwnPropertyNames, ToIntegerOrInfinity, UTF16SurrogatePairToCodePoint: proper function names [Fix] ES2015+: GetOwnPropertyKeys/IsExtensible/{Set,Test}IntegrityLevel: avoid a crash in IE 8 on missing ES5 intrinsics [Fix] helpers/DefineOwnProperty: avoid a crash in IE 8 [Fix] ES2015+: StringCreate: properly check for prototype being String.prototype [Docs] ES2015+: GetV: Fix spec URL [meta] operations: use a URL object instead of a URL string [meta] remove defunct greenkeeper config [meta] better eccheck command; fix indentation [Tests] node v0.6 lacks RegExp.prototype.source [Tests] remove a stray console.log [Tests] properly set the lastIndex in IE 8 [Tests] skip test due to IE 6-8 sparse/undefined bug [Tests] in IE 8, an empty regex is `` and not (?:) [Tests] ES3 engines don’t have .bind [Tests] avoid needless failures in ES3 engines that don't support descriptors [Tests] add test to cover https://github.com/tc39/ecma262/issues/2611 [Deps] update has-symbols, is-negative-zero, is-weakref, object-inspect [Dev Deps] update eslint, @ljharb/eslint-config, object.fromentries, safe-publish-latest, tape [actions] reuse common workflows [actions] update codecov uploader 1.19.1 / 2021-10-02 [Fix] ES2020+: CreateRegExpStringIterator: should not have enumerable methods [Dev Deps] update array.prototype.filter, array.prototype.indexof 1.19.0 / 2021-09-30 [New] ES2021+: IterableToList: make method parameter optional (#61) [New] add ES2021 [New] ES2020+: add StringToBigInt, ToBigInt, ToBigInt64, ToBigUint64 [New] ES2017+: add IsSharedArrayBuffer, OrdinaryToPrimitive [New] ES2015+: add CharacterRange, IsCompatiblePropertyDescriptor [New] ES2020+: add CreateRegExpStringIterator [Fix] ES2020+: ToBigInt64/ToBigUint64: avoid node v10.4-v10.8 bug with limited BigInt range [Fix] ES2020+: AbstractRelationalComparison, AbstractEqualityComparison: support BigInt [Fix] ES2020+: ToBigInt64/ToBigUint64: Improve the definitions of twoSixtyThree and twoSixtyFour (#140) [meta] do not publish .gitattributes [Tests] Correct the behavior of safeBigInt [Tests] Exclude dotfiles from the testing sweep (#141) 1.18.7 / 2021-09-28 [Fix] getOwnPropertyDescriptor helper: avoid crashing in IE < 9 [Fix] ArraySetLength: node v0.6 has a bug where array lengths can be Set but not Defined [eslint] remove unused directive [Tests] fix spelling 1.18.6 / 2021-09-07 [Fix] ES2020+: NumberToBigInt: throw a SyntaxError when BigInts are not supported [Refactor] extract getSymbolDescription logic to get-symbol-description [Refactor] ES2018+: AbstractRelationalComparison: use IsStringPrefix [Deps] update is-callable, is-regex, is-string [Dev Deps] update @ljharb/eslint-config, tape [Tests] GetSubstitution: add cases 1.18.5 / 2021-08-01 [meta] remove \"exports\" (#133) [Dev Deps] update eslint 1.18.4 / 2021-07-29 [meta] partial revert of b54cfe8525faff482450e843a49d43be3a086225 [Deps] update internal-slot, object-inspect [Dev Deps] update eslint, tape [Tests] ArraySetLength: increase coverage 1.18.3 / 2021-05-27 [Fix] ES2020+: ToNumber: ensure it throws on a BigInt (#130) 1.18.2 / 2021-05-25 [meta] add helpers to \"exports\" field, for back compat 1.18.1 / 2021-05-25 [readme] update and clarify entry points [meta] add \"exports\" field, with escape hatch [meta] add sideEffects field [meta] use prepublishOnly, for npm 7+ [eslint] clean up eslint rules [Deps] update is-regex, is-string, object-inspect, unbox-primitive [Dev Deps] update eslint, @ljharb/eslint-config, aud, tape [actions] disable fail-fast on matrix jobs [actions] use node/install action instead of node/run [actions] update codeql-analysis to new best practices 1.18.0 / 2021-03-03 [New] add ES2020, and a number of additional AOs: See the changelog entries for the prereleases for more information: next.3 next.2 next.1 next.0 [Refactor] ES5+: Abstract Relational Comparison: increase coverage [Tests] increase coverage [Tests] do not run coverage on node 0.6 1.18.0-next.3 / 2021-03-01 [New] ES2015: add StringGetIndexProperty [New] ES2015+: add RegExpCreate, SplitMatch, StringCreate [New] ES2016-ES2019: add UTF16Decode [New] ES2020+: add NumberToBigInt [New] ES2020+: add BigInt::/Number::` methods: [Fix] ES5: ToNumber: properly refuse to parse ES6+ forms [Fix] ES2015+: Invoke: optional argumentsList must be a List of arguments, not a list of arguments [Fix] ES2016+: UTF16Encoding: properly return a string code point instead of a numeric code point [Fix] ES2020: NumberBitwiseOp: assert that x and y are Numbers [readme] remove travis/testling badge, fix repo URLs [meta] ES2015: add missing CreateArrayIterator AO [meta] ES2015-ES2017: add missing DaylightSavingTA AO [meta] rerun npm run spackle to update URLs left after 11d8c8df11c0d15d094a6035afed662e22b440ef [meta] update ecma URLs [meta] unignore 2020 operations list [meta] update operations scripts linting [meta] refactor getOps script to fetch all years at once [meta] refactor operations script to keep years in one place [meta] fix ES2015 spec URL [Deps] update has-symbols, string.prototype.trimend, string.prototype.trimstart, get-intrinsic, is-callable, is-regex [Dev Deps] update eslint, @ljharb/eslint-config, array.prototype.indexof, aud, es-value-fixtures, object.fromentries, tape, diff [operations] detect ES2020+ style T:: numeric operations [Tests] increase coverage [Tests] BigInt(1e17) throws on node v10.4-v10.6 [Tests] improve coverage on Number:: methods [Tests] tape v5 .equal now uses strict equality, so no more need for is() [Tests] improve BigInt:: and Number:: coverage [Tests] actually run all the helpers tests [Tests] ensure \"expected missing\" ops list is accurate [Tests] abstract away per-operation skips [Tests] skip BigInt:: tests on envs without BigInts [Tests] use es-value-fixtures [actions] update workflows 1.18.0-next.2 / 2021-01-17 [New] helpers: add isByteValue, isCodePoint, some [Fix] ES2018+: fix GetSubstitution with named captures [Fix] ES2020: GetIterator: add omitted hint parameter [Fix] ES2018/ES2019: SetFunctionLength: Infinities should throw [Fix] ES2020: ToIndex uses SameValue instead of SameValueZero [Fix] ES2020: CopyDataProperties uses CreateDataPropertyOrThrow instead of CreateDataProperty [Refactor] use extracted call-bind instead of local helpers [Refactor] use extracted get-intrinsic package [Deps] update call-bind, get-intrinsic, is-callable, is-negative-zero, is-regex, object-inspect, object.assign, string.prototype.trimend, string.prototype.trimstart [Dev Deps] update eslint, @ljharb/eslint-config, array.prototype.indexof, aud, diff, functions-have-names, has-bigints, has-strict-mode, object-is, object.fromentries, tape [actions] switch Automatic Rebase workflow to pull_request_target event [actions] add \"Allow Edits\" workflow [meta] pin cheerio to v1.0.0-rc.3, to fix getOps [meta] make all URLs consistent, and point to spec artifacts [meta] refactor deltas script; update eslint on operations scripts [meta] do not publish .github dir (#123) [Tests] add v.notNonNegativeIntegers, v.nonConstructorFunctions [Tests] migrate tests to Github Actions [Tests] run coverage on all tests [Tests] add npm run test:ses 1.18.0-next.1 / 2020-09-30 [Fix] ES2020: ToInteger: -0 should always be normalized to +0 (#116) [patch] GetIntrinsic: Adapt to override-mistake-fix pattern (#115) [Fix] callBind: ensure compatibility with SES [Deps] update is-callable, object.assign [Dev Deps] update eslint, @ljharb/eslint-config [eslint] fix warning [Tests] temporarily allow SES tests to fail (#115) [Tests] ses-compat - initialize module after ses lockdown (#113) [Tests] [Refactor] use defineProperty helper rather than assignment [Tests] [Refactor] clean up defineProperty test helper 1.18.0-next.0 / 2020-08-14 [New] add ES2020 [New] GetIntrinsic: add %AggregateError%, %FinalizationRegistry%, and %WeakRef% [New] ES5+: add abs, floor; use modulo consistently [New] GetIntrinsic: Cache accessed intrinsics (#98) [New] GetIntrinsic: Add ES201x function intrinsics (#97) [New] ES2015+: add QuoteJSONString, OrdinaryCreateFromConstructor [New] ES2017+: add StringGetOwnProperty [New] ES2016+: add UTF16Encoding [New] ES2018+: add SetFunctionLength, UnicodeEscape [New] add isLeadingSurrogate/isTrailingSurrogate helpers [Fix] ES5+: ToPropertyDescriptor: use intrinsic TypeError [Fix] ES2018+: CopyDataProperties/NumberToString: use intrinsic TypeError [Deps] update is-regex, object-inspect [Dev Deps] update eslint 1.17.7 / 2020-09-30 [Fix] ES2020: ToInteger: -0 should always be normalized to +0 (#116) [patch] GetIntrinsic: Adapt to override-mistake-fix pattern (#115) [Fix] callBind: ensure compatibility with SES [Deps] update is-callable, is-regex, object-inspect, object.assign [Dev Deps] update eslint, @ljharb/eslint-config 1.17.6 / 2020-06-13 [Fix] helpers/getSymbolDescription: use the global Symbol registry when available (#92) [Fix] ES2015+: IsConstructor: when Reflect.construct is available, be spec-accurate (#93) [Fix] ES2015+: Set: Always return boolean value (#101) [Fix] ES2015+: Set: ensure exceptions are thrown in IE 9 when requested [Fix] Use Reflect.apply(…) if available (#99) [Fix] helpers/floor: module-cache Math.floor [Fix] helpers/getSymbolDescription: Prefer bound description getter when present [Fix] 2016: Use getIteratorMethod in IterableToArrayLike (#94) [Fix] helpers/OwnPropertyKeys: Use Reflect.ownKeys(…) if available (#91) [Fix] 2018+: Fix CopyDataProperties depending on this (#95) [meta] mark spackled files as autogenerated [meta] Type: fix spec URL [meta] ES2015: complete ops list [Deps] update is‑callable, is‑regex [Deps] switch from string.prototype.trimleft/string.prototype.trimright to string.prototype.trimstart/string.prototype.trimend [Dev Deps] update eslint, @ljharb/eslint-config, in-publish, object-is, tape; add aud [eslint] helpers/isPropertyDescriptor: fix indentation [Tests] helpers/getSymbolDescription: add test cases; some envs have Symbol.for but can not infer a name (#92) [Tests] try out CodeQL analysis [Tests] reformat expected missing ops [Tests] Run tests with undefined this (#96) 1.17.5 / 2020-03-22 [Fix] CreateDataProperty: update an existing property [Fix] run missing spackle from cd7504701879ddea0f5981e99cbcf93bfea9171d [Dev Deps] update make-arrow-function, tape, @ljharb/eslint-config 1.17.4 / 2020-01-21 [Fix] 2015+: add code to handle IE 8’s problems [Tests] fix tests for IE 8 1.17.3 / 2020-01-19 [Fix] ObjectCreate 2015+: Fall back to __proto__ and normal new in older browsers [Fix] GetIntrinsic: ensure the allowMissing property actually works on dotted intrinsics 1.17.2 / 2020-01-14 [Fix] helpers/OwnPropertyKeys: include non-enumerables too 1.17.1 / 2020-01-14 [Refactor] add OwnPropertyKeys helper, use it in CopyDataProperties [Refactor] IteratorClose: remove useless assignment [Dev Deps] update eslint, tape, diff 1.17.0 / 2019-12-20 [New] Split up each operation into its own file (prereleased) [Fix] GetIntrinsic: IE 8 has a broken Object.getOwnPropertyDescriptor [Fix] object.assign is a runtime dep (prereleased) [Refactor] GetIntrinsic: remove the internal property salts, since % already handles that [Refactor] GetIntrinsic: further simplification [Deps] update is-callable, string.prototype.trimleft, string.prototype.trimright, is-regex [Dev Deps] update @ljharb/eslint-config, object-is, object.fromentries, tape [Tests] add .eslintignore [meta] remove unused Makefile and associated utils [meta] only run spackle script in publish (#78) (prereleased) 1.17.0-next.1 / 2019-12-11 [Fix] object.assign is a runtime dep [meta] only run spackle script in publish (#78) 1.17.0-next.0 / 2019-12-11 [New] Split up each operation into its own file 1.16.3 / 2019-12-04 [Fix] GetIntrinsic: when given a path to a getter, return the actual getter [Dev Deps] update eslint 1.16.2 / 2019-11-24 [Fix] IE 6-7 lack JSON [Fix] IE 6-8 strings can’t use array slice, they need string slice [Dev Deps] update eslint 1.16.1 / 2019-11-24 [Fix] GetIntrinsics: turns out IE 8 throws when Object.getOwnPropertyDescriptor(arguments);, and does not throw on callee anyways [Deps] update es-to-primitive, has-symbols, object-inspect [Dev Deps] update eslint, @ljharb/eslint-config, safe-publish-latest [meta] re-include year files inside operations [meta] add funding field [actions] add Automatic Rebase github action [Tests] use shared travis-ci config [Tests] disable check-coverage, and let codecov do it 1.16.0 / 2019-10-18 [New] ES2015+: add SetFunctionName [New] ES2015+: add GetPrototypeFromConstructor, with caveats [New] ES2015+: add CreateListFromArrayLike [New] ES2016+: add OrdinarySetPrototypeOf [New] ES2016+: add OrdinaryGetPrototypeOf [New] add getSymbolDescription and getInferredName helpers [Fix] GetIterator: add fallback for pre-Symbol environments, tests [Dev Deps] update object.fromentries [Tests] add node v12.2 1.15.0 / 2019-10-02 [New] ES2018+: add DateString, TimeString [New] ES2015+: add ToDateString [New] ES5+: add msFromTime, SecFromTime, MinFromTime, HourFromTime, TimeWithinDay, Day, DayFromYear, TimeFromYear, YearFromTime, WeekDay, DaysInYear, InLeapYear, DayWithinYear, MonthFromTime, DateFromTime, MakeDay, MakeDate, MakeTime, TimeClip, modulo [New] add regexTester helper [New] add callBound helper [New] add ES2020’s intrinsic dot notation [New] add isPrefixOf helper [New] add maxSafeInteger helper [Deps] update string.prototype.trimleft, string.prototype.trimright [Dev Deps] update eslint [Tests] on node v12.11 [meta] npmignore operations scripts; add \"deltas\" 1.14.2 / 2019-09-08 [Fix] ES2016: IterableToArrayLike: add proper fallback for strings, pre-Symbols [Tests] on node v12.10 1.14.1 / 2019-09-03 [meta] republish with some extra files removed 1.14.0 / 2019-09-02 [New] add ES2019 [New] ES2017+: add IterableToList [New] ES2016: add IterableToArrayLike [New] ES2015+: add ArrayCreate, ArraySetLength, OrdinaryDefineOwnProperty, OrdinaryGetOwnProperty, OrdinaryHasProperty, CreateHTML, GetOwnPropertyKeys, InstanceofOperator, SymbolDescriptiveString, GetSubstitution, ValidateAndApplyPropertyDescriptor, IsPromise, OrdinaryHasInstance, TestIntegrityLevel, SetIntegrityLevel [New] add callBind helper, and use it [New] add helpers: isPropertyDescriptor, every [New] ES5+: add Abstract Relational Comparison [New] ES5+: add Abstract Equality Comparison, Strict Equality Comparison [Fix] ES2015+: GetIterator: only require native Symbols when method is omitted [Fix] ES2015: Call: error message now properly displays Symbols using object-inspect [Fix] ES2015+: ValidateAndApplyPropertyDescriptor: use ES2017 logic to bypass spec bugs [Fix] ES2015+: CreateDataProperty, DefinePropertyOrThrow, ValidateAndApplyPropertyDescriptor: add fallbacks for ES3 [Fix] ES2015+: FromPropertyDescriptor: no longer requires a fully complete Property Descriptor [Fix] ES5: IsPropertyDescriptor: call into IsDataDescriptor and IsAccessorDescriptor [Refactor] use has-symbols for Symbol detection [Fix] helpers/assertRecord: remove console.log [Deps] update object-keys [readme] add security note [meta] change http URLs to https [meta] linter cleanup [meta] fix getOps script [meta] add FUNDING.yml [Dev Deps] update eslint, @ljharb/eslint-config, safe-publish-latest, semver, replace, cheerio, tape [Tests] up to node v12.9, v11.15, v10.16, v8.16, v6.17 [Tests] temporarily allow node 0.6 to fail; segfaulting in travis [Tests] use the values helper more in es5 tests [Tests] fix linting to apply to all files [Tests] run npx aud only on prod deps [Tests] add v.descriptors helpers [Tests] use npx aud instead of npm audit with hoops [Tests] use eclint instead of editorconfig-tools [Tests] some intrinsic cleanup [Tests] migrate es5 tests to use values helper [Tests] add some missing ES2015 ops 1.13.0 / 2019-01-02 [New] add ES2018 [New] add ES2015/ES2016: EnumerableOwnNames; ES2017: EnumerableOwnProperties [New] ES2015+: add thisBooleanValue, thisNumberValue, thisStringValue, thisTimeValue [New] ES2015+: add DefinePropertyOrThrow, DeletePropertyOrThrow, CreateMethodProperty [New] add assertRecord helper [Deps] update is-callable, has, object-keys, es-to-primitive [Dev Deps] update eslint, @ljharb/eslint-config, tape, semver, safe-publish-latest, replace [Tests] use npm audit instead of nsp [Tests] remove jscs [Tests] up to node v11.6, v10.15, v8.15, v6.16 [Tests] move descriptor factories to values helper [Tests] add getOps to programmatically fetch abstract operation names 1.12.0 / 2018-05-31 [New] add GetIntrinsic entry point [New] ES2015+: add ObjectCreate [Robustness]: ES2015+: ensure Math.{abs,floor} and Function.call are cached 1.11.0 / 2018-03-21 [New] ES2015+: add iterator abstract ops [Dev Deps] update eslint, nsp, object.assign, semver, tape [Tests] up to node v9.8, v8.10, v6.13 1.10.0 / 2017-11-24 [New] ES2015+: AdvanceStringIndex [Dev Deps] update eslint, nsp [Tests] require node 0.6 to pass again [Tests] up to node v9.2, v8.9, v6.12; use nvm install-latest-npm; pin included builds to LTS 1.9.0 / 2017-09-30 [New] es2015+: add ArraySpeciesCreate [New] ES2015+: add CreateDataProperty and CreateDataPropertyOrThrow [Tests] consolidate duplicated tests [Tests] increase coverage [Dev Deps] update nsp, eslint 1.8.2 / 2017-09-03 [Fix] es2015+: ToNumber: provide the proper hint for Date objects (#27) [Dev Deps] update eslint 1.8.1 / 2017-08-30 [Fix] ES2015+: ToPropertyKey: should return a symbol for Symbols (#26) [Deps] update function-bind [Dev Deps] update eslint, @ljharb/eslint-config [Docs] github broke markdown parsing 1.8.0 / 2017-08-04 [New] add ES2017 [New] move es6+ to es2015+; leave es6/es7 as aliases [New] ES5+: add IsPropertyDescriptor, IsAccessorDescriptor, IsDataDescriptor, IsGenericDescriptor, FromPropertyDescriptor, ToPropertyDescriptor [New] ES2015+: add CompletePropertyDescriptor, Set, HasOwnProperty, HasProperty, IsConcatSpreadable, Invoke, CreateIterResultObject, RegExpExec [Fix] es7/es2016: do not mutate ES6 [Fix] assign helper only supports one source [Deps] update is-regex [Dev Deps] update nsp, eslint, @ljharb/eslint-config [Dev Deps] update eslint, @ljharb/eslint-config, nsp, semver, tape [Tests] add tests for missing and excess operations [Tests] add codecov for coverage [Tests] up to node v8.2, v7.10, v6.11, v4.8; newer npm breaks on older node [Tests] use same lists of value types across tests; ensure tests are the same when ops are the same [Tests] ES2015: add ToNumber symbol tests [Tests] switch to nyc for code coverage [Tests] make IsRegExp tests consistent across editions 1.7.0 / 2017-01-22 [New] ES6: Add GetMethod (#16) [New] ES6: Add GetV (#16) [New] ES6: Add Get (#17) [Tests] up to node v7.4, v6.9, v4.6; improve test matrix [Dev Deps] update tape, nsp, eslint, @ljharb/eslint-config, safe-publish-latest 1.6.1 / 2016-08-21 [Fix] ES6: IsConstructor should return true for class constructors. 1.6.0 / 2016-08-20 [New] ES5 / ES6: add Type [New] ES6: SpeciesConstructor [Dev Deps] update jscs, nsp, eslint, @ljharb/eslint-config, semver; add safe-publish-latest [Tests] up to node v6.4, v5.12, v4.5 1.5.1 / 2016-05-30 [Fix] ES.IsRegExp: actually look up Symbol.match on the argument [Refactor] create isNaN helper [Deps] update is-callable, function-bind [Deps] update es-to-primitive, fix ES5 tests [Dev Deps] update jscs, eslint, @ljharb/eslint-config, tape, nsp [Tests] up to node v6.2, v5.11, v4.4 [Tests] use pretest/posttest for linting/security 1.5.0 / 2015-12-27 [New] adds Symbol.toPrimitive support via es-to-primitive [Deps] update is-callable, es-to-primitive [Dev Deps] update jscs, nsp, eslint, @ljharb/eslint-config, semver, tape [Tests] up to node v5.3 1.4.3 / 2015-11-04 [Fix] ES6.ToNumber: should give NaN for explicitly signed hex strings (#4) [Refactor] ES6.ToNumber: No need to double-trim [Refactor] group tests better [Tests] should still pass on node v0.8 1.4.2 / 2015-11-02 [Fix] ensure ES.ToNumber trims whitespace, and does not trim non-whitespace (#3) 1.4.1 / 2015-10-31 [Fix] ensure only 0-1 are valid binary and 0-7 are valid octal digits (#2) [Dev Deps] update tape, jscs, nsp, eslint, @ljharb/eslint-config [Tests] on node v5.0 [Tests] fix npm upgrades for older node versions package.json: use object form of \"authors\", add \"contributors\" 1.4.0 / 2015-09-26 [Deps] update is-callable [Dev Deps] update tape, jscs, eslint, @ljharb/eslint-config [Tests] on node v4.2 [New] Add SameValueNonNumber to ES7 1.3.2 / 2015-09-26 [Fix] Fix ES6.IsRegExp to properly handle Symbol.match, per spec. [Tests] up to io.js v3.3, node v4.1 [Dev Deps] update tape, jscs, nsp, eslint, @ljharb/eslint-config, semver 1.3.1 / 2015-08-15 [Fix] Ensure that objects that toString to a binary or octal literal also convert properly 1.3.0 / 2015-08-15 [New] ES6’s ToNumber now supports binary and octal literals. [Dev Deps] update jscs, eslint, @ljharb/eslint-config, tape [Docs] Switch from vb.teelaun.ch to versionbadg.es for the npm version badge SVG [Tests] up to io.js v3.0 1.2.2 / 2015-07-28 [Fix] Both ES5.CheckObjectCoercible and ES6.RequireObjectCoercible return the value if they don't throw. [Tests] Test on latest io.js versions. [Dev Deps] Update eslint, jscs, tape, semver, covert, nsp 1.2.1 / 2015-03-20 Fix isFinite helper. 1.2.0 / 2015-03-19 Use es-to-primitive for ToPrimitive methods. Test on latest io.js versions; allow failures on all but 2 latest node/io.js versions. 1.1.2 / 2015-03-20 Fix isFinite helper. 1.1.1 / 2015-03-19 Fix isPrimitive check for functions Update eslint, editorconfig-tools, semver, nsp 1.1.0 / 2015-02-17 Add ES7 export (non-default). All grade A-supported node/iojs versions now ship with an npm that understands ^. Test on iojs-v1.2. 1.0.1 / 2015-01-30 Use is-callable instead of an internal function. Update tape, jscs, nsp, eslint 1.0.0 / 2015-01-10 v1.0.0"
  },
  "node_modules/es-abstract/README.html": {
    "href": "node_modules/es-abstract/README.html",
    "title": "es-abstract | accouter",
    "keywords": "es-abstract ECMAScript spec abstract operations. Every operation is available by edition/year and by name - for example, es-abstract/2020/Call gives you the Call operation from ES2020, es-abstract/5/Type gives you the Type operation from ES5. All abstract operations are also available under an es5/es2015/es2016/es2017/es2018/es2019/es2020/es2021 entry point, and as a property on the main export, but using deep imports is highly encouraged for bundle size and performance reasons. Non-deep entry points will be removed in the next semver-major release. Example var ES = require('es-abstract'); var assert = require('assert'); assert(ES.isCallable(function () {})); assert(!ES.isCallable(/a/g)); Tests Simply clone the repo, npm install, and run npm test Security Please email @ljharb or see https://tidelift.com/security if you have a potential security vulnerability to report."
  },
  "node_modules/es-define-property/CHANGELOG.html": {
    "href": "node_modules/es-define-property/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.0 - 2024-02-12 Commits Initial implementation, tests, readme, types 3e154e1 Initial commit 07d98de npm init c4eb634 Only apps should have lockfiles 7af86ec"
  },
  "node_modules/es-define-property/README.html": {
    "href": "node_modules/es-define-property/README.html",
    "title": "es-define-property | accouter",
    "keywords": "es-define-property Object.defineProperty, but not IE 8's broken one. Example const assert = require('assert'); const $defineProperty = require('es-define-property'); if ($defineProperty) { assert.equal($defineProperty, Object.defineProperty); } else if (Object.defineProperty) { assert.equal($defineProperty, false, 'this is IE 8'); } else { assert.equal($defineProperty, false, 'this is an ES3 engine'); } Tests Simply clone the repo, npm install, and run npm test Security Please email @ljharb or see https://tidelift.com/security if you have a potential security vulnerability to report."
  },
  "node_modules/es-errors/CHANGELOG.html": {
    "href": "node_modules/es-errors/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.3.0 - 2024-02-05 Commits [New] add EvalError and URIError 1927627 v1.2.1 - 2024-02-04 Commits [Fix] add missing exports entry 5bb5f28 v1.2.0 - 2024-02-04 Commits [New] add ReferenceError 6d8cf5b v1.1.0 - 2024-02-04 Commits [New] add base Error 2983ab6 v1.0.0 - 2024-02-03 Commits Initial implementation, tests, readme, type 8f47631 Initial commit ea5d099 npm init 6f5ebf9 Only apps should have lockfiles e1a0aeb [meta] add sideEffects flag a9c7d46"
  },
  "node_modules/es-errors/README.html": {
    "href": "node_modules/es-errors/README.html",
    "title": "es-errors | accouter",
    "keywords": "es-errors A simple cache for a few of the JS Error constructors. Example const assert = require('assert'); const Base = require('es-errors'); const Eval = require('es-errors/eval'); const Range = require('es-errors/range'); const Ref = require('es-errors/ref'); const Syntax = require('es-errors/syntax'); const Type = require('es-errors/type'); const URI = require('es-errors/uri'); assert.equal(Base, Error); assert.equal(Eval, EvalError); assert.equal(Range, RangeError); assert.equal(Ref, ReferenceError); assert.equal(Syntax, SyntaxError); assert.equal(Type, TypeError); assert.equal(URI, URIError); Tests Simply clone the repo, npm install, and run npm test Security Please email @ljharb or see https://tidelift.com/security if you have a potential security vulnerability to report."
  },
  "node_modules/es-object-atoms/CHANGELOG.html": {
    "href": "node_modules/es-object-atoms/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.0 - 2024-03-16 Commits Initial implementation, tests, readme, types f1499db Initial commit 99eedc7 [meta] rename repo fc851fa npm init b909377 Only apps should have lockfiles 7249edd"
  },
  "node_modules/es-object-atoms/README.html": {
    "href": "node_modules/es-object-atoms/README.html",
    "title": "es-object-atoms | accouter",
    "keywords": "es-object-atoms ES Object-related atoms: Object, ToObject, RequireObjectCoercible. Example const assert = require('assert'); const $Object = require('es-object-atoms'); const ToObject = require('es-object-atoms/ToObject'); const RequireObjectCoercible = require('es-object-atoms/RequireObjectCoercible'); assert.equal($Object, Object); assert.throws(() => ToObject(null), TypeError); assert.throws(() => ToObject(undefined), TypeError); assert.throws(() => RequireObjectCoercible(null), TypeError); assert.throws(() => RequireObjectCoercible(undefined), TypeError); assert.deepEqual(RequireObjectCoercible(true), true); assert.deepEqual(ToObject(true), Object(true)); const obj = {}; assert.equal(RequireObjectCoercible(obj), obj); assert.equal(ToObject(obj), obj); Tests Simply clone the repo, npm install, and run npm test Security Please email @ljharb or see https://tidelift.com/security if you have a potential security vulnerability to report."
  },
  "node_modules/es-set-tostringtag/CHANGELOG.html": {
    "href": "node_modules/es-set-tostringtag/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v2.0.3 - 2024-02-20 Commits add types d538513 [Deps] update get-intrinsic, has-tostringtag, hasown d129b29 [Dev Deps] update aud, npmignore, tape 132ed23 [Tests] fix hasOwn require f89c831 v2.0.2 - 2023-10-20 Commits [Refactor] use hasown instead of has 0cc6c4e [Dev Deps] update @ljharb/eslint-config, aud, tape 70e447c [Deps] update get-intrinsic 826aab7 v2.0.1 - 2023-01-05 Fixed [Fix] move has to prod deps #2 Commits [Dev Deps] update @ljharb/eslint-config b9eecd2 v2.0.0 - 2022-12-21 Commits [Tests] refactor tests 168dcfb [Breaking] do not set toStringTag if it is already set 226ab87 [New] add force option to set even if already set 1abd4ec v1.0.0 - 2022-12-21 Commits Initial implementation, tests, readme a0e1147 Initial commit ffd4aff npm init fffe5bd Only apps should have lockfiles d363871"
  },
  "node_modules/es-set-tostringtag/README.html": {
    "href": "node_modules/es-set-tostringtag/README.html",
    "title": "es-set-tostringtag | accouter",
    "keywords": "es-set-tostringtag A helper to optimistically set Symbol.toStringTag, when possible. Most common usage: var assert = require('assert'); var setToStringTag = require('es-set-tostringtag'); var obj = {}; assert.equal(Object.prototype.toString.call(obj), '[object Object]'); setToStringTag(obj, 'tagged!'); assert.equal(Object.prototype.toString.call(obj), '[object tagged!]'); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/es-to-primitive/CHANGELOG.html": {
    "href": "node_modules/es-to-primitive/CHANGELOG.html",
    "title": "1.2.1 / 2019-11-08 | accouter",
    "keywords": "1.2.1 / 2019-11-08 [readme] remove testling URLs [meta] add funding field [meta] create FUNDING.yml [Dev Deps] update eslint, @ljharb/eslint-config, covert, replace, semver, tape, function.prototype.name [Tests] use shared travis-ci configs [Tests] Add es5 tests for symbol types (#45) [Tests] use npx aud instead of nsp or npm audit with hoops [Tests] remove jscs 1.2.0 / 2018-09-27 [New] create ES2015 entry point/property, to replace ES6 [Fix] Ensure optional arguments are not part of the length (#29) [Deps] update is-callable [Dev Deps] update tape, jscs, nsp, eslint, @ljharb/eslint-config, semver, object-inspect, replace [Tests] avoid util.inspect bug with new Date(NaN) on node v6.0 and v6.1. [Tests] up to node v10.11, v9.11, v8.12, v6.14, v4.9 1.1.1 / 2016-01-03 [Fix: ES5] fix coercion logic: ES5’s ToPrimitive does not coerce any primitive value, regardless of hint (#2) 1.1.0 / 2015-12-27 [New] add Symbol.toPrimitive support [Deps] update is-callable, is-date-object [Dev Deps] update eslint, tape, semver, jscs, covert, nsp, @ljharb/eslint-config [Dev Deps] remove unused deps [Tests] up to node v5.3 [Tests] fix npm upgrades on older node versions [Tests] fix testling [Docs] Switch from vb.teelaun.ch to versionbadg.es for the npm version badge SVG 1.0.1 / 2016-01-03 [Fix: ES5] fix coercion logic: ES5’s ToPrimitive does not coerce any primitive value, regardless of hint (#2) [Deps] update is-callable, is-date-object [Dev Deps] update eslint, tape, semver, jscs, covert, nsp, @ljharb/eslint-config [Dev Deps] remove unused deps [Tests] up to node v5.3 [Tests] fix npm upgrades on older node versions [Tests] fix testling [Docs] Switch from vb.teelaun.ch to versionbadg.es for the npm version badge SVG 1.0.0 / 2015-03-19 Initial release."
  },
  "node_modules/es-to-primitive/README.html": {
    "href": "node_modules/es-to-primitive/README.html",
    "title": "es-to-primitive | accouter",
    "keywords": "es-to-primitive ECMAScript “ToPrimitive” algorithm. Provides ES5 and ES2015 versions. When different versions of the spec conflict, the default export will be the latest version of the abstract operation. Alternative versions will also be available under an es5/es2015 exported property if you require a specific version. Example var toPrimitive = require('es-to-primitive'); var assert = require('assert'); assert(toPrimitive(function () {}) === String(function () {})); var date = new Date(); assert(toPrimitive(date) === String(date)); assert(toPrimitive({ valueOf: function () { return 3; } }) === 3); assert(toPrimitive(['a', 'b', 3]) === String(['a', 'b', 3])); var sym = Symbol(); assert(toPrimitive(Object(sym)) === sym); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/escalade/readme.html": {
    "href": "node_modules/escalade/readme.html",
    "title": "escalade | accouter",
    "keywords": "escalade A tiny (183B to 210B) and fast utility to ascend parent directories With escalade, you can scale parent directories until you've found what you're looking for. Given an input file or directory, escalade will continue executing your callback function until either: the callback returns a truthy value escalade has reached the system root directory (eg, /) Important: Please note that escalade only deals with direct ancestry – it will not dive into parents' sibling directories. Notice: As of v3.1.0, escalade now includes Deno support! Please see Deno Usage below. Install $ npm install --save escalade Modes There are two \"versions\" of escalade available: \"async\" Node.js: >= 8.x Size (gzip): 210 bytes Availability: CommonJS, ES Module This is the primary/default mode. It makes use of async/await and util.promisify. \"sync\" Node.js: >= 6.x Size (gzip): 183 bytes Availability: CommonJS, ES Module This is the opt-in mode, ideal for scenarios where async usage cannot be supported. Usage Example Structure /Users/lukeed └── oss ├── license └── escalade ├── package.json └── test └── fixtures ├── index.js └── foobar └── demo.js Example Usage //~> demo.js import { join } from 'path'; import escalade from 'escalade'; const input = join(__dirname, 'demo.js'); // or: const input = __dirname; const pkg = await escalade(input, (dir, names) => { console.log('~> dir:', dir); console.log('~> names:', names); console.log('---'); if (names.includes('package.json')) { // will be resolved into absolute return 'package.json'; } }); //~> dir: /Users/lukeed/oss/escalade/test/fixtures/foobar //~> names: ['demo.js'] //--- //~> dir: /Users/lukeed/oss/escalade/test/fixtures //~> names: ['index.js', 'foobar'] //--- //~> dir: /Users/lukeed/oss/escalade/test //~> names: ['fixtures'] //--- //~> dir: /Users/lukeed/oss/escalade //~> names: ['package.json', 'test'] //--- console.log(pkg); //=> /Users/lukeed/oss/escalade/package.json // Now search for \"missing123.txt\" // (Assume it doesn't exist anywhere!) const missing = await escalade(input, (dir, names) => { console.log('~> dir:', dir); return names.includes('missing123.txt') && 'missing123.txt'; }); //~> dir: /Users/lukeed/oss/escalade/test/fixtures/foobar //~> dir: /Users/lukeed/oss/escalade/test/fixtures //~> dir: /Users/lukeed/oss/escalade/test //~> dir: /Users/lukeed/oss/escalade //~> dir: /Users/lukeed/oss //~> dir: /Users/lukeed //~> dir: /Users //~> dir: / console.log(missing); //=> undefined Note: To run the above example with \"sync\" mode, import from escalade/sync and remove the await keyword. API escalade(input, callback) Returns: string|void or Promise<string|void> When your callback locates a file, escalade will resolve/return with an absolute path. If your callback was never satisfied, then escalade will resolve/return with nothing (undefined). Important: The sync and async versions share the same API. The only difference is that sync is not Promise-based. input Type: string The path from which to start ascending. This may be a file or a directory path. However, when input is a file, escalade will begin with its parent directory. Important: Unless given an absolute path, input will be resolved from process.cwd() location. callback Type: Function The callback to execute for each ancestry level. It always is given two arguments: dir - an absolute path of the current parent directory names - a list (string[]) of contents relative to the dir parent Note: The names list can contain names of files and directories. When your callback returns a falsey value, then escalade will continue with dir's parent directory, re-invoking your callback with new argument values. When your callback returns a string, then escalade stops iteration immediately. If the string is an absolute path, then it's left as is. Otherwise, the string is resolved into an absolute path from the dir that housed the satisfying condition. Important: Your callback can be a Promise/AsyncFunction when using the \"async\" version of escalade. Benchmarks Running on Node.js v10.13.0 # Load Time find-up 3.891ms escalade 0.485ms escalade/sync 0.309ms # Levels: 6 (target = \"foo.txt\"): find-up x 24,856 ops/sec ±6.46% (55 runs sampled) escalade x 73,084 ops/sec ±4.23% (73 runs sampled) find-up.sync x 3,663 ops/sec ±1.12% (83 runs sampled) escalade/sync x 9,360 ops/sec ±0.62% (88 runs sampled) # Levels: 12 (target = \"package.json\"): find-up x 29,300 ops/sec ±10.68% (70 runs sampled) escalade x 73,685 ops/sec ± 5.66% (66 runs sampled) find-up.sync x 1,707 ops/sec ± 0.58% (91 runs sampled) escalade/sync x 4,667 ops/sec ± 0.68% (94 runs sampled) # Levels: 18 (target = \"missing123.txt\"): find-up x 21,818 ops/sec ±17.37% (14 runs sampled) escalade x 67,101 ops/sec ±21.60% (20 runs sampled) find-up.sync x 1,037 ops/sec ± 2.86% (88 runs sampled) escalade/sync x 1,248 ops/sec ± 0.50% (93 runs sampled) Deno As of v3.1.0, escalade is available on the Deno registry. Please note that the API is identical and that there are still two modes from which to choose: // Choose \"async\" mode import escalade from 'https://deno.land/escalade/async.ts'; // Choose \"sync\" mode import escalade from 'https://deno.land/escalade/sync.ts'; Important: The allow-read permission is required! Related premove - A tiny (247B) utility to remove items recursively totalist - A tiny (195B to 224B) utility to recursively list all (total) files in a directory mk-dirs - A tiny (420B) utility to make a directory and its parents, recursively License MIT © Luke Edwards"
  },
  "node_modules/escape-html/Readme.html": {
    "href": "node_modules/escape-html/Readme.html",
    "title": "escape-html | accouter",
    "keywords": "escape-html Escape string for use in HTML Example var escape = require('escape-html'); var html = escape('foo & bar'); // -> foo &amp; bar Benchmark $ npm run-script bench > escape-html@1.0.3 bench nodejs-escape-html > node benchmark/index.js http_parser@1.0 node@0.10.33 v8@3.14.5.9 ares@1.9.0-DEV uv@0.10.29 zlib@1.2.3 modules@11 openssl@1.0.1j 1 test completed. 2 tests completed. 3 tests completed. no special characters x 19,435,271 ops/sec ±0.85% (187 runs sampled) single special character x 6,132,421 ops/sec ±0.67% (194 runs sampled) many special characters x 3,175,826 ops/sec ±0.65% (193 runs sampled) License MIT"
  },
  "node_modules/escape-string-regexp/readme.html": {
    "href": "node_modules/escape-string-regexp/readme.html",
    "title": "escape-string-regexp | accouter",
    "keywords": "escape-string-regexp Escape RegExp special characters Install $ npm install escape-string-regexp Usage const escapeStringRegexp = require('escape-string-regexp'); const escapedString = escapeStringRegexp('How much $ for a 🦄?'); //=> 'How much \\\\$ for a 🦄\\\\?' new RegExp(escapedString); You can also use this to escape a string that is inserted into the middle of a regex, for example, into a character class. Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "node_modules/etag/HISTORY.html": {
    "href": "node_modules/etag/HISTORY.html",
    "title": "1.8.1 / 2017-09-12 | accouter",
    "keywords": "1.8.1 / 2017-09-12 perf: replace regular expression with substring 1.8.0 / 2017-02-18 Use SHA1 instead of MD5 for ETag hashing Improves performance for larger entities Works with FIPS 140-2 OpenSSL configuration 1.7.0 / 2015-06-08 Always include entity length in ETags for hash length extensions Generate non-Stats ETags using MD5 only (no longer CRC32) Improve stat performance by removing hashing Remove base64 padding in ETags to shorten Use MD5 instead of MD4 in weak ETags over 1KB 1.6.0 / 2015-05-10 Improve support for JXcore Remove requirement of atime in the stats object Support \"fake\" stats objects in environments without fs 1.5.1 / 2014-11-19 deps: crc@3.2.1 Minor fixes 1.5.0 / 2014-10-14 Improve string performance Slightly improve speed for weak ETags over 1KB 1.4.0 / 2014-09-21 Support \"fake\" stats objects Support Node.js 0.6 1.3.1 / 2014-09-14 Use the (new and improved) crc for crc32 1.3.0 / 2014-08-29 Default strings to strong ETags Improve speed for weak ETags over 1KB 1.2.1 / 2014-08-29 Use the (much faster) buffer-crc32 for crc32 1.2.0 / 2014-08-24 Add support for file stat objects 1.1.0 / 2014-08-24 Add fast-path for empty entity Add weak ETag generation Shrink size of generated ETags 1.0.1 / 2014-08-24 Fix behavior of string containing Unicode 1.0.0 / 2014-05-18 Initial release"
  },
  "node_modules/etag/README.html": {
    "href": "node_modules/etag/README.html",
    "title": "etag | accouter",
    "keywords": "etag Create simple HTTP ETags This module generates HTTP ETags (as defined in RFC 7232) for use in HTTP responses. Installation This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install etag API var etag = require('etag') etag(entity, [options]) Generate a strong ETag for the given entity. This should be the complete body of the entity. Strings, Buffers, and fs.Stats are accepted. By default, a strong ETag is generated except for fs.Stats, which will generate a weak ETag (this can be overwritten by options.weak). res.setHeader('ETag', etag(body)) Options etag accepts these properties in the options object. weak Specifies if the generated ETag will include the weak validator mark (that is, the leading W/). The actual entity tag is the same. The default value is false, unless the entity is fs.Stats, in which case it is true. Testing $ npm test Benchmark $ npm run-script bench > etag@1.8.1 bench nodejs-etag > node benchmark/index.js http_parser@2.7.0 node@6.11.1 v8@5.1.281.103 uv@1.11.0 zlib@1.2.11 ares@1.10.1-DEV icu@58.2 modules@48 openssl@1.0.2k > node benchmark/body0-100b.js 100B body 4 tests completed. buffer - strong x 258,647 ops/sec ±1.07% (180 runs sampled) buffer - weak x 263,812 ops/sec ±0.61% (184 runs sampled) string - strong x 259,955 ops/sec ±1.19% (185 runs sampled) string - weak x 264,356 ops/sec ±1.09% (184 runs sampled) > node benchmark/body1-1kb.js 1KB body 4 tests completed. buffer - strong x 189,018 ops/sec ±1.12% (182 runs sampled) buffer - weak x 190,586 ops/sec ±0.81% (186 runs sampled) string - strong x 144,272 ops/sec ±0.96% (188 runs sampled) string - weak x 145,380 ops/sec ±1.43% (187 runs sampled) > node benchmark/body2-5kb.js 5KB body 4 tests completed. buffer - strong x 92,435 ops/sec ±0.42% (188 runs sampled) buffer - weak x 92,373 ops/sec ±0.58% (189 runs sampled) string - strong x 48,850 ops/sec ±0.56% (186 runs sampled) string - weak x 49,380 ops/sec ±0.56% (190 runs sampled) > node benchmark/body3-10kb.js 10KB body 4 tests completed. buffer - strong x 55,989 ops/sec ±0.93% (188 runs sampled) buffer - weak x 56,148 ops/sec ±0.55% (190 runs sampled) string - strong x 27,345 ops/sec ±0.43% (188 runs sampled) string - weak x 27,496 ops/sec ±0.45% (190 runs sampled) > node benchmark/body4-100kb.js 100KB body 4 tests completed. buffer - strong x 7,083 ops/sec ±0.22% (190 runs sampled) buffer - weak x 7,115 ops/sec ±0.26% (191 runs sampled) string - strong x 3,068 ops/sec ±0.34% (190 runs sampled) string - weak x 3,096 ops/sec ±0.35% (190 runs sampled) > node benchmark/stats.js stat 4 tests completed. real - strong x 871,642 ops/sec ±0.34% (189 runs sampled) real - weak x 867,613 ops/sec ±0.39% (190 runs sampled) fake - strong x 401,051 ops/sec ±0.40% (189 runs sampled) fake - weak x 400,100 ops/sec ±0.47% (188 runs sampled) License MIT"
  },
  "node_modules/eventemitter3/README.html": {
    "href": "node_modules/eventemitter3/README.html",
    "title": "EventEmitter3 | accouter",
    "keywords": "EventEmitter3 EventEmitter3 is a high performance EventEmitter. It has been micro-optimized for various of code paths making this, one of, if not the fastest EventEmitter available for Node.js and browsers. The module is API compatible with the EventEmitter that ships by default with Node.js but there are some slight differences: Domain support has been removed. We do not throw an error when you emit an error event and nobody is listening. The newListener and removeListener events have been removed as they are useful only in some uncommon use-cases. The setMaxListeners, getMaxListeners, prependListener and prependOnceListener methods are not available. Support for custom context for events so there is no need to use fn.bind. The removeListener method removes all matching listeners, not only the first. It's a drop in replacement for existing EventEmitters, but just faster. Free performance, who wouldn't want that? The EventEmitter is written in EcmaScript 3 so it will work in the oldest browsers and node versions that you need to support. Installation $ npm install --save eventemitter3 CDN Recommended CDN: https://unpkg.com/eventemitter3@latest/umd/eventemitter3.min.js Usage After installation the only thing you need to do is require the module: var EventEmitter = require('eventemitter3'); And you're ready to create your own EventEmitter instances. For the API documentation, please follow the official Node.js documentation: http://nodejs.org/api/events.html Contextual emits We've upgraded the API of the EventEmitter.on, EventEmitter.once and EventEmitter.removeListener to accept an extra argument which is the context or this value that should be set for the emitted events. This means you no longer have the overhead of an event that required fn.bind in order to get a custom this value. var EE = new EventEmitter() , context = { foo: 'bar' }; function emitted() { console.log(this === context); // true } EE.once('event-name', emitted, context); EE.on('another-event', emitted, context); EE.removeListener('another-event', emitted, context); Tests and benchmarks This module is well tested. You can run: npm test to run the tests under Node.js. npm run test-browser to run the tests in real browsers via Sauce Labs. We also have a set of benchmarks to compare EventEmitter3 with some available alternatives. To run the benchmarks run npm run benchmark. Tests and benchmarks are not included in the npm package. If you want to play with them you have to clone the GitHub repository. Note that you will have to run an additional npm i in the benchmarks folder before npm run benchmark. License MIT"
  },
  "node_modules/fast-glob/README.html": {
    "href": "node_modules/fast-glob/README.html",
    "title": "fast-glob | accouter",
    "keywords": "fast-glob It's a very fast and efficient glob library for Node.js. This package provides methods for traversing the file system and returning pathnames that matched a defined set of a specified pattern according to the rules used by the Unix Bash shell with some simplifications, meanwhile results are returned in arbitrary order. Quick, simple, effective. Table of Contents Details Highlights Old and modern mode Pattern syntax Basic syntax Advanced syntax Installation API Asynchronous Synchronous Stream patterns [options] Helpers generateTasks isDynamicPattern escapePath convertPathToPattern Options Common concurrency cwd deep followSymbolicLinks fs ignore suppressErrors throwErrorOnBrokenSymbolicLink Output control absolute markDirectories objectMode onlyDirectories onlyFiles stats unique Matching control braceExpansion caseSensitiveMatch dot extglob globstar baseNameMatch FAQ What is a static or dynamic pattern? How to write patterns on Windows? Why are parentheses match wrong? How to exclude directory from reading? How to use UNC path? Compatible with node-glob? Benchmarks Server Nettop Changelog License Highlights Fast. Probably the fastest. Supports multiple and negative patterns. Synchronous, Promise and Stream API. Object mode. Can return more than just strings. Error-tolerant. Old and modern mode This package works in two modes, depending on the environment in which it is used. Old mode. Node.js below 10.10 or when the stats option is enabled. Modern mode. Node.js 10.10+ and the stats option is disabled. The modern mode is faster. Learn more about the internal mechanism. Pattern syntax ⚠️ Always use forward-slashes in glob expressions (patterns and ignore option). Use backslashes for escaping characters. There is more than one form of syntax: basic and advanced. Below is a brief overview of the supported features. Also pay attention to our FAQ. 📖 This package uses micromatch as a library for pattern matching. Basic syntax An asterisk (*) — matches everything except slashes (path separators), hidden files (names starting with .). A double star or globstar (**) — matches zero or more directories. Question mark (?) – matches any single character except slashes (path separators). Sequence ([seq]) — matches any character in sequence. 📖 A few additional words about the basic matching behavior. Some examples: src/**/*.js — matches all files in the src directory (any level of nesting) that have the .js extension. src/*.?? — matches all files in the src directory (only first level of nesting) that have a two-character extension. file-[01].js — matches files: file-0.js, file-1.js. Advanced syntax Escapes characters (\\\\) — matching special characters ($^*+?()[]) as literals. POSIX character classes ([[:digit:]]). Extended globs (?(pattern-list)). Bash style brace expansions ({}). Regexp character classes ([1-5]). Regex groups ((a|b)). 📖 A few additional words about the advanced matching behavior. Some examples: src/**/*.{css,scss} — matches all files in the src directory (any level of nesting) that have the .css or .scss extension. file-[[:digit:]].js — matches files: file-0.js, file-1.js, …, file-9.js. file-{1..3}.js — matches files: file-1.js, file-2.js, file-3.js. file-(1|2) — matches files: file-1.js, file-2.js. Installation npm install fast-glob API Asynchronous fg(patterns, [options]) fg.async(patterns, [options]) fg.glob(patterns, [options]) Returns a Promise with an array of matching entries. const fg = require('fast-glob'); const entries = await fg(['.editorconfig', '**/index.js'], { dot: true }); // ['.editorconfig', 'services/index.js'] Synchronous fg.sync(patterns, [options]) fg.globSync(patterns, [options]) Returns an array of matching entries. const fg = require('fast-glob'); const entries = fg.sync(['.editorconfig', '**/index.js'], { dot: true }); // ['.editorconfig', 'services/index.js'] Stream fg.stream(patterns, [options]) fg.globStream(patterns, [options]) Returns a ReadableStream when the data event will be emitted with matching entry. const fg = require('fast-glob'); const stream = fg.stream(['.editorconfig', '**/index.js'], { dot: true }); for await (const entry of stream) { // .editorconfig // services/index.js } patterns Required: true Type: string | string[] Any correct pattern(s). 🔢 Pattern syntax ⚠️ This package does not respect the order of patterns. First, all the negative patterns are applied, and only then the positive patterns. If you want to get a certain order of records, use sorting or split calls. [options] Required: false Type: Options See Options section. Helpers generateTasks(patterns, [options]) Returns the internal representation of patterns (Task is a combining patterns by base directory). fg.generateTasks('*'); [{ base: '.', // Parent directory for all patterns inside this task dynamic: true, // Dynamic or static patterns are in this task patterns: ['*'], positive: ['*'], negative: [] }] patterns Required: true Type: string | string[] Any correct pattern(s). [options] Required: false Type: Options See Options section. isDynamicPattern(pattern, [options]) Returns true if the passed pattern is a dynamic pattern. 🔢 What is a static or dynamic pattern? fg.isDynamicPattern('*'); // true fg.isDynamicPattern('abc'); // false pattern Required: true Type: string Any correct pattern. [options] Required: false Type: Options See Options section. escapePath(path) Returns the path with escaped special characters depending on the platform. Posix: *?|(){}[]; ! at the beginning of line; @+! before the opening parenthesis; \\\\ before non-special characters; Windows: (){}[] ! at the beginning of line; @+! before the opening parenthesis; Characters like *?| cannot be used in the path (windows_naming_conventions), so they will not be escaped; fg.escapePath('!abc'); // \\\\!abc fg.escapePath('[OpenSource] mrmlnc – fast-glob (Deluxe Edition) 2014') + '/*.flac' // \\\\[OpenSource\\\\] mrmlnc – fast-glob \\\\(Deluxe Edition\\\\) 2014/*.flac fg.posix.escapePath('C:\\\\Program Files (x86)\\\\**\\\\*'); // C:\\\\\\\\Program Files \\\\(x86\\\\)\\\\*\\\\*\\\\* fg.win32.escapePath('C:\\\\Program Files (x86)\\\\**\\\\*'); // Windows: C:\\\\Program Files \\\\(x86\\\\)\\\\**\\\\* convertPathToPattern(path) Converts a path to a pattern depending on the platform, including special character escaping. Posix. Works similarly to the fg.posix.escapePath method. Windows. Works similarly to the fg.win32.escapePath method, additionally converting backslashes to forward slashes in cases where they are not escape characters (!()+@{}[]). fg.convertPathToPattern('[OpenSource] mrmlnc – fast-glob (Deluxe Edition) 2014') + '/*.flac'; // \\\\[OpenSource\\\\] mrmlnc – fast-glob \\\\(Deluxe Edition\\\\) 2014/*.flac fg.convertPathToPattern('C:/Program Files (x86)/**/*'); // Posix: C:/Program Files \\\\(x86\\\\)/\\\\*\\\\*/\\\\* // Windows: C:/Program Files \\\\(x86\\\\)/**/* fg.convertPathToPattern('C:\\\\Program Files (x86)\\\\**\\\\*'); // Posix: C:\\\\\\\\Program Files \\\\(x86\\\\)\\\\*\\\\*\\\\* // Windows: C:/Program Files \\\\(x86\\\\)/**/* fg.posix.convertPathToPattern('\\\\\\\\?\\\\c:\\\\Program Files (x86)') + '/**/*'; // Posix: \\\\\\\\\\\\?\\\\\\\\c:\\\\\\\\Program Files \\\\(x86\\\\)/**/* (broken pattern) fg.win32.convertPathToPattern('\\\\\\\\?\\\\c:\\\\Program Files (x86)') + '/**/*'; // Windows: //?/c:/Program Files \\\\(x86\\\\)/**/* Options Common options concurrency Type: number Default: os.cpus().length Specifies the maximum number of concurrent requests from a reader to read directories. 📖 The higher the number, the higher the performance and load on the file system. If you want to read in quiet mode, set the value to a comfortable number or 1. More details In Node, there are two types of threads: Event Loop (code) and a Thread Pool (fs, dns, …). The thread pool size controlled by the UV_THREADPOOL_SIZE environment variable. Its default size is 4 (documentation). The pool is one for all tasks within a single Node process. Any code can make 4 real concurrent accesses to the file system. The rest of the FS requests will wait in the queue. 📖 Each new instance of FG in the same Node process will use the same Thread pool. But this package also has the concurrency option. This option allows you to control the number of concurrent accesses to the FS at the package level. By default, this package has a value equal to the number of cores available for the current Node process. This allows you to set a value smaller than the pool size (concurrency: 1) or, conversely, to prepare tasks for the pool queue more quickly (concurrency: Number.POSITIVE_INFINITY). So, in fact, this package can only make 4 concurrent requests to the FS. You can increase this value by using an environment variable (UV_THREADPOOL_SIZE), but in practice this does not give a multiple advantage. cwd Type: string Default: process.cwd() The current working directory in which to search. deep Type: number Default: Infinity Specifies the maximum depth of a read directory relative to the start directory. For example, you have the following tree: dir/ └── one/ // 1 └── two/ // 2 └── file.js // 3 // With base directory fg.sync('dir/**', { onlyFiles: false, deep: 1 }); // ['dir/one'] fg.sync('dir/**', { onlyFiles: false, deep: 2 }); // ['dir/one', 'dir/one/two'] // With cwd option fg.sync('**', { onlyFiles: false, cwd: 'dir', deep: 1 }); // ['one'] fg.sync('**', { onlyFiles: false, cwd: 'dir', deep: 2 }); // ['one', 'one/two'] 📖 If you specify a pattern with some base directory, this directory will not participate in the calculation of the depth of the found directories. Think of it as a cwd option. followSymbolicLinks Type: boolean Default: true Indicates whether to traverse descendants of symbolic link directories when expanding ** patterns. 📖 Note that this option does not affect the base directory of the pattern. For example, if ./a is a symlink to directory ./b and you specified ['./a**', './b/**'] patterns, then directory ./a will still be read. 📖 If the stats option is specified, the information about the symbolic link (fs.lstat) will be replaced with information about the entry (fs.stat) behind it. fs Type: FileSystemAdapter Default: fs.* Custom implementation of methods for working with the file system. export interface FileSystemAdapter { lstat?: typeof fs.lstat; stat?: typeof fs.stat; lstatSync?: typeof fs.lstatSync; statSync?: typeof fs.statSync; readdir?: typeof fs.readdir; readdirSync?: typeof fs.readdirSync; } ignore Type: string[] Default: [] An array of glob patterns to exclude matches. This is an alternative way to use negative patterns. dir/ ├── package-lock.json └── package.json fg.sync(['*.json', '!package-lock.json']); // ['package.json'] fg.sync('*.json', { ignore: ['package-lock.json'] }); // ['package.json'] suppressErrors Type: boolean Default: false By default this package suppress only ENOENT errors. Set to true to suppress any error. 📖 Can be useful when the directory has entries with a special level of access. throwErrorOnBrokenSymbolicLink Type: boolean Default: false Throw an error when symbolic link is broken if true or safely return lstat call if false. 📖 This option has no effect on errors when reading the symbolic link directory. Output control absolute Type: boolean Default: false Return the absolute path for entries. fg.sync('*.js', { absolute: false }); // ['index.js'] fg.sync('*.js', { absolute: true }); // ['/home/user/index.js'] 📖 This option is required if you want to use negative patterns with absolute path, for example, !${__dirname}/*.js. markDirectories Type: boolean Default: false Mark the directory path with the final slash. fg.sync('*', { onlyFiles: false, markDirectories: false }); // ['index.js', 'controllers'] fg.sync('*', { onlyFiles: false, markDirectories: true }); // ['index.js', 'controllers/'] objectMode Type: boolean Default: false Returns objects (instead of strings) describing entries. fg.sync('*', { objectMode: false }); // ['src/index.js'] fg.sync('*', { objectMode: true }); // [{ name: 'index.js', path: 'src/index.js', dirent: <fs.Dirent> }] The object has the following fields: name (string) — the last part of the path (basename) path (string) — full path relative to the pattern base directory dirent (fs.Dirent) — instance of fs.Dirent 📖 An object is an internal representation of entry, so getting it does not affect performance. onlyDirectories Type: boolean Default: false Return only directories. fg.sync('*', { onlyDirectories: false }); // ['index.js', 'src'] fg.sync('*', { onlyDirectories: true }); // ['src'] 📖 If true, the onlyFiles option is automatically false. onlyFiles Type: boolean Default: true Return only files. fg.sync('*', { onlyFiles: false }); // ['index.js', 'src'] fg.sync('*', { onlyFiles: true }); // ['index.js'] stats Type: boolean Default: false Enables an object mode with an additional field: stats (fs.Stats) — instance of fs.Stats fg.sync('*', { stats: false }); // ['src/index.js'] fg.sync('*', { stats: true }); // [{ name: 'index.js', path: 'src/index.js', dirent: <fs.Dirent>, stats: <fs.Stats> }] 📖 Returns fs.stat instead of fs.lstat for symbolic links when the followSymbolicLinks option is specified. ⚠️ Unlike object mode this mode requires additional calls to the file system. On average, this mode is slower at least twice. See old and modern mode for more details. unique Type: boolean Default: true Ensures that the returned entries are unique. fg.sync(['*.json', 'package.json'], { unique: false }); // ['package.json', 'package.json'] fg.sync(['*.json', 'package.json'], { unique: true }); // ['package.json'] If true and similar entries are found, the result is the first found. Matching control braceExpansion Type: boolean Default: true Enables Bash-like brace expansion. 🔢 Syntax description or more detailed description. dir/ ├── abd ├── acd └── a{b,c}d fg.sync('a{b,c}d', { braceExpansion: false }); // ['a{b,c}d'] fg.sync('a{b,c}d', { braceExpansion: true }); // ['abd', 'acd'] caseSensitiveMatch Type: boolean Default: true Enables a case-sensitive mode for matching files. dir/ ├── file.txt └── File.txt fg.sync('file.txt', { caseSensitiveMatch: false }); // ['file.txt', 'File.txt'] fg.sync('file.txt', { caseSensitiveMatch: true }); // ['file.txt'] dot Type: boolean Default: false Allow patterns to match entries that begin with a period (.). 📖 Note that an explicit dot in a portion of the pattern will always match dot files. dir/ ├── .editorconfig └── package.json fg.sync('*', { dot: false }); // ['package.json'] fg.sync('*', { dot: true }); // ['.editorconfig', 'package.json'] extglob Type: boolean Default: true Enables Bash-like extglob functionality. 🔢 Syntax description. dir/ ├── README.md └── package.json fg.sync('*.+(json|md)', { extglob: false }); // [] fg.sync('*.+(json|md)', { extglob: true }); // ['README.md', 'package.json'] globstar Type: boolean Default: true Enables recursively repeats a pattern containing **. If false, ** behaves exactly like *. dir/ └── a └── b fg.sync('**', { onlyFiles: false, globstar: false }); // ['a'] fg.sync('**', { onlyFiles: false, globstar: true }); // ['a', 'a/b'] baseNameMatch Type: boolean Default: false If set to true, then patterns without slashes will be matched against the basename of the path if it contains slashes. dir/ └── one/ └── file.md fg.sync('*.md', { baseNameMatch: false }); // [] fg.sync('*.md', { baseNameMatch: true }); // ['one/file.md'] FAQ What is a static or dynamic pattern? All patterns can be divided into two types: static. A pattern is considered static if it can be used to get an entry on the file system without using matching mechanisms. For example, the file.js pattern is a static pattern because we can just verify that it exists on the file system. dynamic. A pattern is considered dynamic if it cannot be used directly to find occurrences without using a matching mechanisms. For example, the * pattern is a dynamic pattern because we cannot use this pattern directly. A pattern is considered dynamic if it contains the following characters (… — any characters or their absence) or options: The caseSensitiveMatch option is disabled \\\\ (the escape character) *, ?, ! (at the beginning of line) […] (…|…) @(…), !(…), *(…), ?(…), +(…) (respects the extglob option) {…,…}, {…..…} (respects the braceExpansion option) How to write patterns on Windows? Always use forward-slashes in glob expressions (patterns and ignore option). Use backslashes for escaping characters. With the cwd option use a convenient format. Bad [ 'directory\\\\*', path.join(process.cwd(), '**') ] Good [ 'directory/*', fg.convertPathToPattern(process.cwd()) + '/**' ] 📖 Use the .convertPathToPattern package to convert Windows-style path to a Unix-style path. Read more about matching with backslashes. Why are parentheses match wrong? dir/ └── (special-*file).txt fg.sync(['(special-*file).txt']) // [] Refers to Bash. You need to escape special characters: fg.sync(['\\\\(special-*file\\\\).txt']) // ['(special-*file).txt'] Read more about matching special characters as literals. Or use the .escapePath. How to exclude directory from reading? You can use a negative pattern like this: !**/node_modules or !**/node_modules/**. Also you can use ignore option. Just look at the example below. first/ ├── file.md └── second/ └── file.txt If you don't want to read the second directory, you must write the following pattern: !**/second or !**/second/**. fg.sync(['**/*.md', '!**/second']); // ['first/file.md'] fg.sync(['**/*.md'], { ignore: ['**/second/**'] }); // ['first/file.md'] ⚠️ When you write !**/second/**/* it means that the directory will be read, but all the entries will not be included in the results. You have to understand that if you write the pattern to exclude directories, then the directory will not be read under any circumstances. How to use UNC path? You cannot use Uniform Naming Convention (UNC) paths as patterns (due to syntax) directly, but you can use them as cwd directory or use the fg.convertPathToPattern method. // cwd fg.sync('*', { cwd: '\\\\\\\\?\\\\C:\\\\Python27' /* or //?/C:/Python27 */ }); fg.sync('Python27/*', { cwd: '\\\\\\\\?\\\\C:\\\\' /* or //?/C:/ */ }); // .convertPathToPattern fg.sync(fg.convertPathToPattern('\\\\\\\\?\\\\c:\\\\Python27') + '/*'); Compatible with node-glob? node-glob fast-glob cwd cwd root – dot dot nomount – mark markDirectories nosort – nounique unique nobrace braceExpansion noglobstar globstar noext extglob nocase caseSensitiveMatch matchBase baseNameMatch nodir onlyFiles ignore ignore follow followSymbolicLinks realpath – absolute absolute Benchmarks You can see results here for every commit into the main branch. Product benchmark – comparison with the main competitors. Regress benchmark – regression between the current version and the version from the npm registry. Changelog See the Releases section of our GitHub project for changelog for each release version. License This software is released under the terms of the MIT license."
  },
  "node_modules/fastq/README.html": {
    "href": "node_modules/fastq/README.html",
    "title": "fastq | accouter",
    "keywords": "fastq Fast, in memory work queue. Benchmarks (1 million tasks): setImmediate: 812ms fastq: 854ms async.queue: 1298ms neoAsync.queue: 1249ms Obtained on node 12.16.1, on a dedicated server. If you need zero-overhead series function call, check out fastseries. For zero-overhead parallel function call, check out fastparallel. Installation Usage API Licence & copyright Install npm i fastq --save Usage (callback API) 'use strict' const queue = require('fastq')(worker, 1) queue.push(42, function (err, result) { if (err) { throw err } console.log('the result is', result) }) function worker (arg, cb) { cb(null, arg * 2) } Usage (promise API) const queue = require('fastq').promise(worker, 1) async function worker (arg) { return arg * 2 } async function run () { const result = await queue.push(42) console.log('the result is', result) } run() Setting \"this\" 'use strict' const that = { hello: 'world' } const queue = require('fastq')(that, worker, 1) queue.push(42, function (err, result) { if (err) { throw err } console.log(this) console.log('the result is', result) }) function worker (arg, cb) { console.log(this) cb(null, arg * 2) } Using with TypeScript (callback API) 'use strict' import * as fastq from \"fastq\"; import type { queue, done } from \"fastq\"; type Task = { id: number } const q: queue<Task> = fastq(worker, 1) q.push({ id: 42}) function worker (arg: Task, cb: done) { console.log(arg.id) cb(null) } Using with TypeScript (promise API) 'use strict' import * as fastq from \"fastq\"; import type { queueAsPromised } from \"fastq\"; type Task = { id: number } const q: queueAsPromised<Task> = fastq.promise(asyncWorker, 1) q.push({ id: 42}).catch((err) => console.error(err)) async function asyncWorker (arg: Task): Promise<void> { // No need for a try-catch block, fastq handles errors automatically console.log(arg.id) } API fastqueue() queue#push() queue#unshift() queue#pause() queue#resume() queue#idle() queue#length() queue#getQueue() queue#kill() queue#killAndDrain() queue#error() queue#concurrency queue#drain queue#empty queue#saturated fastqueue.promise() fastqueue([that], worker, concurrency) Creates a new queue. Arguments: that, optional context of the worker function. worker, worker function, it would be called with that as this, if that is specified. concurrency, number of concurrent tasks that could be executed in parallel. queue.push(task, done) Add a task at the end of the queue. done(err, result) will be called when the task was processed. queue.unshift(task, done) Add a task at the beginning of the queue. done(err, result) will be called when the task was processed. queue.pause() Pause the processing of tasks. Currently worked tasks are not stopped. queue.resume() Resume the processing of tasks. queue.idle() Returns false if there are tasks being processed or waiting to be processed. true otherwise. queue.length() Returns the number of tasks waiting to be processed (in the queue). queue.getQueue() Returns all the tasks be processed (in the queue). Returns empty array when there are no tasks queue.kill() Removes all tasks waiting to be processed, and reset drain to an empty function. queue.killAndDrain() Same than kill but the drain function will be called before reset to empty. queue.error(handler) Set a global error handler. handler(err, task) will be called each time a task is completed, err will be not null if the task has thrown an error. queue.concurrency Property that returns the number of concurrent tasks that could be executed in parallel. It can be altered at runtime. queue.drain Function that will be called when the last item from the queue has been processed by a worker. It can be altered at runtime. queue.empty Function that will be called when the last item from the queue has been assigned to a worker. It can be altered at runtime. queue.saturated Function that will be called when the queue hits the concurrency limit. It can be altered at runtime. fastqueue.promise([that], worker(arg), concurrency) Creates a new queue with Promise apis. It also offers all the methods and properties of the object returned by fastqueue with the modified push and unshift methods. Node v10+ is required to use the promisified version. Arguments: that, optional context of the worker function. worker, worker function, it would be called with that as this, if that is specified. It MUST return a Promise. concurrency, number of concurrent tasks that could be executed in parallel. queue.push(task) => Promise Add a task at the end of the queue. The returned Promise will be fulfilled (rejected) when the task is completed successfully (unsuccessfully). This promise could be ignored as it will not lead to a 'unhandledRejection'. queue.unshift(task) => Promise Add a task at the beginning of the queue. The returned Promise will be fulfilled (rejected) when the task is completed successfully (unsuccessfully). This promise could be ignored as it will not lead to a 'unhandledRejection'. queue.drained() => Promise Wait for the queue to be drained. The returned Promise will be resolved when all tasks in the queue have been processed by a worker. This promise could be ignored as it will not lead to a 'unhandledRejection'. License ISC"
  },
  "node_modules/fill-range/README.html": {
    "href": "node_modules/fill-range/README.html",
    "title": "fill-range | accouter",
    "keywords": "fill-range Fill in a range of numbers or letters, optionally passing an increment or step to use, or create a regex-compatible range with options.toRegex Please consider following this project's author, Jon Schlinkert, and consider starring the project to show your ❤️ and support. Install Install with npm: $ npm install --save fill-range Usage Expands numbers and letters, optionally using a step as the last argument. (Numbers may be defined as JavaScript numbers or strings). const fill = require('fill-range'); // fill(from, to[, step, options]); console.log(fill('1', '10')); //=> ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'] console.log(fill('1', '10', { toRegex: true })); //=> [1-9]|10 Params from: {String|Number} the number or letter to start with to: {String|Number} the number or letter to end with step: {String|Number|Object|Function} Optionally pass a step to use. options: {Object|Function}: See all available options Examples By default, an array of values is returned. Alphabetical ranges console.log(fill('a', 'e')); //=> ['a', 'b', 'c', 'd', 'e'] console.log(fill('A', 'E')); //=> [ 'A', 'B', 'C', 'D', 'E' ] Numerical ranges Numbers can be defined as actual numbers or strings. console.log(fill(1, 5)); //=> [ 1, 2, 3, 4, 5 ] console.log(fill('1', '5')); //=> [ 1, 2, 3, 4, 5 ] Negative ranges Numbers can be defined as actual numbers or strings. console.log(fill('-5', '-1')); //=> [ '-5', '-4', '-3', '-2', '-1' ] console.log(fill('-5', '5')); //=> [ '-5', '-4', '-3', '-2', '-1', '0', '1', '2', '3', '4', '5' ] Steps (increments) // numerical ranges with increments console.log(fill('0', '25', 4)); //=> [ '0', '4', '8', '12', '16', '20', '24' ] console.log(fill('0', '25', 5)); //=> [ '0', '5', '10', '15', '20', '25' ] console.log(fill('0', '25', 6)); //=> [ '0', '6', '12', '18', '24' ] // alphabetical ranges with increments console.log(fill('a', 'z', 4)); //=> [ 'a', 'e', 'i', 'm', 'q', 'u', 'y' ] console.log(fill('a', 'z', 5)); //=> [ 'a', 'f', 'k', 'p', 'u', 'z' ] console.log(fill('a', 'z', 6)); //=> [ 'a', 'g', 'm', 's', 'y' ] Options options.step Type: number (formatted as a string or number) Default: undefined Description: The increment to use for the range. Can be used with letters or numbers. Example(s) // numbers console.log(fill('1', '10', 2)); //=> [ '1', '3', '5', '7', '9' ] console.log(fill('1', '10', 3)); //=> [ '1', '4', '7', '10' ] console.log(fill('1', '10', 4)); //=> [ '1', '5', '9' ] // letters console.log(fill('a', 'z', 5)); //=> [ 'a', 'f', 'k', 'p', 'u', 'z' ] console.log(fill('a', 'z', 7)); //=> [ 'a', 'h', 'o', 'v' ] console.log(fill('a', 'z', 9)); //=> [ 'a', 'j', 's' ] options.strictRanges Type: boolean Default: false Description: By default, null is returned when an invalid range is passed. Enable this option to throw a RangeError on invalid ranges. Example(s) The following are all invalid: fill('1.1', '2'); // decimals not supported in ranges fill('a', '2'); // incompatible range values fill(1, 10, 'foo'); // invalid \"step\" argument options.stringify Type: boolean Default: undefined Description: Cast all returned values to strings. By default, integers are returned as numbers. Example(s) console.log(fill(1, 5)); //=> [ 1, 2, 3, 4, 5 ] console.log(fill(1, 5, { stringify: true })); //=> [ '1', '2', '3', '4', '5' ] options.toRegex Type: boolean Default: undefined Description: Create a regex-compatible source string, instead of expanding values to an array. Example(s) // alphabetical range console.log(fill('a', 'e', { toRegex: true })); //=> '[a-e]' // alphabetical with step console.log(fill('a', 'z', 3, { toRegex: true })); //=> 'a|d|g|j|m|p|s|v|y' // numerical range console.log(fill('1', '100', { toRegex: true })); //=> '[1-9]|[1-9][0-9]|100' // numerical range with zero padding console.log(fill('000001', '100000', { toRegex: true })); //=> '0{5}[1-9]|0{4}[1-9][0-9]|0{3}[1-9][0-9]{2}|0{2}[1-9][0-9]{3}|0[1-9][0-9]{4}|100000' options.transform Type: function Default: undefined Description: Customize each value in the returned array (or string). (you can also pass this function as the last argument to fill()). Example(s) // add zero padding console.log(fill(1, 5, value => String(value).padStart(4, '0'))); //=> ['0001', '0002', '0003', '0004', '0005'] About Contributing Pull requests and stars are always welcome. For bugs and feature requests, please create an issue. Running Tests Running and reviewing unit tests is a great way to get familiarized with a library and its API. You can install dependencies and run tests with the following command: $ npm install && npm test Building docs (This project's readme.md is generated by verb, please don't edit the readme directly. Any changes to the readme must be made in the .verb.md readme template.) To generate the readme, run the following command: $ npm install -g verbose/verb#dev verb-generate-readme && verb Contributors Commits Contributor 116 jonschlinkert 4 paulmillr 2 realityking 2 bluelovers 1 edorivai 1 wtgtybhertgeghgtwtg Author Jon Schlinkert GitHub Profile Twitter Profile LinkedIn Profile Please consider supporting me on Patreon, or start your own Patreon page! License Copyright © 2019, Jon Schlinkert. Released under the MIT License. This file was generated by verb-generate-readme, v0.8.0, on April 08, 2019."
  },
  "node_modules/finalhandler/HISTORY.html": {
    "href": "node_modules/finalhandler/HISTORY.html",
    "title": "1.1.0 / 2017-09-24 | accouter",
    "keywords": "1.1.0 / 2017-09-24 Use res.headersSent when available 1.0.6 / 2017-09-22 deps: debug@2.6.9 1.0.5 / 2017-09-15 deps: parseurl@~1.3.2 perf: reduce overhead for full URLs perf: unroll the \"fast-path\" RegExp 1.0.4 / 2017-08-03 deps: debug@2.6.8 1.0.3 / 2017-05-16 deps: debug@2.6.7 deps: ms@2.0.0 1.0.2 / 2017-04-22 deps: debug@2.6.4 deps: ms@0.7.3 1.0.1 / 2017-03-21 Fix missing </html> in HTML document deps: debug@2.6.3 Fix: DEBUG_MAX_ARRAY_LENGTH 1.0.0 / 2017-02-15 Fix exception when err cannot be converted to a string Fully URL-encode the pathname in the 404 message Only include the pathname in the 404 message Send complete HTML document Set Content-Security-Policy: default-src 'self' header deps: debug@2.6.1 Allow colors in workers Deprecated DEBUG_FD environment variable set to 3 or higher Fix error when running under React Native Use same color for same namespace deps: ms@0.7.2 0.5.1 / 2016-11-12 Fix exception when err.headers is not an object deps: statuses@~1.3.1 perf: hoist regular expressions perf: remove duplicate validation path 0.5.0 / 2016-06-15 Change invalid or non-numeric status code to 500 Overwrite status message to match set status code Prefer err.statusCode if err.status is invalid Set response headers from err.headers object Use statuses instead of http module for status messages Includes all defined status messages 0.4.1 / 2015-12-02 deps: escape-html@~1.0.3 perf: enable strict mode perf: optimize string replacement perf: use faster string coercion 0.4.0 / 2015-06-14 Fix a false-positive when unpiping in Node.js 0.8 Support statusCode property on Error objects Use unpipe module for unpiping requests deps: escape-html@1.0.2 deps: on-finished@~2.3.0 Add defined behavior for HTTP CONNECT requests Add defined behavior for HTTP Upgrade requests deps: ee-first@1.1.1 perf: enable strict mode perf: remove argument reassignment 0.3.6 / 2015-05-11 deps: debug@~2.2.0 deps: ms@0.7.1 0.3.5 / 2015-04-22 deps: on-finished@~2.2.1 Fix isFinished(req) when data buffered 0.3.4 / 2015-03-15 deps: debug@~2.1.3 Fix high intensity foreground color for bold deps: ms@0.7.0 0.3.3 / 2015-01-01 deps: debug@~2.1.1 deps: on-finished@~2.2.0 0.3.2 / 2014-10-22 deps: on-finished@~2.1.1 Fix handling of pipelined requests 0.3.1 / 2014-10-16 deps: debug@~2.1.0 Implement DEBUG_FD env variable support 0.3.0 / 2014-09-17 Terminate in progress response only on error Use on-finished to determine request status 0.2.0 / 2014-09-03 Set X-Content-Type-Options: nosniff header deps: debug@~2.0.0 0.1.0 / 2014-07-16 Respond after request fully read prevents hung responses and socket hang ups deps: debug@1.0.4 0.0.3 / 2014-07-11 deps: debug@1.0.3 Add support for multiple wildcards in namespaces 0.0.2 / 2014-06-19 Handle invalid status codes 0.0.1 / 2014-06-05 deps: debug@1.0.2 0.0.0 / 2014-06-05 Extracted from connect/express"
  },
  "node_modules/finalhandler/README.html": {
    "href": "node_modules/finalhandler/README.html",
    "title": "finalhandler | accouter",
    "keywords": "finalhandler Node.js function to invoke as the final step to respond to HTTP request. Installation This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install finalhandler API var finalhandler = require('finalhandler') finalhandler(req, res, [options]) Returns function to be invoked as the final step for the given req and res. This function is to be invoked as fn(err). If err is falsy, the handler will write out a 404 response to the res. If it is truthy, an error response will be written out to the res. When an error is written, the following information is added to the response: The res.statusCode is set from err.status (or err.statusCode). If this value is outside the 4xx or 5xx range, it will be set to 500. The res.statusMessage is set according to the status code. The body will be the HTML of the status code message if env is 'production', otherwise will be err.stack. Any headers specified in an err.headers object. The final handler will also unpipe anything from req when it is invoked. options.env By default, the environment is determined by NODE_ENV variable, but it can be overridden by this option. options.onerror Provide a function to be called with the err when it exists. Can be used for writing errors to a central location without excessive function generation. Called as onerror(err, req, res). Examples always 404 var finalhandler = require('finalhandler') var http = require('http') var server = http.createServer(function (req, res) { var done = finalhandler(req, res) done() }) server.listen(3000) perform simple action var finalhandler = require('finalhandler') var fs = require('fs') var http = require('http') var server = http.createServer(function (req, res) { var done = finalhandler(req, res) fs.readFile('index.html', function (err, buf) { if (err) return done(err) res.setHeader('Content-Type', 'text/html') res.end(buf) }) }) server.listen(3000) use with middleware-style functions var finalhandler = require('finalhandler') var http = require('http') var serveStatic = require('serve-static') var serve = serveStatic('public') var server = http.createServer(function (req, res) { var done = finalhandler(req, res) serve(req, res, done) }) server.listen(3000) keep log of all errors var finalhandler = require('finalhandler') var fs = require('fs') var http = require('http') var server = http.createServer(function (req, res) { var done = finalhandler(req, res, {onerror: logerror}) fs.readFile('index.html', function (err, buf) { if (err) return done(err) res.setHeader('Content-Type', 'text/html') res.end(buf) }) }) server.listen(3000) function logerror (err) { console.error(err.stack || err.toString()) } License MIT"
  },
  "node_modules/find-up/readme.html": {
    "href": "node_modules/find-up/readme.html",
    "title": "find-up | accouter",
    "keywords": "find-up Find a file or directory by walking up parent directories Install $ npm install find-up Usage / └── Users └── sindresorhus ├── unicorn.png └── foo └── bar ├── baz └── example.js example.js const path = require('path'); const findUp = require('find-up'); (async () => { console.log(await findUp('unicorn.png')); //=> '/Users/sindresorhus/unicorn.png' console.log(await findUp(['rainbow.png', 'unicorn.png'])); //=> '/Users/sindresorhus/unicorn.png' console.log(await findUp(async directory => { const hasUnicorns = await findUp.exists(path.join(directory, 'unicorn.png')); return hasUnicorns && directory; }, {type: 'directory'})); //=> '/Users/sindresorhus' })(); API findUp(name, options?) findUp(matcher, options?) Returns a Promise for either the path or undefined if it couldn't be found. findUp([...name], options?) Returns a Promise for either the first path found (by respecting the order of the array) or undefined if none could be found. findUp.sync(name, options?) findUp.sync(matcher, options?) Returns a path or undefined if it couldn't be found. findUp.sync([...name], options?) Returns the first path found (by respecting the order of the array) or undefined if none could be found. name Type: string Name of the file or directory to find. matcher Type: Function A function that will be called with each directory until it returns a string with the path, which stops the search, or the root directory has been reached and nothing was found. Useful if you want to match files with certain patterns, set of permissions, or other advanced use-cases. When using async mode, the matcher may optionally be an async or promise-returning function that returns the path. options Type: object cwd Type: string Default: process.cwd() Directory to start from. type Type: string Default: 'file' Values: 'file' 'directory' The type of paths that can match. allowSymlinks Type: boolean Default: true Allow symbolic links to match if they point to the chosen path type. findUp.exists(path) Returns a Promise<boolean> of whether the path exists. findUp.sync.exists(path) Returns a boolean of whether the path exists. path Type: string Path to a file or directory. findUp.stop A Symbol that can be returned by a matcher function to stop the search and cause findUp to immediately return undefined. Useful as a performance optimization in case the current working directory is deeply nested in the filesystem. const path = require('path'); const findUp = require('find-up'); (async () => { await findUp(directory => { return path.basename(directory) === 'work' ? findUp.stop : 'logo.png'; }); })(); Related find-up-cli - CLI for this module pkg-up - Find the closest package.json file pkg-dir - Find the root directory of an npm package resolve-from - Resolve the path of a module like require.resolve() but from a given path Get professional support for 'find-up' with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "node_modules/flat/README.html": {
    "href": "node_modules/flat/README.html",
    "title": "flat | accouter",
    "keywords": "flat Take a nested Javascript object and flatten it, or unflatten an object with delimited keys. Installation $ npm install flat Methods flatten(original, options) Flattens the object - it'll return an object one level deep, regardless of how nested the original object was: var flatten = require('flat') flatten({ key1: { keyA: 'valueI' }, key2: { keyB: 'valueII' }, key3: { a: { b: { c: 2 } } } }) // { // 'key1.keyA': 'valueI', // 'key2.keyB': 'valueII', // 'key3.a.b.c': 2 // } unflatten(original, options) Flattening is reversible too, you can call flatten.unflatten() on an object: var unflatten = require('flat').unflatten unflatten({ 'three.levels.deep': 42, 'three.levels': { nested: true } }) // { // three: { // levels: { // deep: 42, // nested: true // } // } // } Options delimiter Use a custom delimiter for (un)flattening your objects, instead of .. safe When enabled, both flat and unflatten will preserve arrays and their contents. This is disabled by default. var flatten = require('flat') flatten({ this: [ { contains: 'arrays' }, { preserving: { them: 'for you' }} ] }, { safe: true }) // { // 'this': [ // { contains: 'arrays' }, // { preserving: { // them: 'for you' // }} // ] // } object When enabled, arrays will not be created automatically when calling unflatten, like so: unflatten({ 'hello.you.0': 'ipsum', 'hello.you.1': 'lorem', 'hello.other.world': 'foo' }, { object: true }) // hello: { // you: { // 0: 'ipsum', // 1: 'lorem', // }, // other: { world: 'foo' } // } overwrite When enabled, existing keys in the unflattened object may be overwritten if they cannot hold a newly encountered nested value: unflatten({ 'TRAVIS': 'true', 'TRAVIS.DIR': '/home/travis/build/kvz/environmental' }, { overwrite: true }) // TRAVIS: { // DIR: '/home/travis/build/kvz/environmental' // } Without overwrite set to true, the TRAVIS key would already have been set to a string, thus could not accept the nested DIR element. This only makes sense on ordered arrays, and since we're overwriting data, should be used with care. maxDepth Maximum number of nested objects to flatten. var flatten = require('flat') flatten({ key1: { keyA: 'valueI' }, key2: { keyB: 'valueII' }, key3: { a: { b: { c: 2 } } } }, { maxDepth: 2 }) // { // 'key1.keyA': 'valueI', // 'key2.keyB': 'valueII', // 'key3.a': { b: { c: 2 } } // } transformKey Transform each part of a flat key before and after flattening. var flatten = require('flat') var unflatten = require('flat').unflatten flatten({ key1: { keyA: 'valueI' }, key2: { keyB: 'valueII' }, key3: { a: { b: { c: 2 } } } }, { transformKey: function(key){ return '__' + key + '__'; } }) // { // '__key1__.__keyA__': 'valueI', // '__key2__.__keyB__': 'valueII', // '__key3__.__a__.__b__.__c__': 2 // } unflatten({ '__key1__.__keyA__': 'valueI', '__key2__.__keyB__': 'valueII', '__key3__.__a__.__b__.__c__': 2 }, { transformKey: function(key){ return key.substring(2, key.length - 2) } }) // { // key1: { // keyA: 'valueI' // }, // key2: { // keyB: 'valueII' // }, // key3: { a: { b: { c: 2 } } } // } Command Line Usage flat is also available as a command line tool. You can run it with npx: npx flat foo.json Or install the flat command globally: npm i -g flat && flat foo.json Accepts a filename as an argument: flat foo.json Also accepts JSON on stdin: cat foo.json | flat"
  },
  "node_modules/follow-redirects/README.html": {
    "href": "node_modules/follow-redirects/README.html",
    "title": "| accouter",
    "keywords": "Follow Redirects Drop-in replacement for Node's http and https modules that automatically follows redirects. follow-redirects provides request and get methods that behave identically to those found on the native http and https modules, with the exception that they will seamlessly follow redirects. const { http, https } = require('follow-redirects'); http.get('http://bit.ly/900913', response => { response.on('data', chunk => { console.log(chunk); }); }).on('error', err => { console.error(err); }); You can inspect the final redirected URL through the responseUrl property on the response. If no redirection happened, responseUrl is the original request URL. const request = https.request({ host: 'bitly.com', path: '/UHfDGO', }, response => { console.log(response.responseUrl); // 'http://duckduckgo.com/robots.txt' }); request.end(); Options Global options Global options are set directly on the follow-redirects module: const followRedirects = require('follow-redirects'); followRedirects.maxRedirects = 10; followRedirects.maxBodyLength = 20 * 1024 * 1024; // 20 MB The following global options are supported: maxRedirects (default: 21) – sets the maximum number of allowed redirects; if exceeded, an error will be emitted. maxBodyLength (default: 10MB) – sets the maximum size of the request body; if exceeded, an error will be emitted. Per-request options Per-request options are set by passing an options object: const url = require('url'); const { http, https } = require('follow-redirects'); const options = url.parse('http://bit.ly/900913'); options.maxRedirects = 10; options.beforeRedirect = (options, response, request) => { // Use this to adjust the request options upon redirecting, // to inspect the latest response headers, // or to cancel the request by throwing an error // response.headers = the redirect response headers // response.statusCode = the redirect response code (eg. 301, 307, etc.) // request.url = the requested URL that resulted in a redirect // request.headers = the headers in the request that resulted in a redirect // request.method = the method of the request that resulted in a redirect if (options.hostname === \"example.com\") { options.auth = \"user:password\"; } }; http.request(options); In addition to the standard HTTP and HTTPS options, the following per-request options are supported: followRedirects (default: true) – whether redirects should be followed. maxRedirects (default: 21) – sets the maximum number of allowed redirects; if exceeded, an error will be emitted. maxBodyLength (default: 10MB) – sets the maximum size of the request body; if exceeded, an error will be emitted. beforeRedirect (default: undefined) – optionally change the request options on redirects, or abort the request by throwing an error. agents (default: undefined) – sets the agent option per protocol, since HTTP and HTTPS use different agents. Example value: { http: new http.Agent(), https: new https.Agent() } trackRedirects (default: false) – whether to store the redirected response details into the redirects array on the response object. Advanced usage By default, follow-redirects will use the Node.js default implementations of http and https. To enable features such as caching and/or intermediate request tracking, you might instead want to wrap follow-redirects around custom protocol implementations: const { http, https } = require('follow-redirects').wrap({ http: require('your-custom-http'), https: require('your-custom-https'), }); Such custom protocols only need an implementation of the request method. Browser Usage Due to the way the browser works, the http and https browser equivalents perform redirects by default. By requiring follow-redirects this way: const http = require('follow-redirects/http'); const https = require('follow-redirects/https'); you can easily tell webpack and friends to replace follow-redirect by the built-in versions: { \"follow-redirects/http\" : \"http\", \"follow-redirects/https\" : \"https\" } Contributing Pull Requests are always welcome. Please file an issue detailing your proposal before you invest your valuable time. Additional features and bug fixes should be accompanied by tests. You can run the test suite locally with a simple npm test command. Debug Logging follow-redirects uses the excellent debug for logging. To turn on logging set the environment variable DEBUG=follow-redirects for debug output from just this module. When running the test suite it is sometimes advantageous to set DEBUG=* to see output from the express server as well. Authors Ruben Verborgh Olivier Lalonde James Talmage License MIT License"
  },
  "node_modules/for-each/README.html": {
    "href": "node_modules/for-each/README.html",
    "title": "for-each | accouter",
    "keywords": "for-each A better forEach. Example Like Array.prototype.forEach but works on objects. var forEach = require(\"for-each\") forEach({ key: \"value\" }, function (value, key, object) { /* code */ }) As a bonus, it's also a perfectly function shim/polyfill for arrays too! var forEach = require(\"for-each\") forEach([1, 2, 3], function (value, index, array) { /* code */ }) Installation npm install for-each Contributors Raynos MIT Licenced"
  },
  "node_modules/foreground-child/README.html": {
    "href": "node_modules/foreground-child/README.html",
    "title": "foreground-child | accouter",
    "keywords": "foreground-child Run a child as if it's the foreground process. Give it stdio. Exit when it exits. Mostly this module is here to support some use cases around wrapping child processes for test coverage and such. But it's also generally useful any time you want one program to execute another as if it's the \"main\" process, for example, if a program takes a --cmd argument to execute in some way. USAGE import { foregroundChild } from 'foreground-child' // hybrid module, this also works: // const { foregroundChild } = require('foreground-child') // cats out this file const child = foregroundChild('cat', [__filename]) // At this point, it's best to just do nothing else. // return or whatever. // If the child gets a signal, or just exits, then this // parent process will exit in the same way. You can provide custom spawn options by passing an object after the program and arguments: const child = foregroundChild(`cat ${__filename}`, { shell: true }) A callback can optionally be provided, if you want to perform an action before your foreground-child exits: const child = foregroundChild('cat', [__filename], spawnOptions, () => { doSomeActions() }) The callback can return a Promise in order to perform asynchronous actions. If the callback does not return a promise, then it must complete its actions within a single JavaScript tick. const child = foregroundChild('cat', [__filename], async () => { await doSomeAsyncActions() }) If the callback throws or rejects, then it will be unhandled, and node will exit in error. If the callback returns a string value, then that will be used as the signal to exit the parent process. If it returns a number, then that number will be used as the parent exit status code. If it returns boolean false, then the parent process will not be terminated. If it returns undefined, then it will exit with the same signal/code as the child process. Caveats The \"normal\" standard IO file descriptors (0, 1, and 2 for stdin, stdout, and stderr respectively) are shared with the child process. Additionally, if there is an IPC channel set up in the parent, then messages are proxied to the child on file descriptor 3. In Node, it's possible to also map arbitrary file descriptors into a child process. In these cases, foreground-child will not map the file descriptors into the child. If file descriptors 0, 1, or 2 are used for the IPC channel, then strange behavior may happen (like printing IPC messages to stderr, for example). Note that a SIGKILL will always kill the parent process, but will not proxy the signal to the child process, because SIGKILL cannot be caught. In order to address this, a special \"watchdog\" child process is spawned which will send a SIGKILL to the child process if it does not terminate within half a second after the watchdog receives a SIGHUP due to its parent terminating. On Windows, issuing a process.kill(process.pid, signal) with a fatal termination signal may cause the process to exit with a 1 status code rather than reporting the signal properly. This module tries to do the right thing, but on Windows systems, you may see that incorrect result. There is as far as I'm aware no workaround for this."
  },
  "node_modules/foreground-child/node_modules/cross-spawn/CHANGELOG.html": {
    "href": "node_modules/foreground-child/node_modules/cross-spawn/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. See standard-version for commit guidelines. 7.0.3 (2020-05-25) Bug Fixes detect path key based on correct environment (#133) (159e7e9) 7.0.2 (2020-04-04) Bug Fixes fix worker threads in Node >=11.10.0 (#132) (6c5b4f0) 7.0.1 (2019-10-07) Bug Fixes core: support worker threads (#127) (cfd49c9) 7.0.0 (2019-09-03) ⚠ BREAKING CHANGES drop support for Node.js < 8 drop support for versions below Node.js 8 (#125) (16feb53) 6.0.5 (2018-03-02) Bug Fixes avoid using deprecated Buffer constructor (#94) (d5770df), closes /nodejs.org/api/deprecations.html#deprecations_dep0005 6.0.4 (2018-01-31) Bug Fixes fix paths being incorrectly normalized on unix (06ee3c6), closes #90 6.0.3 (2018-01-23) 6.0.2 (2018-01-23) 6.0.1 (2018-01-23) 6.0.0 (2018-01-23) Bug Fixes fix certain arguments not being correctly escaped or causing batch syntax error (900cf10), closes #82 #51 fix commands as posix relatixe paths not working correctly, e.g.: ./my-command (900cf10) fix options argument being mutated (900cf10) fix commands resolution when PATH was actually Path (900cf10) Features improve compliance with node's ENOENT errors (900cf10) improve detection of node's shell option support (900cf10) Chores upgrade tooling upgrate project to es6 (node v4) BREAKING CHANGES remove support for older nodejs versions, only node >= 4 is supported 5.1.0 (2017-02-26) Bug Fixes fix options.shell support for NodeJS v4.8 5.0.1 (2016-11-04) Bug Fixes fix options.shell support for NodeJS v7 5.0.0 (2016-10-30) Features add support for options.shell improve parsing of shebangs by using shebang-command module Chores refactor some code to make it more clear update README caveats"
  },
  "node_modules/foreground-child/node_modules/cross-spawn/README.html": {
    "href": "node_modules/foreground-child/node_modules/cross-spawn/README.html",
    "title": "cross-spawn | accouter",
    "keywords": "cross-spawn A cross platform solution to node's spawn and spawnSync. Installation Node.js version 8 and up: $ npm install cross-spawn Node.js version 7 and under: $ npm install cross-spawn@6 Why Node has issues when using spawn on Windows: It ignores PATHEXT It does not support shebangs Has problems running commands with spaces Has problems running commands with posix relative paths (e.g.: ./my-folder/my-executable) Has an issue with command shims (files in node_modules/.bin/), where arguments with quotes and parenthesis would result in invalid syntax error No options.shell support on node <v4.8 All these issues are handled correctly by cross-spawn. There are some known modules, such as win-spawn, that try to solve this but they are either broken or provide faulty escaping of shell arguments. Usage Exactly the same way as node's spawn or spawnSync, so it's a drop in replacement. const spawn = require('cross-spawn'); // Spawn NPM asynchronously const child = spawn('npm', ['list', '-g', '-depth', '0'], { stdio: 'inherit' }); // Spawn NPM synchronously const result = spawn.sync('npm', ['list', '-g', '-depth', '0'], { stdio: 'inherit' }); Caveats Using options.shell as an alternative to cross-spawn Starting from node v4.8, spawn has a shell option that allows you run commands from within a shell. This new option solves the PATHEXT issue but: It's not supported in node <v4.8 You must manually escape the command and arguments which is very error prone, specially when passing user input There are a lot of other unresolved issues from the Why section that you must take into account If you are using the shell option to spawn a command in a cross platform way, consider using cross-spawn instead. You have been warned. options.shell support While cross-spawn adds support for options.shell in node <v4.8, all of its enhancements are disabled. This mimics the Node.js behavior. More specifically, the command and its arguments will not be automatically escaped nor shebang support will be offered. This is by design because if you are using options.shell you are probably targeting a specific platform anyway and you don't want things to get into your way. Shebangs support While cross-spawn handles shebangs on Windows, its support is limited. More specifically, it just supports #!/usr/bin/env <program> where <program> must not contain any arguments. If you would like to have the shebang support improved, feel free to contribute via a pull-request. Remember to always test your code on Windows! Tests $ npm test $ npm test -- --watch during development License Released under the MIT License."
  },
  "node_modules/foreground-child/node_modules/path-key/readme.html": {
    "href": "node_modules/foreground-child/node_modules/path-key/readme.html",
    "title": "path-key | accouter",
    "keywords": "path-key Get the PATH environment variable key cross-platform It's usually PATH, but on Windows it can be any casing like Path... Install $ npm install path-key Usage const pathKey = require('path-key'); const key = pathKey(); //=> 'PATH' const PATH = process.env[key]; //=> '/usr/local/bin:/usr/bin:/bin' API pathKey(options?) options Type: object env Type: object Default: process.env Use a custom environment variables object. platform Type: string Default: process.platform Get the PATH key for a specific platform. Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "node_modules/foreground-child/node_modules/shebang-command/readme.html": {
    "href": "node_modules/foreground-child/node_modules/shebang-command/readme.html",
    "title": "shebang-command | accouter",
    "keywords": "shebang-command Get the command from a shebang Install $ npm install shebang-command Usage const shebangCommand = require('shebang-command'); shebangCommand('#!/usr/bin/env node'); //=> 'node' shebangCommand('#!/bin/bash'); //=> 'bash' API shebangCommand(string) string Type: string String containing a shebang."
  },
  "node_modules/foreground-child/node_modules/shebang-regex/readme.html": {
    "href": "node_modules/foreground-child/node_modules/shebang-regex/readme.html",
    "title": "shebang-regex | accouter",
    "keywords": "shebang-regex Regular expression for matching a shebang line Install $ npm install shebang-regex Usage const shebangRegex = require('shebang-regex'); const string = '#!/usr/bin/env node\\nconsole.log(\"unicorns\");'; shebangRegex.test(string); //=> true shebangRegex.exec(string)[0]; //=> '#!/usr/bin/env node' shebangRegex.exec(string)[1]; //=> '/usr/bin/env node' License MIT © Sindre Sorhus"
  },
  "node_modules/foreground-child/node_modules/which/CHANGELOG.html": {
    "href": "node_modules/foreground-child/node_modules/which/CHANGELOG.html",
    "title": "Changes | accouter",
    "keywords": "Changes 2.0.2 Rename bin to node-which 2.0.1 generate changelog and publish on version bump enforce 100% test coverage Promise interface 2.0.0 Parallel tests, modern JavaScript, and drop support for node < 8 1.3.1 update deps update travis v1.3.0 Add nothrow option to which.sync update tap v1.2.14 appveyor: drop node 5 and 0.x travis-ci: add node 6, drop 0.x v1.2.13 test: Pass missing option to pass on windows update tap update isexe to 2.0.0 neveragain.tech pledge request v1.2.12 Removed unused require v1.2.11 Prevent changelog script from being included in package v1.2.10 Use env.PATH only, not env.Path v1.2.9 fix for paths starting with ../ Remove unused is-absolute module v1.2.8 bullet items in changelog that contain (but don't start with) # v1.2.7 strip 'update changelog' changelog entries out of changelog v1.2.6 make the changelog bulleted v1.2.5 make a changelog, and keep it up to date don't include tests in package Properly handle relative-path executables appveyor Attach error code to Not Found error Make tests pass on Windows v1.2.4 Fix typo v1.2.3 update isexe, fix regression in pathExt handling v1.2.2 update deps, use isexe module, test windows v1.2.1 Sometimes windows PATH entries are quoted Fixed a bug in the check for group and user mode bits. This bug was introduced during refactoring for supporting strict mode. doc cli v1.2.0 Add support for opt.all and -as cli flags test the bin update travis Allow checking for multiple programs in bin/which tap 2 v1.1.2 travis Refactored and fixed undefined error on Windows Support strict mode v1.1.1 test +g exes against secondary groups, if available Use windows exe semantics on cygwin & msys cwd should be first in path on win32, not last Handle lower-case 'env.Path' on Windows Update docs use single-quotes v1.1.0 Add tests, depend on is-absolute v1.0.9 which.js: root is allowed to execute files owned by anyone v1.0.8 don't use graceful-fs v1.0.7 add license to package.json v1.0.6 isc license 1.0.5 Awful typo 1.0.4 Test for path absoluteness properly win: Allow '' as a pathext if cmd has a . in it 1.0.3 Remove references to execPath Make which.sync() work on Windows by honoring the PATHEXT variable. Make isExe() always return true on Windows. MIT 1.0.2 Only files can be exes 1.0.1 Respect the PATHEXT env for win32 support should 0755 the bin binary guts package 1st"
  },
  "node_modules/foreground-child/node_modules/which/README.html": {
    "href": "node_modules/foreground-child/node_modules/which/README.html",
    "title": "which | accouter",
    "keywords": "which Like the unix which utility. Finds the first instance of a specified executable in the PATH environment variable. Does not cache the results, so hash -r is not needed when the PATH changes. USAGE var which = require('which') // async usage which('node', function (er, resolvedPath) { // er is returned if no \"node\" is found on the PATH // if it is found, then the absolute path to the exec is returned }) // or promise which('node').then(resolvedPath => { ... }).catch(er => { ... not found ... }) // sync usage // throws if not found var resolved = which.sync('node') // if nothrow option is used, returns null if not found resolved = which.sync('node', {nothrow: true}) // Pass options to override the PATH and PATHEXT environment vars. which('node', { path: someOtherPath }, function (er, resolved) { if (er) throw er console.log('found at %j', resolved) }) CLI USAGE Same as the BSD which(1) binary. usage: which [-as] program ... OPTIONS You may pass an options object as the second argument. path: Use instead of the PATH environment variable. pathExt: Use instead of the PATHEXT environment variable. all: Return all matches, instead of just the first one. Note that this means the function returns an array of strings instead of a single string."
  },
  "node_modules/fresh/HISTORY.html": {
    "href": "node_modules/fresh/HISTORY.html",
    "title": "0.5.2 / 2017-09-13 | accouter",
    "keywords": "0.5.2 / 2017-09-13 Fix regression matching multiple ETags in If-None-Match perf: improve If-None-Match token parsing 0.5.1 / 2017-09-11 Fix handling of modified headers with invalid dates perf: improve ETag match loop 0.5.0 / 2017-02-21 Fix incorrect result when If-None-Match has both * and ETags Fix weak ETag matching to match spec perf: delay reading header values until needed perf: skip checking modified time if ETag check failed perf: skip parsing If-None-Match when no ETag header perf: use Date.parse instead of new Date 0.4.0 / 2017-02-05 Fix false detection of no-cache request directive perf: enable strict mode perf: hoist regular expressions perf: remove duplicate conditional perf: remove unnecessary boolean coercions 0.3.0 / 2015-05-12 Add weak ETag matching support 0.2.4 / 2014-09-07 Support Node.js 0.6 0.2.3 / 2014-09-07 Move repository to jshttp 0.2.2 / 2014-02-19 Revert \"Fix for blank page on Safari reload\" 0.2.1 / 2014-01-29 Fix for blank page on Safari reload 0.2.0 / 2013-08-11 Return stale for Cache-Control: no-cache 0.1.0 / 2012-06-15 Add If-None-Match: * support 0.0.1 / 2012-06-10 Initial release"
  },
  "node_modules/fresh/README.html": {
    "href": "node_modules/fresh/README.html",
    "title": "fresh | accouter",
    "keywords": "fresh HTTP response freshness testing Installation This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install fresh API var fresh = require('fresh') fresh(reqHeaders, resHeaders) Check freshness of the response using request and response headers. When the response is still \"fresh\" in the client's cache true is returned, otherwise false is returned to indicate that the client cache is now stale and the full response should be sent. When a client sends the Cache-Control: no-cache request header to indicate an end-to-end reload request, this module will return false to make handling these requests transparent. Known Issues This module is designed to only follow the HTTP specifications, not to work-around all kinda of client bugs (especially since this module typically does not recieve enough information to understand what the client actually is). There is a known issue that in certain versions of Safari, Safari will incorrectly make a request that allows this module to validate freshness of the resource even when Safari does not have a representation of the resource in the cache. The module jumanji can be used in an Express application to work-around this issue and also provides links to further reading on this Safari bug. Example API usage var reqHeaders = { 'if-none-match': '\"foo\"' } var resHeaders = { 'etag': '\"bar\"' } fresh(reqHeaders, resHeaders) // => false var reqHeaders = { 'if-none-match': '\"foo\"' } var resHeaders = { 'etag': '\"foo\"' } fresh(reqHeaders, resHeaders) // => true Using with Node.js http server var fresh = require('fresh') var http = require('http') var server = http.createServer(function (req, res) { // perform server logic // ... including adding ETag / Last-Modified response headers if (isFresh(req, res)) { // client has a fresh copy of resource res.statusCode = 304 res.end() return } // send the resource res.statusCode = 200 res.end('hello, world!') }) function isFresh (req, res) { return fresh(req.headers, { 'etag': res.getHeader('ETag'), 'last-modified': res.getHeader('Last-Modified') }) } server.listen(3000) License MIT"
  },
  "node_modules/fs-extra/CHANGELOG.html": {
    "href": "node_modules/fs-extra/CHANGELOG.html",
    "title": "| accouter",
    "keywords": "3.0.1 / 2017-05-04 Fix bug in move() & moveSync() when source and destination are the same, and source does not exist. #415 3.0.0 / 2017-04-27 Added BREAKING: Added Promise support. All asynchronous native fs methods and fs-extra methods now return a promise if the callback is not passed. #403 pathExists(), a replacement for the deprecated fs.exists. pathExists has a normal error-first callback signature. Also added pathExistsSync, an alias to fs.existsSync, for completeness. #406 Removed BREAKING: Removed support for setting the default spaces for writeJson(), writeJsonSync(), outputJson(), & outputJsonSync(). This was undocumented. #402 Changed Upgraded jsonfile dependency to v3.0.0: BREAKING: Changed behavior of throws option for readJsonSync(); now does not throw filesystem errors when throws is false. BREAKING: writeJson(), writeJsonSync(), outputJson(), & outputJsonSync() now output minified JSON by default for consistency with JSON.stringify(); set the spaces option to 2 to override this new behavior. #402 Use Buffer.allocUnsafe() instead of new Buffer() in environments that support it. #394 Fixed removeSync() silently failed on Windows in some cases. Now throws an EBUSY error. #408 2.1.2 / 2017-03-16 Fixed Weird windows bug that resulted in ensureDir()'s callback being called twice in some cases. This bug may have also affected remove(). See #392, #393 2.1.1 / 2017-03-15 Fixed Reverted 5597bd, this broke compatibility with Node.js versions v4+ but less than v4.5.0. Remove Buffer.alloc() usage in moveSync(). 2.1.0 / 2017-03-15 Thanks to Mani Maghsoudlou (@manidlou) & Jan Peer Stöcklmair (@JPeer264) for their extraordinary help with this release! Added moveSync() See #309, #381. (@manidlou) copy() and copySync()'s filter option now gets the destination path passed as the second parameter. #366 (@manidlou) Changed Use Buffer.alloc() instead of deprecated new Buffer() in copySync(). #380 (@manidlou) Refactored entire codebase to use ES6 features supported by Node.js v4+ #355. (@JPeer264) Refactored docs. (@manidlou) Fixed move() shouldn't error out when source and dest are the same. #377, #378 (@jdalton) 2.0.0 / 2017-01-16 Removed BREAKING: Removed support for Node v0.12. The Node foundation stopped officially supporting it on Jan 1st, 2017. BREAKING: Remove walk() and walkSync(). walkSync() was only part of fs-extra for a little over two months. Use klaw instead of walk(), in fact, walk() was just an alias to klaw. For walkSync() use klaw-sync. See: #338, #339 Changed BREAKING: Renamed clobber to overwrite. This affects copy(), copySync(), and move(). #330, #333 Moved docs, to docs/. #340 Fixed Apply filters to directories in copySync() like in copy(). #324 A specific condition when disk is under heavy use, copy() can fail. #326 1.0.0 / 2016-11-01 After five years of development, we finally have reach the 1.0.0 milestone! Big thanks goes to Ryan Zim for leading the charge on this release! Added walkSync() Changed BREAKING: dropped Node v0.10 support. disabled rimaf globbing, wasn't used. #280 deprecate copy()/copySync() option filter if it's a RegExp. filter should now be a function. inline rimraf. This is temporary and was done because rimraf depended upon the beefy glob which fs-extra does not use. #300 Fixed bug fix proper closing of file handle on utimesMillis() #271 proper escaping of files with dollar signs #291 copySync() failed if user didn't own file. #199, #301 0.30.0 / 2016-04-28 Brought back Node v0.10 support. I didn't realize there was still demand. Official support will end 2016-10-01. 0.29.0 / 2016-04-27 BREAKING: removed support for Node v0.10. If you still want to use Node v0.10, everything should work except for ensureLink()/ensureSymlink(). Node v0.12 is still supported but will be dropped in the near future as well. 0.28.0 / 2016-04-17 BREAKING: removed createOutputStream(). Use https://www.npmjs.com/package/create-output-stream. See: #192 mkdirs()/mkdirsSync() check for invalid win32 path chars. See: #209, #237 mkdirs()/mkdirsSync() if drive not mounted, error. See: #93 0.27.0 / 2016-04-15 add dereference option to copySync(). #235 0.26.7 / 2016-03-16 fixed copy() if source and dest are the same. #230 0.26.6 / 2016-03-15 fixed if emptyDir() does not have a callback: #229 0.26.5 / 2016-01-27 copy() with two arguments (w/o callback) was broken. See: #215 0.26.4 / 2016-01-05 copySync() made preserveTimestamps default consistent with copy() which is false. See: #208 0.26.3 / 2015-12-17 fixed copy() hangup in copying blockDevice / characterDevice / /dev/null. See: #193 0.26.2 / 2015-11-02 fixed outputJson{Sync}() spacing adherence to fs.spaces 0.26.1 / 2015-11-02 fixed copySync() when clogger=true and the destination is read only. See: #190 0.26.0 / 2015-10-25 extracted the walk() function into its own module klaw. 0.25.0 / 2015-10-24 now has a file walker walk() 0.24.0 / 2015-08-28 removed alias delete() and deleteSync(). See: #171 0.23.1 / 2015-08-07 Better handling of errors for move() when moving across devices. #170 ensureSymlink() and ensureLink() should not throw errors if link exists. #169 0.23.0 / 2015-08-06 added ensureLink{Sync}() and ensureSymlink{Sync}(). See: #165 0.22.1 / 2015-07-09 Prevent calling hasMillisResSync() on module load. See: #149. Fixes regression that was introduced in 0.21.0. 0.22.0 / 2015-07-09 preserve permissions / ownership in copy(). See: #54 0.21.0 / 2015-07-04 add option to preserve timestamps in copy() and copySync(). See: #141 updated graceful-fs@3.x to 4.x. This brings in features from amazing-graceful-fs (much cleaner code / less hacks) 0.20.1 / 2015-06-23 fixed regression caused by latest jsonfile update: See: https://github.com/jprichardson/node-jsonfile/issues/26 0.20.0 / 2015-06-19 removed jsonfile aliases with File in the name, they weren't documented and probably weren't in use e.g. this package had both fs.readJsonFile and fs.readJson that were aliases to each other, now use fs.readJson. preliminary walker created. Intentionally not documented. If you use it, it will almost certainly change and break your code. started moving tests inline upgraded to jsonfile@2.1.0, can now pass JSON revivers/replacers to readJson(), writeJson(), outputJson() 0.19.0 / 2015-06-08 fs.copy() had support for Node v0.8, dropped support 0.18.4 / 2015-05-22 fixed license field according to this: #136 and https://github.com/npm/npm/releases/tag/v2.10.0 0.18.3 / 2015-05-08 bugfix: handle EEXIST when clobbering on some Linux systems. #134 0.18.2 / 2015-04-17 bugfix: allow F_OK (#120) 0.18.1 / 2015-04-15 improved windows support for move() a bit. https://github.com/jprichardson/node-fs-extra/commit/92838980f25dc2ee4ec46b43ee14d3c4a1d30c1b fixed a lot of tests for Windows (appveyor) 0.18.0 / 2015-03-31 added emptyDir() and emptyDirSync() 0.17.0 / 2015-03-28 copySync added clobber option (before always would clobber, now if clobber is false it throws an error if the destination exists). Only works with files at the moment. createOutputStream() added. See: #118 0.16.5 / 2015-03-08 fixed fs.move when clobber is true and destination is a directory, it should clobber. #114 0.16.4 / 2015-03-01 fs.mkdirs fix infinite loop on Windows. See: See https://github.com/substack/node-mkdirp/pull/74 and https://github.com/substack/node-mkdirp/issues/66 0.16.3 / 2015-01-28 reverted https://github.com/jprichardson/node-fs-extra/commit/1ee77c8a805eba5b99382a2591ff99667847c9c9 0.16.2 / 2015-01-28 fixed fs.copy for Node v0.8 (support is temporary and will be removed in the near future) 0.16.1 / 2015-01-28 if setImmediate is not available, fall back to process.nextTick 0.16.0 / 2015-01-28 bugfix fs.move() into itself. Closes #104 bugfix fs.move() moving directory across device. Closes #108 added coveralls support bugfix: nasty multiple callback fs.copy() bug. Closes #98 misc fs.copy code cleanups 0.15.0 / 2015-01-21 dropped ncp, imported code in because of previous, now supports io.js graceful-fs is now a dependency 0.14.0 / 2015-01-05 changed copy/copySync from fs.copy(src, dest, [filters], callback) to fs.copy(src, dest, [options], callback) #100 removed mockfs tests for mkdirp (this may be temporary, but was getting in the way of other tests) 0.13.0 / 2014-12-10 removed touch and touchSync methods (they didn't handle permissions like UNIX touch) updated \"ncp\": \"^0.6.0\" to \"ncp\": \"^1.0.1\" imported mkdirp => minimist and mkdirp are no longer dependences, should now appease people who wanted mkdirp to be --use_strict safe. See #59 0.12.0 / 2014-09-22 copy symlinks in copySync() #85 0.11.1 / 2014-09-02 bugfix copySync() preserve file permissions #80 0.11.0 / 2014-08-11 upgraded \"ncp\": \"^0.5.1\" to \"ncp\": \"^0.6.0\" upgrade jsonfile\": \"^1.2.0\" to jsonfile\": \"^2.0.0\" => on write, json files now have \\n at end. Also adds options.throws to readJsonSync() see https://github.com/jprichardson/node-jsonfile#readfilesyncfilename-options for more details. 0.10.0 / 2014-06-29 bugfix: upgaded \"jsonfile\": \"~1.1.0\" to \"jsonfile\": \"^1.2.0\", bumped minor because of jsonfile dep change from ~ to ^. #67 0.9.1 / 2014-05-22 removed Node.js 0.8.x support, 0.9.0 was published moments ago and should have been done there 0.9.0 / 2014-05-22 upgraded ncp from ~0.4.2 to ^0.5.1, #58 upgraded rimraf from ~2.2.6 to ^2.2.8 upgraded mkdirp from 0.3.x to ^0.5.0 added methods ensureFile(), ensureFileSync() added methods ensureDir(), ensureDirSync() #31 added move() method. From: https://github.com/andrewrk/node-mv 0.8.1 / 2013-10-24 copy failed to return an error to the callback if a file doesn't exist (ulikoehler #38, #39) 0.8.0 / 2013-10-14 filter implemented on copy() and copySync(). (Srirangan / #36) 0.7.1 / 2013-10-12 copySync() implemented (Srirangan / #33) updated to the latest jsonfile version 1.1.0 which gives options params for the JSON methods. Closes #32 0.7.0 / 2013-10-07 update readme conventions copy() now works if destination directory does not exist. Closes #29 0.6.4 / 2013-09-05 changed homepage field in package.json to remove NPM warning 0.6.3 / 2013-06-28 changed JSON spacing default from 4 to 2 to follow Node conventions updated jsonfile dep updated rimraf dep 0.6.2 / 2013-06-28 added .npmignore, #25 0.6.1 / 2013-05-14 modified for strict mode, closes #24 added outputJson()/outputJsonSync(), closes #23 0.6.0 / 2013-03-18 removed node 0.6 support added node 0.10 support upgraded to latest ncp and rimraf. optional graceful-fs support. Closes #17 0.5.0 / 2013-02-03 Removed readTextFile. Renamed readJSONFile to readJSON and readJson, same with write. Restructured documentation a bit. Added roadmap. 0.4.0 / 2013-01-28 Set default spaces in jsonfile from 4 to 2. Updated testutil deps for tests. Renamed touch() to createFile() Added outputFile() and outputFileSync() Changed creation of testing diretories so the /tmp dir is not littered. Added readTextFile() and readTextFileSync(). 0.3.2 / 2012-11-01 Added touch() and touchSync() methods. 0.3.1 / 2012-10-11 Fixed some stray globals. 0.3.0 / 2012-10-09 Removed all CoffeeScript from tests. Renamed mkdir to mkdirs/mkdirp. 0.2.1 / 2012-09-11 Updated rimraf dep. 0.2.0 / 2012-09-10 Rewrote module into JavaScript. (Must still rewrite tests into JavaScript) Added all methods of jsonfile Added Travis-CI. 0.1.3 / 2012-08-13 Added method readJSONFile. 0.1.2 / 2012-06-15 Bug fix: deleteSync() didn't exist. Verified Node v0.8 compatibility. 0.1.1 / 2012-06-15 Fixed bug in remove()/delete() that wouldn't execute the function if a callback wasn't passed. 0.1.0 / 2012-05-31 Renamed copyFile() to copy(). copy() can now copy directories (recursively) too. Renamed rmrf() to remove(). remove() aliased with delete(). Added mkdirp capabilities. Named: mkdir(). Hides Node.js native mkdir(). Instead of exporting the native fs module with new functions, I now copy over the native methods to a new object and export that instead. 0.0.4 / 2012-03-14 Removed CoffeeScript dependency 0.0.3 / 2012-01-11 Added methods rmrf and rmrfSync Moved tests from Jasmine to Mocha"
  },
  "node_modules/fs-extra/README.html": {
    "href": "node_modules/fs-extra/README.html",
    "title": "Node.js: fs-extra | accouter",
    "keywords": "Node.js: fs-extra fs-extra adds file system methods that aren't included in the native fs module and adds promise support to the fs methods. It should be a drop in replacement for fs. Why? I got tired of including mkdirp, rimraf, and ncp in most of my projects. Installation npm install --save fs-extra Usage fs-extra is a drop in replacement for native fs. All methods in fs are attached to fs-extra. All fs methods return promises if the callback isn't passed. You don't ever need to include the original fs module again: const fs = require('fs') // this is no longer necessary you can now do this: const fs = require('fs-extra') or if you prefer to make it clear that you're using fs-extra and not fs, you may want to name your fs variable fse like so: const fse = require('fs-extra') you can also keep both, but it's redundant: const fs = require('fs') const fse = require('fs-extra') Sync vs Async Most methods are async by default. All async methods will return a promise if the callback isn't passed. Sync methods on the other hand will throw if an error occurs. Example: const fs = require('fs-extra') // Async with promises: fs.copy('/tmp/myfile', '/tmp/mynewfile') .then(() => console.log('success!')) .catch(err => console.error(err)) // Async with callbacks: fs.copy('/tmp/myfile', '/tmp/mynewfile', err => { if (err) return console.error(err) console.log('success!') }) // Sync: try { fs.copySync('/tmp/myfile', '/tmp/mynewfile') console.log('success!') } catch (err) { console.error(err) } Methods Async copy emptyDir ensureFile ensureDir ensureLink ensureSymlink mkdirs move outputFile outputJson pathExists readJson remove writeJson Sync copySync emptyDirSync ensureFileSync ensureDirSync ensureLinkSync ensureSymlinkSync mkdirsSync moveSync outputFileSync outputJsonSync pathExistsSync readJsonSync removeSync writeJsonSync NOTE: You can still use the native Node.js methods. They are promisified and copied over to fs-extra. What happened to walk() and walkSync()? They were removed from fs-extra in v2.0.0. If you need the functionality, walk and walkSync are available as separate packages, klaw and klaw-sync. Third Party TypeScript If you like TypeScript, you can use fs-extra with it: https://github.com/borisyankov/DefinitelyTyped/tree/master/fs-extra File / Directory Watching If you want to watch for changes to files or directories, then you should use chokidar. Misc. mfs - Monitor your fs-extra calls. Hacking on fs-extra Wanna hack on fs-extra? Great! Your help is needed! fs-extra is one of the most depended upon Node.js packages. This project uses JavaScript Standard Style - if the name or style choices bother you, you're gonna have to get over it :) If standard is good enough for npm, it's good enough for fs-extra. What's needed? First, take a look at existing issues. Those are probably going to be where the priority lies. More tests for edge cases. Specifically on different platforms. There can never be enough tests. Improve test coverage. See coveralls output for more info. Note: If you make any big changes, you should definitely file an issue for discussion first. Running the Test Suite fs-extra contains hundreds of tests. npm run lint: runs the linter (standard) npm run unit: runs the unit tests npm test: runs both the linter and the tests Windows If you run the tests on the Windows and receive a lot of symbolic link EPERM permission errors, it's because on Windows you need elevated privilege to create symbolic links. You can add this to your Windows's account by following the instructions here: http://superuser.com/questions/104845/permission-to-make-symbolic-links-in-windows-7 However, I didn't have much luck doing this. Since I develop on Mac OS X, I use VMWare Fusion for Windows testing. I create a shared folder that I map to a drive on Windows. I open the Node.js command prompt and run as Administrator. I then map the network drive running the following command: net use z: \"\\\\vmware-host\\Shared Folders\" I can then navigate to my fs-extra directory and run the tests. Naming I put a lot of thought into the naming of these functions. Inspired by @coolaj86's request. So he deserves much of the credit for raising the issue. See discussion(s) here: https://github.com/jprichardson/node-fs-extra/issues/2 https://github.com/flatiron/utile/issues/11 https://github.com/ryanmcgrath/wrench-js/issues/29 https://github.com/substack/node-mkdirp/issues/17 First, I believe that in as many cases as possible, the Node.js naming schemes should be chosen. However, there are problems with the Node.js own naming schemes. For example, fs.readFile() and fs.readdir(): the F is capitalized in File and the d is not capitalized in dir. Perhaps a bit pedantic, but they should still be consistent. Also, Node.js has chosen a lot of POSIX naming schemes, which I believe is great. See: fs.mkdir(), fs.rmdir(), fs.chown(), etc. We have a dilemma though. How do you consistently name methods that perform the following POSIX commands: cp, cp -r, mkdir -p, and rm -rf? My perspective: when in doubt, err on the side of simplicity. A directory is just a hierarchical grouping of directories and files. Consider that for a moment. So when you want to copy it or remove it, in most cases you'll want to copy or remove all of its contents. When you want to create a directory, if the directory that it's suppose to be contained in does not exist, then in most cases you'll want to create that too. So, if you want to remove a file or a directory regardless of whether it has contents, just call fs.remove(path). If you want to copy a file or a directory whether it has contents, just call fs.copy(source, destination). If you want to create a directory regardless of whether its parent directories exist, just call fs.mkdirs(path) or fs.mkdirp(path). Credit fs-extra wouldn't be possible without using the modules from the following authors: Isaac Shlueter Charlie McConnel James Halliday Andrew Kelley License Licensed under MIT Copyright (c) 2011-2017 JP Richardson"
  },
  "node_modules/fs-extra/docs/copy-sync.html": {
    "href": "node_modules/fs-extra/docs/copy-sync.html",
    "title": "copySync(src, dest, [options]) | accouter",
    "keywords": "copySync(src, dest, [options]) Copy a file or directory. The directory can have contents. Like cp -r. src <String> dest <String> options <Object> overwrite <boolean>: overwrite existing file or directory, default is true. Note that the copy operation will silently fail if you set this to false and the destination exists. Use the errorOnExist option to change this behavior. errorOnExist <boolean>: when overwrite is false and the destination exists, throw an error. Default is false. dereference <boolean>: dereference symlinks, default is false. preserveTimestamps <boolean>: will set last modification and access times to the ones of the original source files, default is false. filter <Function>: Function to filter copied files. Return true to include, false to exclude. This can also be a RegExp, however this is deprecated (See issue #239 for background). Example: const fs = require('fs-extra') // copy file fs.copySync('/tmp/myfile', '/tmp/mynewfile') // copy directory, even if it has subdirectories or files fs.copySync('/tmp/mydir', '/tmp/mynewdir') Using filter function const fs = require('fs-extra') const filterFunc = (src, dest) => { // your logic here // it will be copied if return true } fs.copySync('/tmp/mydir', '/tmp/mynewdir', { filter: filterFunc })"
  },
  "node_modules/fs-extra/docs/copy.html": {
    "href": "node_modules/fs-extra/docs/copy.html",
    "title": "copy(src, dest, [options, callback]) | accouter",
    "keywords": "copy(src, dest, [options, callback]) Copy a file or directory. The directory can have contents. Like cp -r. src <String> dest <String> options <Object> overwrite <boolean>: overwrite existing file or directory, default is true. Note that the copy operation will silently fail if you set this to false and the destination exists. Use the errorOnExist option to change this behavior. errorOnExist <boolean>: when overwrite is false and the destination exists, throw an error. Default is false. dereference <boolean>: dereference symlinks, default is false. preserveTimestamps <boolean>: will set last modification and access times to the ones of the original source files, default is false. filter <Function>: Function to filter copied files. Return true to include, false to exclude. This can also be a RegExp, however this is deprecated (See issue #239 for background). callback <Function> Example: const fs = require('fs-extra') fs.copy('/tmp/myfile', '/tmp/mynewfile', err => { if (err) return console.error(err) console.log('success!') }) // copies file fs.copy('/tmp/mydir', '/tmp/mynewdir', err => { if (err) return console.error(err) console.log('success!') }) // copies directory, even if it has subdirectories or files // Promise usage: fs.copy('/tmp/myfile', '/tmp/mynewfile') .then(() => { console.log('success!') }) .catch(err => { console.error(err) }) Using filter function const fs = require('fs-extra') const filterFunc = (src, dest) => { // your logic here // it will be copied if return true } fs.copy('/tmp/mydir', '/tmp/mynewdir', { filter: filterFunc }, err => { if (err) return console.error(err) console.log('success!') })"
  },
  "node_modules/fs-extra/docs/emptyDir-sync.html": {
    "href": "node_modules/fs-extra/docs/emptyDir-sync.html",
    "title": "emptyDirSync(dir) | accouter",
    "keywords": "emptyDirSync(dir) Ensures that a directory is empty. Deletes directory contents if the directory is not empty. If the directory does not exist, it is created. The directory itself is not deleted. Alias: emptydirSync() dir <String> Example: const fs = require('fs-extra') // assume this directory has a lot of files and folders fs.emptyDirSync('/tmp/some/dir')"
  },
  "node_modules/fs-extra/docs/emptyDir.html": {
    "href": "node_modules/fs-extra/docs/emptyDir.html",
    "title": "emptyDir(dir, [callback]) | accouter",
    "keywords": "emptyDir(dir, [callback]) Ensures that a directory is empty. Deletes directory contents if the directory is not empty. If the directory does not exist, it is created. The directory itself is not deleted. Alias: emptydir() dir <String> callback <Function> Example: const fs = require('fs-extra') // assume this directory has a lot of files and folders fs.emptyDir('/tmp/some/dir', err => { if (err) return console.error(err) console.log('success!') }) // With promises fs.emptyDir('/tmp/some/dir') .then(() => { console.log('success!') }) .catch(err => { console.error(err) })"
  },
  "node_modules/fs-extra/docs/ensureDir-sync.html": {
    "href": "node_modules/fs-extra/docs/ensureDir-sync.html",
    "title": "ensureDirSync(dir) | accouter",
    "keywords": "ensureDirSync(dir) Ensures that the directory exists. If the directory structure does not exist, it is created. Like mkdir -p. Aliases: mkdirsSync(), mkdirpSync() dir <String> Example: const fs = require('fs-extra') const dir = '/tmp/this/path/does/not/exist' fs.ensureDirSync(dir) // dir has now been created, including the directory it is to be placed in"
  },
  "node_modules/fs-extra/docs/ensureDir.html": {
    "href": "node_modules/fs-extra/docs/ensureDir.html",
    "title": "ensureDir(dir, [callback]) | accouter",
    "keywords": "ensureDir(dir, [callback]) Ensures that the directory exists. If the directory structure does not exist, it is created. Like mkdir -p. Aliases: mkdirs(), mkdirp() dir <String> callback <Function> Example: const fs = require('fs-extra') const dir = '/tmp/this/path/does/not/exist' fs.ensureDir(dir, err => { console.log(err) // => null // dir has now been created, including the directory it is to be placed in }) // With Promises: fs.ensureDir(dir) .then(() => { console.log('success!') }) .catch(err => { console.error(err) })"
  },
  "node_modules/fs-extra/docs/ensureFile-sync.html": {
    "href": "node_modules/fs-extra/docs/ensureFile-sync.html",
    "title": "ensureFileSync(file) | accouter",
    "keywords": "ensureFileSync(file) Ensures that the file exists. If the file that is requested to be created is in directories that do not exist, these directories are created. If the file already exists, it is NOT MODIFIED. Alias: createFileSync() file <String> Example: const fs = require('fs-extra') const file = '/tmp/this/path/does/not/exist/file.txt' fs.ensureFileSync(file) // file has now been created, including the directory it is to be placed in"
  },
  "node_modules/fs-extra/docs/ensureFile.html": {
    "href": "node_modules/fs-extra/docs/ensureFile.html",
    "title": "ensureFile(file, [callback]) | accouter",
    "keywords": "ensureFile(file, [callback]) Ensures that the file exists. If the file that is requested to be created is in directories that do not exist, these directories are created. If the file already exists, it is NOT MODIFIED. Alias: createFile() file <String> callback <Function> Example: const fs = require('fs-extra') const file = '/tmp/this/path/does/not/exist/file.txt' fs.ensureFile(file, err => { console.log(err) // => null // file has now been created, including the directory it is to be placed in }) // With Promises: fs.ensureFile(file) .then(() => { console.log('success!') }) .catch(err => { console.error(err) })"
  },
  "node_modules/fs-extra/docs/ensureLink-sync.html": {
    "href": "node_modules/fs-extra/docs/ensureLink-sync.html",
    "title": "ensureLinkSync(srcpath, dstpath) | accouter",
    "keywords": "ensureLinkSync(srcpath, dstpath) Ensures that the link exists. If the directory structure does not exist, it is created. srcpath <String> dstpath <String> Example: const fs = require('fs-extra') const srcpath = '/tmp/file.txt' const dstpath = '/tmp/this/path/does/not/exist/file.txt' fs.ensureLinkSync(srcpath, dstpath) // link has now been created, including the directory it is to be placed in"
  },
  "node_modules/fs-extra/docs/ensureLink.html": {
    "href": "node_modules/fs-extra/docs/ensureLink.html",
    "title": "ensureLink(srcpath, dstpath, [callback]) | accouter",
    "keywords": "ensureLink(srcpath, dstpath, [callback]) Ensures that the link exists. If the directory structure does not exist, it is created. srcpath <String> dstpath <String> callback <Function> Example: const fs = require('fs-extra') const srcpath = '/tmp/file.txt' const dstpath = '/tmp/this/path/does/not/exist/file.txt' fs.ensureLink(srcpath, dstpath, err => { console.log(err) // => null // link has now been created, including the directory it is to be placed in }) // With Promises: fs.ensureLink(srcpath, dstpath) .then(() => { console.log('success!') }) .catch(err => { console.error(err) })"
  },
  "node_modules/fs-extra/docs/ensureSymlink-sync.html": {
    "href": "node_modules/fs-extra/docs/ensureSymlink-sync.html",
    "title": "ensureSymlinkSync(srcpath, dstpath, [type]) | accouter",
    "keywords": "ensureSymlinkSync(srcpath, dstpath, [type]) Ensures that the symlink exists. If the directory structure does not exist, it is created. srcpath <String> dstpath <String> type <String> Example: const fs = require('fs-extra') const srcpath = '/tmp/file.txt' const dstpath = '/tmp/this/path/does/not/exist/file.txt' fs.ensureSymlinkSync(srcpath, dstpath) // symlink has now been created, including the directory it is to be placed in"
  },
  "node_modules/fs-extra/docs/ensureSymlink.html": {
    "href": "node_modules/fs-extra/docs/ensureSymlink.html",
    "title": "ensureSymlink(srcpath, dstpath, [type, callback]) | accouter",
    "keywords": "ensureSymlink(srcpath, dstpath, [type, callback]) Ensures that the symlink exists. If the directory structure does not exist, it is created. srcpath <String> dstpath <String> type <String> callback <Function> Example: const fs = require('fs-extra') const srcpath = '/tmp/file.txt' const dstpath = '/tmp/this/path/does/not/exist/file.txt' fs.ensureSymlink(srcpath, dstpath, err => { console.log(err) // => null // symlink has now been created, including the directory it is to be placed in }) // With Promises: fs.ensureSymlink(srcpath, dstpath) .then(() => { console.log('success!') }) .catch(err => { console.error(err) })"
  },
  "node_modules/fs-extra/docs/move-sync.html": {
    "href": "node_modules/fs-extra/docs/move-sync.html",
    "title": "moveSync(src, dest, [options]) | accouter",
    "keywords": "moveSync(src, dest, [options]) Moves a file or directory, even across devices. src <String> dest <String> options <Object> overwrite <boolean>: overwrite existing file or directory, default is false. Example: const fs = require('fs-extra') fs.moveSync('/tmp/somefile', '/tmp/does/not/exist/yet/somefile') Using overwrite option const fs = require('fs-extra') fs.moveSync('/tmp/somedir', '/tmp/may/already/existed/somedir', { overwrite: true })"
  },
  "node_modules/fs-extra/docs/move.html": {
    "href": "node_modules/fs-extra/docs/move.html",
    "title": "move(src, dest, [options, callback]) | accouter",
    "keywords": "move(src, dest, [options, callback]) Moves a file or directory, even across devices. src <String> dest <String> options <Object> overwrite <boolean>: overwrite existing file or directory, default is false. callback <Function> Example: const fs = require('fs-extra') fs.move('/tmp/somefile', '/tmp/does/not/exist/yet/somefile', err => { if (err) return console.error(err) console.log('success!') }) fs.move('/tmp/somefile', '/tmp/does/not/exist/yet/somefile') .then(() => { console.log('success!') }) .catch(err => { console.error(err) }) Using overwrite option const fs = require('fs-extra') fs.move('/tmp/somedir', '/tmp/may/already/existed/somedir', { overwrite: true }, err => { if (err) return console.error(err) console.log('success!') })"
  },
  "node_modules/fs-extra/docs/outputFile-sync.html": {
    "href": "node_modules/fs-extra/docs/outputFile-sync.html",
    "title": "outputFileSync(file, data, [options]) | accouter",
    "keywords": "outputFileSync(file, data, [options]) Almost the same as writeFileSync (i.e. it overwrites), except that if the parent directory does not exist, it's created. file must be a file path (a buffer or a file descriptor is not allowed). options are what you'd pass to fs.writeFileSync(). file <String> data <String> | <Buffer> | <Uint8Array> options <Object> | <String> Example: const fs = require('fs-extra') const file = '/tmp/this/path/does/not/exist/file.txt' fs.outputFileSync(file, 'hello!') const data = fs.readFileSync(file, 'utf8') console.log(data) // => hello!"
  },
  "node_modules/fs-extra/docs/outputFile.html": {
    "href": "node_modules/fs-extra/docs/outputFile.html",
    "title": "outputFile(file, data, [options, callback]) | accouter",
    "keywords": "outputFile(file, data, [options, callback]) Almost the same as writeFile (i.e. it overwrites), except that if the parent directory does not exist, it's created. file must be a file path (a buffer or a file descriptor is not allowed). options are what you'd pass to fs.writeFile(). file <String> data <String> | <Buffer> | <Uint8Array> options <Object> | <String> callback <Function> Example: const fs = require('fs-extra') const file = '/tmp/this/path/does/not/exist/file.txt' fs.outputFile(file, 'hello!', err => { console.log(err) // => null fs.readFile(file, 'utf8', (err, data) => { if (err) return console.error(err) console.log(data) // => hello! }) }) // With Promises: fs.outputFile(file, 'hello!') .then(() => fs.readFile(file, 'utf8')) .then(data => { console.log(data) // => hello! }) .catch(err => { console.error(err) })"
  },
  "node_modules/fs-extra/docs/outputJson-sync.html": {
    "href": "node_modules/fs-extra/docs/outputJson-sync.html",
    "title": "outputJsonSync(file, object, [options]) | accouter",
    "keywords": "outputJsonSync(file, object, [options]) Almost the same as writeJsonSync, except that if the directory does not exist, it's created. options are what you'd pass to jsonFile.writeFileSync(). Alias: outputJSONSync() file <String> object <Object> options <Object> Example: const fs = require('fs-extra') const file = '/tmp/this/path/does/not/exist/file.json' fs.outputJsonSync(file, {name: 'JP'}) const data = fs.readJsonSync(file) console.log(data.name) // => JP"
  },
  "node_modules/fs-extra/docs/outputJson.html": {
    "href": "node_modules/fs-extra/docs/outputJson.html",
    "title": "outputJson(file, object, [options, callback]) | accouter",
    "keywords": "outputJson(file, object, [options, callback]) Almost the same as writeJson, except that if the directory does not exist, it's created. options are what you'd pass to jsonFile.writeFile(). Alias: outputJSON() file <String> object <Object> options <Object> callback <Function> Example: const fs = require('fs-extra') const file = '/tmp/this/path/does/not/exist/file.json' fs.outputJson(file, {name: 'JP'}, err => { console.log(err) // => null fs.readJson(file, (err, data) => { if (err) return console.error(err) console.log(data.name) // => JP }) }) // With Promises: fs.outputJson(file, {name: 'JP'}) .then(() => fs.readJson(file)) .then(data => { console.log(data.name) // => JP }) .catch(err => { console.error(err) })"
  },
  "node_modules/fs-extra/docs/pathExists-sync.html": {
    "href": "node_modules/fs-extra/docs/pathExists-sync.html",
    "title": "pathExistsSync(file) | accouter",
    "keywords": "pathExistsSync(file) An alias for fs.existsSync(), created for consistency with pathExists()."
  },
  "node_modules/fs-extra/docs/pathExists.html": {
    "href": "node_modules/fs-extra/docs/pathExists.html",
    "title": "pathExists(file[, callback]) | accouter",
    "keywords": "pathExists(file[, callback]) Test whether or not the given path exists by checking with the file system. Like fs.exists, but with a normal callback signature (err, exists). Uses fs.access under the hood. file <String> callback <Function> Example: const fs = require('fs-extra') const file = '/tmp/this/path/does/not/exist/file.txt' // Promise usage: fs.pathExists(file) .then(exists => console.log(exists)) // => false // Callback usage: fs.pathExists(file, (err, exists) => { console.log(err) // => null console.log(exists) // => false })"
  },
  "node_modules/fs-extra/docs/readJson-sync.html": {
    "href": "node_modules/fs-extra/docs/readJson-sync.html",
    "title": "readJsonSync(file, [options]) | accouter",
    "keywords": "readJsonSync(file, [options]) Reads a JSON file and then parses it into an object. options are the same that you'd pass to jsonFile.readFileSync. Alias: readJSONSync() file <String> options <Object> Example: const fs = require('fs-extra') const packageObj = fs.readJsonSync('./package.json') console.log(packageObj.version) // => 2.0.0 readJsonSync() can take a throws option set to false and it won't throw if the JSON is invalid. Example: const fs = require('fs-extra') const file = '/tmp/some-invalid.json' const data = '{not valid JSON' fs.writeFileSync(file, data) const obj = fs.readJsonSync(file, { throws: false }) console.log(obj) // => null"
  },
  "node_modules/fs-extra/docs/readJson.html": {
    "href": "node_modules/fs-extra/docs/readJson.html",
    "title": "readJson(file, [options, callback]) | accouter",
    "keywords": "readJson(file, [options, callback]) Reads a JSON file and then parses it into an object. options are the same that you'd pass to jsonFile.readFile. Alias: readJSON() file <String> options <Object> callback <Function> Example: const fs = require('fs-extra') fs.readJson('./package.json', (err, packageObj) => { if (err) console.error(err) console.log(packageObj.version) // => 0.1.3 }) // Promise Usage fs.readJson('./package.json') .then(packageObj => { console.log(packageObj.version) // => 0.1.3 }) .catch(err => { console.error(err) }) readJson() can take a throws option set to false and it won't throw if the JSON is invalid. Example: const fs = require('fs-extra') const file = '/tmp/some-invalid.json' const data = '{not valid JSON' fs.writeFileSync(file, data) fs.readJson(file, { throws: false }, (err, obj) => { if (err) console.error(err) console.log(obj) // => null }) // Promise Usage fs.readJson(file, { throws: false }) .then(obj => { console.log(obj) // => null }) .catch(err => { console.error(err) // Not called })"
  },
  "node_modules/fs-extra/docs/remove-sync.html": {
    "href": "node_modules/fs-extra/docs/remove-sync.html",
    "title": "removeSync(path) | accouter",
    "keywords": "removeSync(path) Removes a file or directory. The directory can have contents. Like rm -rf. path <String> Example: const fs = require('fs-extra') // remove file fs.removeSync('/tmp/myfile') fs.removeSync('/home/jprichardson') // I just deleted my entire HOME directory."
  },
  "node_modules/fs-extra/docs/remove.html": {
    "href": "node_modules/fs-extra/docs/remove.html",
    "title": "remove(path, [callback]) | accouter",
    "keywords": "remove(path, [callback]) Removes a file or directory. The directory can have contents. Like rm -rf. path <String> callback <Function> Example: const fs = require('fs-extra') // remove file fs.remove('/tmp/myfile', err => { if (err) return console.error(err) console.log('success!') }) fs.remove('/home/jprichardson', err => { if (err) return console.error(err) console.log('success!') // I just deleted my entire HOME directory. }) // Promise Usage fs.remove('/tmp/myfile') .then(() => { console.log('success!') }) .catch(err => { console.error(err) })"
  },
  "node_modules/fs-extra/docs/writeJson-sync.html": {
    "href": "node_modules/fs-extra/docs/writeJson-sync.html",
    "title": "writeJsonSync(file, object, [options]) | accouter",
    "keywords": "writeJsonSync(file, object, [options]) Writes an object to a JSON file. options are the same that you'd pass to jsonFile.writeFileSync(). Alias: writeJSONSync() file <String> object <Object> options <Object> Example: const fs = require('fs-extra') fs.writeJsonSync('./package.json', {name: 'fs-extra'}) See also: outputJsonSync()"
  },
  "node_modules/fs-extra/docs/writeJson.html": {
    "href": "node_modules/fs-extra/docs/writeJson.html",
    "title": "writeJson(file, object, [options, callback]) | accouter",
    "keywords": "writeJson(file, object, [options, callback]) Writes an object to a JSON file. options are the same that you'd pass to jsonFile.writeFile(). Alias: writeJSON() file <String> object <Object> options <Object> callback <Function> Example: const fs = require('fs-extra') fs.writeJson('./package.json', {name: 'fs-extra'}, err => { if (err) return console.error(err) console.log('success!') }) // With Promises fs.writeJson('./package.json', {name: 'fs-extra'}) .then(() => { console.log('success!') }) .catch(err => { console.error(err) }) See also: outputJson()"
  },
  "node_modules/fs.realpath/README.html": {
    "href": "node_modules/fs.realpath/README.html",
    "title": "fs.realpath | accouter",
    "keywords": "fs.realpath A backwards-compatible fs.realpath for Node v6 and above In Node v6, the JavaScript implementation of fs.realpath was replaced with a faster (but less resilient) native implementation. That raises new and platform-specific errors and cannot handle long or excessively symlink-looping paths. This module handles those cases by detecting the new errors and falling back to the JavaScript implementation. On versions of Node prior to v6, it has no effect. USAGE var rp = require('fs.realpath') // async version rp.realpath(someLongAndLoopingPath, function (er, real) { // the ELOOP was handled, but it was a bit slower }) // sync version var real = rp.realpathSync(someLongAndLoopingPath) // monkeypatch at your own risk! // This replaces the fs.realpath/fs.realpathSync builtins rp.monkeypatch() // un-do the monkeypatching rp.unmonkeypatch()"
  },
  "node_modules/function-bind/CHANGELOG.html": {
    "href": "node_modules/function-bind/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.1.2 - 2023-10-12 Merged Point to the correct file #16 Commits [Tests] migrate tests to Github Actions 4f8b57c [Tests] remove jscs 90eb2ed [meta] update .gitignore 53fcdc3 [Tests] up to node v11.10, v10.15, v9.11, v8.15, v6.16, v4.9; use nvm install-latest-npm; run audit script in tests 1fe8f6e [meta] add auto-changelog 1921fcb [Robustness] remove runtime dependency on all builtins except .apply f743e61 Docs: enable badges; update wording 503cb12 [readme] update badges 290c5db [Tests] switch to nyc for coverage ea360ba [Dev Deps] update eslint, @ljharb/eslint-config, tape cae5e9e [meta] add funding field; create FUNDING.yml c9f4274 [Tests] fix eslint errors from #15 f69aaa2 [actions] fix permissions 99a0cd9 [meta] use npmignore to autogenerate an npmignore file f03b524 [Dev Deps] update @ljharb/eslint‑config, eslint, tape 7af9300 [Dev Deps] update eslint, @ljharb/eslint-config, covert, tape 64a9127 [Tests] use aud instead of npm audit e75069c [Dev Deps] update @ljharb/eslint-config, aud, tape d03555c [meta] add safe-publish-latest 9c8f809 [Dev Deps] update @ljharb/eslint-config, tape baf6893 [meta] create SECURITY.md 4db1779 [Tests] add npm run audit c8b38ec Revert \"Point to the correct file\" 05cdf0f v1.1.1 - 2017-08-28 Commits [Tests] up to node v8; newer npm breaks on older node; fix scripts 817f7d2 [Dev Deps] update eslint, jscs, tape, @ljharb/eslint-config 854288b [Dev Deps] update tape, jscs, eslint, @ljharb/eslint-config 83e639f Only apps should have lockfiles 5ed97f5 Use a SPDX-compliant “license” field. 5feefea v1.1.0 - 2016-02-14 Commits Update eslint, tape; use my personal shared eslint config 9c9062a Add npm run eslint dd96c56 [New] return the native bind when available. 82186e0 [Dev Deps] update tape, jscs, eslint, @ljharb/eslint-config a3dd767 Update eslint 3dae2f7 Update tape, covert, jscs a181eee [Tests] up to node v5.6, v4.3 964929a Test up to io.js v2.1 2be7310 Update tape, jscs, eslint, @ljharb/eslint-config 45f3d68 [Dev Deps] update tape, jscs 6e1340d [Tests] up to io.js v3.3, node v4.1 d9bad2b Update eslint 935590c [Dev Deps] update jscs, eslint, @ljharb/eslint-config 8c9a1ef Test on io.js v2.2 9a3a38c Run travis-ci tests on iojs and node v0.12; speed up builds; allow 0.8 failures. 69afc26 [Dev Deps] Update tape, eslint 36c1be0 Update tape, jscs 98d8303 Update jscs 9633a4e Update tape, jscs c80ef0f Test up to io.js v3.0 7e2c853 Test on io.js v2.4 5a199a2 Test on io.js v2.3 a511b88 Fixing a typo from 822b4e1938db02dc9584aa434fd3a45cb20caf43 732d6b6 Update jscs da52a48 Lock covert to v1.0.0. d6150fd v1.0.2 - 2014-10-04 v1.0.1 - 2014-10-03 Merged make CI build faster #3 Commits Using my standard jscs.json d8ee94c Adding npm run lint 7571ab7 Using consistent indentation e91a1b1 Updating jscs 7e17892 Using consistent quotes c50b57f Adding keywords cb94631 Directly export a function expression instead of using a declaration, and relying on hoisting. 5a33c5f Naming npm URL and badge in README; use SVG 2aef8fc Naming deps URLs in README 04228d7 Naming travis-ci URLs in README; using SVG 62c810c Make sure functions are invoked correctly (also passing coverage tests) 2b289b4 Removing the strict mode pragmas; they make tests fail. 1aa701d Adding myself as a contributor 85fd57b Adding strict mode pragmas 915b08e Adding devDeps URLs to README 4ccc731 Fixing the description. a7a472c Using a function expression instead of a function declaration. b5d3e4e Updating tape f086be6 Updating jscs 5f9bdb3 Updating jscs 9b409ba Run coverage as part of tests. 8e1b6d4 Run linter as part of tests c1ca83f Updating covert 701e837 v1.0.0 - 2014-08-09 Commits Make sure old and unstable nodes don't fail Travis 27adca3 Fixing an issue when the bound function is called as a constructor in ES3. e20122d Adding npm run coverage a2e29c4 Updating tape b741168 Upgrading tape 63631a0 Updating tape 363cb46 v0.2.0 - 2014-03-23 Commits Updating test coverage to match es5-shim. aa94d44 initial 942ee07 Setting the bound function's length properly. 079f46a Ensuring that some older browsers will throw when given a regex. 36ac55b Removing npm scripts that don't have dependencies 9d2be60 Updating tape 297a4ac Skipping length tests for now. d9891ea don't take my tea dccd930"
  },
  "node_modules/function-bind/README.html": {
    "href": "node_modules/function-bind/README.html",
    "title": "function-bind | accouter",
    "keywords": "function-bind Implementation of function.prototype.bind Old versions of phantomjs, Internet Explorer < 9, and node < 0.6 don't support Function.prototype.bind. Example Function.prototype.bind = require(\"function-bind\") Installation npm install function-bind Contributors Raynos MIT Licenced"
  },
  "node_modules/function.prototype.name/CHANGELOG.html": {
    "href": "node_modules/function.prototype.name/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.1.6 - 2023-08-28 Commits [actions] reuse common workflows 5f6bfba [meta] use npmignore to autogenerate an npmignore file 28ea2f9 [Fix] properly recognize document.all in IE 6-8 316d676 [Fix] only return an own name d647609 [Tests] add browserstack browser tests 67ae402 [meta] better eccheck command 728df4c [meta] add auto-changelog dbb700b [readme] fix eclint c98fdf1 [readme] add tested browsers d41325c [actions] update rebase action to use reusable workflow 085f340 [Dev Deps] update eslint, @ljharb/eslint-config, @es-shims/api, safe-publish-latest, tape 3f071ce [actions] update codecov uploader a187b4f [Deps] update define-properties, es-abstract 3ca42ef [Dev Deps] update eslint, @ljharb/eslint-config, aud, tape 8de25d2 [Dev Deps] update @es-shims/api, @ljharb/eslint-config, aud, tape 8b04da7 [Dev Deps] update @ljharb/eslint-config, aud, tape 39d8538 [meta] reorder scripts 054f96b [Dev Deps] update eslint, @ljharb/eslint-config, tape bebee89 [Dev Deps] update aud, tape 8e68159 [Tests] handle Function.prototype in Opera 12.1 f3b8f9a [Deps] update es-abstract, functions-have-names 6a59889 [Deps] update define-properties, es-abstract cd1c5e7 [Deps] update es-abstract 3584585 [Deps] update es-abstract 0e2f6d9 [Deps] update es-abstract b11748e [Dev Deps] update tape d787a81 [Deps] update es-abstract 4692639 [Dev Deps] add in-publish 568e263 1.1.5 / 2021-10-01 [Deps] update es-abstract [meta] use prepublishOnly script for npm 7+ [Dev Deps] update eslint, @ljharb/eslint-config, @es-shims/api, aud, tape [actions] update workflows [actions] use node/install instead of node/run; use codecov action 1.1.4 / 2021-02-22 [readme] remove travis badge [meta] remove audit-level [meta] gitignore coverage output [meta] do not publish github action workflow files [Deps] update call-bind, es-abstract, functions-have-names [Dev Deps] update eslint, @ljharb/eslint-config, aud, has-strict-mode, tape [Tests] increase coverage [actions] update workflows 1.1.3 / 2020-11-27 [Deps] update es-abstract, functions-have-names; use call-bind where applicable [Dev Deps] update eslint, @ljharb/eslint-config, tape, make-arrow-function, make-generator-function; add aud, make-async-function [actions] add \"Allow Edits\" workflow [actions] switch Automatic Rebase workflow to pull_request_target event [Tests] migrate tests to Github Actions [Tests] run nyc on all tests [Tests] add implementation test; run es-shim-api in postlint; use tape runner [Tests] only audit prod deps 1.1.2 / 2019-12-14 [Refactor] use es-abstract [Deps] update functions-have-names [meta] add funding field [meta] fix repo capitalization [Dev Deps] update eslint, @ljharb/eslint-config, safe-publish-latest [Tests] use shared travis-ci configs [actions] add automatic rebasing / merge commit blocking 1.1.1 / 2019-07-24 [Refactor] use functions-have-names [meta] clean up package.json scripts [meta] update links [meta] create FUNDING.yml [Deps] update is-callable, define-properties [Dev Deps] update eslint, @ljharb/eslint-config, tape, safe-publish-latest, covert [Tests] use eccheck over editorconfig-tools [Tests] use npx aud instead of nsp or npm audit with hoops [Tests] up to node v11.7, v10.15, v9.11, v8.15, v6.16, v4.9 [Test] remove jscs 1.1.0 / 2017-12-31 [New] add auto entry point [Deps] update function-bind [Dev Deps] update uglify-register, tape, nsp, eslint, @ljharb/eslint-config, @es-shims/api [Tests] up to node v9.3, v8.9, v6.12; use nvm install-latest-npm; pin included builds to LTS 1.0.3 / 2017-07-21 [Fix] be robust against function name mangling [Refactor] move function name detection to separate file 1.0.2 / 2017-07-14 [Refactor] shim: Remove unnecessary !functionsHaveNames check 1.0.1 / 2017-07-11 [Fix] in IE 9-11, we must rely on .call being available (#13) [Fix] ensure that Function.prototype.name does not erase the getter [Deps] update is-callable [Dev Deps] add safe-publish-latest [Dev Deps] update tape, jscs, nsp, eslint, @ljharb/eslint-config, @es-shims/api [Tests] up to node v8.1; v7.10, v6.11, v4.8; improve matrix; newer npm fails on older nodes [Tests] use Object to avoid function name inference in node 7 1.0.0 / 2016-02-27 Initial release."
  },
  "node_modules/function.prototype.name/README.html": {
    "href": "node_modules/function.prototype.name/README.html",
    "title": "function.prototype.name | accouter",
    "keywords": "function.prototype.name An ES2015 spec-compliant Function.prototype.name shim. Invoke its \"shim\" method to shim Function.prototype.name if it is unavailable. Note: Function#name requires a true ES5 environment - specifically, one with ES5 getters. This package implements the es-shim API interface. It works in an ES5-supported environment and complies with the spec. Most common usage: Example var functionName = require('function.prototype.name'); var assert = require('assert'); assert.equal(functionName(function foo() {}), 'foo'); functionName.shim(); assert.equal(function foo() {}.name, 'foo'); Supported engines Automatically tested in every minor version of node. Manually tested in: Safari: v4 - v15 (4, 5, 5.1, 6.0.5, 6.2, 7.1, 8, 9.1.3, 10.1.2, 11.1.2, 12.1, 13.1.2, 14.1.2, 15.3, 15.6.1) Chrome: v15 - v81, v83 - v106(every integer version) Note: This includes Edge v80+ and Opera v15+, which matches Chrome Firefox: v3, v3.6, v4 - v105 (every integer version) Note: in v42 - v63, Function.prototype.toString throws on HTML element constructors, or a Proxy to a function Note: in v20 - v35, HTML element constructors are not callable, despite having typeof function IE: v6 - v11(every integer version Opera: v11.1, v11.5, v11.6, v12.0, v12.1, v12.14, v12.15, v12.16, v15+ v15+ matches Chrome Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/functions-have-names/CHANGELOG.html": {
    "href": "node_modules/functions-have-names/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.2.3 - 2022-04-19 Fixed [Fix] in IE 9-11, the descriptor is absent #11 #25 Commits [actions] reuse common workflows 4ed274a [actions] use node/install instead of node/run; use codecov action 96dfcaa [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape 9e674f8 [readme] add github actions/codecov badges; update URLs d913f5b [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, safe-publish-latest, tape f61058f [actions] update codecov uploader 3348839 [Dev Deps] update eslint, @ljharb/eslint-config, safe-publish-latest, tape ee1a321 [Dev Deps] update eslint, @ljharb/eslint-config, tape b8dc1a2 [Dev Deps] update @ljharb/eslint-config, tape 0e825c4 [meta] use prepublishOnly script for npm 7+ 9489d66 v1.2.2 - 2020-12-14 Commits [Tests] migrate tests to Github Actions 39bf4fe [meta] do not publish github action workflow files 45ab0cb [readme] add docs, fix URLs fad3af6 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape 82df94a [Tests] run nyc on all tests; use tape runner 8038329 [actions] add automatic rebasing / merge commit blocking 49795eb [actions] add \"Allow Edits\" workflow 2096fe6 [actions] switch Automatic Rebase workflow to pull_request_target event ec1c6fe [Dev Deps] update auto-changelog; add aud 79fdb23 [Tests] only audit prod deps d9ca245 [Dev Deps] update auto-changelog, tape ac026d4 [Dev Deps] update tape a8c5ee3 [Dev Deps] update @ljharb/eslint-config b25fafd v1.2.1 - 2020-01-19 Commits [Tests] use shared travis-ci configs 612823a [Fix] IE 8 has a broken Object.getOwnPropertyDescriptor ba01c22 [Dev Deps] update eslint, @ljharb/eslint-config, auto-changelog; add safe-publish-latest b28d9d2 [Dev Deps] update eslint, @ljharb/eslint-config, tape a62fbd6 [meta] add funding field 8734a94 v1.2.0 - 2019-10-20 Commits [Dev Deps] update eslint, @ljharb/eslint-config, auto-changelog 7e07444 [New] add boundFunctionsHaveNames() 05661be v1.1.1 - 2019-07-24 Commits [Tests] fix linting errors 0cb8017 [Tests] fix tests when name is not configurable 38a8aee [Fix] ensure function name mangling does not break detection f6926ab v1.1.0 - 2019-07-23 Commits [New] add functionsHaveConfigurableNames function on main export ce73f75 v1.0.0 - 2019-07-22 Commits [Tests] add travis.yml 06ed096 Initial commit ced60bd npm init 79088ab add tests c9e8e09 [Tests] add npm run lint 988b924 [meta] create FUNDING.yml 2e443ef [meta] add version scripts 52005e3 implementation b7b4942 Only apps should have lockfiles 81d2e04 [Tests] use npx aud baa92d8"
  },
  "node_modules/functions-have-names/README.html": {
    "href": "node_modules/functions-have-names/README.html",
    "title": "functions-have-names | accouter",
    "keywords": "functions-have-names Does this JS environment support the name property on functions? Example var functionsHaveNames = require('functions-have-names'); var assert = require('assert'); assert.equal(functionsHaveNames(), true); // will be `false` in IE 6-8 Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/get-caller-file/LICENSE.html": {
    "href": "node_modules/get-caller-file/LICENSE.html",
    "title": "| accouter",
    "keywords": "ISC License (ISC) Copyright 2018 Stefan Penner Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies. THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE."
  },
  "node_modules/get-caller-file/README.html": {
    "href": "node_modules/get-caller-file/README.html",
    "title": "get-caller-file | accouter",
    "keywords": "get-caller-file This is a utility, which allows a function to figure out from which file it was invoked. It does so by inspecting v8's stack trace at the time it is invoked. Inspired by http://stackoverflow.com/questions/13227489 note: this relies on Node/V8 specific APIs, as such other runtimes may not work Installation yarn add get-caller-file Usage Given: // ./foo.js const getCallerFile = require('get-caller-file'); module.exports = function() { return getCallerFile(); // figures out who called it }; // index.js const foo = require('./foo'); foo() // => /full/path/to/this/file/index.js Options: getCallerFile(position = 2): where position is stack frame whos fileName we want."
  },
  "node_modules/get-intrinsic/CHANGELOG.html": {
    "href": "node_modules/get-intrinsic/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.2.4 - 2024-02-05 Commits [Refactor] use all 7 <+ ES6 Errors from es-errors bcac811 v1.2.3 - 2024-02-03 Commits [Refactor] use es-errors, so things that only need those do not need get-intrinsic f11db9c [Dev Deps] update aud, es-abstract, mock-property, npmignore b7ac7d1 [meta] simplify exports faa0cc6 [meta] add missing engines.node 774dd0b [Dev Deps] update tape 5828e8e [Robustness] use null objects for lookups eb9a11f [meta] add sideEffects flag 89bcc7a v1.2.2 - 2023-10-20 Commits [Dev Deps] update @ljharb/eslint-config, aud, call-bind, es-abstract, mock-property, object-inspect, tape f51bcf2 [Refactor] use hasown instead of has 18d14b7 [Deps] update function-bind 6e109c8 v1.2.1 - 2023-05-13 Commits [Fix] avoid a crash in envs without __proto__ 7bad8d0 [Dev Deps] update es-abstract c60e6b7 v1.2.0 - 2023-01-19 Commits [actions] update checkout action ca6b12f [Dev Deps] update @ljharb/eslint-config, es-abstract, object-inspect, tape 41a3727 [Fix] ensure Error.prototype is undeniable c511e97 [Dev Deps] update aud, es-abstract, tape 1bef8a8 [Dev Deps] update aud, es-abstract 0d41f16 [New] add BigInt64Array and BigUint64Array a6cca25 [Tests] use gopd ecf7722 v1.1.3 - 2022-09-12 Commits [Dev Deps] update es-abstract, es-value-fixtures, tape 07ff291 [Fix] properly check for % signs 50ac176 v1.1.2 - 2022-06-08 Fixed [Fix] properly validate against extra % signs #16 Commits [actions] reuse common workflows 0972547 [meta] use npmignore to autogenerate an npmignore file 5ba0b51 [actions] use node/install instead of node/run; use codecov action c364492 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, es-abstract, object-inspect, tape dc04dad [Dev Deps] update eslint, @ljharb/eslint-config, es-abstract, object-inspect, safe-publish-latest, tape 1c14059 [Tests] use mock-property b396ef0 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, object-inspect, tape c2c758d [Dev Deps] update eslint, @ljharb/eslint-config, aud, es-abstract, es-value-fixtures, object-inspect, tape 29e3c09 [actions] update codecov uploader 8cbc141 [Dev Deps] update @ljharb/eslint-config, es-abstract, es-value-fixtures, object-inspect, tape 10b6f5c [readme] add github actions/codecov badges 4e25400 [Tests] use for-each instead of foreach c05b957 [Dev Deps] update es-abstract 29b05ae [meta] use prepublishOnly script for npm 7+ 95c285d [Deps] update has-symbols 593cb4f [readme] fix repo URLs 1c8305b [Deps] update has-symbols c7138b6 [Dev Deps] remove unused has-bigints bd63aff v1.1.1 - 2021-02-03 Fixed [meta] export ./package.json #9 Commits [readme] flesh out the readme; use evalmd d12f12c [eslint] set up proper globals config 5a8c098 [Dev Deps] update eslint 7b9a5c0 v1.1.0 - 2021-01-25 Fixed [Refactor] delay Function eval until syntax-derived values are requested #3 Commits [Tests] migrate tests to Github Actions 2ab762b [meta] do not publish github action workflow files 5e7108e [Tests] add some coverage 01ac7a8 [Dev Deps] update eslint, @ljharb/eslint-config, call-bind, es-abstract, tape; add call-bind 911b672 [Refactor] rearrange evalled constructors a bit 7e7e4bf [meta] add Automatic Rebase and Require Allow Edits workflows 0199968 v1.0.2 - 2020-12-17 Commits [Fix] Throw for non‑existent intrinsics 68f873b [Fix] Throw for non‑existent segments in the intrinsic path 8325dee [Dev Deps] update eslint, @ljharb/eslint-config, aud, has-bigints, object-inspect 0c227a7 [meta] do not lint coverage output 70d2419 v1.0.1 - 2020-10-30 Commits [Tests] gather coverage data on every job d1d280d [Fix] add missing dependencies 5031771 [Tests] use es-value-fixtures af48765 v1.0.0 - 2020-10-29 Commits Implementation bbce57c Tests 17b4f0d Initial commit 3153294 npm init fb326c4 [meta] add Automatic Rebase and Require Allow Edits workflows 48862fb [meta] add auto-changelog 5f28ad0 [meta] add \"funding\"; create FUNDING.yml c2bbdde [Tests] add npm run lint 0a84b98 Only apps should have lockfiles 9586c75"
  },
  "node_modules/get-intrinsic/README.html": {
    "href": "node_modules/get-intrinsic/README.html",
    "title": "get-intrinsic | accouter",
    "keywords": "get-intrinsic Get and robustly cache all JS language-level intrinsics at first require time. See the syntax described in the JS spec for reference. Example var GetIntrinsic = require('get-intrinsic'); var assert = require('assert'); // static methods assert.equal(GetIntrinsic('%Math.pow%'), Math.pow); assert.equal(Math.pow(2, 3), 8); assert.equal(GetIntrinsic('%Math.pow%')(2, 3), 8); delete Math.pow; assert.equal(GetIntrinsic('%Math.pow%')(2, 3), 8); // instance methods var arr = [1]; assert.equal(GetIntrinsic('%Array.prototype.push%'), Array.prototype.push); assert.deepEqual(arr, [1]); arr.push(2); assert.deepEqual(arr, [1, 2]); GetIntrinsic('%Array.prototype.push%').call(arr, 3); assert.deepEqual(arr, [1, 2, 3]); delete Array.prototype.push; GetIntrinsic('%Array.prototype.push%').call(arr, 4); assert.deepEqual(arr, [1, 2, 3, 4]); // missing features delete JSON.parse; // to simulate a real intrinsic that is missing in the environment assert.throws(() => GetIntrinsic('%JSON.parse%')); assert.equal(undefined, GetIntrinsic('%JSON.parse%', true)); Tests Simply clone the repo, npm install, and run npm test Security Please email @ljharb or see https://tidelift.com/security if you have a potential security vulnerability to report."
  },
  "node_modules/get-stdin/readme.html": {
    "href": "node_modules/get-stdin/readme.html",
    "title": "get-stdin | accouter",
    "keywords": "get-stdin Get stdin as a string or buffer Install $ npm install get-stdin Usage // example.js import getStdin from 'get-stdin'; console.log(await getStdin()); //=> 'unicorns' $ echo unicorns | node example.js unicorns API Both methods returns a promise that is resolved when the end event fires on the stdin stream, indicating that there is no more data to be read. getStdin() Get stdin as a string. In a TTY context, a promise that resolves to an empty string is returned. getStdin.buffer() Get stdin as a Buffer. In a TTY context, a promise that resolves to an empty Buffer is returned. Related get-stream - Get a stream as a string or buffer Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "node_modules/get-symbol-description/CHANGELOG.html": {
    "href": "node_modules/get-symbol-description/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.2 - 2024-02-07 Fixed [Deps] add missing get-intrinsic #3 v1.0.1 - 2024-02-05 Commits [actions] reuse common workflows 168adf2 [meta] use npmignore to autogenerate an npmignore file fa3b323 [Dev Deps] update eslint, @ljharb/eslint-config, aud, es-value-fixtures, foreach, object-inspect, tape 9301b9e [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, object-inspect, tape a92a011 [actions] update rebase action to use reusable workflow 66cea29 [actions] update codecov uploader 84079e1 [Dev Deps] update eslint, @ljharb/eslint-config, object-inspect, safe-publish-latest, tape 9f298a5 [Dev Deps] use hasown instead of has e993bd6 [Dev Deps] update aud, npmignore, tape 5044bed [Dev Deps] update @ljharb/eslint-config, aud, tape 3923eab [Refactor] use es-errors, so things that only need those do not need get-intrinsic a24f5c5 [Deps] update call-bind, get-intrinsic accd484 [Dev Deps] update object-inspect, tape 6c66623 [Dev Deps] update object-inspect, tape 586dfe3 [Dev Deps] update @ljharb/eslint-config, aud bc8c7e0 [Tests] use for-each instead of foreach ca97918 [Robustness] cache String slice 5ce0c56 [Deps] update get-intrinsic b656c5c [Deps] update get-intrinsic 74cf3b6 [meta] fix FUNDING.yml 6cf76c8 v1.0.0 - 2021-08-17 Commits Initial commit: pulled from es-abstract 6e34a05 Initial commit 3862092 [meta] do not publish github action workflow files 9d1e2b9 npm init 5051b32 Only apps should have lockfiles b866d1c"
  },
  "node_modules/get-symbol-description/README.html": {
    "href": "node_modules/get-symbol-description/README.html",
    "title": "get-symbol-description | accouter",
    "keywords": "get-symbol-description Gets the description of a Symbol. Handles Symbol() vs Symbol('') properly when possible. Example var getSymbolDescription = require('get-symbol-description'); var assert = require('assert'); assert(getSymbolDescription(Symbol()) === undefined); assert(getSymbolDescription(Symbol('')) === ''); // or `undefined`, if in an engine that lacks name inference from concise method assert(getSymbolDescription(Symbol('foo')) === 'foo'); assert(getSymbolDescription(Symbol.iterator) === 'Symbol.iterator'); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/glob-parent/CHANGELOG.html": {
    "href": "node_modules/glob-parent/CHANGELOG.html",
    "title": "| accouter",
    "keywords": "5.1.2 (2021-03-06) Bug Fixes eliminate ReDoS (#36) (f923116) 5.1.1 (2021-01-27) Bug Fixes unescape exclamation mark (#26) (a98874f) 5.1.0 (2021-01-27) Features add flipBackslashes option to disable auto conversion of slashes (closes #24) (#25) (eecf91d) 5.0.0 (2021-01-27) ⚠ BREAKING CHANGES Drop support for node <6 & bump dependencies Miscellaneous Chores Drop support for node <6 & bump dependencies (896c0c0) 4.0.0 (2021-01-27) ⚠ BREAKING CHANGES question marks are valid path characters on Windows so avoid flagging as a glob when alone Update is-glob dependency Features hoist regexps and strings for performance gains (4a80667) question marks are valid path characters on Windows so avoid flagging as a glob when alone (2a551dd) Update is-glob dependency (e41fcd8) 3.1.0 (2021-01-27) Features allow basic win32 backslash use (272afa5) handle extglobs (parentheses) containing separators (7db1bdb) new approach to braces/brackets handling (8269bd8) pre-process braces/brackets sections (9ef8a87) preserve escaped brace/bracket at end of string (8cfb0ba) Bug Fixes trailing escaped square brackets (99ec9fe) 3.0.1 (2021-01-27) Features use path-dirname ponyfill (cdbea5f) Bug Fixes unescape glob-escaped dirnames on output (598c533) 3.0.0 (2021-01-27) ⚠ BREAKING CHANGES update is-glob dependency Features update is-glob dependency (5c5f8ef) 2.0.0 (2021-01-27) Features move up to dirname regardless of glob characters (f97fb83) 1.3.0 (2021-01-27) 1.2.0 (2021-01-27) Reverts feat: make regex test strings smaller (dc80fa9) 1.1.0 (2021-01-27) Features make regex test strings smaller (cd83220) 1.0.0 (2021-01-27)"
  },
  "node_modules/glob-parent/README.html": {
    "href": "node_modules/glob-parent/README.html",
    "title": "glob-parent | accouter",
    "keywords": "glob-parent Extract the non-magic parent path from a glob string. Usage var globParent = require('glob-parent'); globParent('path/to/*.js'); // 'path/to' globParent('/root/path/to/*.js'); // '/root/path/to' globParent('/*.js'); // '/' globParent('*.js'); // '.' globParent('**/*.js'); // '.' globParent('path/{to,from}'); // 'path' globParent('path/!(to|from)'); // 'path' globParent('path/?(to|from)'); // 'path' globParent('path/+(to|from)'); // 'path' globParent('path/*(to|from)'); // 'path' globParent('path/@(to|from)'); // 'path' globParent('path/**/*'); // 'path' // if provided a non-glob path, returns the nearest dir globParent('path/foo/bar.js'); // 'path/foo' globParent('path/foo/'); // 'path/foo' globParent('path/foo'); // 'path' (see issue #3 for details) API globParent(maybeGlobString, [options]) Takes a string and returns the part of the path before the glob begins. Be aware of Escaping rules and Limitations below. options { // Disables the automatic conversion of slashes for Windows flipBackslashes: true } Escaping The following characters have special significance in glob patterns and must be escaped if you want them to be treated as regular path characters: ? (question mark) unless used as a path segment alone * (asterisk) | (pipe) ( (opening parenthesis) ) (closing parenthesis) { (opening curly brace) } (closing curly brace) [ (opening bracket) ] (closing bracket) Example globParent('foo/[bar]/') // 'foo' globParent('foo/\\\\[bar]/') // 'foo/[bar]' Limitations Braces & Brackets This library attempts a quick and imperfect method of determining which path parts have glob magic without fully parsing/lexing the pattern. There are some advanced use cases that can trip it up, such as nested braces where the outer pair is escaped and the inner one contains a path separator. If you find yourself in the unlikely circumstance of being affected by this or need to ensure higher-fidelity glob handling in your library, it is recommended that you pre-process your input with expand-braces and/or expand-brackets. Windows Backslashes are not valid path separators for globs. If a path with backslashes is provided anyway, for simple cases, glob-parent will replace the path separator for you and return the non-glob parent path (now with forward-slashes, which are still valid as Windows path separators). This cannot be used in conjunction with escape characters. // BAD globParent('C:\\\\Program Files \\\\(x86\\\\)\\\\*.ext') // 'C:/Program Files /(x86/)' // GOOD globParent('C:/Program Files\\\\(x86\\\\)/*.ext') // 'C:/Program Files (x86)' If you are using escape characters for a pattern without path parts (i.e. relative to cwd), prefix with ./ to avoid confusing glob-parent. // BAD globParent('foo \\\\[bar]') // 'foo ' globParent('foo \\\\[bar]*') // 'foo ' // GOOD globParent('./foo \\\\[bar]') // 'foo [bar]' globParent('./foo \\\\[bar]*') // '.' License ISC"
  },
  "node_modules/glob/README.html": {
    "href": "node_modules/glob/README.html",
    "title": "Glob | accouter",
    "keywords": "Glob Match files using the patterns the shell uses, like stars and stuff. This is a glob implementation in JavaScript. It uses the minimatch library to do its matching. Usage Install with npm npm i glob var glob = require(\"glob\") // options is optional glob(\"**/*.js\", options, function (er, files) { // files is an array of filenames. // If the `nonull` option is set, and nothing // was found, then files is [\"**/*.js\"] // er is an error object or null. }) Glob Primer \"Globs\" are the patterns you type when you do stuff like ls *.js on the command line, or put build/* in a .gitignore file. Before parsing the path part patterns, braced sections are expanded into a set. Braced sections start with { and end with }, with any number of comma-delimited sections within. Braced sections may contain slash characters, so a{/b/c,bcd} would expand into a/b/c and abcd. The following characters have special magic meaning when used in a path portion: * Matches 0 or more characters in a single path portion ? Matches 1 character [...] Matches a range of characters, similar to a RegExp range. If the first character of the range is ! or ^ then it matches any character not in the range. !(pattern|pattern|pattern) Matches anything that does not match any of the patterns provided. ?(pattern|pattern|pattern) Matches zero or one occurrence of the patterns provided. +(pattern|pattern|pattern) Matches one or more occurrences of the patterns provided. *(a|b|c) Matches zero or more occurrences of the patterns provided @(pattern|pat*|pat?erN) Matches exactly one of the patterns provided ** If a \"globstar\" is alone in a path portion, then it matches zero or more directories and subdirectories searching for matches. It does not crawl symlinked directories. Dots If a file or directory path portion has a . as the first character, then it will not match any glob pattern unless that pattern's corresponding path part also has a . as its first character. For example, the pattern a/.*/c would match the file at a/.b/c. However the pattern a/*/c would not, because * does not start with a dot character. You can make glob treat dots as normal characters by setting dot:true in the options. Basename Matching If you set matchBase:true in the options, and the pattern has no slashes in it, then it will seek for any file anywhere in the tree with a matching basename. For example, *.js would match test/simple/basic.js. Empty Sets If no matching files are found, then an empty array is returned. This differs from the shell, where the pattern itself is returned. For example: $ echo a*s*d*f a*s*d*f To get the bash-style behavior, set the nonull:true in the options. See Also: man sh man bash (Search for \"Pattern Matching\") man 3 fnmatch man 5 gitignore minimatch documentation glob.hasMagic(pattern, [options]) Returns true if there are any special characters in the pattern, and false otherwise. Note that the options affect the results. If noext:true is set in the options object, then +(a|b) will not be considered a magic pattern. If the pattern has a brace expansion, like a/{b/c,x/y} then that is considered magical, unless nobrace:true is set in the options. glob(pattern, [options], cb) pattern {String} Pattern to be matched options {Object} cb {Function} err {Error | null} matches {Array<String>} filenames found matching the pattern Perform an asynchronous glob search. glob.sync(pattern, [options]) pattern {String} Pattern to be matched options {Object} return: {Array<String>} filenames found matching the pattern Perform a synchronous glob search. Class: glob.Glob Create a Glob object by instantiating the glob.Glob class. var Glob = require(\"glob\").Glob var mg = new Glob(pattern, options, cb) It's an EventEmitter, and starts walking the filesystem to find matches immediately. new glob.Glob(pattern, [options], [cb]) pattern {String} pattern to search for options {Object} cb {Function} Called when an error occurs, or matches are found err {Error | null} matches {Array<String>} filenames found matching the pattern Note that if the sync flag is set in the options, then matches will be immediately available on the g.found member. Properties minimatch The minimatch object that the glob uses. options The options object passed in. aborted Boolean which is set to true when calling abort(). There is no way at this time to continue a glob search after aborting, but you can re-use the statCache to avoid having to duplicate syscalls. cache Convenience object. Each field has the following possible values: false - Path does not exist true - Path exists 'FILE' - Path exists, and is not a directory 'DIR' - Path exists, and is a directory [file, entries, ...] - Path exists, is a directory, and the array value is the results of fs.readdir statCache Cache of fs.stat results, to prevent statting the same path multiple times. symlinks A record of which paths are symbolic links, which is relevant in resolving ** patterns. realpathCache An optional object which is passed to fs.realpath to minimize unnecessary syscalls. It is stored on the instantiated Glob object, and may be re-used. Events end When the matching is finished, this is emitted with all the matches found. If the nonull option is set, and no match was found, then the matches list contains the original pattern. The matches are sorted, unless the nosort flag is set. match Every time a match is found, this is emitted with the specific thing that matched. It is not deduplicated or resolved to a realpath. error Emitted when an unexpected error is encountered, or whenever any fs error occurs if options.strict is set. abort When abort() is called, this event is raised. Methods pause Temporarily stop the search resume Resume the search abort Stop the search forever Options All the options that can be passed to Minimatch can also be passed to Glob to change pattern matching behavior. Also, some have been added, or have glob-specific ramifications. All options are false by default, unless otherwise noted. All options are added to the Glob object, as well. If you are running many glob operations, you can pass a Glob object as the options argument to a subsequent operation to shortcut some stat and readdir calls. At the very least, you may pass in shared symlinks, statCache, realpathCache, and cache options, so that parallel glob operations will be sped up by sharing information about the filesystem. cwd The current working directory in which to search. Defaults to process.cwd(). This option is always coerced to use forward-slashes as a path separator, because it is not tested as a glob pattern, so there is no need to escape anything. root The place where patterns starting with / will be mounted onto. Defaults to path.resolve(options.cwd, \"/\") (/ on Unix systems, and C:\\ or some such on Windows.) This option is always coerced to use forward-slashes as a path separator, because it is not tested as a glob pattern, so there is no need to escape anything. windowsPathsNoEscape Use \\\\ as a path separator only, and never as an escape character. If set, all \\\\ characters are replaced with / in the pattern. Note that this makes it impossible to match against paths containing literal glob pattern characters, but allows matching with patterns constructed using path.join() and path.resolve() on Windows platforms, mimicking the (buggy!) behavior of Glob v7 and before on Windows. Please use with caution, and be mindful of the caveat below about Windows paths. (For legacy reasons, this is also set if allowWindowsEscape is set to the exact value false.) dot Include .dot files in normal matches and globstar matches. Note that an explicit dot in a portion of the pattern will always match dot files. nomount By default, a pattern starting with a forward-slash will be \"mounted\" onto the root setting, so that a valid filesystem path is returned. Set this flag to disable that behavior. mark Add a / character to directory matches. Note that this requires additional stat calls. nosort Don't sort the results. stat Set to true to stat all results. This reduces performance somewhat, and is completely unnecessary, unless readdir is presumed to be an untrustworthy indicator of file existence. silent When an unusual error is encountered when attempting to read a directory, a warning will be printed to stderr. Set the silent option to true to suppress these warnings. strict When an unusual error is encountered when attempting to read a directory, the process will just continue on in search of other matches. Set the strict option to raise an error in these cases. cache See cache property above. Pass in a previously generated cache object to save some fs calls. statCache A cache of results of filesystem information, to prevent unnecessary stat calls. While it should not normally be necessary to set this, you may pass the statCache from one glob() call to the options object of another, if you know that the filesystem will not change between calls. (See \"Race Conditions\" below.) symlinks A cache of known symbolic links. You may pass in a previously generated symlinks object to save lstat calls when resolving ** matches. sync DEPRECATED: use glob.sync(pattern, opts) instead. nounique In some cases, brace-expanded patterns can result in the same file showing up multiple times in the result set. By default, this implementation prevents duplicates in the result set. Set this flag to disable that behavior. nonull Set to never return an empty set, instead returning a set containing the pattern itself. This is the default in glob(3). debug Set to enable debug logging in minimatch and glob. nobrace Do not expand {a,b} and {1..3} brace sets. noglobstar Do not match ** against multiple filenames. (Ie, treat it as a normal * instead.) noext Do not match +(a|b) \"extglob\" patterns. nocase Perform a case-insensitive match. Note: on case-insensitive filesystems, non-magic patterns will match by default, since stat and readdir will not raise errors. matchBase Perform a basename-only match if the pattern does not contain any slash characters. That is, *.js would be treated as equivalent to **/*.js, matching all js files in all directories. nodir Do not match directories, only files. (Note: to match only directories, simply put a / at the end of the pattern.) ignore Add a pattern or an array of glob patterns to exclude matches. Note: ignore patterns are always in dot:true mode, regardless of any other settings. follow Follow symlinked directories when expanding ** patterns. Note that this can result in a lot of duplicate references in the presence of cyclic links. realpath Set to true to call fs.realpath on all of the results. In the case of a symlink that cannot be resolved, the full absolute path to the matched entry is returned (though it will usually be a broken symlink) absolute Set to true to always receive absolute paths for matched files. Unlike realpath, this also affects the values returned in the match event. fs File-system object with Node's fs API. By default, the built-in fs module will be used. Set to a volume provided by a library like memfs to avoid using the \"real\" file-system. Comparisons to other fnmatch/glob implementations While strict compliance with the existing standards is a worthwhile goal, some discrepancies exist between node-glob and other implementations, and are intentional. The double-star character ** is supported by default, unless the noglobstar flag is set. This is supported in the manner of bsdglob and bash 4.3, where ** only has special significance if it is the only thing in a path part. That is, a/**/b will match a/x/y/b, but a/**b will not. Note that symlinked directories are not crawled as part of a **, though their contents may match against subsequent portions of the pattern. This prevents infinite loops and duplicates and the like. If an escaped pattern has no matches, and the nonull flag is set, then glob returns the pattern as-provided, rather than interpreting the character escapes. For example, glob.match([], \"\\\\*a\\\\?\") will return \"\\\\*a\\\\?\" rather than \"*a?\". This is akin to setting the nullglob option in bash, except that it does not resolve escaped pattern characters. If brace expansion is not disabled, then it is performed before any other interpretation of the glob pattern. Thus, a pattern like +(a|{b),c)}, which would not be valid in bash or zsh, is expanded first into the set of +(a|b) and +(a|c), and those patterns are checked for validity. Since those two are valid, matching proceeds. Comments and Negation Previously, this module let you mark a pattern as a \"comment\" if it started with a # character, or a \"negated\" pattern if it started with a ! character. These options were deprecated in version 5, and removed in version 6. To specify things that should not match, use the ignore option. Windows Please only use forward-slashes in glob expressions. Though windows uses either / or \\ as its path separator, only / characters are used by this glob implementation. You must use forward-slashes only in glob expressions. Back-slashes will always be interpreted as escape characters, not path separators. Results from absolute patterns such as /foo/* are mounted onto the root setting using path.join. On windows, this will by default result in /foo/* matching C:\\foo\\bar.txt. To automatically coerce all \\ characters to / in pattern strings, thus making it impossible to escape literal glob characters, you may set the windowsPathsNoEscape option to true. Race Conditions Glob searching, by its very nature, is susceptible to race conditions, since it relies on directory walking and such. As a result, it is possible that a file that exists when glob looks for it may have been deleted or modified by the time it returns the result. As part of its internal implementation, this program caches all stat and readdir calls that it makes, in order to cut down on system overhead. However, this also makes it even more susceptible to races, especially if the cache or statCache objects are reused between glob calls. Users are thus advised not to use a glob result as a guarantee of filesystem state in the face of rapid changes. For the vast majority of operations, this is never a problem. Glob Logo Glob's logo was created by Tanya Brassie. Logo files can be found here. The logo is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License. Contributing Any change to behavior (including bugfixes) must come with a test. Patches that fail tests or reduce performance will be rejected. # to run tests npm test # to re-generate test fixtures npm run test-regen # to benchmark against bash/zsh npm run bench # to profile javascript npm run prof"
  },
  "node_modules/globalthis/CHANGELOG.html": {
    "href": "node_modules/globalthis/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.4 - 2024-04-29 Commits [actions] remove redundant finisher 280d796 [Refactor] use gopd 0209ccb [actions] update rebase action to use reusable workflow c08aea6 [Dev Deps] update @es-shims/api, @ljharb/eslint-config, aud, tape f38f2af [Dev Deps] update aud, tape a1be102 [Deps] update define-properties 3e41644 [Deps] update define-properties 3d81f70 [Dev Deps] add missing npmignore dep c2d00f7 v1.0.3 - 2022-05-07 Commits [actions] reuse common workflows 65891e4 [actions] use node/install instead of node/run; use codecov action 82f8481 [meta] use npmignore to autogenerate an npmignore file 53afc39 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape 03169d4 [Dev Deps] update eslint, @ljharb/eslint-config, safe-publish-latest, tape 4986e3e [actions] update codecov uploader 15c4b06 [Dev Deps] update eslint, @ljharb/eslint-config, auto-changelog, tape 8b04a74 [Fix] globalThis should be writable 8759985 [readme] add github actions/codecov badges 0263f0d [Dev Deps] update aud, eslint, tape e88d296 [meta] use prepublishOnly script for npm 7+ c81fde6 [Tests] nycignore dist bde0c0d [meta] gitignore coverage output 79f73f8 v1.0.2 - 2021-02-22 Commits [Tests] migrate tests to Github Actions a3f50f7 [meta] do not publish github action workflow files eb5c787 [Tests] add implementation est; run es-shim-api in postlint; use tape runner c9dd792 [Tests] fix native tests 6b76dff [Tests] run nyc on all tests 0407f79 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape, browserify b8cc020 [actions] add \"Allow Edits\" workflow e2854df [readme] remove travis badge 262eb76 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog; add safe-publish-latest 3c76883 [Dev Deps] update eslint, @ljharb/eslint-config, aud, tape 7276123 [actions] update workflows bcb0f42 [Dev Deps] update eslint, @ljharb/eslint-config, tape 5485851 [Dev Deps] update auto-changelog, tape 6a01da3 [Dev Deps] update @ljharb/eslint-config, tape 7a07f4e [meta] only run the build script in publish 797e492 [meta] combine duplicate prepublish scripts 92bbef0 [Dev Deps] update auto-changelog; add aud be6dbec [actions] switch Automatic Rebase workflow to pull_request_target event bfd54f8 [Tests] only audit prod deps 0f64b47 v1.0.1 - 2019-12-15 Fixed [Refactor] only use global in node; only check browser globals in browsers #2 Commits [Tests] use shared travis-ci configs edb1cc9 [Tests] remove jscs 1847ac2 [meta] add auto-changelog 933c381 [Dev Deps] update eslint, @ljharb/eslint-config, browserify, tape 93310bc [actions] add automatic rebasing / merge commit blocking 231dec5 [Dev Deps] update eslint, @ljharb/eslint-config, browserify, covert, is, tape e50c1f6 [Tests] use npx aud instead of nsp or npm audit with hoops 4abd340 [meta] add funding field 2d1f9eb [meta] remove unused deps 5bd6bef readme: Fix casing + phrasing 66379cc [Deps] update define-properties, object-keys 4585e5a fix issue with Webpack's CaseSensitivePathsPlugin 842e84e v1.0.0 - 2018-08-10 Commits Dotfiles. f01b02d [Tests] up to node v10.7, v9.11, v8.11, v7.10, v6.14, v4.9; use nvm install-latest-npm; improve matrix ed1fa5d Tests ab99527 [breaking] update property name, rename repo be42e3d package.json ca43a36 implementation 80b5a40 read me f6df9b3 Rename System.global to global fa8503c Initial commit 99f1dc3 [Tests] up to node v6.7, v5.12, v4.6; improve test matrix 712ec0e [Dev Deps] update browserify, tape, jscs, nsp, eslint, @ljharb/eslint-config 73278bd [Dev Deps] update @es-shims/api, @ljharb/eslint-config, browserify, eslint, for-each, is, nsp, tape 75fa992 [Dev Deps] update browserify, is, tape, nsp, eslint b223e86 [Tests] fix linting; remove parallelshell 271b329 [Deps] update function-bind, object-keys 002d0c5 Only apps should have lockfiles 960f1d0 [Tests] on node v10.8 37fad9d [Dev Deps] update eslint, @ljharb/eslint-config df28dfe [New] add auto entry point 86eb2ab [Dev Deps] update eslint 1bdc1aa [Deps] update object-keys 72cdbf5 Update most common usage to invoke the function upon being required 5026296"
  },
  "node_modules/globalthis/README.html": {
    "href": "node_modules/globalthis/README.html",
    "title": "globalThis | accouter",
    "keywords": "globalThis An ECMAScript spec-compliant polyfill/shim for globalThis. Invoke its \"shim\" method to shim globalThis if it is unavailable. This package implements the es-shim API interface. It works in an ES3-supported environment and complies with the spec proposal. Most common usage: var globalThis = require('globalthis')(); // returns native globalThis if compliant /* or */ var globalThis = require('globalthis/polyfill')(); // returns native globalThis if compliant Example var assert = require('assert'); // the below function is not CSP-compliant, but reliably gets the // global object in sloppy mode in every engine. var getGlobal = Function('return this'); assert.equal(globalThis, getGlobal()); /* when `globalThis` is not present */ var shimmedGlobal = require('globalthis').shim(); /* or */ var shimmedGlobal = require('globalthis/shim')(); assert.equal(shimmedGlobal, globalThis); assert.equal(shimmedGlobal, getGlobal()); /* when `globalThis` is present */ var shimmedGlobal = require('globalthis').shim(); assert.equal(shimmedGlobal, globalThis); assert.equal(shimmedGlobal, getGlobal()); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/globby/readme.html": {
    "href": "node_modules/globby/readme.html",
    "title": "globby | accouter",
    "keywords": "globby User-friendly glob matching Based on fast-glob but adds a bunch of useful features. Features Promise API Multiple patterns Negated patterns: ['foo*', '!foobar'] Expands directories: foo → foo/**/* Supports .gitignore and similar ignore config files Supports URL as cwd Install $ npm install globby Usage ├── unicorn ├── cake └── rainbow import {globby} from 'globby'; const paths = await globby(['*', '!cake']); console.log(paths); //=> ['unicorn', 'rainbow'] API Note that glob patterns can only contain forward-slashes, not backward-slashes, so if you want to construct a glob pattern from path components, you need to use path.posix.join() instead of path.join(). globby(patterns, options?) Returns a Promise<string[]> of matching paths. patterns Type: string | string[] See supported minimatch patterns. options Type: object See the fast-glob options in addition to the ones below. expandDirectories Type: boolean | string[] | object Default: true If set to true, globby will automatically glob directories for you. If you define an Array it will only glob files that matches the patterns inside the Array. You can also define an object with files and extensions like below: import {globby} from 'globby'; (async () => { const paths = await globby('images', { expandDirectories: { files: ['cat', 'unicorn', '*.jpg'], extensions: ['png'] } }); console.log(paths); //=> ['cat.png', 'unicorn.png', 'cow.jpg', 'rainbow.jpg'] })(); Note that if you set this option to false, you won't get back matched directories unless you set onlyFiles: false. gitignore Type: boolean Default: false Respect ignore patterns in .gitignore files that apply to the globbed files. ignoreFiles Type: string | string[] Default: undefined Glob patterns to look for ignore files, which are then used to ignore globbed files. This is a more generic form of the gitignore option, allowing you to find ignore files with a compatible syntax. For instance, this works with Babel's .babelignore, Prettier's .prettierignore, or ESLint's .eslintignore files. globbySync(patterns, options?) Returns string[] of matching paths. globbyStream(patterns, options?) Returns a stream.Readable of matching paths. Since Node.js 10, readable streams are iterable, so you can loop over glob matches in a for await...of loop like this: import {globbyStream} from 'globby'; (async () => { for await (const path of globbyStream('*.tmp')) { console.log(path); } })(); generateGlobTasks(patterns, options?) Returns an Promise<object[]> in the format {patterns: string[], options: Object}, which can be passed as arguments to fast-glob. This is useful for other globbing-related packages. Note that you should avoid running the same tasks multiple times as they contain a file system cache. Instead, run this method each time to ensure file system changes are taken into consideration. generateGlobTasksSync(patterns, options?) Returns an object[] in the format {patterns: string[], options: Object}, which can be passed as arguments to fast-glob. This is useful for other globbing-related packages. Takes the same arguments as generateGlobTasks. isDynamicPattern(patterns, options?) Returns a boolean of whether there are any special glob characters in the patterns. Note that the options affect the results. This function is backed by fast-glob. isGitIgnored(options?) Returns a Promise<(path: URL | string) => boolean> indicating whether a given path is ignored via a .gitignore file. Takes cwd?: URL | string as options. import {isGitIgnored} from 'globby'; const isIgnored = await isGitIgnored(); console.log(isIgnored('some/file')); isGitIgnoredSync(options?) Returns a (path: URL | string) => boolean indicating whether a given path is ignored via a .gitignore file. Takes cwd?: URL | string as options. Globbing patterns Just a quick overview. * matches any number of characters, but not / ? matches a single character, but not / ** matches any number of characters, including /, as long as it's the only thing in a path part {} allows for a comma-separated list of \"or\" expressions ! at the beginning of a pattern will negate the match Various patterns and expected matches. globby for enterprise Available as part of the Tidelift Subscription. The maintainers of globby and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more. Related multimatch - Match against a list instead of the filesystem matcher - Simple wildcard matching del - Delete files and directories make-dir - Make a directory and its parents if needed"
  },
  "node_modules/gopd/CHANGELOG.html": {
    "href": "node_modules/gopd/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.1 - 2022-11-01 Commits [Fix] actually export gOPD instead of dP 4b624bf v1.0.0 - 2022-11-01 Commits Initial implementation, tests, readme 0911e01 Initial commit b84e33f [actions] add reusable workflows 12ae28a npm init 280118b [meta] add auto-changelog bb78de5 [meta] create FUNDING.yml; add funding in package.json 11c22e6 [meta] use npmignore to autogenerate an npmignore file 4f4537a Only apps should have lockfiles c567022"
  },
  "node_modules/gopd/README.html": {
    "href": "node_modules/gopd/README.html",
    "title": "gopd | accouter",
    "keywords": "gopd Object.getOwnPropertyDescriptor, but accounts for IE's broken implementation. Usage var gOPD = require('gopd'); var assert = require('assert'); if (gOPD) { assert.equal(typeof gOPD, 'function', 'descriptors supported'); // use gOPD like Object.getOwnPropertyDescriptor here } else { assert.ok(!gOPD, 'descriptors not supported'); }"
  },
  "node_modules/graceful-fs/README.html": {
    "href": "node_modules/graceful-fs/README.html",
    "title": "graceful-fs | accouter",
    "keywords": "graceful-fs graceful-fs functions as a drop-in replacement for the fs module, making various improvements. The improvements are meant to normalize behavior across different platforms and environments, and to make filesystem access more resilient to errors. Improvements over fs module Queues up open and readdir calls, and retries them once something closes if there is an EMFILE error from too many file descriptors. fixes lchmod for Node versions prior to 0.6.2. implements fs.lutimes if possible. Otherwise it becomes a noop. ignores EINVAL and EPERM errors in chown, fchown or lchown if the user isn't root. makes lchmod and lchown become noops, if not available. retries reading a file if read results in EAGAIN error. On Windows, it retries renaming a file for up to one second if EACCESS or EPERM error occurs, likely because antivirus software has locked the directory. USAGE // use just like fs var fs = require('graceful-fs') // now go and do stuff with it... fs.readFile('some-file-or-whatever', (err, data) => { // Do stuff here. }) Sync methods This module cannot intercept or handle EMFILE or ENFILE errors from sync methods. If you use sync methods which open file descriptors then you are responsible for dealing with any errors. This is a known limitation, not a bug. Global Patching If you want to patch the global fs module (or any other fs-like module) you can do this: // Make sure to read the caveat below. var realFs = require('fs') var gracefulFs = require('graceful-fs') gracefulFs.gracefulify(realFs) This should only ever be done at the top-level application layer, in order to delay on EMFILE errors from any fs-using dependencies. You should not do this in a library, because it can cause unexpected delays in other parts of the program. Changes This module is fairly stable at this point, and used by a lot of things. That being said, because it implements a subtle behavior change in a core part of the node API, even modest changes can be extremely breaking, and the versioning is thus biased towards bumping the major when in doubt. The main change between major versions has been switching between providing a fully-patched fs module vs monkey-patching the node core builtin, and the approach by which a non-monkey-patched fs was created. The goal is to trade EMFILE errors for slower fs operations. So, if you try to open a zillion files, rather than crashing, open operations will be queued up and wait for something else to close. There are advantages to each approach. Monkey-patching the fs means that no EMFILE errors can possibly occur anywhere in your application, because everything is using the same core fs module, which is patched. However, it can also obviously cause undesirable side-effects, especially if the module is loaded multiple times. Implementing a separate-but-identical patched fs module is more surgical (and doesn't run the risk of patching multiple times), but also imposes the challenge of keeping in sync with the core module. The current approach loads the fs module, and then creates a lookalike object that has all the same methods, except a few that are patched. It is safe to use in all versions of Node from 0.8 through 7.0. v4 Do not monkey-patch the fs module. This module may now be used as a drop-in dep, and users can opt into monkey-patching the fs builtin if their app requires it. v3 Monkey-patch fs, because the eval approach no longer works on recent node. fixed possible type-error throw if rename fails on windows verify that we never get EMFILE errors Ignore ENOSYS from chmod/chown clarify that graceful-fs must be used as a drop-in v2.1.0 Use eval rather than monkey-patching fs. readdir: Always sort the results win32: requeue a file if error has an OK status v2.0 A return to monkey patching wrap process.cwd v1.1 wrap readFile Wrap fs.writeFile. readdir protection Don't clobber the fs builtin Handle fs.read EAGAIN errors by trying again Expose the curOpen counter No-op lchown/lchmod if not implemented fs.rename patch only for win32 Patch fs.rename to handle AV software on Windows Close #4 Chown should not fail on einval or eperm if non-root Fix isaacs/fstream#1 Only wrap fs one time Fix #3 Start at 1024 max files, then back off on EMFILE lutimes that doens't blow up on Linux A full on-rewrite using a queue instead of just swallowing the EMFILE error Wrap Read/Write streams as well 1.0 Update engines for node 0.6 Be lstat-graceful on Windows first"
  },
  "node_modules/has-bigints/CHANGELOG.html": {
    "href": "node_modules/has-bigints/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.2 - 2022-04-19 Commits [actions] reuse common workflows a655b7f [actions] use node/install instead of node/run; use codecov action 730a2e5 [readme] add github actions/codecov badges; update URLs 9a83788 [Dev Deps] update eslint, @ljharb/eslint-config, safe-publish-latest, tape b1edc52 [actions] update codecov uploader cbb1bd0 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape 8717e6d [Dev Deps] update eslint, @ljharb/eslint-config, auto-changelog, safe-publish-latest, tape 5f70eab [Dev Deps] update eslint, @ljharb/eslint-config, aud, tape a1446bc [meta] use prepublishOnly script for npm 7+ f2dd197 [actions] use checkout v3 1ba72f1 [Refactor] use a global variable to get the original BigInt instead of a global property a7ccfac [actions] skip npm ls on older nodes 62d31e7 v1.0.1 - 2020-12-13 Commits [Tests] use shared travis-ci configs 46a0d6b [Tests] migrate tests to Github Actions 91a38fa [meta] do not publish github action workflow files 69aacba [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape 64e2c08 [Tests] run nyc on all tests; use tape runner 8009375 [actions] add automatic rebasing / merge commit blocking e599917 [actions] add \"Allow Edits\" workflow bd0126e [readme] remove travis badge 8e02a73 [Dev Deps] update eslint, @ljharb/eslint-config, auto-changelog, safe-publish-latest 95859f2 [Dev Deps] update auto-changelog, in-publish, tape 0588f41 [Dev Deps] update eslint, @ljharb/eslint-config, tape 5b024a6 [meta] add version scripts 4788d61 [actions] switch Automatic Rebase workflow to pull_request_target event be0e0de [Dev Deps] update auto-changelog; add aud 13a8d1b [actions] fix action name f873d9a [meta] add funding field 1b51f49 [Dev Deps] update auto-changelog 2322461 [Tests] only audit prod deps aabdade v1.0.0 - 2019-08-10 Commits [Tests] add .travis.yml 9730412 Initial commit 65f7c38 [Tests] add tests e374a78 readme 5d39092 npm init 1be2e3d implementation b7bc812 [Tests] add linting 04533be [meta] create FUNDING.yml cf824a7 Only apps should have lockfiles 64e8242"
  },
  "node_modules/has-bigints/README.html": {
    "href": "node_modules/has-bigints/README.html",
    "title": "has-bigints | accouter",
    "keywords": "has-bigints Determine if the JS environment has BigInt support. Example var hasBigInts = require('has-bigints'); hasBigInts() === true; // if the environment has native BigInt support. Not polyfillable, not forgeable. Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/has-flag/readme.html": {
    "href": "node_modules/has-flag/readme.html",
    "title": "has-flag | accouter",
    "keywords": "has-flag Check if argv has a specific flag Correctly stops looking after an -- argument terminator. Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies. Install $ npm install has-flag Usage // foo.js const hasFlag = require('has-flag'); hasFlag('unicorn'); //=> true hasFlag('--unicorn'); //=> true hasFlag('f'); //=> true hasFlag('-f'); //=> true hasFlag('foo=bar'); //=> true hasFlag('foo'); //=> false hasFlag('rainbow'); //=> false $ node foo.js -f --unicorn --foo=bar -- --rainbow API hasFlag(flag, [argv]) Returns a boolean for whether the flag exists. flag Type: string CLI flag to look for. The -- prefix is optional. argv Type: string[] Default: process.argv CLI arguments. Security To report a security vulnerability, please use the Tidelift security contact. Tidelift will coordinate the fix and disclosure. License MIT © Sindre Sorhus"
  },
  "node_modules/has-property-descriptors/CHANGELOG.html": {
    "href": "node_modules/has-property-descriptors/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.2 - 2024-02-12 Commits [Refactor] use es-define-property f93a8c8 [Dev Deps] update aud, npmignore, tape 42b0c9d [Deps] update get-intrinsic 35e9b46 v1.0.1 - 2023-10-20 Commits [meta] use npmignore to autogenerate an npmignore file 5bbf4da [actions] update rebase action to use reusable workflow 3a5585b [Dev Deps] update @ljharb/eslint-config, aud, tape e5c1212 [Dev Deps] update aud, tape e942917 [Deps] update get-intrinsic f4a44ec [Deps] update get-intrinsic eeb275b v1.0.0 - 2022-04-14 Commits Initial implementation, tests 303559f Initial commit 3a7ca2d read me dd73dce npm init c1e6557 Only apps should have lockfiles e72f7c6"
  },
  "node_modules/has-property-descriptors/README.html": {
    "href": "node_modules/has-property-descriptors/README.html",
    "title": "has-property-descriptors | accouter",
    "keywords": "has-property-descriptors Does the environment have full property descriptor support? Handles IE 8's broken defineProperty/gOPD. Example var hasPropertyDescriptors = require('has-property-descriptors'); var assert = require('assert'); assert.equal(hasPropertyDescriptors(), true); // will be `false` in IE 6-8, and ES5 engines // Arrays can not have their length `[[Defined]]` in some engines assert.equal(hasPropertyDescriptors.hasArrayLengthDefineBug(), false); // will be `true` in Firefox 4-22, and node v0.6 Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/has-proto/CHANGELOG.html": {
    "href": "node_modules/has-proto/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.3 - 2024-02-19 Commits [types] add missing declaration file 26ecade v1.0.2 - 2024-02-19 Commits add types 6435262 [Dev Deps] update @ljharb/eslint-config, aud, npmignore, tape f16a5e4 [Refactor] tiny cleanup d1f1a4b [meta] add sideEffects flag e7ab1a6 v1.0.1 - 2022-12-21 Commits [meta] correct URLs and description ef34483 [patch] add an additional criteria e81959e [Dev Deps] update aud 2bec2c4 v1.0.0 - 2022-12-12 Commits Initial implementation, tests, readme 6886fea Initial commit 99129c8 npm init 2844ad8 Only apps should have lockfiles c65bc5e"
  },
  "node_modules/has-proto/README.html": {
    "href": "node_modules/has-proto/README.html",
    "title": "has-proto | accouter",
    "keywords": "has-proto Does this environment have the ability to set the [[Prototype]] of an object on creation with __proto__? Example var hasProto = require('has-proto'); var assert = require('assert'); assert.equal(typeof hasProto(), 'boolean'); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/has-symbols/CHANGELOG.html": {
    "href": "node_modules/has-symbols/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.3 - 2022-03-01 Commits [actions] use node/install instead of node/run; use codecov action 518b28f [meta] add bugs and homepage fields; reorder package.json c480b13 [actions] reuse common workflows 01d0ee0 [actions] update codecov uploader 6424ebe [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape dfa7e7f [Dev Deps] update eslint, @ljharb/eslint-config, safe-publish-latest, tape 0c8d436 [Dev Deps] update eslint, @ljharb/eslint-config, aud, tape 9026554 [readme] add actions and codecov badges eaa9682 [Dev Deps] update eslint, tape bc7a3ba [Dev Deps] update eslint, auto-changelog 0ace00a [meta] use prepublishOnly script for npm 7+ 093f72b [Tests] test on all 16 minors 9b80d3d v1.0.2 - 2021-02-27 Fixed [Fix] use a universal way to get the original Symbol #11 Commits [Tests] migrate tests to Github Actions 90ae798 [meta] do not publish github action workflow files 29e60a1 [Tests] run nyc on all tests 8476b91 [readme] fix repo URLs, remove defunct badges 126288e [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, core-js, get-own-property-symbols d84bdfa [Tests] fix linting errors 0df3070 [actions] add \"Allow Edits\" workflow 1e6bc29 [Dev Deps] update eslint, @ljharb/eslint-config, tape 36cea2a [Dev Deps] update eslint, @ljharb/eslint-config, aud, tape 1278338 [Dev Deps] update eslint, @ljharb/eslint-config, aud, tape 1493254 [Dev Deps] update eslint, @ljharb/eslint-config, core-js b090bf2 [actions] switch Automatic Rebase workflow to pull_request_target event 4addb7a [Dev Deps] update auto-changelog, tape 81d0baf [Dev Deps] update auto-changelog; add aud 1a4e561 [readme] remove unused testling URLs 3000941 [Tests] only audit prod deps 692e974 [Dev Deps] update @ljharb/eslint-config 51c946c v1.0.1 - 2019-11-16 Commits [Tests] use shared travis-ci configs ce396c9 [Tests] up to node v12.4, v11.15, v10.15, v9.11, v8.15, v7.10, v6.17, v4.9; use nvm install-latest-npm 0690732 [meta] add auto-changelog 2163d0b [Dev Deps] update eslint, @ljharb/eslint-config, core-js, safe-publish-latest, tape 8e0951f [actions] add automatic rebasing / merge commit blocking b09cdb7 [Dev Deps] update eslint, @ljharb/eslint-config, safe-publish-latest, core-js, get-own-property-symbols, tape 1dd42cd [meta] create FUNDING.yml aa57a17 Only apps should have lockfiles a2d8bea [Tests] use npx aud instead of nsp or npm audit with hoops 9e96cb7 [meta] add funding field a0b32cf [Dev Deps] update safe-publish-latest cb9f0a5 v1.0.0 - 2016-09-19 Commits Tests. ecb6eb9 package.json 88a337c Initial commit 42e1e55 Initial implementation. 33f5cc6 read me 01f1170"
  },
  "node_modules/has-symbols/README.html": {
    "href": "node_modules/has-symbols/README.html",
    "title": "has-symbols | accouter",
    "keywords": "has-symbols Determine if the JS environment has Symbol support. Supports spec, or shams. Example var hasSymbols = require('has-symbols'); hasSymbols() === true; // if the environment has native Symbol support. Not polyfillable, not forgeable. var hasSymbolsKinda = require('has-symbols/shams'); hasSymbolsKinda() === true; // if the environment has a Symbol sham that mostly follows the spec. Supported Symbol shams get-own-property-symbols npm | github core-js npm | github Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/has-tostringtag/CHANGELOG.html": {
    "href": "node_modules/has-tostringtag/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.2 - 2024-02-01 Fixed [Fix] move has-symbols back to prod deps #3 v1.0.1 - 2024-02-01 Commits [patch] add types 9276414 [meta] use npmignore to autogenerate an npmignore file 5c0dcd1 [actions] reuse common workflows dee9509 [actions] update codecov uploader b8cb3a0 [Tests] generate coverage be5b288 [Dev Deps] update eslint, @ljharb/eslint-config, safe-publish-latest, tape 69a0827 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape 4c9e210 [actions] update rebase action to use reusable workflow ca8dcd3 [Dev Deps] update @ljharb/eslint-config, aud, npmignore, tape 07f3eaf [Deps] update has-symbols 999e009 [Tests] remove staging tests since they fail on modern node 9d9526b v1.0.0 - 2021-08-05 Commits Tests 6b6f573 Initial commit 2f8190e [meta] do not publish github action workflow files 6e08cc4 readme 94bed6c npm init be67840 Implementation c4914ec [meta] use auto-changelog 4aaf768 Only apps should have lockfiles bc4d99e [meta] add safe-publish-latest 6523c05"
  },
  "node_modules/has-tostringtag/README.html": {
    "href": "node_modules/has-tostringtag/README.html",
    "title": "has-tostringtag | accouter",
    "keywords": "has-tostringtag Determine if the JS environment has Symbol.toStringTag support. Supports spec, or shams. Example var hasSymbolToStringTag = require('has-tostringtag'); hasSymbolToStringTag() === true; // if the environment has native Symbol.toStringTag support. Not polyfillable, not forgeable. var hasSymbolToStringTagKinda = require('has-tostringtag/shams'); hasSymbolToStringTagKinda() === true; // if the environment has a Symbol.toStringTag sham that mostly follows the spec. Supported Symbol shams get-own-property-symbols npm | github core-js npm | github Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/hasown/CHANGELOG.html": {
    "href": "node_modules/hasown/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v2.0.2 - 2024-03-10 Commits [types] use shared config 68e9d4d [actions] remove redundant finisher; use reusable workflow 241a68e [Tests] increase coverage 4125c0d [Tests] skip npm ls in old node due to TS 01b9282 [types] improve predicate type d340f85 [Dev Deps] update tape 70089fc [Tests] use @arethetypeswrong/cli 50b272c v2.0.1 - 2024-02-10 Commits [types] use a handwritten d.ts file; fix exported type 012b989 [Dev Deps] update @types/function-bind, @types/mock-property, @types/tape, aud, mock-property, npmignore, tape, typescript 977a56f [meta] add sideEffects flag 3a60b7b v2.0.0 - 2023-10-19 Commits revamped implementation, tests, readme 72bf8b3 [meta] revamp package.json 079775f Only apps should have lockfiles 6640e23 v1.0.1 - 2023-10-10 Commits Initial commit 8dbfde6"
  },
  "node_modules/hasown/README.html": {
    "href": "node_modules/hasown/README.html",
    "title": "hasown | accouter",
    "keywords": "hasown A robust, ES3 compatible, \"has own property\" predicate. Example const assert = require('assert'); const hasOwn = require('hasown'); assert.equal(hasOwn({}, 'toString'), false); assert.equal(hasOwn([], 'length'), true); assert.equal(hasOwn({ a: 42 }, 'a'), true); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/he/README.html": {
    "href": "node_modules/he/README.html",
    "title": "he | accouter",
    "keywords": "he he (for “HTML entities”) is a robust HTML entity encoder/decoder written in JavaScript. It supports all standardized named character references as per HTML, handles ambiguous ampersands and other edge cases just like a browser would, has an extensive test suite, and — contrary to many other JavaScript solutions — he handles astral Unicode symbols just fine. An online demo is available. Installation Via npm: npm install he Via Bower: bower install he Via Component: component install mathiasbynens/he In a browser: <script src=\"he.js\"></script> In Node.js, io.js, Narwhal, and RingoJS: var he = require('he'); In Rhino: load('he.js'); Using an AMD loader like RequireJS: require( { 'paths': { 'he': 'path/to/he' } }, ['he'], function(he) { console.log(he); } ); API he.version A string representing the semantic version number. he.encode(text, options) This function takes a string of text and encodes (by default) any symbols that aren’t printable ASCII symbols and &, <, >, \", ', and `, replacing them with character references. he.encode('foo © bar ≠ baz 𝌆 qux'); // → 'foo &#xA9; bar &#x2260; baz &#x1D306; qux' As long as the input string contains allowed code points only, the return value of this function is always valid HTML. Any (invalid) code points that cannot be represented using a character reference in the input are not encoded: he.encode('foo \\0 bar'); // → 'foo \\0 bar' However, enabling the strict option causes invalid code points to throw an exception. With strict enabled, he.encode either throws (if the input contains invalid code points) or returns a string of valid HTML. The options object is optional. It recognizes the following properties: useNamedReferences The default value for the useNamedReferences option is false. This means that encode() will not use any named character references (e.g. &copy;) in the output — hexadecimal escapes (e.g. &#xA9;) will be used instead. Set it to true to enable the use of named references. Note that if compatibility with older browsers is a concern, this option should remain disabled. // Using the global default setting (defaults to `false`): he.encode('foo © bar ≠ baz 𝌆 qux'); // → 'foo &#xA9; bar &#x2260; baz &#x1D306; qux' // Passing an `options` object to `encode`, to explicitly disallow named references: he.encode('foo © bar ≠ baz 𝌆 qux', { 'useNamedReferences': false }); // → 'foo &#xA9; bar &#x2260; baz &#x1D306; qux' // Passing an `options` object to `encode`, to explicitly allow named references: he.encode('foo © bar ≠ baz 𝌆 qux', { 'useNamedReferences': true }); // → 'foo &copy; bar &ne; baz &#x1D306; qux' decimal The default value for the decimal option is false. If the option is enabled, encode will generally use decimal escapes (e.g. &#169;) rather than hexadecimal escapes (e.g. &#xA9;). Beside of this replacement, the basic behavior remains the same when combined with other options. For example: if both options useNamedReferences and decimal are enabled, named references (e.g. &copy;) are used over decimal escapes. HTML entities without a named reference are encoded using decimal escapes. // Using the global default setting (defaults to `false`): he.encode('foo © bar ≠ baz 𝌆 qux'); // → 'foo &#xA9; bar &#x2260; baz &#x1D306; qux' // Passing an `options` object to `encode`, to explicitly disable decimal escapes: he.encode('foo © bar ≠ baz 𝌆 qux', { 'decimal': false }); // → 'foo &#xA9; bar &#x2260; baz &#x1D306; qux' // Passing an `options` object to `encode`, to explicitly enable decimal escapes: he.encode('foo © bar ≠ baz 𝌆 qux', { 'decimal': true }); // → 'foo &#169; bar &#8800; baz &#119558; qux' // Passing an `options` object to `encode`, to explicitly allow named references and decimal escapes: he.encode('foo © bar ≠ baz 𝌆 qux', { 'useNamedReferences': true, 'decimal': true }); // → 'foo &copy; bar &ne; baz &#119558; qux' encodeEverything The default value for the encodeEverything option is false. This means that encode() will not use any character references for printable ASCII symbols that don’t need escaping. Set it to true to encode every symbol in the input string. When set to true, this option takes precedence over allowUnsafeSymbols (i.e. setting the latter to true in such a case has no effect). // Using the global default setting (defaults to `false`): he.encode('foo © bar ≠ baz 𝌆 qux'); // → 'foo &#xA9; bar &#x2260; baz &#x1D306; qux' // Passing an `options` object to `encode`, to explicitly encode all symbols: he.encode('foo © bar ≠ baz 𝌆 qux', { 'encodeEverything': true }); // → '&#x66;&#x6F;&#x6F;&#x20;&#xA9;&#x20;&#x62;&#x61;&#x72;&#x20;&#x2260;&#x20;&#x62;&#x61;&#x7A;&#x20;&#x1D306;&#x20;&#x71;&#x75;&#x78;' // This setting can be combined with the `useNamedReferences` option: he.encode('foo © bar ≠ baz 𝌆 qux', { 'encodeEverything': true, 'useNamedReferences': true }); // → '&#x66;&#x6F;&#x6F;&#x20;&copy;&#x20;&#x62;&#x61;&#x72;&#x20;&ne;&#x20;&#x62;&#x61;&#x7A;&#x20;&#x1D306;&#x20;&#x71;&#x75;&#x78;' strict The default value for the strict option is false. This means that encode() will encode any HTML text content you feed it, even if it contains any symbols that cause parse errors. To throw an error when such invalid HTML is encountered, set the strict option to true. This option makes it possible to use he as part of HTML parsers and HTML validators. // Using the global default setting (defaults to `false`, i.e. error-tolerant mode): he.encode('\\x01'); // → '&#x1;' // Passing an `options` object to `encode`, to explicitly enable error-tolerant mode: he.encode('\\x01', { 'strict': false }); // → '&#x1;' // Passing an `options` object to `encode`, to explicitly enable strict mode: he.encode('\\x01', { 'strict': true }); // → Parse error allowUnsafeSymbols The default value for the allowUnsafeSymbols option is false. This means that characters that are unsafe for use in HTML content (&, <, >, \", ', and `) will be encoded. When set to true, only non-ASCII characters will be encoded. If the encodeEverything option is set to true, this option will be ignored. he.encode('foo © and & ampersand', { 'allowUnsafeSymbols': true }); // → 'foo &#xA9; and & ampersand' Overriding default encode options globally The global default setting can be overridden by modifying the he.encode.options object. This saves you from passing in an options object for every call to encode if you want to use the non-default setting. // Read the global default setting: he.encode.options.useNamedReferences; // → `false` by default // Override the global default setting: he.encode.options.useNamedReferences = true; // Using the global default setting, which is now `true`: he.encode('foo © bar ≠ baz 𝌆 qux'); // → 'foo &copy; bar &ne; baz &#x1D306; qux' he.decode(html, options) This function takes a string of HTML and decodes any named and numerical character references in it using the algorithm described in section 12.2.4.69 of the HTML spec. he.decode('foo &copy; bar &ne; baz &#x1D306; qux'); // → 'foo © bar ≠ baz 𝌆 qux' The options object is optional. It recognizes the following properties: isAttributeValue The default value for the isAttributeValue option is false. This means that decode() will decode the string as if it were used in a text context in an HTML document. HTML has different rules for parsing character references in attribute values — set this option to true to treat the input string as if it were used as an attribute value. // Using the global default setting (defaults to `false`, i.e. HTML text context): he.decode('foo&ampbar'); // → 'foo&bar' // Passing an `options` object to `decode`, to explicitly assume an HTML text context: he.decode('foo&ampbar', { 'isAttributeValue': false }); // → 'foo&bar' // Passing an `options` object to `decode`, to explicitly assume an HTML attribute value context: he.decode('foo&ampbar', { 'isAttributeValue': true }); // → 'foo&ampbar' strict The default value for the strict option is false. This means that decode() will decode any HTML text content you feed it, even if it contains any entities that cause parse errors. To throw an error when such invalid HTML is encountered, set the strict option to true. This option makes it possible to use he as part of HTML parsers and HTML validators. // Using the global default setting (defaults to `false`, i.e. error-tolerant mode): he.decode('foo&ampbar'); // → 'foo&bar' // Passing an `options` object to `decode`, to explicitly enable error-tolerant mode: he.decode('foo&ampbar', { 'strict': false }); // → 'foo&bar' // Passing an `options` object to `decode`, to explicitly enable strict mode: he.decode('foo&ampbar', { 'strict': true }); // → Parse error Overriding default decode options globally The global default settings for the decode function can be overridden by modifying the he.decode.options object. This saves you from passing in an options object for every call to decode if you want to use a non-default setting. // Read the global default setting: he.decode.options.isAttributeValue; // → `false` by default // Override the global default setting: he.decode.options.isAttributeValue = true; // Using the global default setting, which is now `true`: he.decode('foo&ampbar'); // → 'foo&ampbar' he.escape(text) This function takes a string of text and escapes it for use in text contexts in XML or HTML documents. Only the following characters are escaped: &, <, >, \", ', and `. he.escape('<img src=\\'x\\' onerror=\"prompt(1)\">'); // → '&lt;img src=&#x27;x&#x27; onerror=&quot;prompt(1)&quot;&gt;' he.unescape(html, options) he.unescape is an alias for he.decode. It takes a string of HTML and decodes any named and numerical character references in it. Using the he binary To use the he binary in your shell, simply install he globally using npm: npm install -g he After that you will be able to encode/decode HTML entities from the command line: $ he --encode 'föo ♥ bår 𝌆 baz' f&#xF6;o &#x2665; b&#xE5;r &#x1D306; baz $ he --encode --use-named-refs 'föo ♥ bår 𝌆 baz' f&ouml;o &hearts; b&aring;r &#x1D306; baz $ he --decode 'f&ouml;o &hearts; b&aring;r &#x1D306; baz' föo ♥ bår 𝌆 baz Read a local text file, encode it for use in an HTML text context, and save the result to a new file: $ he --encode < foo.txt > foo-escaped.html Or do the same with an online text file: $ curl -sL \"http://git.io/HnfEaw\" | he --encode > escaped.html Or, the opposite — read a local file containing a snippet of HTML in a text context, decode it back to plain text, and save the result to a new file: $ he --decode < foo-escaped.html > foo.txt Or do the same with an online HTML snippet: $ curl -sL \"http://git.io/HnfEaw\" | he --decode > decoded.txt See he --help for the full list of options. Support he has been tested in at least: Chrome 27-50 Firefox 3-45 Safari 4-9 Opera 10-12, 15–37 IE 6–11 Edge Narwhal 0.3.2 Node.js v0.10, v0.12, v4, v5 PhantomJS 1.9.0 Rhino 1.7RC4 RingoJS 0.8-0.11 Unit tests & code coverage After cloning this repository, run npm install to install the dependencies needed for he development and testing. You may want to install Istanbul globally using npm install istanbul -g. Once that’s done, you can run the unit tests in Node using npm test or node tests/tests.js. To run the tests in Rhino, Ringo, Narwhal, and web browsers as well, use grunt test. To generate the code coverage report, use grunt cover. Acknowledgements Thanks to Simon Pieters (@zcorpan) for the many suggestions. Author Mathias Bynens License he is available under the MIT license."
  },
  "node_modules/hosted-git-info/CHANGELOG.html": {
    "href": "node_modules/hosted-git-info/CHANGELOG.html",
    "title": "Change Log | accouter",
    "keywords": "Change Log All notable changes to this project will be documented in this file. See standard-version for commit guidelines. 2.8.9 (2021-04-07) Bug Fixes backport regex fix from #76 (29adfe5), closes #84 2.8.8 (2020-02-29) Bug Fixes #61 & #65 addressing issues w/ url.URL implmentation which regressed node 6 support (5038b18), closes #66 2.8.7 (2020-02-26) Bug Fixes Do not attempt to use url.URL when unavailable (2d0bb66), closes #61 #62 Do not pass scp-style URLs to the WhatWG url.URL (f2cdfcf), closes #60 2.8.6 (2020-02-25) 2.8.5 (2019-10-07) Bug Fixes updated pathmatch for gitlab (e8325b5), closes #51 updated pathmatch for gitlab (ffe056f) 2.8.4 (2019-08-12) 2.8.3 (2019-08-12) 2.8.2 (2019-08-05) Bug Fixes http protocol use sshurl by default (3b1d629), closes #48 2.8.1 (2019-08-05) Bug Fixes ignore noCommittish on tarball url generation (5d4a8d7) use gist tarball url that works for anonymous gists (1692435) 2.8.0 (2019-08-05) Bug Fixes Allow slashes in gitlab project section (bbcf7b2), closes #46 #43 git-host: disallow URI-encoded slash (%2F) in path (3776fa5), closes #44 gitlab: Do not URL encode slashes in project name for GitLab https URL (cbf04f9), closes #47 do not allow invalid gist urls (d5cf830) cache: Switch to lru-cache to save ourselves from unlimited memory consumption (e518222), closes #38 Features give these objects a name (60abaea) 2.7.1 (2018-07-07) Bug Fixes index: Guard against non-string types (5bc580d) parse: Crash on strings that parse to having no host (c931482), closes #35 2.7.0 (2018-07-06) Bug Fixes github tarball: update github tarballtemplate (6efd582), closes #34 gitlab docs: switched to lowercase anchors for readmes (701bcd1) Features all: Support www. prefixes on hostnames (3349575), closes #32 2.6.1 (2018-06-25) Bug Fixes Revert: \"compat: remove Object.assign fallback (#25)\" (cce5a62) Revert: \"git-host: fix forgotten extend()\" (a815ec9) 2.6.0 (2018-03-07) Bug Fixes compat: remove Object.assign fallback (#25) (627ab55) git-host: fix forgotten extend() (eba1f7b) Features browse: fragment support for browse() (#28) (cd5e5bb)"
  },
  "node_modules/hosted-git-info/README.html": {
    "href": "node_modules/hosted-git-info/README.html",
    "title": "hosted-git-info | accouter",
    "keywords": "hosted-git-info This will let you identify and transform various git hosts URLs between protocols. It also can tell you what the URL is for the raw path for particular file for direct access without git. Example var hostedGitInfo = require(\"hosted-git-info\") var info = hostedGitInfo.fromUrl(\"git@github.com:npm/hosted-git-info.git\", opts) /* info looks like: { type: \"github\", domain: \"github.com\", user: \"npm\", project: \"hosted-git-info\" } */ If the URL can't be matched with a git host, null will be returned. We can match git, ssh and https urls. Additionally, we can match ssh connect strings (git@github.com:npm/hosted-git-info) and shortcuts (eg, github:npm/hosted-git-info). Github specifically, is detected in the case of a third, unprefixed, form: npm/hosted-git-info. If it does match, the returned object has properties of: info.type -- The short name of the service info.domain -- The domain for git protocol use info.user -- The name of the user/org on the git host info.project -- The name of the project on the git host Version Contract The major version will be bumped any time… The constructor stops accepting URLs that it previously accepted. A method is removed. A method can no longer accept the number and type of arguments it previously accepted. A method can return a different type than it currently returns. Implications: I do not consider the specific format of the urls returned from, say .https() to be a part of the contract. The contract is that it will return a string that can be used to fetch the repo via HTTPS. But what that string looks like, specifically, can change. Dropping support for a hosted git provider would constitute a breaking change. Usage var info = hostedGitInfo.fromUrl(gitSpecifier[, options]) gitSpecifer is a URL of a git repository or a SCP-style specifier of one. options is an optional object. It can have the following properties: noCommittish — If true then committishes won't be included in generated URLs. noGitPlus — If true then git+ won't be prefixed on URLs. Methods All of the methods take the same options as the fromUrl factory. Options provided to a method override those provided to the constructor. info.file(path, opts) Given the path of a file relative to the repository, returns a URL for directly fetching it from the githost. If no committish was set then master will be used as the default. For example hostedGitInfo.fromUrl(\"git@github.com:npm/hosted-git-info.git#v1.0.0\").file(\"package.json\") would return https://raw.githubusercontent.com/npm/hosted-git-info/v1.0.0/package.json info.shortcut(opts) eg, github:npm/hosted-git-info info.browse(path, fragment, opts) eg, https://github.com/npm/hosted-git-info/tree/v1.2.0, https://github.com/npm/hosted-git-info/tree/v1.2.0/package.json, https://github.com/npm/hosted-git-info/tree/v1.2.0/REAMDE.md#supported-hosts info.bugs(opts) eg, https://github.com/npm/hosted-git-info/issues info.docs(opts) eg, https://github.com/npm/hosted-git-info/tree/v1.2.0#readme info.https(opts) eg, git+https://github.com/npm/hosted-git-info.git info.sshurl(opts) eg, git+ssh://git@github.com/npm/hosted-git-info.git info.ssh(opts) eg, git@github.com:npm/hosted-git-info.git info.path(opts) eg, npm/hosted-git-info info.tarball(opts) eg, https://github.com/npm/hosted-git-info/archive/v1.2.0.tar.gz info.getDefaultRepresentation() Returns the default output type. The default output type is based on the string you passed in to be parsed info.toString(opts) Uses the getDefaultRepresentation to call one of the other methods to get a URL for this resource. As such hostedGitInfo.fromUrl(url).toString() will give you a normalized version of the URL that still uses the same protocol. Shortcuts will still be returned as shortcuts, but the special case github form of org/project will be normalized to github:org/project. SSH connect strings will be normalized into git+ssh URLs. Supported hosts Currently this supports Github, Bitbucket and Gitlab. Pull requests for additional hosts welcome."
  },
  "node_modules/http-errors/HISTORY.html": {
    "href": "node_modules/http-errors/HISTORY.html",
    "title": "2.0.0 / 2021-12-17 | accouter",
    "keywords": "2.0.0 / 2021-12-17 Drop support for Node.js 0.6 Remove I'mateapot export; use ImATeapot instead Remove support for status being non-first argument Rename UnorderedCollection constructor to TooEarly deps: depd@2.0.0 Replace internal eval usage with Function constructor Use instance methods on process to check for listeners deps: statuses@2.0.1 Fix messaging casing of 418 I'm a Teapot Remove code 306 Rename 425 Unordered Collection to standard 425 Too Early 2021-11-14 / 1.8.1 deps: toidentifier@1.0.1 2020-06-29 / 1.8.0 Add isHttpError export to determine if value is an HTTP error deps: setprototypeof@1.2.0 2019-06-24 / 1.7.3 deps: inherits@2.0.4 2019-02-18 / 1.7.2 deps: setprototypeof@1.1.1 2018-09-08 / 1.7.1 Fix error creating objects in some environments 2018-07-30 / 1.7.0 Set constructor name when possible Use toidentifier module to make class names deps: statuses@'>= 1.5.0 < 2' 2018-03-29 / 1.6.3 deps: depd@~1.1.2 perf: remove argument reassignment deps: setprototypeof@1.1.0 deps: statuses@'>= 1.4.0 < 2' 2017-08-04 / 1.6.2 deps: depd@1.1.1 Remove unnecessary Buffer loading 2017-02-20 / 1.6.1 deps: setprototypeof@1.0.3 Fix shim for old browsers 2017-02-14 / 1.6.0 Accept custom 4xx and 5xx status codes in factory Add deprecation message to \"I'mateapot\" export Deprecate passing status code as anything except first argument in factory Deprecate using non-error status codes Make message property enumerable for HttpErrors 2016-11-16 / 1.5.1 deps: inherits@2.0.3 Fix issue loading in browser deps: setprototypeof@1.0.2 deps: statuses@'>= 1.3.1 < 2' 2016-05-18 / 1.5.0 Support new code 421 Misdirected Request Use setprototypeof module to replace __proto__ setting deps: statuses@'>= 1.3.0 < 2' Add 421 Misdirected Request perf: enable strict mode perf: enable strict mode 2016-01-28 / 1.4.0 Add HttpError export, for err instanceof createError.HttpError deps: inherits@2.0.1 deps: statuses@'>= 1.2.1 < 2' Fix message for status 451 Remove incorrect nginx status code 2015-02-02 / 1.3.1 Fix regression where status can be overwritten in createError props 2015-02-01 / 1.3.0 Construct errors using defined constructors from createError Fix error names that are not identifiers createError[\"I'mateapot\"] is now createError.ImATeapot Set a meaningful name property on constructed errors 2014-12-09 / 1.2.8 Fix stack trace from exported function Remove arguments.callee usage 2014-10-14 / 1.2.7 Remove duplicate line 2014-10-02 / 1.2.6 Fix expose to be true for ClientError constructor 2014-09-28 / 1.2.5 deps: statuses@1 2014-09-21 / 1.2.4 Fix dependency version to work with old npms 2014-09-21 / 1.2.3 deps: statuses@~1.1.0 2014-09-21 / 1.2.2 Fix publish error 2014-09-21 / 1.2.1 Support Node.js 0.6 Use inherits instead of util 2014-09-09 / 1.2.0 Fix the way inheriting functions Support expose being provided in properties argument 2014-09-08 / 1.1.0 Default status to 500 Support provided error to extend 2014-09-08 / 1.0.1 Fix accepting string message 2014-09-08 / 1.0.0 Initial release"
  },
  "node_modules/http-errors/README.html": {
    "href": "node_modules/http-errors/README.html",
    "title": "http-errors | accouter",
    "keywords": "http-errors Create HTTP errors for Express, Koa, Connect, etc. with ease. Install This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install http-errors Example var createError = require('http-errors') var express = require('express') var app = express() app.use(function (req, res, next) { if (!req.user) return next(createError(401, 'Please login to view this page.')) next() }) API This is the current API, currently extracted from Koa and subject to change. Error Properties expose - can be used to signal if message should be sent to the client, defaulting to false when status >= 500 headers - can be an object of header names to values to be sent to the client, defaulting to undefined. When defined, the key names should all be lower-cased message - the traditional error message, which should be kept short and all single line status - the status code of the error, mirroring statusCode for general compatibility statusCode - the status code of the error, defaulting to 500 createError([status], [message], [properties]) Create a new error object with the given message msg. The error object inherits from createError.HttpError. var err = createError(404, 'This video does not exist!') status: 500 - the status code as a number message - the message of the error, defaulting to node's text for that status code. properties - custom properties to attach to the object createError([status], [error], [properties]) Extend the given error object with createError.HttpError properties. This will not alter the inheritance of the given error object, and the modified error object is the return value. fs.readFile('foo.txt', function (err, buf) { if (err) { if (err.code === 'ENOENT') { var httpError = createError(404, err, { expose: false }) } else { var httpError = createError(500, err) } } }) status - the status code as a number error - the error object to extend properties - custom properties to attach to the object createError.isHttpError(val) Determine if the provided val is an HttpError. This will return true if the error inherits from the HttpError constructor of this module or matches the \"duck type\" for an error this module creates. All outputs from the createError factory will return true for this function, including if an non-HttpError was passed into the factory. new createError[code || name]([msg])) Create a new error object with the given message msg. The error object inherits from createError.HttpError. var err = new createError.NotFound() code - the status code as a number name - the name of the error as a \"bumpy case\", i.e. NotFound or InternalServerError. List of all constructors Status Code Constructor Name 400 BadRequest 401 Unauthorized 402 PaymentRequired 403 Forbidden 404 NotFound 405 MethodNotAllowed 406 NotAcceptable 407 ProxyAuthenticationRequired 408 RequestTimeout 409 Conflict 410 Gone 411 LengthRequired 412 PreconditionFailed 413 PayloadTooLarge 414 URITooLong 415 UnsupportedMediaType 416 RangeNotSatisfiable 417 ExpectationFailed 418 ImATeapot 421 MisdirectedRequest 422 UnprocessableEntity 423 Locked 424 FailedDependency 425 TooEarly 426 UpgradeRequired 428 PreconditionRequired 429 TooManyRequests 431 RequestHeaderFieldsTooLarge 451 UnavailableForLegalReasons 500 InternalServerError 501 NotImplemented 502 BadGateway 503 ServiceUnavailable 504 GatewayTimeout 505 HTTPVersionNotSupported 506 VariantAlsoNegotiates 507 InsufficientStorage 508 LoopDetected 509 BandwidthLimitExceeded 510 NotExtended 511 NetworkAuthenticationRequired License MIT"
  },
  "node_modules/http-errors/node_modules/statuses/HISTORY.html": {
    "href": "node_modules/http-errors/node_modules/statuses/HISTORY.html",
    "title": "2.0.1 / 2021-01-03 | accouter",
    "keywords": "2.0.1 / 2021-01-03 Fix returning values from Object.prototype 2.0.0 / 2020-04-19 Drop support for Node.js 0.6 Fix messaging casing of 418 I'm a Teapot Remove code 306 Remove status[code] exports; use status.message[code] Remove status[msg] exports; use status.code[msg] Rename 425 Unordered Collection to standard 425 Too Early Rename STATUS_CODES export to message Return status message for statuses(code) when given code 1.5.0 / 2018-03-27 Add 103 Early Hints 1.4.0 / 2017-10-20 Add STATUS_CODES export 1.3.1 / 2016-11-11 Fix return type in JSDoc 1.3.0 / 2016-05-17 Add 421 Misdirected Request perf: enable strict mode 1.2.1 / 2015-02-01 Fix message for status 451 451 Unavailable For Legal Reasons 1.2.0 / 2014-09-28 Add 208 Already Repored Add 226 IM Used Add 306 (Unused) Add 415 Unable For Legal Reasons Add 508 Loop Detected 1.1.1 / 2014-09-24 Add missing 308 to codes.json 1.1.0 / 2014-09-21 Add codes.json for universal support 1.0.4 / 2014-08-20 Package cleanup 1.0.3 / 2014-06-08 Add 308 to .redirect category 1.0.2 / 2014-03-13 Add .retry category 1.0.1 / 2014-03-12 Initial release"
  },
  "node_modules/http-errors/node_modules/statuses/README.html": {
    "href": "node_modules/http-errors/node_modules/statuses/README.html",
    "title": "statuses | accouter",
    "keywords": "statuses HTTP status utility for node. This module provides a list of status codes and messages sourced from a few different projects: The IANA Status Code Registry The Node.js project The NGINX project The Apache HTTP Server project Installation This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install statuses API var status = require('statuses') status(code) Returns the status message string for a known HTTP status code. The code may be a number or a string. An error is thrown for an unknown status code. status(403) // => 'Forbidden' status('403') // => 'Forbidden' status(306) // throws status(msg) Returns the numeric status code for a known HTTP status message. The message is case-insensitive. An error is thrown for an unknown status message. status('forbidden') // => 403 status('Forbidden') // => 403 status('foo') // throws status.codes Returns an array of all the status codes as Integers. status.code[msg] Returns the numeric status code for a known status message (in lower-case), otherwise undefined. status['not found'] // => 404 status.empty[code] Returns true if a status code expects an empty body. status.empty[200] // => undefined status.empty[204] // => true status.empty[304] // => true status.message[code] Returns the string message for a known numeric status code, otherwise undefined. This object is the same format as the Node.js http module http.STATUS_CODES. status.message[404] // => 'Not Found' status.redirect[code] Returns true if a status code is a valid redirect status. status.redirect[200] // => undefined status.redirect[301] // => true status.retry[code] Returns true if you should retry the rest. status.retry[501] // => undefined status.retry[503] // => true License MIT"
  },
  "node_modules/http-proxy/CHANGELOG.html": {
    "href": "node_modules/http-proxy/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. Generated by auto-changelog. v1.18.1 - 2020-05-17 Merged Skip sending the proxyReq event when the expect header is present #1447 Remove node6 support, add node12 to build #1397 1.18.0 - 2019-09-18 Merged Added in auto-changelog module set to keepachangelog format #1373 fix 'Modify Response' readme section to avoid unnecessary array copying #1300 Fix incorrect target name for reverse proxy example #1135 Fix modify response middleware example #1139 [dist] Update dependency async to v3 #1359 Fix path to local http-proxy in examples. #1072 fix reverse-proxy example require path #1067 Update README.md #970 [dist] Update dependency request to ~2.88.0 [SECURITY] #1357 [dist] Update dependency eventemitter3 to v4 #1365 [dist] Update dependency colors to v1 #1360 [dist] Update all non-major dependencies #1356 [dist] Update dependency agentkeepalive to v4 #1358 [dist] Update dependency nyc to v14 #1367 [dist] Update dependency concat-stream to v2 #1363 x-forwarded-host overwrite for mutli level proxies #1267 [refactor doc] Complete rename to http-party org. #1362 Highlight correct lines for createProxyServer #1117 Fix docs for rewrite options - 201 also handled #1147 Update .nyc_output #1339 Configure Renovate #1355 [examples] Restream body before proxying, support for Content-Type of application/x-www-form-urlencoded #1264 Commits [dist] New test fixtures. 7e4a0e5 [dist] End of an era. a9b09cc [dist] Version bump. 1.18.0 9bbe486 [fix] Latest versions. 59c4403 [fix test] Update tests. dd1d08b [dist] Update dependency ws to v3 [SECURITY] b00911c [dist] .gitattributes all the things. fc93520 [dist] Regenerate package-lock.json. 16d4f8a 1.17.0 - 2018-04-20 Merged Fix overwriting of global options #1074 Update README.md #1131 Update README.md with CoC link #1120 Add Code Of Conduct #1119 [deps] Update eventemitter3 to version 2.0.x #1109 Fixed Fix \"Can't set headers after they are sent\" errors #930 Include websocket non-upgrade response #890 Commits Add followRedirects option c9a556c [test] add test for selfHandleRequest and remove modifyResponse as selfHandleRequest is the only way that functionality works 4a37175 Adding ability to set cookie path 2c98416 Updating docs and adding more tests. f5c2381 [dist] make tests work reliably, add package-lock.json 09dcb98 add support for modify response e5c02b8 [wip] proper tests and reporting f4ff100 Add detail about \"buffer\" option 6f88caf Add use case for proxy to HTTPS using a PKCS12 client certificate d2f9db8 [test] for override method feature 81d58c5 [dist] doc updates e94d529 feat: 添加response自处理参数 89f9ef8 [dist][test] codecov config a4bccc3 Removing unnecessary check since this is a private API bc6a237 issue #953: stop using writeHead 2c44039 [fix] move badges 543636d fix small typos in README 8231984 Added timeout option to docs 107c187 [dist] document the feature d533a1b [fix] slightly more tolerant de1b808 Forgot 'i' flag when changing from regex shorthand to string. 50f58b4 Update common.js c5d8466 [fix] rm newline e6f24ba [dist] update package-lock.json abf882e 1.16.2 - 2016-12-06 Merged [WIP] Revert default behavior of writeHeaders method #1104 1.16.1 - 2016-12-04 Commits Enable proxy response to have multiple Set-Cookie raw headers #1101 8cb451f [dist] Version bump. 1.16.1 ac1a01b 1.16.0 - 2016-12-02 Merged Fix newly introduced error in error handler for ECONNREFUSED in forward proxy #1100 Keep original letter case of response header keys #1098 Handle errors for forward request, add test case #1099 Commits add node 6 to travis 2f7f037 1.15.2 - 2016-10-22 Merged Add proxy-timeout option to documentation #1075 Commits Do not rely on func.name (no scope) 61c2889 Do not rely on func.name (no scope) d48f67e Expose full callback names 220f5fb test case added f5217d6 [fix] style nits d0f1dfe With a comment fbc2668 Fix browserification 8eddf45 not setting connection header in case of http2 as it is deprecated 2d01edc 1.15.1 - 2016-09-14 Merged Properly write response header optionally including statusMessage #1061 Commits [dist] Version bump. 1.15.1 912cd3a 1.15.0 - 2016-09-14 Merged Made it not to crash with omited Host http header #1050 README.md: fix typo: 'ingoing' should be 'incoming' #1060 Fix for Reason-Phrase being overwritten on proxy response. #1051 cookieDomainRewrite option #1009 Update ntlm-authentication.js #1025 Restream body before proxying #1027 Location rewriting for responses with status 201 #1024 #866 Copy CA from options into outbound proxy #1042 Fixed Restream body before proxying (#1027) #955 Commits [dist] Version bump. 1.15.0 b98c75b 1.14.0 - 2016-06-15 Merged Emit disconnected event instead of error when ECONNRESET #966 fix test for node 0.10 + socket.io-client@1.4.6 (engine.io-client@1.6.9) #1010 Commits [dist] Version bump. 1.14.0 fcfb0b3 1.13.3 - 2016-05-16 Merged fix browserify compatibility #975 alter message error #998 Sanitize header keys before setting them #997 Update ntlm-authentication.js #989 Add expected datatype to readme #983 Update README #982 Fix formatting of the headers option #974 Set the x-forwarded-host flag when xfwd is enabled #967 Fixed Sanitize header keys before setting them (#997) #996 Commits [dist] Update LICENSE to reflect 2015 changes. f345a1a [dist] Version bump. 1.13.3 5082acc 1.13.2 - 2016-02-17 Merged Fixed missing documentation: #options.headers #806 #949 Proxy example using req instead res on README #950 mocha: Use default reporter #962 Remove \"transfer-encoding\" header if \"content-length\" is set to zero #961 Commits [dist] Version bump. 1.13.2 e1b2f4c 1.13.1 - 2016-02-02 Merged README.md: summary to specify reverse proxy #932 fix(common) urlJoin replace: \":/\" -> \"http?s:/\" #947 Update README.md #948 Commits [dist] Version bump. 1.13.1 9d9fa94 1.13.0 - 2016-01-26 Merged Fix for #839 (Ignore path and the trailing slash) #934 Update license year range to 2016 #943 Commits [dist] Version bump. 1.13.0 268994e 1.12.1 - 2016-01-24 Merged Bump version for npm publish #942 Added check to passes/web-outgoing.js to make sure the header being s… #940 Created reverse-proxy.js example. #825 SSE example and test #922 More structured readme #912 Updated markdown docs to mention proxy rules module #910 Add tests for forwarding of continuation frames #901 Bump requires-port, server and ws #904 [example] add an example for NTLM authentication #903 Commits Organized README more cd1d777 Add tests for testing forwarding of continuation frames 64fa520 Added back to top helpers 6106d4c [ci] use node 4.2 to test and do not allow failures f82ce18 [fix] bump requires-port, server and ws 9ea1e89 Updated markdown docs to mention proxy rules eea79ca Fixed tests depending on ignorePath f9540de Added check to passes/web-outgoing.js to make sure the header being set is not undefined, which should be the only falsey value that could accidently show up and break that call. This fixes windows NTLM auth issues behind http-proxy. 3b39d2c No longer appends / to path if ignorePath is set f2093b5 README.md: introduction to specify reverse proxy 41414a5 Added note for appending trailing / when using ignorePath 0cb1d3c 1.12.0 - 2015-10-22 Merged Issue #896: provide a \"proxyReq\" event also for websocket connections. #897 Commits Provide a \"proxyReq\" event also for websocket connections. a05fc2d fixes after PR review 9752652 [dist] Version bump. 1.12.0 b5a6d0e 1.11.3 - 2015-10-19 Merged Removed unspecified trailing slash in proxy url #893 Updating the upgrading doc #892 Commits [dist] Update .travis.yml to be more modern. 302d981 [dist] Version bump. 1.11.3 60baca5 docs: options.headers c86ae51 1.11.2 - 2015-08-30 Merged Update gzip-middleware.js #870 Fix broken option list indentation #863 Added missing configuration options #852 Added installation instructions #823 fixes comment #817 Commits Created reverse-proxy.js example. 38864d0 Added websocket set-cookie headers test 855cebd [fix] make more functional cea0e86 Modify the set-cookie header fix to work with node 0.10.x. da674ec Use raw headers instead parsed. 8bfd90c Replaced Object.keys().map with for in loop. 3d2350c [dist] Version bump. 1.11.2 30e3b37 Websocket key was unnecessary long. ca73208 v1.11.1 - 2015-04-22 Commits [dist] Version bump. 1.11.1 7e6c66a [fix] dont use bind in the one case we do d26ef56 [dist] update to new version of EE3 607f96c [fix] use the main export for EE3 18c77ca v1.11.0 - 2015-04-20 Merged [api] add an ignorePath option if you want to disregard the path of the ... #759 Commits [dist] Version bump. 1.11.0 934e6c4 v1.10.1 - 2015-04-02 Merged Fix default port detection with node 0.12.x #799 Commits [dist] add semver and normalize package.json with --save-dev 1b89bc9 fix protocol and default port detection on node 0.12.x, compatible with 0.10.x 5f14bca fix expected error message when node 0.12.x 0ee314c force cipher AES128-GCM-SHA256 in https tests c33d161 [fix] properly support iojs with test checking for HTTPS c6dfb04 [dist] Version bump. 1.10.1 0bd446c [ci] add 0.12 and iojs to travis a6ae6c4 v1.10.0 - 2015-04-01 Merged Fixes / additions to URL rewriting #787 Commits [dist] Version bump. 1.10.0 1dabda2 v1.9.1 - 2015-04-01 Merged Fix #747 #798 Fixed Merge pull request #798 from damonmcminn/master #747 Fix https://github.com/nodejitsu/node-http-proxy/issues/747 #747 Commits Add test for https://github.com/nodejitsu/node-http-proxy/issues/747 d145152 [dist] Version bump. 1.9.1 21b30b7 v1.9.0 - 2015-03-12 Merged Adding the nodejs0.12 auth option #792 fix \"x-forwarded-proto\" in node 0.12 and iojs #789 Add support for auto host rewriting and protocol rewriting #1 changed highlighted part - very minor #756 Update README.md for benchmarks #625 Fixed fix \"x-forwarded-proto\" in node 0.12 and iojs #772 [api] add an ignorePath option if you want to disregard the path of the incoming request when proxying to the target server fixes #758 #758 Commits added auth header test df158bf added auth header test ff1626f refactor some tests for greater readability 14415a5 only rewrite redirect urls when it matches target 26029ba auth header added ab5c3e5 [dist] Version bump. 1.9.0 87a92a7 end of file line space e907d7b space instead of tabs 7298510 space instead of tabs 63c9262 auth header added tests f55ffa3 v1.8.1 - 2014-12-17 Commits Pass HTTPS client parameters. 402ab05 [dist] Version bump. 1.8.1 3311106 v1.8.0 - 2014-12-17 Merged Fix variables scope in test #752 Fix typo #751 Commits Added websocket close event test 8bff3dd Deprecated proxySocket event in favor to open event. c62610e Update README.md 05d18a4 [fix] style spacing wtf ea0a4de [api] add close event in ws-incoming.js 2653786 [minor] grammar f304861 Changed proxyServer and destiny to local variables. 8a8a894 [dist] Version bump. 1.8.0 f0db5b3 v1.7.3 - 2014-12-09 Fixed [fix] use simple regex instead of indexOf to check the protocol to support without the colon fixes #711 #711 Commits [test] show that we support protocol without the colon 89f9ca1 [dist] Version bump. 1.7.3 6a330ff v1.7.2 - 2014-12-08 Merged Fix grammar in README.md #749 Fixed [fix] properly include port in host header with changeOrigin in all cases fixes #750 #750 Commits [test] add tests for the changeOrigin cases in properly setting the host header 71a06aa [dist] pin down deps and add requires-port 81874f7 [dist] Version bump. 1.7.2 2086e49 v1.7.1 - 2014-12-02 Merged Adding harmon to the README #716 Fixed [fix] fix #738 #738 [fix] simple fixes #748 #744 #746 #748 Commits [test] add proper failing test case for #738 410a8ce [Bugfix] Allow for multiple ? in outgoing urls. 70ed1c4 [dist] Version bump. 1.7.1 56a7b77 v1.7.0 - 2014-11-25 Merged Allow optional redirect host rewriting. #741 Set Content-Length header for OPTIONS requests #742 copy headers instead of referencing them so they don't unexpectedly get overwritten #736 Updated to support error callback on proxy.web and start/proxyReq/end co... #735 Commits 📝 Add host rewrite docs and specs. add8133 [minor] style consistency 48ae5d8 Updated to support error callback on proxy.web and start/proxyReq/end continue working. 9ba8311 style changes 84036e9 [fix] be defensive and ensure location is in headers before running url.parse() 8d68ac0 [dist] Version bump. 1.7.0 276f65a v1.6.2 - 2014-11-11 Merged do not modify the query string #733 Commits [fix] style changes 7c5e40a [minor] this shouldnt be in var block 3f19e6e [dist] Version bump. 1.6.2 709b3e9 v1.6.1 - 2014-11-04 Merged websocket needs to respect options.secure too #729 changeOrigin option docs fix #724 Commits [dist] Version bump. 1.6.1 fa797fc v1.6.0 - 2014-10-29 Merged Added changeOrigin option with test and docs #723 I presume you mean couchdb here #717 update modify request body eg #712 Commits harmon notes 9f684d0 [dist] Version bump. 1.6.0 43641b0 v1.5.3 - 2014-10-01 Merged close socket if upstream request fails #709 Commits [dist] Version bump. 1.5.3 9577a0f v1.5.2 - 2014-10-01 Merged close websocket if proxyReq is closed before upgrade #708 Commits test closing upstream socket prior to upgrade 7730548 [dist] Version bump. 1.5.2 43c6f0c v1.5.1 - 2014-09-30 Commits [fix] do a check to make sure the server exists before we try and emit 10a294a [dist] Version bump. 1.5.1 f0bf741 v1.5.0 - 2014-09-30 Merged exposing proxySocket on socket to support sniffing messages coming from proxy target #706 Fixed misleading documentation #705 Fix typo in README.md #702 handle 'upgrade' in comma-separated connection header #691 Commits test new detection of connection: upgrade ec683b9 emitting proxySocket on proxyServer 000eb53 [fix] perf optimization so we have a precompiled regexp c0a796b use regex to check for upgrade header 65a21bc [dist] Version bump. 1.5.0 232258b [minor] extra space e7d50b1 v1.4.3 - 2014-09-12 Merged Urgent: Fix breaking bug on url joining resulting in paths like ///path. #699 Commits [minor] Added missing JSDoc comments 73e8a4c Fix breaking bug on url joining resulting in paths like ///path. 73d865b [minor] Code style adjustment. 3ab6e95 Bump version v1.4.3 554f59c [ignore] Ignore npm-debug.log a934cb6 v1.4.2 - 2014-09-12 Commits [fix] ensure path works on windows because path.join doesnt like URLs ed73f06 [dist] Version bump. 1.4.2 df12aeb v1.4.1 - 2014-09-11 Merged Trimming contents of distributed npm package. #644 Remove changelog - it was not maintained #669 Removed duplicated imported dependencies #695 Commits [test] add test for prependPath option e44fabe [api] add prependPath option to go with path change 9a534c6 [dist] Version bump. 1.4.1 d5c656b [dist] Version bump. 1.4.0 dceef40 v1.3.1 - 2014-09-09 Merged Allow proxy to maintain the original target path #693 Clarify usable parameters for 'proxyRes' event #686 Commits fix tests for maintaining proxy path a65021d Fix proxy path 511b7b3 Clarify usable parameters for proxyRes event. 49a0de1 [dist] Version bump. 1.3.1 fc73828 [ci] remove 0.11.x to avoid failing builds caused by TLS errors 6b83ae4 v1.3.0 - 2014-08-14 Merged Added functionality to close proxy. #679 Commits [fix] cleanup and stylize close function 261742a updated close function for safety 8be9d94 [dist] Version bump. 1.3.0 05f0b89 v1.2.1 - 2014-08-14 Commits Added close method to proxy server. a3d0219 [fix] emit an error if proper URL is not passed in as a target 37036dd [dist] Version bump. 1.2.1 0a6b424 v1.2.0 - 2014-08-05 Merged [api] Add event-based ability to modify pre-flight proxy requests. #673 Commits [dist] Version bump. 1.2.0 63c53a1 v1.1.6 - 2014-07-17 Fixed do proper checking for a pass not existing. fixes #671 #671 Commits Remove changelog - it was not maintained e336b52 [dist] Version bump. 1.1.6 ed9e12b v1.1.5 - 2014-07-10 Merged Fix simple-balancer example #666 Added proxyTimeout option and two tests for timeout #658 Fixed Fix #657 #657 Fix #657 #657 Commits Added targetTimeout option and two tests for timeout 0f24351 Change name targetTimeout to proxyTimeout 7b79a74 Trimming contents of distributed npm package. 431aba7 [api] also emit the target on a proxy error d1baa36 [dist] Version bump. 1.1.5 7104a7c fix balancer example 9df4bc1 v1.1.4 - 2014-05-11 Merged proxyRes event, provide access to the req and res objects #642 Commits Add a test for the proxyRes event 1385635 [dist] Version bump. 1.1.4 7cb98a4 Add the req and res objects to the proxyRes event 1213e46 v1.1.3 - 2014-05-11 Merged Don't override connection header if Upgrading #640 Commits Adding test cases on preventing upgrade override 8aa7c51 Update README.md for benchmarks 4947484 [minor] style ccad177 [dist] Version bump. 1.1.3 c472527 v1.1.2 - 2014-04-14 Commits [fix test] handle proxy error since we are properly aborting the proxy Request 61c8734 [fix] handle error on incoming request as well and properly abort proxy if client request is aborted 77a1cff [dist] Version bump. 1.1.2 c54278b v1.1.1 - 2014-04-11 Commits [dist] Version bump. 1.1.1 d908e2a [fix] let user make the decision on what to do with the buffer 4f07dc2 v1.1.0 - 2014-04-09 Merged Update UPGRADING.md #616 Fixed [fix] always be an eventemitter for consistency fixes #606 #606 Commits [api] emit a start an an end event 8b48a9f [dist] Version bump. 1.1.0 97ceeb3 [minor] missing angle bracket eca765a v1.0.3 - 2014-03-27 Merged Fix for #591 #592 Add Repository field to package.json #578 Fix doc: option lines #575 Fixed [api] add toProxy method to allow absolute URLs to be sent when sending to another proxy fixes #603 #603 Commits [doc] update docs with toProxy option ece85b4 [fix] set connection to CLOSE in cases where the agent is false. 89a22bc @xtreme-topher-bullock - update package.json to have proper repository key and formatting 68fa17b [dist] Version bump. 1.0.3 07fceb7 Add support for localAddress e633b0f v1.0.2 - 2014-01-28 Merged Update README.md #566 Fix argument order for ws stream pass #560 Extend listen to enable IPv6 support. #558 Fix before and after type check #556 Fixed Close outgoing ws if incoming ws emits error #559 [fix] closes #555 #555 Commits [fix] replicate node core behavior and throw an error if the user does not add their own error listener daad470 [dist] Version bump. 1.0.2 4bdc3e4 [doc] Fix broken image in npm by using an absolute link 8004f4e v1.0.1 - 2014-01-17 Fixed [fix] closes #553 #553 Commits [dist] bump v1.0.1 68c5512 typo 689459f v1.0.0 - 2014-01-16 Merged Http proxy 1.0 #552 Caronte #551 Only emit response if a valid server is present #549 [fix] add type to before and after to grab correct passes, fixes #537 #539 export the proxy itself from the main require #536 Fixed [fix] closes #547 #547 Merge pull request #539 from nodejitsu/fix-before-after #537 [fix] add type to before and after to grab correct passes, fixes #537 #537 Commits [nuke] old files a4ee8f9 [docs] upgrade UPGRADING.md e599151 [api] export the httpProxy.Server as the main export but preserve the createServer factory 182c76c [fix] remove caronte d6d2d0c [fix] ee3 error handling d23353d [fix] comments 6fa23e1 v0.10.4 - 2013-12-27 Merged Update README.md #521 Better examples #520 Send path in req.path and not the url #416 Fix websocket error handing #518 attempting to fix links to 2 source locations in README.md #502 [merge] rename codename to actual project name #492 [merge] Added error handling example #484 [merge] https & agent #482 [merge] caronte tests #476 FIX: ws error event #475 Fix accidental write to global variable. #472 [fix] 2 spelling mistakes #14 [fix] add ability to proxy websockets over HTTPS #11 Tests #3 Fixed determine x-forwarded-port from host header #341 [fix] closes #529 #529 [fix] fixes #341 #341 [tests] https test pass, fix #511. Exposed the rejectUnauthorized flag #511 [fix] pass proper options object that extend the global options and parse the per proxy args into options. fixes #510 #510 [readme] add links to badges on readme, fix #483 #483 [fix] pooled connections, closes #478 #478 [fix] add 0.10 link, fixes #459 #459 [fix] closes #473 #473 [fix] add 0.10 compatibily.. closes #474 #474 [fix] headers, closes #469 #469 [fix] headers, fixes #467 #467 [fix] yawnt baaaka .. fixes #8 #8 Commits [fix] more jshint intendation 17399e7 [fix] tests a255f98 [minor] remove coverage 335af81 [examples] updated websockets examples ed8c9ee [tests] removed unused tests 7e25bde [tests] Added a test case for run all the examples bc236d7 [tests] drop the test of own streams, moved the usable tests dc9d7e5 [fix] default port d166354 [tests] added the ws passes test and the streams webscokets test 8b3fe32 [refactor minor] s/caronte/http-proxy/ or s/caronte/httpProxy/ where appropriate. bb0d28c [examples] updated bodyDecoder middleware example c82ff2c [dist] first 4d13156 [examples] update forward and custom error examples b726116 [refactor docs] add descriptions d05af4a [tests] make the tests run with the last refactor 5bb83b9 [examples] deleted this examples bdeabb7 websocket draft 07551c6 [fix] naming 2a59366 [dist doc] Added documentation for consistent benchmarking of node-http-proxy f7f5fa7 [examples] update old examples 7e44d36 [docs] more short examples to the Readme 0393b5d [examples] updated old proxy examples e02317c [wip] Initial HTTPS->HTTP test, updated https-secure example. Work in progress, need to add more https tests 33a2462 [docs] readme 886a870 [examples] added error-handling using callbacks and HTTP-to-HTTPS examples d7064f2 [examples] updated old examples 588327c stuff e45bfd6 [doc] added some documentation to functions and comments to understand better the code 5dcdf2b Fixed issue where error callback would not invoke, including new test cases. Added req/res values to error events. 0bfb9be [examples] updated balancer examples 831a44b socket.io stuff a74cd85 [tests] move contributions of @mmoulton to correct place 7c72f3b [tests] this file is not necessary anymore 881c7e6 [refactor] move to leaner architecture 8273cb6 [fix] remove trailing whitespaces 0aeaba7 [test] added tests for web-outgoing.js 16a4d9d [fix] some stuff start debugging proxystream d4f0da8 [tests] now each test use a different port to avoid some slow opening and closing ports c75d06c [tests] fixed inherits problem and listen for the correct event c65ffbb [fix] ProxyStraem now works 356f43d [examples] fix the copyright header of example files e592c53 [feature] start working on the new server b79bd29 ENH: updated examples f566a42 [examples] add example of gzip using the connect.compress() middleware 2142c50 [fix] refactor error handling 601dbcb [tests] fixed according new refactor and added test to common.setupSocket() 1cb967b [feature] websocket support 79a14ac keepalive sockets dad211e [tests] Using target field, tests now pass. We are missing the tests using forward field 8085178 [fix] callback as optional error handler c7924e0 ENH: added new https example, needs to be simplified before merge 427d8d8 [test] proxystream test c961279 [lib] initial draft to websockets passes 79f7f99 [fix] minor 7599cee [tests] added HTTPS to HTTPS test 31d919b [feature] started working on error propagation, kinda sucks, gotta think it over 9ab8749 [test] testing the onResponse proxy method 27df8d7 [fix] remove duplicate 10c0f11 [tests] add more tests cedc5c4 [docs] Update readme with more how to ae0faef [tests] added test for socket.io proxying 10a0db4 [tests] added test HTTPS to HTTP using own server bbe3bfd [examples] update the error-handling example using the new error handle way a1b25a1 [fix] quote c4ddc4e ENH: updated README and added examples file. 07091b5 [test] passes/web.js (first 2 funcs) d40e4be [test] add test for forwardstream 8fc3389 [tests] fixing tests, fixed some typos and changed how passes are stored a704213 [test] added the lib/caronte/streams/forward.js initial test, one test pending 2fac7b9 [api] add draft for proxystream 4f24664 [experiment] new api for proxying 07cfa6b [tests] the options got a problem and this test probe that timeout is not being set 1d1ee88 new error propagation 3a39e44 [fix] docs ec981c5 [examples] added concurrent proxy example 04c1011 [fix] closes number #487 cde08fb [test] started writing tests 16eacfa [tests] added tests for websockets 02007ed Revert \"[fix] fixed options and server reference to can access them from passes functions\" babdf53 mm test file 1a7bef0 [fix] fixed options and server reference to can access them from passes functions 90fb01d [examples] added forward example 7a3f6df [docs] add UPGRADING.md db12f6c DOC: Added error handling example 32a4088 [examples] updated the modifyResponse-middleware example de3ff11 [test] test onError part, proxying to no where b85aa16 ENH: updated agent options in common.setupOutgoing 12cda56 [fix] minor and short fixes e0faaaf support websockets 4a4607d [test] COVERAGE 004a46c [misc] add a LICENSE file 584ce76 ENH: updated https and agent option 13741a8 [fix] write connection header 2c10f25 [fix] merge #495, thanks @glasser d0862af support forward 8c8c455 [tests] fix tests set correct host headers cfd417d [fix] Optimize fix for x-forwarded-for-port. 2d42709 ENH: updated readme with an example edd8e2f [doc] update README.md dcb873a [test] passes/web.js XHeaders func c02b721 [fix] fixed passes functions, now 'this' can be used and options are stored on 'this.options' 9b3e1eb Revert \"[fix] fixed passes functions, now 'this' can be used and options are stored on 'this.options'\" 5e130de [minor] Remove duplicate dependencies and cleanup of the scripts a51b062 TEST: added agent and header tests 39b0c46 [examples] fix styling and bad spaces 6a6dfbb ENH: added error events 1b867a7 [test] remove chunked on http1.0 ca09263 [tests] fix test to use the new way to pass options 52ecd52 [examples] fixed https examples a467b7b Revert \"[tests] fix test to use the new way to pass options\" 2bf20d6 [fix] better code 3d8e538 [feature] implement _write and _read 6a4294c [fix] use the correct arguments order cc09ae6 [fix] fix the correct order of arguments in ws-incoming passes 02df9a3 [fix] write status e08d4ed [fix] finished jshint fixes 455f97e Update the README to describe middleware err handler. 25bb3bf Prevent headers to be sent twice 8332e74 [examples] added package.json with the dependencies needed by examples d85ccdd [tests] added .travis.yml file 0602500 [dist minor] 2 space indents next time @samalba 7e8041d [fix] naming 8931009 Fix for #458. Host header may cause some sites not to be proxyable with changeOrigin enabled 781c038 [docs] typos, typos everywhere... 03880d8 ENH: updated ws and web functions to use the global options object as a base 268afe3 [fix] make @mmalecki a happy camper c9cd6d2 write f97c0c6 [fix] a9f9e21 [fix] coveralls.. will it work? f36cb4d ENH: updated target and forward options so that a string may be specified ef946a7 added option for eventlistenerCount(max) 8eb6780 [fix] support buffer 1204a35 DOC: updated readme with options 1b5fb1d ENH: added 'headers' to available options, to add or overwrite existing headers 7d840d3 [fix] move logo 57abb7f FIX: tests. still need to add more tests tho a350fad [fix] move logo aaff196 [docs] add travis build status 6b61878 [fix] do not send chunked responses to http1.0 clients 8663ac1 [dist] Bump dependencies. a81dd8d [fix] readme 4d3a4e1 [fix] proxying to https 26c4c43 [fix] new logo ee3cc38 [fix] naming convention 7d71a86 fix docs 9243444 [fix] short circuit a6256ca [tests] this test is already in web-incoming tests 920f1e7 Emit middlewareError when on middleware error. bc12ca3 DOC: updated readme 7ad5c0f [docs] add logo 8b05626 [fix] making @stoke a happy camper 34f16e7 [feature] add buffer support e3f8d5f [Fix] 2 spelling mistakes 5823842 [fix] do not call .end 6e77cd3 attempting to fix link to valid options properties bbe2b27 [fix] slimmer proxying 031aa0f [fix] use agent pool abf1d90 [tests] fix test using undefined url c4d56a5 [fix] legacy 162a42f [tests] fixing minor typos b333e63 Updated readme bd106d6 [misc] use the local mocha instead the global f1aeb05 added unlimited listeners to the reverproxy event obj. 1333c0c [tests] throw error when no options, ALL TESTS PASSING! YAY 86750c7 ENH: updated example 1c7ace2 [merge] PR #470 38e6d7c [fix] remove stuff 6a03e5f [test][misc] remove node@0.8 to test on travis 8eff1a1 merge with @cronopio 0fb3381 [merge] text 98f29bd [fix] woops bd3df45 [test] Test on newer version of node ebbba73 new error propagation - follows 1993faf [fix] minor typo 5a1504f [fix] proxy to http(s) 3c91ed3 Put the arguments the right way around in the README. 1457980 [fix] use some 4480699 [fix] layout d7078e2 [docs] logo dd0f7b8 [fix] url 0637322 [fix] opts adc5be0 [docs] fix syntax highlighting da9de70 [fix] typo 275a519 [tests] fix code coverage, changed pattern on blanket options 4090250 Put the arguments the right way around in emitter. 7c8ecc8 [fix] link 72a89ea [fix] space 69f126b [fix] tests 8269eca [fix] console 18341d5 Set travis to run npm test while we fix coveralss.io integration e2a5d51 [fix] making @jcrugzz a happy camper 2e7343d [fix] minor typo 5d66ce1 [tests] tests fixed d60353f [tests] disabled the examples-test by now d83fdf6 [fix] _ because it is unused 590bb60 [tests] disable test, by now is not throwing without options a2b1f0a [fix] support target and forward 961d2f9 [dist] Version bump. 0.10.4 840f6d8 [fix] remove old reminescence 4d65280 [feature] add emit proxyRes dda6f7a [docs] test badge 1ceea3e [tests] remove caronte and use http-proxy for file names c9f5772 [logo] 4c2f2f3 v0.10.3 - 2013-06-20 Merged Pass default certs to SNICallback example #419 Fixed Pass default certs to SNICallback example #399 Commits [dist] Bump version to 0.10.3 2fd748f [fix] Respect maxSockets from target options in RoutingProxy e1d384e Send path in req.path and not the url 0c75323 v0.10.2 - 2013-04-21 Merged Correct keep-alive responses to HTTP 1.0 clients #407 Fixed [minor] Style compliance. Fixes #402. #402 Commits Correct keep-alive responses to HTTP 1.0 clients. a29b5e8 [minor] Strip trailing whitespace. 7fc39d7 Add headers on 'handshake' 985025c Don't test raw HTTP 1.0 requests over HTTPS. daf53bd [dist] Version bump. 0.10.2 de0928f v0.10.1 - 2013-04-12 Merged Fix for slab buffer retention, leading to large memory consumption #370 Commits [dist] Version bump. 0.10.1 9c13ad4 v0.10.0 - 2013-03-18 Merged Change the emitter of the proxyResponse event #385 Fixing a bug that generates an unexpected TypeError #383 Mention Harmon used for response modifications in the readme #384 Commits [dist] Update CHANGELOG.md 8665f3c Harmon messsage 35ba0db [fix breaking] Emit the proxyResponse event on the HttpProxy instance to reduce listener churn and reference counts. 2620f06 [dist] Version bump. 0.10.0 71183bf Fixing the if statement as it lead to 'TypeError: Parameter 'url' must be a string, not undefined' in certain cases c9b6895 Harmon messsage 4e42354 v0.9.1 - 2013-03-09 Commits [dist doc] Updated CHANGELOG.md for v0.9.1 ea5e214 [dist] Version bump. 0.9.1 701dc69 [breaking] Ensure that webSocketProxyError also receives the error to be consistent with proxyError events. c78356e v0.9.0 - 2013-03-09 Merged If HTTP 1.1 is used and backend doesn't return 'Connection' header, expicitly return Connection: keep-alive. #298 add \"with custom server logic\" to the \"Proxying WebSockets\" section of the readme #332 routing proxy 'this' reference bug? #365 fixed issue #364 'proxyError' event emitted twice #374 Misleading documentation for Websockets via .createServer #349 Fixed [api test] Manually merge #195 from @tglines since that fork was deleted. Update tests to use new macros. Fixes #195. Fixes #60. #195 #60 [fix] Set \"content-length\" header to \"0\" if it is not already set on DELETE requests. Fixes #338. #338 [fix] Do not use \"Transfer-Encoding: chunked\" header for proxied DELETE requests with no \"Content-Length\" header. Fixes #373. #373 [fix] http-proxy should not modify the protocol in redirect request for external sites. Fixes #359. #359 [fix] Emit notFound event when ProxyTable location does not exist. Fixes #355. Fixes #333. #355 #333 [fix] Make options immutable in RoutingProxy. Fixes #248. #248 [fix] Remove special case handling of 304 responses since it was fixed in 182dcd3. Fixes #322. #322 [fix] Ensure response.headers.location is defined. Fixes #276. #276 Commits [minor] s/function(/function (/ s/){/) {/ 9cecd97 working on x-forwarded-for 1332409 Routing Proxy was not sending x-forward-*. Fixing It... 916d44e Added timeout option and test to test new timeout parameter, added requestFail assertion. 89d43c2 Add tests for headers bug fixes ecb5472 Added simple round robin example with websocket support 83fbd42 support unix donain sockets and windows named pipes (socketPath) on node 0.8.x. On node 0.6.x the support was opaque via port, but on the new node, socketPath should be set explicitely. ffe74ed pathnameOnly flag added. Ignores hostname and applies routing table to the paths being requested. 46b078a [doc] added comments to pathnameOnly block. 5e6be6c remove offending code, final fix for issue #364 3b84e27 memory leak fix in closing of the scokets 2055d0c Fix truncated chunked responses ef66833 Re-added previous description 603106a pathnameOnly option documented in the Readme.md a1607c1 [fix minor] Prevent crashes from attempting to remove listeners more than once when proxying websocket requests. a681493 Added comments 64efa7f Revert \"[fix minor] Prevent crashes from attempting to remove listeners more than once when proxying websocket requests.\" c6da760 [doc dist] Update CHANGELOG.md for v0.9.0. 133115c add support for loading CA bundles 10f6b05 problem: don't want to run my server as root to bind to privileged ports (e.g. 80, 443). 2c36507 Add 'proxyResponse' event so observer can modify response headers or abort response. 3b86a7a [minor] Move private helper to end of file. 476cbe7 Fix for retaining large slab buffers in node core d2888c8 [dist] Update devDependencies ad21310 [minor] Small whitespace compliance. ea0587a [doc fix] Add undefined var in example. deca756 working on x-forwarded-for 31fc94a Allow event observers to access upstream response headers and data. 4c130f5 [fix doc] Fix bad variable reference in README.md. 440013c Change wording for handling websocket proxy events ee6bbe0 [dist] Version bump. 0.9.0 c68e038 fix 'this' reference in routing proxy listener bindings 15afc23 cleanning 8d87399 cleanning 9672b99 Fix typo which slipped in during patch clean-up ba65a48 Remove data event that is not needed after-all. b1c4bd6 v0.8.7 - 2012-12-22 Commits [fix] Handle errors on request object edfe869 [dist] Bump version to 0.8.7 26d3646 [fix] Don't remove error listener after response ends 223eacd v0.8.6 - 2012-12-21 Merged http-proxy: 304 responses should emit 'end' too #337 Commits [bench] Remove silly \"benchmarks\" 2bd9cd9 [bench] Add a benchmark for websockets throughput 6797a27 [fix] Handle socket errors 2a61ec8 [dist] Update devDependencies b81d9b7 [dist] Bump version to 0.8.6 6cd78f6 [bench] More exact size display 7bc1a62 v0.8.5 - 2012-11-16 Merged lib: allow overriding maxSockets #323 Fixed [fix] Convert strings to numbers if possible in .createServer #321 Commits [test] Delete invalid core test 886a395 [test] Upgrade common.js from node core fefbf04 add \"with custom server logic\" to the \"Proxying WebSockets\" section of the readme.md 03dbe11 [test] Kill child process when exiting test runner 74ec175 [fix] Correctly kill test processes b8c27ed [test] Make global detection work with older node versions 3531fd6 [dist] Bump version to 0.8.5 22639b3 [test] Run core tests on npm test 41c9a9c [test] Stop testing on node v0.9, tests timeout 9042665 v0.8.4 - 2012-10-23 Merged Events patch #320 documentation for options #315 Added travis build status #308 Fix installation instructions: s/http/https/ #302 If supplied pass changeOrigin option through to HttpProxy instance if set in RoutingProxy #285 Commits [fix test] Fix examples to use newest version of socket.io and helpers. Added tests for ensuring that examples require as expected with no errors. fd648a5 [fix] spdy should look like https when forwarding (until we get a client) 698b01d [docs] options 4c8e1d9 http-proxy: emit websocket:start 5df6e7b [fix] destroy() websockets in case of an error 0d00b06 [fix] Suppress EADDRINUSE errors from test/examples-test.js since we are just looking for require-time errors. Isolate tests to ensure idempotency of ports c4a7b15 [docs] more options d4cb9da If HTTP 1.1 is used and backend doesn't return 'Connection' header, explicitly 850171c [refactor] Pass all options to Agent constructor eafdc74 Fix socket leaks when FIN packet isn't responded to 24b8406 [fix] Partial fix for rejecting self-signed certs in tests 2e7d8a8 [fix] Dont use -i when running vows because it supresses --target= and --proxy= CLI arguments 1783ab0 [test] Add node v0.9 testing, test all branches 4f6387c [minor] Remove setEncoding on incoming socket 812868d [dist] v0.8.3 a89a5b8 [fix] Ignore npm version errors when installing dependencies for examples a454666 [fix] function 213e03c [dist] Bump version to 0.8.4 4d7e8a8 [minor doc] Correct comment cee27fe v0.8.2 - 2012-07-22 Merged Add example for gzip middleware using a proxy table. #221 Implement RoutingProxy.prototype.remove #246 prefer target.hostname over target.host #235 add \"Using two certificiates\" to the https section of the readme.md #275 Add support for setting the host in the executable #268 Hi! I fixed some calls to \"sys\" for you! #270 Fix bug: x-forwarded-proto set incorrectly as httphttps or wswss #266 Commits [refactor] Rewrite tests to use saner vows idioms. Update tests to use latest socket.io 4ae7a5b [dist] Remove out-dated docco docs 2d75510 [refactor test] Finish removing old test code. e2dc7f9 [dist] Complete JSHint compliance except for too many var statements 36226da [refactor test] Add support for http*-to-http* testing from CLI arguments 828dbeb [fix api] Optimize lookups in the ProxyTable. Ensure that RoutingProxy can proxy to https by default. 55286a7 Whitespace fixes. 04ce49c [refactor tests] Finished refactoring tests to support ws*-to-ws* tests based on CLI arguments 7e854d7 [doc] Minor formatting updates to README.md 6753951 [fix] Changed require('util') to require('util') for compatibility with node v0.8 bf7e328 [test] Add .travis.yml file for Travis CI. 29e6e74 Use changeOrigin for proxyRequest. 0273958 adding support for setting the host 06e78f2 match style requested by @cronopio 415d4ed Fix bug: x-forwarded-proto set incorrectly 0933f1c [dist] Version bump. 0.8.2 13c34d0 v0.8.1 - 2012-06-05 Merged [misc] Updating the changelog. Close #137 #256 Fix problem with req.url not being not properly replaced. #218 Re-emit 'start', 'forward' and 'end' events in RoutingProxy, and fix some hanging issues. #216 Fixes to make the websockets example work. #225 [minor] Syntax error #222 [docs] Making README links consistent with latest project structure. #208 [docs] improved grammar #205 proposed doc addition for #180 #189 Fixed Merge pull request #256 from nodejitsu/changelog #137 [misc] Updating the changelog. Close #137 #137 Commits Whitespace fixes e9fd3f4 Added example for gzip middleware using a ProxyTable. 6201328 [examples] Added simple load balancer example fd7fcd8 [dist] Update author field for consistency 27316e2 Add documentation for listening for proxy events to prevent a common mistake. 4f2bc58 Fix RoutingProxy hanging when there is an error b26b434 prefer target.hostname over target.host c4d185d [doc] Fix style in websockets example ed06af9 Add tests for remapping URL properly. 5d839dd fixed comment typos in examples/http/proxy-https-to-http.js and proxy-https-to-https.js, lines 37 and 46 868f7e7 [misc] changelog updated to version 0.8.1 e9a3a30 Implement RoutingProxy.prototype.remove 0532995 Making README links consistent with latest project structure. 7fa6599 Address ticket #180 here since that problem is so hard to discover when you run into it. If there was an error, people would search for the error text, but there isn't. 73e415a [tests] used socket.io 0.6.17 fixed version for tests 45d67f4 [fix] x-forwarded-proto sets properly ca37ad7 [doc] add missing {} to make an object 843901e fix the broken english and clarified the sentence (I hope) e15db4f Re-emit 'start', 'forward' and 'end' events in RoutingProxy. 99ee542 [doc] call listen() to get the server started 4fc1ee8 syntax error fixed 5842d0e [dist] Version bump 0.8.1 81f6095 finally removed hidden char 4358a4c [minor fix] delete white space df650d1 v0.8.0 - 2011-12-23 Merged Fix issue where front-end is HTTPS, back-end is HTTP, and server issues a redirect. #165 Modified the ad-hoc proxy lookup to use _getKey(), rather than the error-prone in-line method. #164 Allows node-http-proxy to append new values to existing headers for incoming \"x-forward-for\",\"x-forward-proto\" and \"x-forward-port\" #163 [fix] only set one drain listener while paused #136 [docs] grammar correction #134 Fixed [fix] Avoid Transfer-Encoding: chunked for HTTP/1.0 client, closes #59. #59 Commits [refactor minor] Update vendor/websocket.js to be compatible with node@0.6.x ea7fea6 [test] Add common.js file from core 543f214 [test] Add core test-http-proxy test feb324b [test] Add core test-http test 25a9e2d [test] Add core test-http-host-headers test f298411 [test] Add core test-http-extra-response test c26ab5e [test] Add core test-http-set-cookies test b3b5cce [test] Add core test-http-client-abort test 7bf8d4a [test] Add core test-http-client-upload test 7648fe5 [test] Add core test-http-client-upload-buf test 5ac9878 [test] Add core test-http-upgrade-server2 test bc98c0d [test] Implement basic runner for multiple tests a4079c6 [test] Add core test-http-upload-timeout test 60ff181 [test] Add core test-http-status-code test 82060a5 [test] Add core test-http-many-keep-alive-connections test 4e1ca6e [test] Add core test-http-chunked test d7461f3 [test] Add core test-http-head-response-has-no-body-end test 13389db [test] Add core test-http-server-multiheaders test d7f15d0 [test] Add core test-http-multi-line-headers test 35d2088 [test] Add core test-http-head-response-has-no-body test f79f3ad [refactor] Improved event handler cleanup 9f92332 [fix minor] Correctly set x-forwarded-proto in WebSocket requests c81bae2 Revert \"[refactor] Improved event handler cleanup \" c83d88e Allowing the common proxy headers' value to be appended in proxy chain scenarios. 621f9b4 [test] Add basic test runner 87999d0 [examples] Add some hand-crafted middleware 6e65c20 [test] Add core test-http-malformed-request test a635389 [example] Response modification middleware dd83199 [test] Add core test-http-head-request test c0857f2 [test] Add core test-http-response-close test f1c0be3 [refactor] core proxy logic. all tests should be passing. 63ac925 [test] Add core test-http-contentLength0 test 275109b [test] Add core test-http-client-abort2 test 98bbe54 adding tests for url segment proxytable routing 91e9bb9 [test] Add core test-http-eof-on-connect test 80c216d [example] Replace sys usages with util 8d701bb [refactor] Updates to support http2 from @mikeal 5b52c89 [refactor] Listen for socket events since reverseProxy.socket is no longer set synchronously 3828616 [test] Run tests in test/core/simple by default 68cebbe simplify proxytable path segment rewrite logic c03a450 change proxytable routing to route one level shallower 4d50915 [docs] Little explanation for test/core directory 8ca5d83 [minor] Allow user to set colors.mode 48d4a8b [minor] Indentation fix 9e630da [v0.6] http.Agent uses different structure for sockets 86b4122 [minor] Nicer output from test runner 5c3d41b Modified the ad-hoc proxy lookup to use _getKey(), rather than the 553e7fb [fix] When client request is aborted, abort server request 4d43d81 Fixes memory leak when clients abort connections c98ccb4 [fix test] Make test runner exit after test exits 31a8c68 [test dist] Run core tests on npm test 8358ef8 don't add upgrade handler if a custom handler is passed in d6ea3a4 always emit end in 0.4 182dcd3 [fix] Fix incorrect depth check. 3ab02f3 [minor] Everybody loves Unicode 38bd906 [test minor] Update copyright notice on test runner 2ccc5c7 [minor] When running tests output only basename e109eba [dist] Version bump. 0.8.0 5055689 Revert \"[dist] Adjusted engines field to allow for 0.6; version bump 0.7.7\" 1e33434 changeOrigin option: set the host header to the proxy destination f27d26f [dist] Adjusted engines field to allow for 0.6; version bump 0.7.7 30dac89 [fix] In routing proxy, match line beginning 63dfc7f [v0.6] Don't use agent.appendMessage() 6655e01 bump version 0.7.4 3dfba2b bump version 0.7.6 c5dc929 Revert \"update outgoing.headers.host incase the destination does proxying\" 2061c71 update outgoing.headers.host incase the destination does proxying 65b7872 bump version 0.7.5 b4d41c3 [minor] Fix indent on timeout notice c4124da [minor] Change test runner output order b76680b grammar correction 729496d [dist] Test runner depends on async 219b0ff [test fix] Remove unnecessary console.log in tests/websocket/websocket-proxy-test.js f188f4f [test refactor] test/core/{run =&gt; run-single} 004be38 v0.7.3 - 2011-10-03 Commits added what is necessary for having proxyError on Routing proxywq b7adf86 [dist] Version bump. 0.7.3 db185bb v0.7.2 - 2011-09-30 Merged [fix] Examples have working require paths now. #118 Commits [fix] Fixed require paths in examples 2e8d4c6 [websockets] add latest websockets support 45ef87e [dist] Version bump. 0.7.2 ccccc45 v0.7.1 - 2011-09-21 Merged Readme fixes #114 #107: Set x-forwarded-for header (amongst others) #110 command line tool - make sure targetPort is an integer #109 Fixed [dist] Version bump v0.7.1, closes #107 #112 #107 Commits [test] Added a test for the \"x-forwarded-for\" header 66e9820 [docs] Updated examples in README.md for 0.7.x API. 24ef919 [examples] Updated examples to v0.7.x API. 8fc8d96 [examples] More fixes to examples. 549360a [fix] x-forwarded http headers should set properly. 2677bb6 [fix] connection.socket -> socket for source of x-forwarded-for data 1f33943 Make sure the target port is an integer 5ba25aa v0.7.0 - 2011-09-10 Fixed [fix] Add x-forward-* headers for WebSocket requests. Closes #74 #74 [doc] Document setMaxSockets. Fixes #81 #81 Commits [api test dist] Stubbed out the API for the higher-level RoutingProxy object to be exposed by node-http-proxy 5927ecd [api] Finalized the RoutingProxy API f765f90 [minor] Move private methods to the bottom of file(s) ec03d72 [test] Updated tests to reflect finalized API of the RoutingProxy 734769f [api doc] Rebuilt httpProxy.createServer() with the newer high-level RoutingProxy API 598fe2e [minor] Remove commented out debug statements. 5575bcf [doc] Updated examples 13eaec5 Add flow control 6a7fd14 Add flow control 2b9e09b Emit drain if it doesn't happen on its own in 100ms 37e2541 resume() can throw 558a8a4 [fix] Memory leak hunting. ca1d12c Emit drain if it doesn't happen on its own in 100ms 84be9f2 resume() can throw 0c71119 [dist] Update examples/package.json to conform to nodejitsu style guidelines 2937229 Fixed large DoS vector in the middleware implementation 0e36912 [api] Added new close() method which cleans up sockets from HttpProxy instances 0eae2a9 Fixed large DoS vector in the middleware implementation 07c8d2e [minor] More contextual errors when middleware(s) error 38315f6 [dist] Update scripts in package.json 6e1ade0 [dist] Version bump. 0.7.0 0182ba3 [merge] Merge from significant internal refactor in v0.7.x. No external API changes f7010e5 [minor] Small update to bin/node-http-proxy 2cd8256 [dist] Update .gitignore 6c1c554 [doc] Update README.md 0ba5023 [doc] Drop version number from README.md. bdf48be [dist] Version bump. 0.7.0 00e34a1 [test] Whitespace fix 3a4d312 [dist] Reorganize examples based on classification(s): http, websocket, or middleware 81d6c31 v0.6.6 - 2011-08-31 Commits Memory leak hunting. f4fcf93 [fix] Add guards to every throw-able res.end call e1c41d0 [fix] Only set x-forward-* headers if req.connection and req.connection.socket de4a6fe [dist] Version bump. 0.6.6 967884c v0.6.5 - 2011-08-29 Commits [fix] Use req.connection for all x-forward-* headers f6dc12a [dist] Version bump. 0.6.5 7beead5 v0.6.4 - 2011-08-28 Fixed Fix #95 Don't look on req.connection if it's not set. #95 Commits [api breaking] Begin refactor to optimize node-http-proxy by managing one instance of HttpProxy per host:port location d2b0e43 [api test] Updated httpProxy.createServer() for new API exposed by simplified HttpProxy object. be4562d [test fix] A few minor fixes to ensure basic WebSocket tests are working. Better scope tests by supported protocol daf9231 [test] Updates for readability db10c4a Add guards to every throw-able res.end call 7bda25b [minor] Dont use .bind() 340be42 [dist] Version bump. 0.6.4 216d46d v0.6.3 - 2011-08-28 Merged This adds a flag to ProxyRequest to disable the setting of x-forwarded-[for|port|proto] #73 Fixed Merge branch 'patch-1' of https://github.com/KimSchneider/node-http-proxy #80 Commits [minor] Style updates and whitespace cleaning for consistency f0917a3 [api] refactor out middlewares from examples. 2cf4e0a [docs] add middleware examples (first draft) 020290a [fix] use routing table mhen proxying WebSockets. efa17ef Tested & fixed url middleware example, added comments. 4cc18f4 [minor] add middleware to node-http-proxy b54666f [minor] add middleware to node-http-proxy c773eed [minor] add url-proxying middleware example 45f3df8 [fix] Removed bad example. 2626308 [minor] add example to test concurrency 6ec8d6c [minor] add example of using middleware to gzip response d3c0697 support old (port,host) and (options) style when using middlewares 7976de1 [minor] Added body decoder middleware example. Needs fixing. 8eaec35 [minor dist] Use pkginfo. Minor updates to variable scoping in .createServer() 5d0bbb3 [doc] add comments to examples/url-middleware.js f6484de Handle cases where res.write throws be3a0d8 [minor] code style changes 8b48b7e [doc] note in readme about middleware b5d5eaa Allow forwarding for x-forwarded-[for|port|proto] to enabled layering of http-proxies. 404818b [style] tidy 0f8fe8e [fix] do not use middleware code if it's not needed 2012588 [minor] minor fixes to gzip middleware example caa1f49 [minor] default enableXForwarded to true e3d95ec Updating to enableXForwarded ee3506a [api] Expose adapted version of stack so it can be used with HttpProxy instances not created by httpProxy.createServer() 5d6e6b9 The number of maxSockets has to be set after the agent is created. Setting the property in the constructor does not work. 2caa5d2 [fix] Dont use res.* in proxyWebSocketRequest f7452bc [fix] fix syntax errors. close issue #86 b8f8499 [api] merge middleware branch e6ff8d6 [dist] Version bump. 0.6.3 1389b70 merged 5ba0f89 [fix] handler variable in createServer was global (!) 25c06a3 [dist] bump version 6.0 03475a5 [dist] bump version 0.6.2 d8068a8 [dist] bump version 5.12 5d33ad7 [dist] bump version 0.6.1 fea371d [fix] broken RegExp 549bfea [doc] add note on middleware to Using node-http-proxy section of the README 5bf2d59 v0.5.11 - 2011-06-26 Fixed [api] Simplify the usage for the .changeHeaders option. Fixes #34 #34 Commits [api doc test] node-http-proxy now emits websocket:* on important WebSocket events. Added tests for these features and updated some code docs 4f85ca0 [doc] Updated docco docs f0649d8 [doc] Added examples/latent-websocket-proxy.js fcfe846 [doc] Added sample for custom error messages using the proxyError event 4cdbf0e [doc] Add examples/standalone-websocket-proxy.js 1ee8ae7 [dist] Version bump. 0.5.11 baf0b9e [doc] Small update to code docs 9d9509f [minor] Add missing space b608a02 v0.5.10 - 2011-06-13 Commits [refactor] Manage our own internal list of Agent instances 887c580 [doc] Update docco docs for 0.5.9 b4ac4d4 [test] Update tests to use localhost a1cdf00 [dist] Version bump. 0.5.10 7b574d3 [doc] Bump version in README.md 653c6ca v0.5.9 - 2011-05-23 Commits [fix] Change sec-websocket-location header when proxying WSS --> WS. Added test coverage for this scenario 028d204 [dist] Version bump. 0.5.9 57ca62c v0.5.8 - 2011-05-21 Commits [doc] Regenerate docco docs c5fd368 [doc] Update docco docs 74120d8 [doc] Update to v0.5.7 in code and README.md 6fd272a [dist] Version bump. 0.5.8. Forwards compatible with new versions of nodejs 76ecb51 [fix] Dont force Connection: close now that Keep-Alive is supported a86d18b [test] Update to vows description for web-socket-proxy-test.js a865fe6 v0.5.7 - 2011-05-19 Commits [api] Add x-forwarded-proto and x-forwarded-port to proxied HTTP requests 421895f [dist] Version bump. v0.5.7. Only good on node v0.4.7. See issue #48. 0911c17 [fix] Set x-forwarded-for from req.connection.socket.remoteAddress if req.connection.remoteAddress is not defined e9b3ec9 v0.5.6 - 2011-05-19 Commits [fix doc] Add error handler to reverseProxy request when proxying WebSockets to prevent unhandled ParseError. Rename some variables in proxyWebSocketRequest to make the code more readable 76580c2 [doc] Regenerate docco docs bd45216 [api minor] Small refactor to emit webSocketProxyError from a single helper function on any of the various error events in the proxy chain 5d2192e [api] Manual merge of #46: add custom proxyError event and enable production error handling. 652cca3 [dist] Version bump. v0.5.6 Only good on node v0.4.7. See issue #48. f1c0f64 v0.5.5 - 2011-05-19 Commits [fix] Change variable references for Websockets, bugs found from using wsbench 7bf0cae [dist] Version bump. 0.5.5. Only good on node v0.4.7. See issue #48. acacc05 v0.5.4 - 2011-05-19 Commits [doc] Update docco docs faf2618 [doc] Update README.md to reflect the new HTTPS to HTTP proxy capabilities abc01bc [doc test api] Improve node-http-proxy API to allow for HTTPS to HTTP proxying scenarios. Update tests accordingly. 895f577 [doc] Update examples for HTTPS to HTTP proxying 91737fa [dist] Version bump. 0.5.4. Only good on node v0.4.7. See issue #48. c04eec1 [minor] Update README.md to conform to Github flavored markdown 32a15dd [minor] Update README.md to conform to Github flavored markdown 521fe27 v0.5.3 - 2011-05-18 Commits [test] Continued work around Origin mismatch tests 44a8566 [doc] Regenerate docco docs 9e36d2d [fix test api] Only change Origin headers in WebSocket requests when the changeOrigin option is set explicitly. Added tests to ensure Origin and sec-websocket-origin headers match when proxying websockets. 9c6c4b9 [test] Improve websocket tests to inspect outgoing and incoming HTTP headers to test origin mismatch bugs 6e679c8 [test] Refined tests to begin checking Origin == Sec-Websocket-Origin 9ab54ab [doc minor] Update docs and code docs for v0.5.3 release 03b9087 [dist] Version bump. v0.5.3. Only good on node v0.4.7. See issue #48. d9fa261 v0.5.2 - 2011-05-17 Merged Readme: fix syntax error, reformat code blocks #52 Commits format markdown for syntax highlighting on GitHub 28f6dc1 [doc] Regenerate docco docs a5e1e3e [test] Fix tests in https mode 1ee6bef [fix] Manage bookkeeping for incoming requests to the underlying sockets behind reverse proxied websocket events. Only use the appropriate variables in the closure scope of the upgrade event from this bookkeeping 85223ea [minor] Fix syntax in examples/ ff82946 add spacing around code blocks to fix README rendering ab8c264 [dist] Use devDependencies in package.json e6c52d4 don't highlight non-javascript as javascript d5b9ba7 fix syntax error in README example 332d2d7 [minor] Ignore npm modules and debug logs e90cbd6 [dist] Include docco module as a dev dependency d08c2bb [dist] Version bump. 0.5.2. Only good on node v0.4.7. See issue #48. 360e79a v0.5.1 - 2011-05-10 Commits [dist] Version bump. 0.5.1. Only good on node v0.4.7. See issue #48. 6c80177 Revert \"Fixed \"Invalid argument to getAgent\" when proxying HTTP\" 40dc9de [fix] Fix typo in bin/node-http-proxy 57127a3 Merged pull request #39 from timmattison/master. ac425d7 Fixed \"Invalid argument to getAgent\" when proxying HTTP 642e158 v0.5.0 - 2011-04-17 Commits [doc] Breakout demo.js into files in example/. Add web-socket-proxy.js example 6e4bf6a [api test doc] Improve HTTPS support. Update minor documentation. Change tests accordingly. bf68dc3 [api] Update WebSocket support to use http.Agent APIs b0b0183 [api] Update .proxyRequest() and .proxyWebSocketRequest() APIs to take an options hash instead of a set of arguments. Add HTTPS support. cfddd12 [doc api] Update README.md and CHANGELOG.md for v0.5.0. Update bin/node-http-proxy to read files specified in config.https 212009d [test] Add WebSocket tests 4d18ac1 [doc] Regenerate docco docs c485c87 [doc test] Small updates to README.md. Update to try require socket.io 12064d8 [api] Remove winston logging in favor of custom events a89b397 [doc] Update README.md bd6a262 [dist] Version bump. v0.5.0 ddf31b2 [api] Update request event to be consistent by emitting both req and res. Add x-forwarded-for header. a3cb527 [api] Emit end event when done proxying 5681fc1 [minor] Small update to README.md 40c51a7 [dist] Move pgriess' websocket client into vendor/* 7cbf447 v0.4.2 - 2011-04-13 Commits [dist] Version bump. 0.4.2. Remove eyes dependency. a5d88aa v0.4.1 - 2011-03-20 Commits [dist] Version bump. 0.4.1. Fix package.json 0d1a3fe v0.4.0 - 2011-03-20 Commits [api] Further work on refactor for node 0.4.0 e39a9f9 [doc] Added docco generated literate coding documentation 3bc7d16 [doc api test] Wrap things up for v0.4.0 release: Add hostnameOnly routing to ProxyTable, add more documentation, fix edge-cases until they can be further investigated in node.js core 5715318 [api] First pass at removing pool and working with node v0.4.0 9faa924 [doc api test] Rename HttpProxy.pause to HttpProxy.resume. Update documentation and tests accordingly 4110448 [doc] Added more documentation 973f19f [doc] Regenerate docco docs 6c42f04 [api] Force connection header to be close until keep-alive is replemented 3fd3c96 [dist] Version bump. 0.4.0 cbb5fbc [api test] All tests are passing when run as individual files 389159d [minor doc] Update demo and small fix to node-http-proxy d8c5406 [fix] Fixed cli parsing issue when --argument=value is not used 34cba38 [test] Small update to proxy-table-test.js 3588687 [minor] Expose version on module 1dd9b3b [doc] Update to v0.3.1 in README.md 8ef2e1f [dist] Change package.json for npm version bump 0e7f362 v0.3.1 - 2010-11-22 Commits [api test doc] Updated tests. Added ProxyTable functionality bedc7a3 [test] Simplified tests. Added tests for experimental websocket support 8c3e993 [test doc api] Added forward proxy functionality with tests c06f4bf [dist minor] Removed vendored pool. Changed all references of sys to util 8251296 WebSocket proxy support, fixed 304 code halting 7249ef3 [api] pseduo-vendor pool until pull request is finalized 7c2eb5d No-server fix f84880f [api test bin doc] Added bin script and simple logging 00014d6 [debug] Removed pool as a dependency for stress test 73381cf 'end' event becomes 'close', added more try-catch handling cd78af5 Added support of automatic websocket tunneling, added test for it 56003b5 [debug] Better debug messages to try to determine if pool is slowly losing clients to forever busy dd1918d [doc dist] Version bump. Added CHANGELOG.md de53d5e Moved error handling to response.on('end'), fixed error handling in websocket's part 7e61f0c [minor] Pushing hot-fix from Mikeal for vendored pool repo 60791f3 [api] Integrated commits from donnerjack and worked on pool changes 3bb458e [doc] Updated Copyright ... added Fedor 9128a8c [minor] Listen to error event on pool so we dont fail out unexpectedly anymore 711258e adding more debugging messages 5d54ea5 adding some debug messages for live testing 4069a7e [minor] Listen to error events re-emitted by pool into the ClientRequest f8bff4c [minor] Updated max clients for pool 32aaf74 [debug] Trying to repair pool busy client growth 7b0ea85 [debug] Roll back last commit ... connection = close was ineffective 266e524 v0.3.0 - 2010-09-10 Commits [api] Revert to old 0.1.x codebase for bug testing and performance comparison 66afb2a [api test dist doc] Updated for 0.3.0 release a9084b9 [api] Object creation is cheap for HttpProxy, so lets take advantage 9f0aeac [doc] Update contributors for 0.3.0 6d47d98 v0.2.0 - 2010-09-07 Commits [dist] Version bump and update to README + LICENCE. Word to Mikeal for coming thru for 0.2.0 69c162d [api dist] Merge of branch 0.2.0 fd61828 [api] Completely refactored node-http-proxy with help from Mikeal 1221939 [api minor debug] Remove debug code, set Connection header if not set 6d08f24 [debug] Added some debugging to figure out why AB wont complete a test with v0.2.0 9715ebd [api] Integrated a little more from Mikeal to make our return headers consistent eb39018 [doc] Updated README.md f291efb v0.1.5 - 2010-09-02 Commits [api] More changes for createServer api 5d94ae2 added colors and asciimo d490b50 [api] First commit of http-proxy 30b68c1 updating demo c4b7c0d initial release v0.1.0, sure to have many updates coming. 85f7372 fleshing out demo 994f748 [docs] added benchmarks bbed176 updated paths to use npm 972c8c0 added spark demo d0ad931 [test] Updated tests to include support for latent requests 095e86a started to flesh out simple demo based on tests 2fb5ffb added createServer but hated it, gonna remove b1eb13e [test] Updated node-http-proxy tests 2f265a2 [api] Updated request hashes to use a unique identifier c887a75 [api] Updated http-proxy to work with vows ead7567 [dist] Renamed node-proxy to node-http-proxy, updated package.json 2f49810 updating docs, almost there 6e651f4 changed api to better reflect nodes api. updated demos, tests, docs bde98f4 updating docs 341bbd4 fixed npm package, i think. bumped version 0.1.1 fca40da updated demo b622702 added readme d6a2f8a [api] Corrected chain of argument passing da55777 updated demo e9511ea [deploy] Added package.json dce80b9 updated readme 76d0649 update to docs and package.json d15bba4 [minor] Removed eyes dependency eaeed83 merge 93505a4 fixed additional port / server mismatches for new api 15c18b6 [doc] added nodejitsu.com link to ReadMe. http-proxy is used in our front facing load-balancers. look for bugs...try to improve benchmarks.... ^_^ 6661753 removed extra self, updated colors requirement, bumped to version 0.1.3 9bc5b6f fixed pathing issue, bumped version 0.1.3 ede6490 updated docs 07d96bb updated docs 1594367 updated readme fb8c5ab updated docs 17b6c69 updated docs c8dd8c4 updated package.json again ddba155 initial release v0.1.0, sure to have many updates coming. 6a1baa2 bumped to version 0.1.5 b195a16 updated readme 9aa2216 added spark demo d408e39 bumped to version 0.1.4. improved on api 82b8228 initial release v0.1.0, sure to have many updates coming. 1e04552 updated readme 0a2eaaa updating docs 198000f [api] Added createServer api to node-http-proxy 2e2b55f"
  },
  "node_modules/http-proxy/CODE_OF_CONDUCT.html": {
    "href": "node_modules/http-proxy/CODE_OF_CONDUCT.html",
    "title": "Contributor Covenant Code of Conduct | accouter",
    "keywords": "Contributor Covenant Code of Conduct Our Pledge In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation. Our Standards Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Our Responsibilities Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful. Scope This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers. Enforcement Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at https://github.com/http-party/node-http-proxy. All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership. Attribution This Code of Conduct is adapted from the Contributor Covenant, version 1.4, available at http://contributor-covenant.org/version/1/4"
  },
  "node_modules/http-proxy/README.html": {
    "href": "node_modules/http-proxy/README.html",
    "title": "node-http-proxy | accouter",
    "keywords": "node-http-proxy node-http-proxy is an HTTP programmable proxying library that supports websockets. It is suitable for implementing components such as reverse proxies and load balancers. Table of Contents Installation Upgrading from 0.8.x ? Core Concept Use Cases Setup a basic stand-alone proxy server Setup a stand-alone proxy server with custom server logic Setup a stand-alone proxy server with proxy request header re-writing Modify a response from a proxied server Setup a stand-alone proxy server with latency Using HTTPS Proxying WebSockets Options Listening for proxy events Shutdown Miscellaneous Test ProxyTable API Logo Contributing and Issues License Installation npm install http-proxy --save Back to top Upgrading from 0.8.x ? Click here Back to top Core Concept A new proxy is created by calling createProxyServer and passing an options object as argument (valid properties are available here) var httpProxy = require('http-proxy'); var proxy = httpProxy.createProxyServer(options); // See (†) †Unless listen(..) is invoked on the object, this does not create a webserver. See below. An object will be returned with four methods: web req, res, [options] (used for proxying regular HTTP(S) requests) ws req, socket, head, [options] (used for proxying WS(S) requests) listen port (a function that wraps the object in a webserver, for your convenience) close [callback] (a function that closes the inner webserver and stops listening on given port) It is then possible to proxy requests by calling these functions http.createServer(function(req, res) { proxy.web(req, res, { target: 'http://mytarget.com:8080' }); }); Errors can be listened on either using the Event Emitter API proxy.on('error', function(e) { ... }); or using the callback API proxy.web(req, res, { target: 'http://mytarget.com:8080' }, function(e) { ... }); When a request is proxied it follows two different pipelines (available here) which apply transformations to both the req and res object. The first pipeline (incoming) is responsible for the creation and manipulation of the stream that connects your client to the target. The second pipeline (outgoing) is responsible for the creation and manipulation of the stream that, from your target, returns data to the client. Back to top Use Cases Setup a basic stand-alone proxy server var http = require('http'), httpProxy = require('http-proxy'); // // Create your proxy server and set the target in the options. // httpProxy.createProxyServer({target:'http://localhost:9000'}).listen(8000); // See (†) // // Create your target server // http.createServer(function (req, res) { res.writeHead(200, { 'Content-Type': 'text/plain' }); res.write('request successfully proxied!' + '\\n' + JSON.stringify(req.headers, true, 2)); res.end(); }).listen(9000); †Invoking listen(..) triggers the creation of a web server. Otherwise, just the proxy instance is created. Back to top Setup a stand-alone proxy server with custom server logic This example shows how you can proxy a request using your own HTTP server and also you can put your own logic to handle the request. var http = require('http'), httpProxy = require('http-proxy'); // // Create a proxy server with custom application logic // var proxy = httpProxy.createProxyServer({}); // // Create your custom server and just call `proxy.web()` to proxy // a web request to the target passed in the options // also you can use `proxy.ws()` to proxy a websockets request // var server = http.createServer(function(req, res) { // You can define here your custom logic to handle the request // and then proxy the request. proxy.web(req, res, { target: 'http://127.0.0.1:5050' }); }); console.log(\"listening on port 5050\") server.listen(5050); Back to top Setup a stand-alone proxy server with proxy request header re-writing This example shows how you can proxy a request using your own HTTP server that modifies the outgoing proxy request by adding a special header. var http = require('http'), httpProxy = require('http-proxy'); // // Create a proxy server with custom application logic // var proxy = httpProxy.createProxyServer({}); // To modify the proxy connection before data is sent, you can listen // for the 'proxyReq' event. When the event is fired, you will receive // the following arguments: // (http.ClientRequest proxyReq, http.IncomingMessage req, // http.ServerResponse res, Object options). This mechanism is useful when // you need to modify the proxy request before the proxy connection // is made to the target. // proxy.on('proxyReq', function(proxyReq, req, res, options) { proxyReq.setHeader('X-Special-Proxy-Header', 'foobar'); }); var server = http.createServer(function(req, res) { // You can define here your custom logic to handle the request // and then proxy the request. proxy.web(req, res, { target: 'http://127.0.0.1:5050' }); }); console.log(\"listening on port 5050\") server.listen(5050); Back to top Modify a response from a proxied server Sometimes when you have received a HTML/XML document from the server of origin you would like to modify it before forwarding it on. Harmon allows you to do this in a streaming style so as to keep the pressure on the proxy to a minimum. Back to top Setup a stand-alone proxy server with latency var http = require('http'), httpProxy = require('http-proxy'); // // Create a proxy server with latency // var proxy = httpProxy.createProxyServer(); // // Create your server that makes an operation that waits a while // and then proxies the request // http.createServer(function (req, res) { // This simulates an operation that takes 500ms to execute setTimeout(function () { proxy.web(req, res, { target: 'http://localhost:9008' }); }, 500); }).listen(8008); // // Create your target server // http.createServer(function (req, res) { res.writeHead(200, { 'Content-Type': 'text/plain' }); res.write('request successfully proxied to: ' + req.url + '\\n' + JSON.stringify(req.headers, true, 2)); res.end(); }).listen(9008); Back to top Using HTTPS You can activate the validation of a secure SSL certificate to the target connection (avoid self-signed certs), just set secure: true in the options. HTTPS -> HTTP // // Create the HTTPS proxy server in front of a HTTP server // httpProxy.createServer({ target: { host: 'localhost', port: 9009 }, ssl: { key: fs.readFileSync('valid-ssl-key.pem', 'utf8'), cert: fs.readFileSync('valid-ssl-cert.pem', 'utf8') } }).listen(8009); HTTPS -> HTTPS // // Create the proxy server listening on port 443 // httpProxy.createServer({ ssl: { key: fs.readFileSync('valid-ssl-key.pem', 'utf8'), cert: fs.readFileSync('valid-ssl-cert.pem', 'utf8') }, target: 'https://localhost:9010', secure: true // Depends on your needs, could be false. }).listen(443); HTTP -> HTTPS (using a PKCS12 client certificate) // // Create an HTTP proxy server with an HTTPS target // httpProxy.createProxyServer({ target: { protocol: 'https:', host: 'my-domain-name', port: 443, pfx: fs.readFileSync('path/to/certificate.p12'), passphrase: 'password', }, changeOrigin: true, }).listen(8000); Back to top Proxying WebSockets You can activate the websocket support for the proxy using ws:true in the options. // // Create a proxy server for websockets // httpProxy.createServer({ target: 'ws://localhost:9014', ws: true }).listen(8014); Also you can proxy the websocket requests just calling the ws(req, socket, head) method. // // Setup our server to proxy standard HTTP requests // var proxy = new httpProxy.createProxyServer({ target: { host: 'localhost', port: 9015 } }); var proxyServer = http.createServer(function (req, res) { proxy.web(req, res); }); // // Listen to the `upgrade` event and proxy the // WebSocket requests as well. // proxyServer.on('upgrade', function (req, socket, head) { proxy.ws(req, socket, head); }); proxyServer.listen(8015); Back to top Options httpProxy.createProxyServer supports the following options: target: url string to be parsed with the url module forward: url string to be parsed with the url module agent: object to be passed to http(s).request (see Node's https agent and http agent objects) ssl: object to be passed to https.createServer() ws: true/false, if you want to proxy websockets xfwd: true/false, adds x-forward headers secure: true/false, if you want to verify the SSL Certs toProxy: true/false, passes the absolute URL as the path (useful for proxying to proxies) prependPath: true/false, Default: true - specify whether you want to prepend the target's path to the proxy path ignorePath: true/false, Default: false - specify whether you want to ignore the proxy path of the incoming request (note: you will have to append / manually if required). localAddress: Local interface string to bind for outgoing connections changeOrigin: true/false, Default: false - changes the origin of the host header to the target URL preserveHeaderKeyCase: true/false, Default: false - specify whether you want to keep letter case of response header key auth: Basic authentication i.e. 'user:password' to compute an Authorization header. hostRewrite: rewrites the location hostname on (201/301/302/307/308) redirects. autoRewrite: rewrites the location host/port on (201/301/302/307/308) redirects based on requested host/port. Default: false. protocolRewrite: rewrites the location protocol on (201/301/302/307/308) redirects to 'http' or 'https'. Default: null. cookieDomainRewrite: rewrites domain of set-cookie headers. Possible values: false (default): disable cookie rewriting String: new domain, for example cookieDomainRewrite: \"new.domain\". To remove the domain, use cookieDomainRewrite: \"\". Object: mapping of domains to new domains, use \"*\" to match all domains. For example keep one domain unchanged, rewrite one domain and remove other domains: cookieDomainRewrite: { \"unchanged.domain\": \"unchanged.domain\", \"old.domain\": \"new.domain\", \"*\": \"\" } cookiePathRewrite: rewrites path of set-cookie headers. Possible values: false (default): disable cookie rewriting String: new path, for example cookiePathRewrite: \"/newPath/\". To remove the path, use cookiePathRewrite: \"\". To set path to root use cookiePathRewrite: \"/\". Object: mapping of paths to new paths, use \"*\" to match all paths. For example, to keep one path unchanged, rewrite one path and remove other paths: cookiePathRewrite: { \"/unchanged.path/\": \"/unchanged.path/\", \"/old.path/\": \"/new.path/\", \"*\": \"\" } headers: object with extra headers to be added to target requests. proxyTimeout: timeout (in millis) for outgoing proxy requests timeout: timeout (in millis) for incoming requests followRedirects: true/false, Default: false - specify whether you want to follow redirects selfHandleResponse true/false, if set to true, none of the webOutgoing passes are called and it's your responsibility to appropriately return the response by listening and acting on the proxyRes event buffer: stream of data to send as the request body. Maybe you have some middleware that consumes the request stream before proxying it on e.g. If you read the body of a request into a field called 'req.rawbody' you could restream this field in the buffer option: 'use strict'; const streamify = require('stream-array'); const HttpProxy = require('http-proxy'); const proxy = new HttpProxy(); module.exports = (req, res, next) => { proxy.web(req, res, { target: 'http://localhost:4003/', buffer: streamify(req.rawBody) }, next); }; NOTE: options.ws and options.ssl are optional. options.target and options.forward cannot both be missing If you are using the proxyServer.listen method, the following options are also applicable: ssl: object to be passed to https.createServer() ws: true/false, if you want to proxy websockets Back to top Listening for proxy events error: The error event is emitted if the request to the target fail. We do not do any error handling of messages passed between client and proxy, and messages passed between proxy and target, so it is recommended that you listen on errors and handle them. proxyReq: This event is emitted before the data is sent. It gives you a chance to alter the proxyReq request object. Applies to \"web\" connections proxyReqWs: This event is emitted before the data is sent. It gives you a chance to alter the proxyReq request object. Applies to \"websocket\" connections proxyRes: This event is emitted if the request to the target got a response. open: This event is emitted once the proxy websocket was created and piped into the target websocket. close: This event is emitted once the proxy websocket was closed. (DEPRECATED) proxySocket: Deprecated in favor of open. var httpProxy = require('http-proxy'); // Error example // // Http Proxy Server with bad target // var proxy = httpProxy.createServer({ target:'http://localhost:9005' }); proxy.listen(8005); // // Listen for the `error` event on `proxy`. proxy.on('error', function (err, req, res) { res.writeHead(500, { 'Content-Type': 'text/plain' }); res.end('Something went wrong. And we are reporting a custom error message.'); }); // // Listen for the `proxyRes` event on `proxy`. // proxy.on('proxyRes', function (proxyRes, req, res) { console.log('RAW Response from the target', JSON.stringify(proxyRes.headers, true, 2)); }); // // Listen for the `open` event on `proxy`. // proxy.on('open', function (proxySocket) { // listen for messages coming FROM the target here proxySocket.on('data', hybiParseAndLogMessage); }); // // Listen for the `close` event on `proxy`. // proxy.on('close', function (res, socket, head) { // view disconnected websocket connections console.log('Client disconnected'); }); Back to top Shutdown When testing or running server within another program it may be necessary to close the proxy. This will stop the proxy from accepting new connections. var proxy = new httpProxy.createProxyServer({ target: { host: 'localhost', port: 1337 } }); proxy.close(); Back to top Miscellaneous If you want to handle your own response after receiving the proxyRes, you can do so with selfHandleResponse. As you can see below, if you use this option, you are able to intercept and read the proxyRes but you must also make sure to reply to the res itself otherwise the original client will never receive any data. Modify response var option = { target: target, selfHandleResponse : true }; proxy.on('proxyRes', function (proxyRes, req, res) { var body = []; proxyRes.on('data', function (chunk) { body.push(chunk); }); proxyRes.on('end', function () { body = Buffer.concat(body).toString(); console.log(\"res from proxied server:\", body); res.end(\"my response to cli\"); }); }); proxy.web(req, res, option); ProxyTable API A proxy table API is available through this add-on module, which lets you define a set of rules to translate matching routes to target routes that the reverse proxy will talk to. Test $ npm test Logo Logo created by Diego Pasquali Back to top Contributing and Issues Read carefully our Code Of Conduct Search on Google/Github If you can't find anything, open an issue If you feel comfortable about fixing the issue, fork the repo Commit to your local branch (which must be different from master) Submit your Pull Request (be sure to include tests and update documentation) Back to top License The MIT License (MIT) Copyright (c) 2010 - 2016 Charlie Robbins, Jarrett Cruger & the Contributors. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/iconv-lite/Changelog.html": {
    "href": "node_modules/iconv-lite/Changelog.html",
    "title": "0.4.24 / 2018-08-22 | accouter",
    "keywords": "0.4.24 / 2018-08-22 Added MIK encoding (#196, by @Ivan-Kalatchev) 0.4.23 / 2018-05-07 Fix deprecation warning in Node v10 due to the last usage of new Buffer (#185, by @felixbuenemann) Switched from NodeBuffer to Buffer in typings (#155 by @felixfbecker, #186 by @larssn) 0.4.22 / 2018-05-05 Use older semver style for dependencies to be compatible with Node version 0.10 (#182, by @dougwilson) Fix tests to accomodate fixes in Node v10 (#182, by @dougwilson) 0.4.21 / 2018-04-06 Fix encoding canonicalization (#156) Fix the paths in the \"browser\" field in package.json (#174 by @LMLB) Removed \"contributors\" section in package.json - see Git history instead. 0.4.20 / 2018-04-06 Updated new Buffer() usages with recommended replacements as it's being deprecated in Node v10 (#176, #178 by @ChALkeR) 0.4.19 / 2017-09-09 Fixed iso8859-1 codec regression in handling untranslatable characters (#162, caused by #147) Re-generated windows1255 codec, because it was updated in iconv project Fixed grammar in error message when iconv-lite is loaded with encoding other than utf8 0.4.18 / 2017-06-13 Fixed CESU-8 regression in Node v8. 0.4.17 / 2017-04-22 Updated typescript definition file to support Angular 2 AoT mode (#153 by @larssn) 0.4.16 / 2017-04-22 Added support for React Native (#150) Changed iso8859-1 encoding to usine internal 'binary' encoding, as it's the same thing (#147 by @mscdex) Fixed typo in Readme (#138 by @jiangzhuo) Fixed build for Node v6.10+ by making correct version comparison Added a warning if iconv-lite is loaded not as utf-8 (see #142) 0.4.15 / 2016-11-21 Fixed typescript type definition (#137) 0.4.14 / 2016-11-20 Preparation for v1.0 Added Node v6 and latest Node versions to Travis CI test rig Deprecated Node v0.8 support Typescript typings (@larssn) Fix encoding of Euro character in GB 18030 (inspired by @lygstate) Add ms prefix to dbcs windows encodings (@rokoroku) 0.4.13 / 2015-10-01 Fix silly mistake in deprecation notice. 0.4.12 / 2015-09-26 Node v4 support: Added CESU-8 decoding (#106) Added deprecation notice for extendNodeEncodings Added Travis tests for Node v4 and io.js latest (#105 by @Mithgol) 0.4.11 / 2015-07-03 Added CESU-8 encoding. 0.4.10 / 2015-05-26 Changed UTF-16 endianness heuristic to take into account any ASCII chars, not just spaces. This should minimize the importance of \"default\" endianness. 0.4.9 / 2015-05-24 Streamlined BOM handling: strip BOM by default, add BOM when encoding if addBOM: true. Added docs to Readme. UTF16 now uses UTF16-LE by default. Fixed minor issue with big5 encoding. Added io.js testing on Travis; updated node-iconv version to test against. Now we just skip testing SBCS encodings that node-iconv doesn't support. (internal refactoring) Updated codec interface to use classes. Use strict mode in all files. 0.4.8 / 2015-04-14 added alias UNICODE-1-1-UTF-7 for UTF-7 encoding (#94) 0.4.7 / 2015-02-05 stop official support of Node.js v0.8. Should still work, but no guarantees. reason: Packages needed for testing are hard to get on Travis CI. work in environment where Object.prototype is monkey patched with enumerable props (#89). 0.4.6 / 2015-01-12 fix rare aliases of single-byte encodings (thanks @mscdex) double the timeout for dbcs tests to make them less flaky on travis 0.4.5 / 2014-11-20 fix windows-31j and x-sjis encoding support (@nleush) minor fix: undefined variable reference when internal error happens 0.4.4 / 2014-07-16 added encodings UTF-7 (RFC2152) and UTF-7-IMAP (RFC3501 Section 5.1.3) fixed streaming base64 encoding 0.4.3 / 2014-06-14 added encodings UTF-16BE and UTF-16 with BOM 0.4.2 / 2014-06-12 don't throw exception if extendNodeEncodings() is called more than once 0.4.1 / 2014-06-11 codepage 808 added 0.4.0 / 2014-06-10 code is rewritten from scratch all widespread encodings are supported streaming interface added browserify compatibility added (optional) extend core primitive encodings to make usage even simpler moved from vows to mocha as the testing framework"
  },
  "node_modules/iconv-lite/README.html": {
    "href": "node_modules/iconv-lite/README.html",
    "title": "| accouter",
    "keywords": "Pure JS character encoding conversion Doesn't need native code compilation. Works on Windows and in sandboxed environments like Cloud9. Used in popular projects like Express.js (body_parser), Grunt, Nodemailer, Yeoman and others. Faster than node-iconv (see below for performance comparison). Intuitive encode/decode API Streaming support for Node v0.10+ [Deprecated] Can extend Node.js primitives (buffers, streams) to support all iconv-lite encodings. In-browser usage via Browserify (~180k gzip compressed with Buffer shim included). Typescript type definition file included. React Native is supported (need to explicitly npm install two more modules: buffer and stream). License: MIT. Usage Basic API var iconv = require('iconv-lite'); // Convert from an encoded buffer to js string. str = iconv.decode(Buffer.from([0x68, 0x65, 0x6c, 0x6c, 0x6f]), 'win1251'); // Convert from js string to an encoded buffer. buf = iconv.encode(\"Sample input string\", 'win1251'); // Check if encoding is supported iconv.encodingExists(\"us-ascii\") Streaming API (Node v0.10+) // Decode stream (from binary stream to js strings) http.createServer(function(req, res) { var converterStream = iconv.decodeStream('win1251'); req.pipe(converterStream); converterStream.on('data', function(str) { console.log(str); // Do something with decoded strings, chunk-by-chunk. }); }); // Convert encoding streaming example fs.createReadStream('file-in-win1251.txt') .pipe(iconv.decodeStream('win1251')) .pipe(iconv.encodeStream('ucs2')) .pipe(fs.createWriteStream('file-in-ucs2.txt')); // Sugar: all encode/decode streams have .collect(cb) method to accumulate data. http.createServer(function(req, res) { req.pipe(iconv.decodeStream('win1251')).collect(function(err, body) { assert(typeof body == 'string'); console.log(body); // full request body string }); }); [Deprecated] Extend Node.js own encodings NOTE: This doesn't work on latest Node versions. See details. // After this call all Node basic primitives will understand iconv-lite encodings. iconv.extendNodeEncodings(); // Examples: buf = new Buffer(str, 'win1251'); buf.write(str, 'gbk'); str = buf.toString('latin1'); assert(Buffer.isEncoding('iso-8859-15')); Buffer.byteLength(str, 'us-ascii'); http.createServer(function(req, res) { req.setEncoding('big5'); req.collect(function(err, body) { console.log(body); }); }); fs.createReadStream(\"file.txt\", \"shift_jis\"); // External modules are also supported (if they use Node primitives, which they probably do). request = require('request'); request({ url: \"http://github.com/\", encoding: \"cp932\" }); // To remove extensions iconv.undoExtendNodeEncodings(); Supported encodings All node.js native encodings: utf8, ucs2 / utf16-le, ascii, binary, base64, hex. Additional unicode encodings: utf16, utf16-be, utf-7, utf-7-imap. All widespread singlebyte encodings: Windows 125x family, ISO-8859 family, IBM/DOS codepages, Macintosh family, KOI8 family, all others supported by iconv library. Aliases like 'latin1', 'us-ascii' also supported. All widespread multibyte encodings: CP932, CP936, CP949, CP950, GB2312, GBK, GB18030, Big5, Shift_JIS, EUC-JP. See all supported encodings on wiki. Most singlebyte encodings are generated automatically from node-iconv. Thank you Ben Noordhuis and libiconv authors! Multibyte encodings are generated from Unicode.org mappings and WHATWG Encoding Standard mappings. Thank you, respective authors! Encoding/decoding speed Comparison with node-iconv module (1000x256kb, on MacBook Pro, Core i5/2.6 GHz, Node v0.12.0). Note: your results may vary, so please always check on your hardware. operation iconv@2.1.4 iconv-lite@0.4.7 ---------------------------------------------------------- encode('win1251') ~96 Mb/s ~320 Mb/s decode('win1251') ~95 Mb/s ~246 Mb/s BOM handling Decoding: BOM is stripped by default, unless overridden by passing stripBOM: false in options (f.ex. iconv.decode(buf, enc, {stripBOM: false})). A callback might also be given as a stripBOM parameter - it'll be called if BOM character was actually found. If you want to detect UTF-8 BOM when decoding other encodings, use node-autodetect-decoder-stream module. Encoding: No BOM added, unless overridden by addBOM: true option. UTF-16 Encodings This library supports UTF-16LE, UTF-16BE and UTF-16 encodings. First two are straightforward, but UTF-16 is trying to be smart about endianness in the following ways: Decoding: uses BOM and 'spaces heuristic' to determine input endianness. Default is UTF-16LE, but can be overridden with defaultEncoding: 'utf-16be' option. Strips BOM unless stripBOM: false. Encoding: uses UTF-16LE and writes BOM by default. Use addBOM: false to override. Other notes When decoding, be sure to supply a Buffer to decode() method, otherwise bad things usually happen. Untranslatable characters are set to � or ?. No transliteration is currently supported. Node versions 0.10.31 and 0.11.13 are buggy, don't use them (see #65, #77). Testing $ git clone git@github.com:ashtuchkin/iconv-lite.git $ cd iconv-lite $ npm install $ npm test $ # To view performance: $ node test/performance.js $ # To view test coverage: $ npm run coverage $ open coverage/lcov-report/index.html"
  },
  "node_modules/ignore-by-default/README.html": {
    "href": "node_modules/ignore-by-default/README.html",
    "title": "ignore-by-default | accouter",
    "keywords": "ignore-by-default This is a package aimed at Node.js development tools. It provides a list of directories that should probably be ignored by such tools, e.g. when watching for file changes. It's used by AVA and nodemon. Please contribute! Installation npm install --save ignore-by-default Usage The ignore-by-default module exports a directories() function, which will return an array of directory names. These are the ones you should ignore. // ['.git', '.sass_cache', …] var ignoredDirectories = require('ignore-by-default').directories()"
  },
  "node_modules/ignore/README.html": {
    "href": "node_modules/ignore/README.html",
    "title": "ignore | accouter",
    "keywords": "Linux OS X Windows Coverage Downloads ignore ignore is a manager, filter and parser which implemented in pure JavaScript according to the .gitignore spec 2.22.1. ignore is used by eslint, gitbook and many others. Pay ATTENTION that minimatch (which used by fstream-ignore) does not follow the gitignore spec. To filter filenames according to a .gitignore file, I recommend this npm package, ignore. To parse an .npmignore file, you should use minimatch, because an .npmignore file is parsed by npm using minimatch and it does not work in the .gitignore way. Tested on ignore is fully tested, and has more than five hundreds of unit tests. Linux + Node: 0.8 - 7.x Windows + Node: 0.10 - 7.x, node < 0.10 is not tested due to the lack of support of appveyor. Actually, ignore does not rely on any versions of node specially. Since 4.0.0, ignore will no longer support node < 6 by default, to use in node < 6, require('ignore/legacy'). For details, see CHANGELOG. Table Of Main Contents Usage Pathname Conventions See Also: glob-gitignore matches files using patterns and filters them according to gitignore rules. Upgrade Guide Install npm i ignore Usage import ignore from 'ignore' const ig = ignore().add(['.abc/*', '!.abc/d/']) Filter the given paths const paths = [ '.abc/a.js', // filtered out '.abc/d/e.js' // included ] ig.filter(paths) // ['.abc/d/e.js'] ig.ignores('.abc/a.js') // true As the filter function paths.filter(ig.createFilter()); // ['.abc/d/e.js'] Win32 paths will be handled ig.filter(['.abc\\\\a.js', '.abc\\\\d\\\\e.js']) // if the code above runs on windows, the result will be // ['.abc\\\\d\\\\e.js'] Why another ignore? ignore is a standalone module, and is much simpler so that it could easy work with other programs, unlike isaacs's fstream-ignore which must work with the modules of the fstream family. ignore only contains utility methods to filter paths according to the specified ignore rules, so ignore never try to find out ignore rules by traversing directories or fetching from git configurations. ignore don't cares about sub-modules of git projects. Exactly according to gitignore man page, fixes some known matching issues of fstream-ignore, such as: '/*.js' should only match 'a.js', but not 'abc/a.js'. '**/foo' should match 'foo' anywhere. Prevent re-including a file if a parent directory of that file is excluded. Handle trailing whitespaces: 'a '(one space) should not match 'a '(two spaces). 'a \\ ' matches 'a ' All test cases are verified with the result of git check-ignore. Methods .add(pattern: string | Ignore): this .add(patterns: Array<string | Ignore>): this pattern String | Ignore An ignore pattern string, or the Ignore instance patterns Array<String | Ignore> Array of ignore patterns. Adds a rule or several rules to the current manager. Returns this Notice that a line starting with '#'(hash) is treated as a comment. Put a backslash ('\\') in front of the first hash for patterns that begin with a hash, if you want to ignore a file with a hash at the beginning of the filename. ignore().add('#abc').ignores('#abc') // false ignore().add('\\\\#abc').ignores('#abc') // true pattern could either be a line of ignore pattern or a string of multiple ignore patterns, which means we could just ignore().add() the content of a ignore file: ignore() .add(fs.readFileSync(filenameOfGitignore).toString()) .filter(filenames) pattern could also be an ignore instance, so that we could easily inherit the rules of another Ignore instance. .addIgnoreFile(path) REMOVED in 3.x for now. To upgrade ignore@2.x up to 3.x, use import fs from 'fs' if (fs.existsSync(filename)) { ignore().add(fs.readFileSync(filename).toString()) } instead. .filter(paths: Array<Pathname>): Array<Pathname> type Pathname = string Filters the given array of pathnames, and returns the filtered array. paths Array.<Pathname> The array of pathnames to be filtered. Pathname Conventions: 1. Pathname should be a path.relative()d pathname Pathname should be a string that have been path.join()ed, or the return value of path.relative() to the current directory, // WRONG, an error will be thrown ig.ignores('./abc') // WRONG, for it will never happen, and an error will be thrown // If the gitignore rule locates at the root directory, // `'/abc'` should be changed to `'abc'`. // ``` // path.relative('/', '/abc') -> 'abc' // ``` ig.ignores('/abc') // WRONG, that it is an absolute path on Windows, an error will be thrown ig.ignores('C:\\\\abc') // Right ig.ignores('abc') // Right ig.ignores(path.join('./abc')) // path.join('./abc') -> 'abc' In other words, each Pathname here should be a relative path to the directory of the gitignore rules. Suppose the dir structure is: /path/to/your/repo |-- a | |-- a.js | |-- .b | |-- .c |-- .DS_store Then the paths might be like this: [ 'a/a.js' '.b', '.c/.DS_store' ] 2. filenames and dirnames node-ignore does NO fs.stat during path matching, so for the example below: // First, we add a ignore pattern to ignore a directory ig.add('config/') // `ig` does NOT know if 'config', in the real world, // is a normal file, directory or something. ig.ignores('config') // `ig` treats `config` as a file, so it returns `false` ig.ignores('config/') // returns `true` Specially for people who develop some library based on node-ignore, it is important to understand that. Usually, you could use glob with option.mark = true to fetch the structure of the current directory: import glob from 'glob' glob('**', { // Adds a / character to directory matches. mark: true }, (err, files) => { if (err) { return console.error(err) } let filtered = ignore().add(patterns).filter(files) console.log(filtered) }) .ignores(pathname: Pathname): boolean new in 3.2.0 Returns Boolean whether pathname should be ignored. ig.ignores('.abc/a.js') // true .createFilter() Creates a filter function which could filter an array of paths with Array.prototype.filter. Returns function(path) the filter function. .test(pathname: Pathname) since 5.0.0 Returns TestResult interface TestResult { ignored: boolean // true if the `pathname` is finally unignored by some negative pattern unignored: boolean } {ignored: true, unignored: false}: the pathname is ignored {ignored: false, unignored: true}: the pathname is unignored {ignored: false, unignored: false}: the pathname is never matched by any ignore rules. static ignore.isPathValid(pathname): boolean since 5.0.0 Check whether the pathname is an valid path.relative()d path according to the convention. This method is NOT used to check if an ignore pattern is valid. ignore.isPathValid('./foo') // false ignore(options) options.ignorecase since 4.0.0 Similar as the core.ignorecase option of git-config, node-ignore will be case insensitive if options.ignorecase is set to true (the default value), otherwise case sensitive. const ig = ignore({ ignorecase: false }) ig.add('*.png') ig.ignores('*.PNG') // false options.ignoreCase?: boolean since 5.2.0 Which is alternative to options.ignoreCase options.allowRelativePaths?: boolean since 5.2.0 This option brings backward compatibility with projects which based on ignore@4.x. If options.allowRelativePaths is true, ignore will not check whether the given path to be tested is path.relative()d. However, passing a relative path, such as './foo' or '../foo', to test if it is ignored or not is not a good practise, which might lead to unexpected behavior ignore({ allowRelativePaths: true }).ignores('../foo/bar.js') // And it will not throw Upgrade Guide Upgrade 4.x -> 5.x Since 5.0.0, if an invalid Pathname passed into ig.ignores(), an error will be thrown, unless options.allowRelative = true is passed to the Ignore factory. While ignore < 5.0.0 did not make sure what the return value was, as well as .ignores(pathname: Pathname): boolean .filter(pathnames: Array<Pathname>): Array<Pathname> .createFilter(): (pathname: Pathname) => boolean .test(pathname: Pathname): {ignored: boolean, unignored: boolean} See the convention here for details. If there are invalid pathnames, the conversion and filtration should be done by users. import {isPathValid} from 'ignore' // introduced in 5.0.0 const paths = [ // invalid ////////////////// '', false, '../foo', '.', ////////////////// // valid 'foo' ] .filter(isValidPath) ig.filter(paths) Upgrade 3.x -> 4.x Since 4.0.0, ignore will no longer support node < 6, to use ignore in node < 6: var ignore = require('ignore/legacy') Upgrade 2.x -> 3.x All options of 2.x are unnecessary and removed, so just remove them. ignore() instance is no longer an EventEmitter, and all events are unnecessary and removed. .addIgnoreFile() is removed, see the .addIgnoreFile section for details. Collaborators @whitecolor Alex @SamyPesse Samy Pessé @azproduction Mikhail Davydov @TrySound Bogdan Chadkin @JanMattner Jan Mattner @ntwb Stephen Edgar @kasperisager Kasper Isager @sandersn Nathan Shively-Sanders"
  },
  "node_modules/immutable/README.html": {
    "href": "node_modules/immutable/README.html",
    "title": "Immutable collections for JavaScript | accouter",
    "keywords": "Immutable collections for JavaScript Immutable data cannot be changed once created, leading to much simpler application development, no defensive copying, and enabling advanced memoization and change detection techniques with simple logic. Persistent data presents a mutative API which does not update the data in-place, but instead always yields new updated data. Immutable.js provides many Persistent Immutable data structures including: List, Stack, Map, OrderedMap, Set, OrderedSet and Record. These data structures are highly efficient on modern JavaScript VMs by using structural sharing via hash maps tries and vector tries as popularized by Clojure and Scala, minimizing the need to copy or cache data. Immutable also provides a lazy Seq, allowing efficient chaining of collection methods like map and filter without creating intermediate representations. Create some Seq with Range and Repeat. Want to hear more? Watch the presentation about Immutable.js: Getting started Install immutable using npm. npm install immutable Then require it into any module. var Immutable = require('immutable'); var map1 = Immutable.Map({a:1, b:2, c:3}); var map2 = map1.set('b', 50); map1.get('b'); // 2 map2.get('b'); // 50 Browser To use immutable from a browser, download dist/immutable.min.js or use a CDN such as CDNJS or jsDelivr. Then, add it as a script tag to your page: <script src=\"immutable.min.js\"></script> <script> var map1 = Immutable.Map({a:1, b:2, c:3}); var map2 = map1.set('b', 50); map1.get('b'); // 2 map2.get('b'); // 50 </script> Or use an AMD loader (such as RequireJS): require(['./immutable.min.js'], function (Immutable) { var map1 = Immutable.Map({a:1, b:2, c:3}); var map2 = map1.set('b', 50); map1.get('b'); // 2 map2.get('b'); // 50 }); If you're using browserify, the immutable npm module also works from the browser. TypeScript Use these Immutable collections and sequences as you would use native collections in your TypeScript programs while still taking advantage of type generics, error detection, and auto-complete in your IDE. Just add a reference with a relative path to the type declarations at the top of your file. ///<reference path='./node_modules/immutable/dist/immutable.d.ts'/> import Immutable = require('immutable'); var map1: Immutable.Map<string, number>; map1 = Immutable.Map({a:1, b:2, c:3}); var map2 = map1.set('b', 50); map1.get('b'); // 2 map2.get('b'); // 50 The case for Immutability Much of what makes application development difficult is tracking mutation and maintaining state. Developing with immutable data encourages you to think differently about how data flows through your application. Subscribing to data events throughout your application creates a huge overhead of book-keeping which can hurt performance, sometimes dramatically, and creates opportunities for areas of your application to get out of sync with each other due to easy to make programmer error. Since immutable data never changes, subscribing to changes throughout the model is a dead-end and new data can only ever be passed from above. This model of data flow aligns well with the architecture of React and especially well with an application designed using the ideas of Flux. When data is passed from above rather than being subscribed to, and you're only interested in doing work when something has changed, you can use equality. Immutable collections should be treated as values rather than objects. While objects represents some thing which could change over time, a value represents the state of that thing at a particular instance of time. This principle is most important to understanding the appropriate use of immutable data. In order to treat Immutable.js collections as values, it's important to use the Immutable.is() function or .equals() method to determine value equality instead of the === operator which determines object reference identity. var map1 = Immutable.Map({a:1, b:2, c:3}); var map2 = map1.set('b', 2); assert(map1.equals(map2) === true); var map3 = map1.set('b', 50); assert(map1.equals(map3) === false); Note: As a performance optimization Immutable attempts to return the existing collection when an operation would result in an identical collection, allowing for using === reference equality to determine if something definitely has not changed. This can be extremely useful when used within memoization function which would prefer to re-run the function if a deeper equality check could potentially be more costly. The === equality check is also used internally by Immutable.is and .equals() as a performance optimization. If an object is immutable, it can be \"copied\" simply by making another reference to it instead of copying the entire object. Because a reference is much smaller than the object itself, this results in memory savings and a potential boost in execution speed for programs which rely on copies (such as an undo-stack). var map1 = Immutable.Map({a:1, b:2, c:3}); var clone = map1; JavaScript-first API While immutable is inspired by Clojure, Scala, Haskell and other functional programming environments, it's designed to bring these powerful concepts to JavaScript, and therefore has an Object-Oriented API that closely mirrors that of ES6 Array, Map, and Set. The difference for the immutable collections is that methods which would mutate the collection, like push, set, unshift or splice instead return a new immutable collection. Methods which return new arrays like slice or concat instead return new immutable collections. var list1 = Immutable.List.of(1, 2); var list2 = list1.push(3, 4, 5); var list3 = list2.unshift(0); var list4 = list1.concat(list2, list3); assert(list1.size === 2); assert(list2.size === 5); assert(list3.size === 6); assert(list4.size === 13); assert(list4.get(0) === 1); Almost all of the methods on Array will be found in similar form on Immutable.List, those of Map found on Immutable.Map, and those of Set found on Immutable.Set, including collection operations like forEach() and map(). var alpha = Immutable.Map({a:1, b:2, c:3, d:4}); alpha.map((v, k) => k.toUpperCase()).join(); // 'A,B,C,D' Accepts raw JavaScript objects. Designed to inter-operate with your existing JavaScript, immutable accepts plain JavaScript Arrays and Objects anywhere a method expects an Iterable with no performance penalty. var map1 = Immutable.Map({a:1, b:2, c:3, d:4}); var map2 = Immutable.Map({c:10, a:20, t:30}); var obj = {d:100, o:200, g:300}; var map3 = map1.merge(map2, obj); // Map { a: 20, b: 2, c: 10, d: 100, t: 30, o: 200, g: 300 } This is possible because immutable can treat any JavaScript Array or Object as an Iterable. You can take advantage of this in order to get sophisticated collection methods on JavaScript Objects, which otherwise have a very sparse native API. Because Seq evaluates lazily and does not cache intermediate results, these operations can be extremely efficient. var myObject = {a:1,b:2,c:3}; Immutable.Seq(myObject).map(x => x * x).toObject(); // { a: 1, b: 4, c: 9 } Keep in mind, when using JS objects to construct Immutable Maps, that JavaScript Object properties are always strings, even if written in a quote-less shorthand, while Immutable Maps accept keys of any type. var obj = { 1: \"one\" }; Object.keys(obj); // [ \"1\" ] obj[\"1\"]; // \"one\" obj[1]; // \"one\" var map = Immutable.fromJS(obj); map.get(\"1\"); // \"one\" map.get(1); // undefined Property access for JavaScript Objects first converts the key to a string, but since Immutable Map keys can be of any type the argument to get() is not altered. Converts back to raw JavaScript objects. All immutable Iterables can be converted to plain JavaScript Arrays and Objects shallowly with toArray() and toObject() or deeply with toJS(). All Immutable Iterables also implement toJSON() allowing them to be passed to JSON.stringify directly. var deep = Immutable.Map({ a: 1, b: 2, c: Immutable.List.of(3, 4, 5) }); deep.toObject() // { a: 1, b: 2, c: List [ 3, 4, 5 ] } deep.toArray() // [ 1, 2, List [ 3, 4, 5 ] ] deep.toJS() // { a: 1, b: 2, c: [ 3, 4, 5 ] } JSON.stringify(deep) // '{\"a\":1,\"b\":2,\"c\":[3,4,5]}' Embraces ES6 Immutable takes advantage of features added to JavaScript in ES6, the latest standard version of ECMAScript (JavaScript), including Iterators, Arrow Functions, Classes, and Modules. It's also inspired by the Map and Set collections added to ES6. The library is \"transpiled\" to ES3 in order to support all modern browsers. All examples are presented in ES6. To run in all browsers, they need to be translated to ES3. // ES6 foo.map(x => x * x); // ES3 foo.map(function (x) { return x * x; }); Nested Structures The collections in immutable are intended to be nested, allowing for deep trees of data, similar to JSON. var nested = Immutable.fromJS({a:{b:{c:[3,4,5]}}}); // Map { a: Map { b: Map { c: List [ 3, 4, 5 ] } } } A few power-tools allow for reading and operating on nested data. The most useful are mergeDeep, getIn, setIn, and updateIn, found on List, Map and OrderedMap. var nested2 = nested.mergeDeep({a:{b:{d:6}}}); // Map { a: Map { b: Map { c: List [ 3, 4, 5 ], d: 6 } } } nested2.getIn(['a', 'b', 'd']); // 6 var nested3 = nested2.updateIn(['a', 'b', 'd'], value => value + 1); // Map { a: Map { b: Map { c: List [ 3, 4, 5 ], d: 7 } } } var nested4 = nested3.updateIn(['a', 'b', 'c'], list => list.push(6)); // Map { a: Map { b: Map { c: List [ 3, 4, 5, 6 ], d: 7 } } } Lazy Seq Seq describes a lazy operation, allowing them to efficiently chain use of all the Iterable methods (such as map and filter). Seq is immutable — Once a Seq is created, it cannot be changed, appended to, rearranged or otherwise modified. Instead, any mutative method called on a Seq will return a new Seq. Seq is lazy — Seq does as little work as necessary to respond to any method call. For example, the following does not perform any work, because the resulting Seq is never used: var oddSquares = Immutable.Seq.of(1,2,3,4,5,6,7,8) .filter(x => x % 2).map(x => x * x); Once the Seq is used, it performs only the work necessary. In this example, no intermediate arrays are ever created, filter is called three times, and map is only called twice: console.log(oddSquares.get(1)); // 9 Any collection can be converted to a lazy Seq with .toSeq(). var seq = Immutable.Map({a:1, b:1, c:1}).toSeq(); Seq allow for the efficient chaining of sequence operations, especially when converting to a different concrete type (such as to a JS object): seq.flip().map(key => key.toUpperCase()).flip().toObject(); // Map { A: 1, B: 1, C: 1 } As well as expressing logic that would otherwise seem memory-limited: Immutable.Range(1, Infinity) .skip(1000) .map(n => -n) .filter(n => n % 2 === 0) .take(2) .reduce((r, n) => r * n, 1); // 1006008 Note: An iterable is always iterated in the same order, however that order may not always be well defined, as is the case for the Map. Equality treats Collections as Data Immutable provides equality which treats immutable data structures as pure data, performing a deep equality check if necessary. var map1 = Immutable.Map({a:1, b:1, c:1}); var map2 = Immutable.Map({a:1, b:1, c:1}); assert(map1 !== map2); // two different instances assert(Immutable.is(map1, map2)); // have equivalent values assert(map1.equals(map2)); // alternatively use the equals method Immutable.is() uses the same measure of equality as Object.is including if both are immutable and all keys and values are equal using the same measure of equality. Batching Mutations If a tree falls in the woods, does it make a sound? If a pure function mutates some local data in order to produce an immutable return value, is that ok? — Rich Hickey, Clojure Applying a mutation to create a new immutable object results in some overhead, which can add up to a minor performance penalty. If you need to apply a series of mutations locally before returning, Immutable gives you the ability to create a temporary mutable (transient) copy of a collection and apply a batch of mutations in a performant manner by using withMutations. In fact, this is exactly how Immutable applies complex mutations itself. As an example, building list2 results in the creation of 1, not 3, new immutable Lists. var list1 = Immutable.List.of(1,2,3); var list2 = list1.withMutations(function (list) { list.push(4).push(5).push(6); }); assert(list1.size === 3); assert(list2.size === 6); Note: immutable also provides asMutable and asImmutable, but only encourages their use when withMutations will not suffice. Use caution to not return a mutable copy, which could result in undesired behavior. Important!: Only a select few methods can be used in withMutations including set, push and pop. These methods can be applied directly against a persistent data-structure where other methods like map, filter, sort, and splice will always return new immutable data-structures and never mutate a mutable collection. Documentation Read the docs and eat your vegetables. Docs are automatically generated from Immutable.d.ts. Please contribute! Also, don't miss the Wiki which contains articles on specific topics. Can't find something? Open an issue. Testing If you are using the Chai Assertion Library, Chai Immutable provides a set of assertions to use against Immutable collections. Contribution Use Github issues for requests. We actively welcome pull requests, learn how to contribute. Changelog Changes are tracked as Github releases. Thanks Phil Bagwell, for his inspiration and research in persistent data structures. Hugh Jackson, for providing the npm package name. If you're looking for his unsupported package, see this repository. License Immutable.js is MIT-licensed."
  },
  "node_modules/immutable/contrib/cursor/README.html": {
    "href": "node_modules/immutable/contrib/cursor/README.html",
    "title": "| accouter",
    "keywords": "Cursors Cursors allow you to hold a reference to a path in a nested immutable data structure, allowing you to pass smaller sections of a larger nested collection to portions of your application while maintaining a central point aware of changes to the entire data structure: an onChange function which is called whenever a cursor or sub-cursor calls update. This is particularly useful when used in conjuction with component-based UI libraries like React or to simulate \"state\" throughout an application while maintaining a single flow of logic. var Immutable = require('immutable'); var Cursor = require('immutable/contrib/cursor'); var data = Immutable.fromJS({ a: { b: { c: 1 } } }); var cursor = Cursor.from(data, ['a', 'b'], newData => { data = newData; }); // ... elsewhere ... cursor.get('c'); // 1 cursor = cursor.update('c', x => x + 1); cursor.get('c'); // 2 // ... back to data ... data.getIn(['a', 'b', 'c']); // 2"
  },
  "node_modules/indent-string/readme.html": {
    "href": "node_modules/indent-string/readme.html",
    "title": "indent-string | accouter",
    "keywords": "indent-string Indent each line in a string Install $ npm install indent-string Usage import indentString from 'indent-string'; indentString('Unicorns\\nRainbows', 4); //=> ' Unicorns\\n Rainbows' indentString('Unicorns\\nRainbows', 4, {indent: '♥'}); //=> '♥♥♥♥Unicorns\\n♥♥♥♥Rainbows' API indentString(string, count?, options?) string Type: string The string to indent. count Type: number Default: 1 How many times you want options.indent repeated. options Type: object indent Type: string Default: ' ' The string to use for the indent. includeEmptyLines Type: boolean Default: false Also indent empty lines. Related indent-string-cli - CLI for this module strip-indent - Strip leading whitespace from every line in a string Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "node_modules/inflight/README.html": {
    "href": "node_modules/inflight/README.html",
    "title": "inflight | accouter",
    "keywords": "inflight Add callbacks to requests in flight to avoid async duplication USAGE var inflight = require('inflight') // some request that does some stuff function req(key, callback) { // key is any random string. like a url or filename or whatever. // // will return either a falsey value, indicating that the // request for this key is already in flight, or a new callback // which when called will call all callbacks passed to inflightk // with the same key callback = inflight(key, callback) // If we got a falsey value back, then there's already a req going if (!callback) return // this is where you'd fetch the url or whatever // callback is also once()-ified, so it can safely be assigned // to multiple events etc. First call wins. setTimeout(function() { callback(null, key) }, 100) } // only assigns a single setTimeout // when it dings, all cbs get called req('foo', cb1) req('foo', cb2) req('foo', cb3) req('foo', cb4)"
  },
  "node_modules/inherits/README.html": {
    "href": "node_modules/inherits/README.html",
    "title": "| accouter",
    "keywords": "Browser-friendly inheritance fully compatible with standard node.js inherits. This package exports standard inherits from node.js util module in node environment, but also provides alternative browser-friendly implementation through browser field. Alternative implementation is a literal copy of standard one located in standalone module to avoid requiring of util. It also has a shim for old browsers with no Object.create support. While keeping you sure you are using standard inherits implementation in node.js environment, it allows bundlers such as browserify to not include full util package to your client code if all you need is just inherits function. It worth, because browser shim for util package is large and inherits is often the single function you need from it. It's recommended to use this package instead of require('util').inherits for any code that has chances to be used not only in node.js but in browser too. usage var inherits = require('inherits'); // then use exactly as the standard one note on version ~1.0 Version ~1.0 had completely different motivation and is not compatible neither with 2.0 nor with standard node.js inherits. If you are using version ~1.0 and planning to switch to ~2.0, be careful: new version uses super_ instead of super for referencing superclass new version overwrites current prototype while old one preserves any existing fields on it"
  },
  "node_modules/internal-slot/CHANGELOG.html": {
    "href": "node_modules/internal-slot/CHANGELOG.html",
    "title": "| accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. Dates are displayed in UTC. Generated by auto-changelog. v1.0.7 5 February 2024 [Dev Deps] update aud, npmignore, tape 89c88c1 [Refactor] use es-errors, so things that only need those do not need get-intrinsic b437631 v1.0.6 20 October 2023 [Dev Deps] update @ljharb/eslint-config, aud, object-inspect, tape 4d568d2 [Refactor] use hasown instead of has f946e94 [Deps] update get-intrinsic 1bbc885 [meta] remove unused .eslintignore 6fdde1a v1.0.5 9 February 2023 [Dev Deps] update @ljharb/eslint-config, aud, object-inspect, tape e427703 [Deps] update get-intrinsic aa652f0 [Fix] improve assertion message 8df86e3 v1.0.4 13 December 2022 [actions] reuse common workflows 82a1aee [meta] use npmignore to autogenerate an npmignore file 56f7e71 [actions] use node/install instead of node/run; use codecov action e25ff67 [actions] update rebase action to use reusable workflow 227e81e [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, foreach, object-inspect, tape fc9f319 [Dev Deps] update eslint, @ljharb/eslint-config, auto-changelog, object-inspect, safe-publish-latest, tape 0a72a0f [actions] update codecov uploader e2b993f [Dev Deps] update eslint, @ljharb/eslint-config, aud, object-inspect, tape 8f0ab80 [actions] update checkout action 8da4b91 [Dev Deps] update eslint, @ljharb/eslint-config, @safe-publish-latest, tape 7ab37aa [readme] add github actions/codecov badges 71234be [Fix] assert: throw on a nonexistent slot even when an object already has other slots 12580bd [Tests] use for-each instead of foreach 7229df0 [meta] use prepublishOnly script for npm 7+ 8728872 [Deps] update get-intrinsic 1b7088f [Deps] update get-intrinsic 063621e v1.0.3 26 January 2021 [Tests] use shared travis-ci configs 0ef2263 [Tests] migrate tests to Github Actions 6253915 [meta] do not publish github action workflow files ef94e55 [Tests] run nyc on all tests; use tape runner 917d6ca [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, object-inspect, tape 8dcb6fe [actions] add \"Allow Edits\" workflow 7aa3e86 [Refactor] use get-intrinsic instead of es-abstract; update side-channel 11ad17d [readme] remove travis badge 5b75452 [actions] switch Automatic Rebase workflow to pull_request_target event d531688 [Dev Deps] update @ljharb/eslint-config, tape c76fa91 [Dev Deps] update eslint, tape e733ccd [Dev Deps] update auto-changelog; add aud df20bf5 [meta] fix autochangelog e89e6f1 [Tests] only audit prod deps 71317b9 [Deps] update es-abstract c17ccf4 [Dev Deps] update tape d81ae03 [Deps] update es-abstract b56303b [Deps] update es-abstract 9996d1c v1.0.2 20 December 2019 [Deps] update es-abstract, side-channel 5c9df03 [Dev Deps] update @ljharb/eslint-config, tape 7820f98 v1.0.1 1 December 2019 [Refactor] use side-channel package d38639f [actions] add automatic rebasing / merge commit blocking 74267e6 [Dev Deps] update eslint, @ljharb/eslint-config, auto-changelog, object-inspect, safe-publish-latest b042eef [Deps] update es-abstract 98cf4e8 v1.0.0 20 October 2019 Tests b50fa41 implementation c5a59f3 Initial commit 15ebe4d readme 382a3f5 npm init d5e7c97 [meta] add FUNDING.yml 685b608 [meta] add auto-changelog, safe-publish-latest f8fdf1c [Tests] add npm run lint baaaa09 Only apps should have lockfiles dfa7efa"
  },
  "node_modules/internal-slot/README.html": {
    "href": "node_modules/internal-slot/README.html",
    "title": "internal-slot | accouter",
    "keywords": "internal-slot Truly private storage, akin to the JS spec’s concept of internal slots. Uses a WeakMap when available; a Map when not; and a regular object in even older engines. Performance and garbage collection behavior will reflect the environment’s capabilities accordingly. Example var SLOT = require('internal-slot'); var assert = require('assert'); var o = {}; assert.throws(function () { SLOT.assert(o, 'foo'); }); assert.equal(SLOT.has(o, 'foo'), false); assert.equal(SLOT.get(o, 'foo'), undefined); SLOT.set(o, 'foo', 42); assert.equal(SLOT.has(o, 'foo'), true); assert.equal(SLOT.get(o, 'foo'), 42); assert.doesNotThrow(function () { SLOT.assert(o, 'foo'); }); Tests Simply clone the repo, npm install, and run npm test Security Please email @ljharb or see https://tidelift.com/security if you have a potential security vulnerability to report."
  },
  "node_modules/is-array-buffer/CHANGELOG.html": {
    "href": "node_modules/is-array-buffer/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v3.0.4 - 2024-02-02 Commits [patch] add types 15fab4c v3.0.3 - 2024-02-02 Commits [Fix] TAs can take a DataView in node 0.8; use a simpler check 69a03f6 [Dev Deps] update aud, available-typed-arrays, npmignore, object-inspect, tape 53ca341 [Deps] update call-bind, get-intrinsic, is-typed-array bec883f [Dev Deps] update @ljharb/eslint-config, aud, tape 944d4ce [meta] add missing engines.node 0852be6 [Deps] update get-intrinsic b59c4af v3.0.2 - 2023-03-01 Commits [Fix] node 0.8: an object arg to a TA only throws a RangeError when it is an ArrayBuffer of an incompatible byte length d5108f6 [Dev Deps] update object-inspect, tape 400f456 [Deps] update get-intrinsic 133732e v3.0.1 - 2023-01-05 Commits [Fix] in node 0.8, TAs do not coerce Uint8Arrays to an ArrayBuffer properly e488763 [Dev Deps] update @ljharb/eslint-config, aud 8eebfa2 v3.0.0 - 2023-01-04 Commits [Breaking] replace package implementation b65f929 Initial implementation, tests, readme 06afa73 Initial commit 051813f npm init 946d3de [meta] use npmignore to autogenerate an npmignore file ca4c446 Only apps should have lockfiles be7d8eb docs: fix badge link 9ea7fb6 2.0.0 (Feb 12, 2021) Refactor in TypeScript. Drop the dist directory. Drop the UMD bundled file. Add a declaration file for TypeScript. 1.0.1 (Apr 1, 2018) Improve code style. 1.0.0 (Jul 25, 2017) Supports UMD, CommonJS and ES Module. 0.1.0 (Nov 28, 2015) Check if ArrayBuffer is defined first. 0.0.1 (Nov 11, 2015) Initial release."
  },
  "node_modules/is-array-buffer/README.html": {
    "href": "node_modules/is-array-buffer/README.html",
    "title": "is-array-buffer | accouter",
    "keywords": "is-array-buffer Is this value a JS ArrayBuffer? This module works cross-realm/iframe, does not depend on instanceof or mutable properties, and despite ES6 Symbol.toStringTag. Example var assert = require('assert'); var isArrayBuffer = require('is-array-buffer'); assert(!isArrayBuffer(function () {})); assert(!isArrayBuffer(null)); assert(!isArrayBuffer(function* () { yield 42; return Infinity; }); assert(!isArrayBuffer(Symbol('foo'))); assert(!isArrayBuffer(1n)); assert(!isArrayBuffer(Object(1n))); assert(!isArrayBuffer(new Set())); assert(!isArrayBuffer(new WeakSet())); assert(!isArrayBuffer(new Map())); assert(!isArrayBuffer(new WeakMap())); assert(!isArrayBuffer(new WeakRef({}))); assert(!isArrayBuffer(new FinalizationRegistry(() => {}))); assert(!isArrayBuffer(new SharedArrayBuffer())); assert(isArrayBuffer(new ArrayBuffer())); class MyArrayBuffer extends ArrayBuffer {} assert(isArrayBuffer(new MyArrayBuffer())); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/is-arrayish/README.html": {
    "href": "node_modules/is-arrayish/README.html",
    "title": "node-is-arrayish | accouter",
    "keywords": "node-is-arrayish Determines if an object can be used like an Array Example var isArrayish = require('is-arrayish'); isArrayish([]); // true isArrayish({__proto__: []}); // true isArrayish({}); // false isArrayish({length:10}); // false License Licensed under the MIT License. You can find a copy of it in LICENSE."
  },
  "node_modules/is-bigint/CHANGELOG.html": {
    "href": "node_modules/is-bigint/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.4 - 2021-08-11 Commits [eslint] remove unnecessary eslintrc file 7220aa5 [readme] add github actions/codecov badges 053a071 [Deps] add has-bigints as a runtime dependency 0fc3c9d [Dev Deps] update tape 145f11d v1.0.3 - 2021-08-06 Commits [Tests] use has-tostringtag for easier checking of Symbol.toStringTag 3b44080 [Dev Deps] update auto-changelog, eslint, object-inspect, tape e4d4a6c [Fix] use has-bigints for more robust BigInt detection 7bb9d7a v1.0.2 - 2021-05-04 Commits [meta] do not publish github action workflow files 276d677 [actions] use node/install instead of node/run; use codecov action cea7fb6 [readme] fix repo URLs; remove travis badge c8e7c36 [Dev Deps] update eslint, @ljharb/eslint-config, aud, has-symbols, object-inspect, tape 32f3d90 [Dev Deps] update eslint, @ljharb/eslint-config, object-inspect, tape c2f20f5 [meta] remove unneeded token; update checkout action 94e46e9 [meta] use prepublishOnly script for npm 7+ 3e663ec v1.0.1 - 2020-11-30 Commits [Tests] use shared travis-ci configs 28f1211 [Tests] migrate tests to Github Actions 0998c64 [meta] add auto-changelog 2352de6 [Tests] run nyc on all tests 9c16a9a [Dev Deps] update eslint, @ljharb/eslint-config, auto-changelog, object-inspect, tape 4cd0edd [actions] add automatic rebasing / merge commit blocking f0f4b91 [actions] add \"Allow Edits\" workflow 7f4f46e [meta] create FUNDING.yml 2d0cb9a [Dev Deps] update eslint, @ljharb/eslint-config, aud 0ee110e [Dev Deps] update eslint, @ljharb/eslint-config, has-symbols, object-inspect, tape 5bb7f3a [Dev Deps] update eslint, @ljharb/eslint-config, safe-publish-latest, tape d3d67d0 [Dev Deps] update auto-changelog, tape 54e270f [Dev Deps] update @ljharb/eslint-config, tape d82bfe7 [Dev Deps] update auto-changelog; add aud 9c34bd1 [Tests] add missing posttest script 0690bd9 [meta] add funding field 7ca36d0 [actions] switch Automatic Rebase workflow to pull_request_target event 5ffa8da [Dev Deps] update eslint 8512c2f [Tests] only audit prod deps f2147dc [readme] fix header d6eff75 v1.0.0 - 2018-09-20 Commits [Tests] add tests 847f12a Initial commit b53f3c6 readme 66c15fe Implementation c2c0974 package.json 98b174c Only apps should have lockfiles a77c74b"
  },
  "node_modules/is-bigint/README.html": {
    "href": "node_modules/is-bigint/README.html",
    "title": "is-bigint | accouter",
    "keywords": "is-bigint Is this an ES BigInt value? Example var isBigInt = require('is-bigint'); assert(!isBigInt(function () {})); assert(!isBigInt(null)); assert(!isBigInt(function* () { yield 42; return Infinity; }); assert(!isBigInt(Symbol('foo'))); assert(isBigInt(1n)); assert(isBigInt(Object(1n))); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/is-binary-path/readme.html": {
    "href": "node_modules/is-binary-path/readme.html",
    "title": "is-binary-path | accouter",
    "keywords": "is-binary-path Check if a file path is a binary file Install $ npm install is-binary-path Usage const isBinaryPath = require('is-binary-path'); isBinaryPath('source/unicorn.png'); //=> true isBinaryPath('source/unicorn.txt'); //=> false Related binary-extensions - List of binary file extensions is-text-path - Check if a filepath is a text file License MIT © Sindre Sorhus, Paul Miller"
  },
  "node_modules/is-boolean-object/CHANGELOG.html": {
    "href": "node_modules/is-boolean-object/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.1.2 - 2021-08-05 Commits [Refactor] use has-tostringtag to behave correctly in the presence of symbol shams 6d319ea [Dev Deps] update auto-changelog, core-js, eslint, tape 4f85bef v1.1.1 - 2021-05-07 Commits [actions] use node/install instead of node/run; use codecov action 7201c41 [Tests] run tests with core-js as well 9590e61 [meta] do not publish github action workflow files 341472b [readme] update repo URLs; remove travis badge 9fdbbc6 [Dev Deps] update eslint, @ljharb/eslint-config, aud, tape 1cd35c9 [readme] add actions and codecov badges 03769fe [Dev Deps] update eslint, @ljharb/eslint-config, tape db6598c [Fix] do not use Object.prototype.toString when Symbol.toStringTag is shammed e0b8a9f [readme] remove defunct testling badge 986a621 [meta] use prepublishOnly script for npm 7+ 7bb3b29 [Deps] update call-bind 3af6a71 [meta] do not publish corejs test file d911f03 [actions] update workflows 9bb3d90 v1.1.0 - 2020-12-05 Commits [Tests] migrate tests to Github Actions 6cdb652 [Tests] run nyc on all tests 9a33076 [Tests] add .editorconfig bb401c0 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape 5cb2405 [Robustness] use call-bind to avoid a dependency on .call 76d87ae [actions] add \"Allow Edits\" workflow 337206a [Dev Deps] update eslint, @ljharb/eslint-config, tape 11f0481 [Dev Deps] update eslint, @ljharb/eslint-config, tape b9602c8 [Dev Deps] update auto-changelog, tape; add aud 999e9e2 [actions] switch Automatic Rebase workflow to pull_request_target event bbb6728 v1.0.1 - 2019-12-18 Commits [Tests] use shared travis-ci configs a1778b8 Update eslint; use my personal shared eslint config. 2c42c50 [Tests] remove jscs 3807025 [Tests] up to node v8.4, v7.10, v6.11, v5.12, v4.8; improve matrix; newer npm breaks in older node; improve scripts. a02b986 [Dev Deps] update eslint, @ljharb/eslint-config, is, jscs, nsp, semver, tape d9030a9 Update eslint, nsp a1b6388 [Tests] up to node v10.0, v9.11, v8.11, v6.14, v4.9; use nvm install-latest-npm 17a0fd3 [Tests] up to node v12.10, v11.15, v10.16, v8.16, v6.17 0b1818f [meta] remove unused Makefile and associated utilities 33dc0ae Update covert, jscs, eslint, semver 7e513c1 [Tests] up to node v11.4, v10.14, v8.14, v6.15 992b849 [meta] add auto-changelog 63d71b8 Update tape, eslint, semver 76aea69 Update tape, jscs, eslint, @ljharb/eslint-config a6cbec0 [Dev Deps] update eslint, @ljharb/eslint-config, replace, semver, tape; add safe-publish-latest 7cf6bb0 [Dev Deps] update eslint, @ljharb/eslint-config, safe-publish-latest 57d713c [actions] add automatic rebasing / merge commit blocking f7a2bdb [meta] create FUNDING.yml 9765e73 [Dev Deps] update eslint, @ljharb/eslint-config, is, replace, semver, tape 5c16b56 [Dev Deps] update tape, jscs, eslint, @ljharb/eslint-config 5717aad [Dev Deps] update is, jscs, nsp, eslint, @ljharb/eslint-config, semver 80b924d [Dev Deps] update jscs 2e5479e Test up to io.js v2.2 93379a4 [Tests] remove nsp; use npm audit; allow to fail for now 36ae30a [Tests] up to io.js v3.3, node v4.1 ef76976 [Tests] use npx aud instead of nsp or npm audit with hoops a1182bd [Dev Deps] update eslint, @ljharb/eslint-config, covert, tape 4f79b47 [Tests] up to node v10.3 5e96464 [Dev Deps] update eslint, nsp, semver, tape e1eb3fa Only apps should have lockfiles. c7f301f [meta] add funding field fad0366 [Dev Deps] update eslint, @ljharb/eslint-config 80d39d9 [Tests] use eclint instead of editorconfig-tools 980e91b [Dev Deps] Update tape, eslint 9960830 Test up to io.js v3.0 a3c3cd0 [Dev Deps] update tape 217fbd6 [Tests] only audit prod deps 89284ee [Performance] only use toStringTag code path when the value has that property 2863bc5 [Dev Deps] update replace 53e72a5 [Enhancement] slight optimization for null a90a3c4 [Dev Deps] update tape 9377bd5 Switch from vb.teelaun.ch to versionbadg.es for the npm version badge SVG. 3085530 Test on io.js v2.4 8af335c Test on io.js v2.3 1eb3424 v1.0.0 - 2015-04-28 Commits Dotfiles 6b9b998 make release d5e50b3 package.json 117676a Read me ef327a7 Initial commit 2346886 Tests 67211f8 Implementation 2d88bd6"
  },
  "node_modules/is-boolean-object/README.html": {
    "href": "node_modules/is-boolean-object/README.html",
    "title": "is-boolean-object | accouter",
    "keywords": "is-boolean-object Is this value a JS Boolean? This module works cross-realm/iframe, and despite ES6 @@toStringTag. Example var isBoolean = require('is-boolean-object'); var assert = require('assert'); assert.notOk(isBoolean(undefined)); assert.notOk(isBoolean(null)); assert.notOk(isBoolean('foo')); assert.notOk(isBoolean(function () {})); assert.notOk(isBoolean([])); assert.notOk(isBoolean({})); assert.notOk(isBoolean(/a/g)); assert.notOk(isBoolean(new RegExp('a', 'g'))); assert.notOk(isBoolean(new Date())); assert.notOk(isBoolean(42)); assert.notOk(isBoolean(NaN)); assert.notOk(isBoolean(Infinity)); assert.ok(isBoolean(new Boolean(42))); assert.ok(isBoolean(false)); assert.ok(isBoolean(Object(false))); assert.ok(isBoolean(true)); assert.ok(isBoolean(Object(true))); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/is-callable/CHANGELOG.html": {
    "href": "node_modules/is-callable/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.2.7 - 2022-09-23 Commits [Fix] recognize document.all in IE 6-10 06c1db2 [Tests] improve logic for FF 20-35 0f7d9b9 [Fix] handle document.all in FF 27 (and +, probably) 696c661 [Tests] fix proxy tests in FF 42-63 985df0d [readme] update tested browsers 389e919 [Fix] detect document.all in Opera 12.16 b9f1022 [Fix] HTML elements: properly report as callable in Opera 12.16 17391fe [Tests] fix inverted logic in FF3 test 056ebd4 v1.2.6 - 2022-09-14 Commits [Fix] work for document.all in Firefox 3 and IE 6-8 015132a [Test] skip function toString check for nullish values 8698116 [readme] add \"supported engines\" section 0442207 [Tests] skip one of the fixture objects in FF 3.6 a501141 [Tests] allow class constructor tests to fail in FF v45 - v54, which has undetectable classes b12e4a4 [Fix] Safari 4: regexes should not be considered callable 4b732ff [Fix] properly recognize document.all in Safari 4 3193735 v1.2.5 - 2022-09-11 Commits [actions] reuse common workflows 5bb4b32 [meta] better eccheck command b9bd597 [meta] use npmignore to autogenerate an npmignore file 3192d38 [Fix] for HTML constructors, always use tryFunctionObject even in pre-toStringTag browsers 3076ea2 [Dev Deps] update eslint, @ljharb/eslint-config, available-typed-arrays, object-inspect, safe-publish-latest, tape 8986746 [meta] add auto-changelog 7dda9d0 [Fix] properly report document.all da90b2b [actions] update codecov uploader c8f847c [Dev Deps] update eslint, @ljharb/eslint-config, aud, object-inspect, tape 899ae00 [Dev Deps] update eslint, @ljharb/eslint-config, es-value-fixtures, object-inspect, tape 344e913 [meta] remove greenkeeper config 737dce5 [meta] npmignore coverage output 680a883 1.2.4 / 2021-08-05 [Fix] use has-tostringtag approach to behave correctly in the presence of symbol shams [readme] fix repo URLs [readme] add actions and codecov badges [readme] remove defunct badges [meta] ignore eclint checking coverage output [meta] use prepublishOnly script for npm 7+ [actions] use node/install instead of node/run; use codecov action [actions] remove unused workflow file [Tests] run nyc on all tests; use tape runner [Tests] use available-typed-arrays, for-each, has-symbols, object-inspect [Dev Deps] update available-typed-arrays, eslint, @ljharb/eslint-config, aud, object-inspect, tape 1.2.3 / 2021-01-31 [Fix] document.all is callable (do not use document.all!) [Dev Deps] update eslint, @ljharb/eslint-config, aud, tape [Tests] migrate tests to Github Actions [actions] add \"Allow Edits\" workflow [actions] switch Automatic Rebase workflow to pull_request_target event 1.2.2 / 2020-09-21 [Fix] include actual fix from 579179e [Dev Deps] update eslint 1.2.1 / 2020-09-09 [Fix] phantomjs‘ Reflect.apply does not throw properly on a bad array-like [Dev Deps] update eslint, @ljharb/eslint-config [meta] fix eclint error 1.2.0 / 2020-06-02 [New] use Reflect.apply‑based callability detection [readme] add install instructions (#55) [meta] only run aud on prod deps [Dev Deps] update eslint, @ljharb/eslint-config, tape, make-arrow-function, make-generator-function; add aud, safe-publish-latest, make-async-function [Tests] add tests for function proxies (#53, #25) 1.1.5 / 2019-12-18 [meta] remove unused Makefile and associated utilities [meta] add funding field; add FUNDING.yml [Dev Deps] update eslint, @ljharb/eslint-config, semver, tape, covert, rimraf [Tests] use shared travis configs [Tests] use eccheck over editorconfig-tools [Tests] use npx aud instead of nsp or npm audit with hoops [Tests] remove jscs [actions] add automatic rebasing / merge commit blocking 1.1.4 / 2018-07-02 [Fix] improve class and arrow function detection (#30, #31) [Tests] on all latest node minors; improve matrix [Dev Deps] update all dev deps 1.1.3 / 2016-02-27 [Fix] ensure “class “ doesn’t screw up “class” detection [Tests] up to node v5.7, v4.3 [Dev Deps] update to eslint v2, @ljharb/eslint-config, jscs 1.1.2 / 2016-01-15 [Fix] Make sure comments don’t screw up “class” detection (#4) [Tests] up to node v5.3 [Tests] Add parallelshell, run both --es-staging and stock tests at once [Dev Deps] update tape, jscs, nsp, eslint, @ljharb/eslint-config [Refactor] convert isNonES6ClassFn into isES6ClassFn 1.1.1 / 2015-11-30 [Fix] do not throw when a non-function has a function in its [[Prototype]] (#2) [Dev Deps] update tape, eslint, @ljharb/eslint-config, jscs, nsp, semver [Tests] up to node v5.1 [Tests] no longer allow node 0.8 to fail. [Tests] fix npm upgrades in older nodes 1.1.0 / 2015-10-02 [Fix] Some browsers report TypedArray constructors as typeof object [New] return false for \"class\" constructors, when possible. [Tests] up to io.js v3.3, node v4.1 [Dev Deps] update eslint, editorconfig-tools, nsp, tape, semver, jscs, covert, make-arrow-function [Docs] Switch from vb.teelaun.ch to versionbadg.es for the npm version badge SVG 1.0.4 / 2015-01-30 If @@toStringTag is not present, use the old-school Object#toString test. 1.0.3 / 2015-01-29 Add tests to ensure arrow functions are callable. Refactor to aid optimization of non-try/catch code. 1.0.2 / 2015-01-29 Fix broken package.json 1.0.1 / 2015-01-29 Add early exit for typeof not \"function\" 1.0.0 / 2015-01-29 Initial release."
  },
  "node_modules/is-callable/README.html": {
    "href": "node_modules/is-callable/README.html",
    "title": "is-callable | accouter",
    "keywords": "is-callable Is this JS value callable? Works with Functions and GeneratorFunctions, despite ES6 @@toStringTag. Supported engines Automatically tested in every minor version of node. Manually tested in: Safari: v4 - v15 (4, 5, 5.1, 6.0.5, 6.2, 7.1, 8, 9.1.3, 10.1.2, 11.1.2, 12.1, 13.1.2, 14.1.2, 15.3, 15.6.1) Note: Safari 9 has class, but Function.prototype.toString hides that progeny and makes them look like functions, so class constructors will be reported by this package as callable, when they are not in fact callable. Chrome: v15 - v81, v83 - v106(every integer version) Note: This includes Edge v80+ and Opera v15+, which matches Chrome Firefox: v3, v3.6, v4 - v105 (every integer version) Note: v45 - v54 has class, but Function.prototype.toString hides that progeny and makes them look like functions, so class constructors will be reported by this package as callable, when they are not in fact callable. Note: in v42 - v63, Function.prototype.toString throws on HTML element constructors, or a Proxy to a function Note: in v20 - v35, HTML element constructors are not callable, despite having typeof function. Note: in v19, document.all is not callable. IE: v6 - v11(every integer version Opera: v11.1, v11.5, v11.6, v12.1, v12.14, v12.15, v12.16, v15+ v15+ matches Chrome Example var isCallable = require('is-callable'); var assert = require('assert'); assert.notOk(isCallable(undefined)); assert.notOk(isCallable(null)); assert.notOk(isCallable(false)); assert.notOk(isCallable(true)); assert.notOk(isCallable([])); assert.notOk(isCallable({})); assert.notOk(isCallable(/a/g)); assert.notOk(isCallable(new RegExp('a', 'g'))); assert.notOk(isCallable(new Date())); assert.notOk(isCallable(42)); assert.notOk(isCallable(NaN)); assert.notOk(isCallable(Infinity)); assert.notOk(isCallable(new Number(42))); assert.notOk(isCallable('foo')); assert.notOk(isCallable(Object('foo'))); assert.ok(isCallable(function () {})); assert.ok(isCallable(function* () {})); assert.ok(isCallable(x => x * x)); Install Install with npm install is-callable Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/is-core-module/CHANGELOG.html": {
    "href": "node_modules/is-core-module/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v2.13.1 - 2023-10-20 Commits [Refactor] use hasown instead of has 0e52096 [Dev Deps] update mock-property, tape 8736b35 v2.13.0 - 2023-08-05 Commits [Dev Deps] update @ljharb/eslint-config, aud, semver, tape c75b263 [New] node:test/reporters and wasi/node:wasi are in v18.17 d76cbf8 v2.12.1 - 2023-05-16 Commits [Fix] test/reporters now requires the node: prefix as of v20.2 12183d0 v2.12.0 - 2023-04-10 Commits [actions] update rebase action to use reusable workflow c0a7251 [Dev Deps] update @ljharb/eslint-config, aud, tape 9ae8b7f [New] test/reporters added in v19.9, wasi added in v20 9d5341a [Dev Deps] add missing in-publish dep 5980245 v2.11.0 - 2022-10-18 Commits [meta] use npmignore to autogenerate an npmignore file 3360011 [Dev Deps] update aud, tape 651c6b0 [New] inspector/promises and node:inspector/promises is now available in node 19 22d332f v2.10.0 - 2022-08-03 Commits [New] node:test is now available in node ^16.17 e8fd36e [Tests] improve skip message c014a4c v2.9.0 - 2022-04-19 Commits [New] add node:test, in node 18+ f853eca [Tests] use mock-property 03b3644 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape 7c0e2d0 [meta] simplify \"exports\" d6ed201 v2.8.1 - 2022-01-05 Commits [actions] reuse common workflows cd2cf9b [Fix] update node 0.4 results 062195d [Dev Deps] update eslint, @ljharb/eslint-config, safe-publish-latest, tape 0790b62 [Dev Deps] update eslint, @ljharb/eslint-config, tape 7d139a6 [Tests] run nyc in tests-only, not test 780e8a0 v2.8.0 - 2021-10-14 Commits [actions] update codecov uploader 0cfe94e [New] add readline/promises to node v17+ 4f78c30 [Tests] node ^14.18 supports node: prefixes for CJS 43e2f17 v2.7.0 - 2021-09-27 Commits [New] node v14.18 added node:-prefixed core modules to require 6d943ab [Tests] add coverage for Object.prototype pollution c6baf5f [Dev Deps] update @ljharb/eslint-config 6717f00 [eslint] fix linter warning 594c10b [meta] add sideEffects flag c32cfa5 v2.6.0 - 2021-08-17 Commits [Dev Deps] update eslint, tape 6cc928f [New] add stream/consumers to node &gt;= 16.7 a1a423e [Refactor] Remove duplicated && operand 86faea7 [Tests] include prereleases a4da7a6 v2.5.0 - 2021-07-12 Commits [Dev Deps] update auto-changelog, eslint 6334cc9 [New] add stream/web to node v16.5+ 17ac59b v2.4.0 - 2021-05-09 Commits [readme] add actions and codecov badges 82b7faa [Dev Deps] update @ljharb/eslint-config, aud 8096868 [Dev Deps] update eslint 6726824 [New] add diagnostics_channel to node ^14.17 86c6563 [meta] fix prepublish script 697a01e v2.3.0 - 2021-04-24 Commits [meta] do not publish github action workflow files 060d4bb [New] add support for node: prefix, in node 16+ 7341223 [actions] use node/install instead of node/run; use codecov action 016269a [patch] remove unneeded .0 in version ranges cb466a6 [Dev Deps] update eslint, @ljharb/eslint-config, aud, tape c9f9c39 [actions] update workflows 3ee4a89 [Dev Deps] update eslint, @ljharb/eslint-config dee4fed [Dev Deps] update eslint, @ljharb/eslint-config 7d046ba [meta] use prepublishOnly script for npm 7+ 149e677 [readme] remove travis badge 903b51d v2.2.0 - 2020-11-26 Commits [Tests] migrate tests to Github Actions c919f57 [patch] core.json: %s/ /\\t/g db3f685 [Tests] run nyc on all tests b2f925f [Dev Deps] update eslint, @ljharb/eslint-config, aud; add safe-publish-latest 89f02a2 [New] add path/posix, path/win32, util/types 77f94f1 v2.1.0 - 2020-11-04 Commits [Dev Deps] update eslint 5e0034e [New] Add diagnostics_channel c2d83d0 v2.0.0 - 2020-09-29 Commits v2 implementation 865aeb5 Only apps should have lockfiles 5a5e660 Initial commit for v2 5a51524 Tests 116eae4 [meta] add auto-changelog c24388b [actions] add \"Automatic Rebase\" and \"require allow edits\" actions 34292db [Tests] add npm run lint 4f9eeee [readme] fix travis badges, https all URLs e516a73 [meta] create FUNDING.yml 1aabebc [Fix] domain: domain landed sometime > v0.7.7 and <= v0.7.12 2df7d37 [Fix] sys: worked in 0.6, not 0.7, and 0.8+ a75c134 v1.0.2 - 2014-09-28 Commits simpler 66fe90f v1.0.1 - 2014-09-28 Commits remove stupid f21f906 update readme 1eff0ec v1.0.0 - 2014-09-28 Commits init 48e5e76"
  },
  "node_modules/is-core-module/README.html": {
    "href": "node_modules/is-core-module/README.html",
    "title": "is-core-module | accouter",
    "keywords": "is-core-module Is this specifier a node.js core module? Optionally provide a node version to check; defaults to the current node version. Example var isCore = require('is-core-module'); var assert = require('assert'); assert(isCore('fs')); assert(!isCore('butts')); Tests Clone the repo, npm install, and run npm test"
  },
  "node_modules/is-data-view/CHANGELOG.html": {
    "href": "node_modules/is-data-view/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.1 - 2024-02-02 Commits [patch] add types c2728ef [Dev Deps] update aud, available-typed-arrays, has-tostringtag, npmignore, object-inspect, tape e7f9ebc [Deps] update is-typed-array 2ca9333 v1.0.0 - 2024-01-31 Commits Initial implementation, tests, readme 6f7e424 Initial commit 4b7ea57 npm init 25130e2 Only apps should have lockfiles 18cde47"
  },
  "node_modules/is-data-view/README.html": {
    "href": "node_modules/is-data-view/README.html",
    "title": "is-data-view | accouter",
    "keywords": "is-data-view Is this value a JS DataView? This module works cross-realm/iframe, does not depend on instanceof or mutable properties, and despite ES6 Symbol.toStringTag. Example var isDataView = require('is-data-view'); var assert = require('assert'); assert.equal(false, isDataView(undefined)); assert.equal(false, isDataView(null)); assert.equal(false, isDataView(false)); assert.equal(false, isDataView(true)); assert.equal(false, isDataView([])); assert.equal(false, isDataView({})); assert.equal(false, isDataView(/a/g)); assert.equal(false, isDataView(new RegExp('a', 'g'))); assert.equal(false, isDataView(new Date())); assert.equal(false, isDataView(42)); assert.equal(false, isDataView(NaN)); assert.equal(false, isDataView(Infinity)); assert.equal(false, isDataView(new Number(42))); assert.equal(false, isDataView('foo')); assert.equal(false, isDataView(Object('foo'))); assert.equal(false, isDataView(function () {})); assert.equal(false, isDataView(function* () {})); assert.equal(false, isDataView(x => x * x)); assert.equal(false, isDataView([])); assert.equal(false, isDataView(new Int8Array())); assert.equal(false, isDataView(new Uint8Array())); assert.equal(false, isDataView(new Uint8ClampedArray())); assert.equal(false, isDataView(new Int16Array())); assert.equal(false, isDataView(new Uint16Array())); assert.equal(false, isDataView(new Int32Array())); assert.equal(false, isDataView(new Uint32Array())); assert.equal(false, isDataView(new Float32Array())); assert.equal(false, isDataView(new Float64Array())); assert.equal(false, isDataView(new BigInt64Array())); assert.equal(false, isDataView(new BigUint64Array())); assert.ok(isDataView(new DataView(new ArrayBuffer(0)))); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/is-date-object/CHANGELOG.html": {
    "href": "node_modules/is-date-object/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.5 - 2021-08-05 Commits [meta] remove .jscs.json 31c731c [Fix] use has-tostringtag to behave correctly in the presence of symbol shams 17a6df4 [Dev Deps] update eslint, auto-changelog, tape 79db3af v1.0.4 - 2021-05-07 Commits [Fix] do not use Object.prototype.toString when Symbol.toStringTag is shammed 8943a4a [readme] make all URLs https 1d4d6cd [Dev Deps] update eslint a7abeaa v1.0.3 - 2021-05-05 Commits [Tests] migrate tests to Github Actions 023504f [readme] add actions and codecov badges e63305f [meta] do not publish github action workflow files 017d906 [Tests] run nyc on all tests 0376b6f [readme] fix repo URLs; remove defunct badges 1c148c6 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape c7a3f54 [actions] add \"Allow Edits\" workflow e79b5b2 [Dev Deps] update eslint, @ljharb/eslint-config, aud, tape da28980 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog 5cabae9 [readme] add actions and codecov badges 33dfb88 [Dev Deps] update eslint, @ljharb/eslint-config, tape 745eb04 [Dev Deps] update eslint, @ljharb/eslint-config, tape 466c62b [actions] use checkout v2; remove unneeded env ff87a16 [Dev Deps] update auto-changelog, tape 93188f5 [meta] use prepublishOnly script for npm 7+ 1d0e3ea [actions] update workflows 4d1a235 [Dev Deps] update auto-changelog; add aud 67be59a [actions] switch Automatic Rebase workflow to pull_request_target event a6661c2 [Tests] only audit prod deps dd4a47f v1.0.2 - 2019-12-18 Commits [Tests] use shared travis-ci configs 8a378b8 [Tests] on all node minors; use nvm install-latest-npm; fix scripts; improve matrix 6e97a21 [Dev Deps] update eslint, @ljharb/eslint-config, is, jscs, nsp, semver, tape 8472b90 [Tests] up to node v10.0, v9.11, v8.11, v6.14, v4.9 ae73e38 [meta] add auto-changelog 82f8f47 [meta] remove unused Makefile and associated utilities 788a2cd [Tests] up to node v11.4, v10.14, v8.14, v6.15 b9caf7c [Tests] up to node v12.4, v11.15, v10.15, v8.15, v6.17; use nvm install-latest-npm cda0abc [Tests] up to node v12.10, v10.16, v8.16 49bc482 [Dev Deps] update eslint, @ljharb/eslint-config, semver, tape; add safe-publish-latest f77fec4 [actions] add automatic rebasing / merge commit blocking 68605fc [meta] create FUNDING.yml 4f82d88 [Dev Deps] update tape, jscs, eslint, @ljharb/eslint-config 3cbf28a [Dev Deps] update eslint, @ljharb/eslint-config@, is, semver, tape abf9fb0 [Tests] switch from nsp to npm audit 6543c7d [Dev Deps] update eslint, @ljharb/eslint-config, covert, tape ba5d2d7 [Dev Deps] update eslint, nsp, semver, tape c1e3525 [Tests] use npx aud instead of nsp or npm audit with hoops 14e4824 [Dev Deps] update eslint, @ljharb/eslint-config, safe-publish-latest 68ead64 [Dev Deps] update eslint, semver, tape, semver [f55453f`](https://github.com/inspect-js/is-date-object/commit/f55453f200903277465d7e9307a9c49120a4f419) Only apps should have lockfiles 6c848eb [Tests] remove jscs 3fd3a62 [Dev Deps] update eslint, tape 77d3130 [meta] add funding field 9ef6d58 v1.0.1 - 2015-09-27 Commits Update tape, semver, eslint; use my personal shared eslint config. 731aa13 Update is, tape, covert, jscs, editorconfig-tools, nsp, eslint, semver 53e43a6 Update eslint d2fc304 Update tape, jscs, eslint, @ljharb/eslint-config c9568df Test on latest node and io.js versions. a21d537 Update nsp, eslint, semver 9e1d908 Update covert, jscs, eslint, semver f198f6b [Dev Deps] update tape, jscs, eslint ab9bdbb If @@toStringTag is not present, use the old-school Object#toString test. c03afce [Dev Deps] update jscs, nsp, tape, eslint, @ljharb/eslint-config 9d94ccb [Dev Deps] update is, eslint, @ljharb/eslint-config, semver 35cbff7 Test up to io.js v2.3 be5d11e [Tests] on io.js v3.3, up to node v4.1 20221a3 [Tests] up to io.js v3.2 7009b4a Test on io.js v2.1 68b29b1 Remove editorconfig-tools 8d3972c [Dev Deps] update tape 204945d Switch from vb.teelaun.ch to versionbadg.es for the npm version badge SVG. 7bff214 Test on io.js v2.5 92f7bd6 Test on io.js v2.4 ebb34bf Fix tests for faked @@toStringTag 3b9c26c Test on io.js v3.0 5eedf4b v1.0.0 - 2015-01-28 Commits Dotfiles. 5b6a929 make release e8d40ce package.json a107259 Read me eb92695 Initial commit 4fc7755 Tests. b6f432f Implementation. dd0fd96"
  },
  "node_modules/is-date-object/README.html": {
    "href": "node_modules/is-date-object/README.html",
    "title": "is-date-object | accouter",
    "keywords": "is-date-object Is this value a JS Date object? This module works cross-realm/iframe, and despite ES6 @@toStringTag. Example var isDate = require('is-date-object'); var assert = require('assert'); assert.notOk(isDate(undefined)); assert.notOk(isDate(null)); assert.notOk(isDate(false)); assert.notOk(isDate(true)); assert.notOk(isDate(42)); assert.notOk(isDate('foo')); assert.notOk(isDate(function () {})); assert.notOk(isDate([])); assert.notOk(isDate({})); assert.notOk(isDate(/a/g)); assert.notOk(isDate(new RegExp('a', 'g'))); assert.ok(isDate(new Date())); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/is-extglob/README.html": {
    "href": "node_modules/is-extglob/README.html",
    "title": "is-extglob | accouter",
    "keywords": "is-extglob Returns true if a string has an extglob. Install Install with npm: $ npm install --save is-extglob Usage var isExtglob = require('is-extglob'); True isExtglob('?(abc)'); isExtglob('@(abc)'); isExtglob('!(abc)'); isExtglob('*(abc)'); isExtglob('+(abc)'); False Escaped extglobs: isExtglob('\\\\?(abc)'); isExtglob('\\\\@(abc)'); isExtglob('\\\\!(abc)'); isExtglob('\\\\*(abc)'); isExtglob('\\\\+(abc)'); Everything else... isExtglob('foo.js'); isExtglob('!foo.js'); isExtglob('*.js'); isExtglob('**/abc.js'); isExtglob('abc/*.js'); isExtglob('abc/(aaa|bbb).js'); isExtglob('abc/[a-z].js'); isExtglob('abc/{a,b}.js'); isExtglob('abc/?.js'); isExtglob('abc.js'); isExtglob('abc/def/ghi.js'); History v2.0 Adds support for escaping. Escaped exglobs no longer return true. About Related projects has-glob: Returns true if an array has a glob pattern. | homepage is-glob: Returns true if the given string looks like a glob pattern or an extglob pattern… more | homepage micromatch: Glob matching for javascript/node.js. A drop-in replacement and faster alternative to minimatch and multimatch. | homepage Contributing Pull requests and stars are always welcome. For bugs and feature requests, please create an issue. Building docs (This document was generated by verb-generate-readme (a verb generator), please don't edit the readme directly. Any changes to the readme must be made in .verb.md.) To generate the readme and API documentation with verb: $ npm install -g verb verb-generate-readme && verb Running tests Install dev dependencies: $ npm install -d && npm test Author Jon Schlinkert github/jonschlinkert twitter/jonschlinkert License Copyright © 2016, Jon Schlinkert. Released under the MIT license. This file was generated by verb-generate-readme, v0.1.31, on October 12, 2016."
  },
  "node_modules/is-fullwidth-code-point/readme.html": {
    "href": "node_modules/is-fullwidth-code-point/readme.html",
    "title": "is-fullwidth-code-point | accouter",
    "keywords": "is-fullwidth-code-point Check if the character represented by a given Unicode code point is fullwidth Install $ npm install is-fullwidth-code-point Usage const isFullwidthCodePoint = require('is-fullwidth-code-point'); isFullwidthCodePoint('谢'.codePointAt(0)); //=> true isFullwidthCodePoint('a'.codePointAt(0)); //=> false API isFullwidthCodePoint(codePoint) codePoint Type: number The code point of a character. License MIT © Sindre Sorhus"
  },
  "node_modules/is-glob/README.html": {
    "href": "node_modules/is-glob/README.html",
    "title": "is-glob | accouter",
    "keywords": "is-glob Returns true if the given string looks like a glob pattern or an extglob pattern. This makes it easy to create code that only uses external modules like node-glob when necessary, resulting in much faster code execution and initialization time, and a better user experience. Please consider following this project's author, Jon Schlinkert, and consider starring the project to show your ❤️ and support. Install Install with npm: $ npm install --save is-glob You might also be interested in is-valid-glob and has-glob. Usage var isGlob = require('is-glob'); Default behavior True Patterns that have glob characters or regex patterns will return true: isGlob('!foo.js'); isGlob('*.js'); isGlob('**/abc.js'); isGlob('abc/*.js'); isGlob('abc/(aaa|bbb).js'); isGlob('abc/[a-z].js'); isGlob('abc/{a,b}.js'); //=> true Extglobs isGlob('abc/@(a).js'); isGlob('abc/!(a).js'); isGlob('abc/+(a).js'); isGlob('abc/*(a).js'); isGlob('abc/?(a).js'); //=> true False Escaped globs or extglobs return false: isGlob('abc/\\\\@(a).js'); isGlob('abc/\\\\!(a).js'); isGlob('abc/\\\\+(a).js'); isGlob('abc/\\\\*(a).js'); isGlob('abc/\\\\?(a).js'); isGlob('\\\\!foo.js'); isGlob('\\\\*.js'); isGlob('\\\\*\\\\*/abc.js'); isGlob('abc/\\\\*.js'); isGlob('abc/\\\\(aaa|bbb).js'); isGlob('abc/\\\\[a-z].js'); isGlob('abc/\\\\{a,b}.js'); //=> false Patterns that do not have glob patterns return false: isGlob('abc.js'); isGlob('abc/def/ghi.js'); isGlob('foo.js'); isGlob('abc/@.js'); isGlob('abc/+.js'); isGlob('abc/?.js'); isGlob(); isGlob(null); //=> false Arrays are also false (If you want to check if an array has a glob pattern, use has-glob): isGlob(['**/*.js']); isGlob(['foo.js']); //=> false Option strict When options.strict === false the behavior is less strict in determining if a pattern is a glob. Meaning that some patterns that would return false may return true. This is done so that matching libraries like micromatch have a chance at determining if the pattern is a glob or not. True Patterns that have glob characters or regex patterns will return true: isGlob('!foo.js', {strict: false}); isGlob('*.js', {strict: false}); isGlob('**/abc.js', {strict: false}); isGlob('abc/*.js', {strict: false}); isGlob('abc/(aaa|bbb).js', {strict: false}); isGlob('abc/[a-z].js', {strict: false}); isGlob('abc/{a,b}.js', {strict: false}); //=> true Extglobs isGlob('abc/@(a).js', {strict: false}); isGlob('abc/!(a).js', {strict: false}); isGlob('abc/+(a).js', {strict: false}); isGlob('abc/*(a).js', {strict: false}); isGlob('abc/?(a).js', {strict: false}); //=> true False Escaped globs or extglobs return false: isGlob('\\\\!foo.js', {strict: false}); isGlob('\\\\*.js', {strict: false}); isGlob('\\\\*\\\\*/abc.js', {strict: false}); isGlob('abc/\\\\*.js', {strict: false}); isGlob('abc/\\\\(aaa|bbb).js', {strict: false}); isGlob('abc/\\\\[a-z].js', {strict: false}); isGlob('abc/\\\\{a,b}.js', {strict: false}); //=> false About Contributing Pull requests and stars are always welcome. For bugs and feature requests, please create an issue. Running Tests Running and reviewing unit tests is a great way to get familiarized with a library and its API. You can install dependencies and run tests with the following command: $ npm install && npm test Building docs (This project's readme.md is generated by verb, please don't edit the readme directly. Any changes to the readme must be made in the .verb.md readme template.) To generate the readme, run the following command: $ npm install -g verbose/verb#dev verb-generate-readme && verb Related projects You might also be interested in these projects: assemble: Get the rocks out of your socks! Assemble makes you fast at creating web projects… more | homepage base: Framework for rapidly creating high quality, server-side node.js applications, using plugins like building blocks | homepage update: Be scalable! Update is a new, open source developer framework and CLI for automating updates… more | homepage verb: Documentation generator for GitHub projects. Verb is extremely powerful, easy to use, and is used… more | homepage Contributors Commits Contributor 47 jonschlinkert 5 doowb 1 phated 1 danhper 1 paulmillr Author Jon Schlinkert GitHub Profile Twitter Profile LinkedIn Profile License Copyright © 2019, Jon Schlinkert. Released under the MIT License. This file was generated by verb-generate-readme, v0.8.0, on March 27, 2019."
  },
  "node_modules/is-negative-zero/CHANGELOG.html": {
    "href": "node_modules/is-negative-zero/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v2.0.3 - 2024-02-19 Commits add types e28f0d5 [meta] use npmignore to autogenerate an npmignore file f68ec13 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape 70abff7 [actions] update rebase action to use reusable workflow 6e1356e [Dev Deps] update @ljharb/eslint-config, aud, npmignore, tape c00d4ab [meta] add sideEffects flag 9c45539 v2.0.2 - 2021-12-10 Commits [actions] reuse common workflows ece923d [actions] use node/install instead of node/run; use codecov action 3a26f43 [meta] do not publish workflow files 2cea0c2 [readme] add github actions/codecov badges; update URLs 0c0be3e [Dev Deps] update eslint, @ljharb/eslint-config, safe-publish-latest, tape a93d16e [meta] create FUNDING.yml b4f425e [actions] update codecov uploader 7999db3 [Dev Deps] update eslint, @ljharb/eslint-config, auto-changelog, safe-publish-latest, tape 140e4d9 [Dev Deps] update eslint, @ljharb/eslint-config, aud, tape 23a8b6d [readme] add actions and codecov badges fe92126 [readme] fix repo URLs 50c428e [Dev Deps] update eslint, @ljharb/eslint-config, tape 688155f [meta] use prepublishOnly script for npm 7+ 83171f9 [actions] update workflows e9823db v2.0.1 - 2020-12-04 Commits [Tests] use shared travis-ci configs 5b92482 [Tests] up to node v11.7, v10.15, v9.11, v8.15, v7.10, v6.16, v5.12, v4.9; use nvm install-latest-npm; fix test scripts 0f5d2f8 [Tests] migrate tests to Github Actions b80f05a [Tests] remove jscs 7ccaf41 [meta] add missing changelog 992bdde [readme] fix repo URLs; remove defunct badges 80fd18d [Tests] run nyc on all tests df26f14 Update tape, jscs, eslint, @ljharb/eslint-config d7723aa [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape 9fdaabe [Dev Deps] update eslint, @ljharb/eslint-config, covert, tape f07eeb2 [Dev Deps] update tape, jscs, eslint, @ljharb/eslint-config bd5c751 [actions] add automatic rebasing / merge commit blocking 5666a91 [meta] add auto-changelog f70fb2b [actions] add \"Allow Edits\" workflow 2b040a8 [Dev Deps] update eslint, @ljharb/eslint-config, tape; add safe-publish-latest 09e2e53 [Tests] use npm audit instead of nsp 7df2669 [Tests] up to io.js v3.3, node v4.1 4ff97c5 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog 9e8cb7b [Dev Deps] update jscs, eslint, @ljharb/eslint-config, nsp 70b9888 [Dev Deps] update jscs 59d0c42 Add npm run security eb418ed [Dev Deps] update eslint, @ljharb/eslint-config, tape 86a758d Only apps should have lockfiles a0ab621 [Tests] use npx aud instead of nsp or npm audit with hoops 5c51349 [meta] add funding field 1d0b2f4 [actions] switch Automatic Rebase workflow to pull_request_target event 9b12367 [Dev Deps] update auto-changelog, tape 6d98b8d [Dev Deps] Update tape, eslint a258cdb [Dev Deps] update auto-changelog; add aud 2ca2afb Test up to io.js v3.0 1254ae8 [Dev Deps] update auto-changelog 4b54722 [Tests] only audit prod deps 86d298b [Dev Deps] update tape 3a47e27 Switch from vb.teelaun.ch to versionbadg.es for the npm version badge SVG. 128d9bd v2.0.0 - 2015-07-24 Commits Update tape, eslint; use my personal shared eslint config. 648d002 Add npm run eslint 5a52d80 Using my standard jscs.json file 5a667d9 Adding npm run lint 9a85ed9 Update tape, covert, jscs c6cd3a6 Update eslint e9c9b6e Test on latest io.js 2f7c8a9 Adding license and downloads badges 717087a Remove Number type coercion. 481295d Test up to io.js v2.1 139a84a Update eslint 2f5fbfb Update eslint 53cb4c5 Test on io.js v2.2 98a1824 All grade A-supported node/iojs versions now ship with an npm that understands ^. 772d6cd Run travis-ci tests on iojs and node v0.12; speed up builds; allow 0.8 failures. 3e6147e Use SVG badges instead of PNG d986cb4 Update tape, jscs 9f9d7e7 Update jscs 079eaf6 Update tape, jscs cffe3fc Update tape, jscs 3a16616 Use consistent quotes 9509a81 Test on io.js v2.4 a9150a3 Test on io.js v2.3 36d7acf Lock covert to v1.0.0. 29d8917 Updating jscs fe09c8a Updating jscs 5877bc7 Running linter as part of tests 9e77756 Updating covert 520a695 v1.0.0 - 2014-08-08 Commits Updating tape 31d1942 Updating tape e7143bf v0.1.1 - 2014-05-13 Merged Simplify code #1 Commits Adding a trailing newline 61fb37f v0.1.0 - 2014-05-13 Commits Make sure old and unstable nodes don't break Travis f627215 Updating deps b502f48 Oops, negative numbers were negative zero! 746cb97 Updating covert 99ef4ed Updating tape ee9cfc2 Testing on node 0.6 again 6a9bf0a v0.0.0 - 2014-01-19 Commits package.json 8411d92 read me 5c8bf3c Initial commit c06f7dc Tests. 5c554d4 Travis CI 334d000 Implementation. 4ef4491"
  },
  "node_modules/is-negative-zero/README.html": {
    "href": "node_modules/is-negative-zero/README.html",
    "title": "is-negative-zero | accouter",
    "keywords": "is-negative-zero Is this value negative zero? === will lie to you. Example var isNegativeZero = require('is-negative-zero'); var assert = require('assert'); assert.notOk(isNegativeZero(undefined)); assert.notOk(isNegativeZero(null)); assert.notOk(isNegativeZero(false)); assert.notOk(isNegativeZero(true)); assert.notOk(isNegativeZero(0)); assert.notOk(isNegativeZero(42)); assert.notOk(isNegativeZero(Infinity)); assert.notOk(isNegativeZero(-Infinity)); assert.notOk(isNegativeZero(NaN)); assert.notOk(isNegativeZero('foo')); assert.notOk(isNegativeZero(function () {})); assert.notOk(isNegativeZero([])); assert.notOk(isNegativeZero({})); assert.ok(isNegativeZero(-0)); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/is-number-like/README.html": {
    "href": "node_modules/is-number-like/README.html",
    "title": "is-number-like | accouter",
    "keywords": "is-number-like var looksLikeNumber = isNumberLike(val) Checks whether provided parameter looks like a number val (any) - the value to check returns (boolean) looksLikeNumber - true if val looks like a number, false otherwise const isNumberLike = require('is-number-like') isNumberLike('2') // true isNumberLike('a') // false"
  },
  "node_modules/is-number-object/CHANGELOG.html": {
    "href": "node_modules/is-number-object/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.7 - 2022-04-01 Commits [actions] reuse common workflows 8f9a1b0 [meta] better eccheck command 9dc8dff [Dev Deps] update eslint, @ljharb/eslint-config, core-js, safe-publish-latest, tape c50ecbf [actions] update codecov uploader f1a2560 [Dev Deps] update eslint, @ljharb/eslint-config, aud, core-js, tape 4b06ace [Dev Deps] update eslint, @ljharb/eslint-config, auto-changelog, core-js, tape 3dc0e8b [meta] add bugs/homepage package.json fields d7e0bcf v1.0.6 - 2021-08-05 Commits [Tests] run tests with core-js as well 5177312 [Refactor] use has-tostringtag to behave correctly in the presence of symbol shams ca2b31d [Dev Deps] update auto-changelog, core-js, eslint, tape 50950f9 v1.0.5 - 2021-05-07 Commits [Tests] migrate tests to Github Actions 9666737 [actions] use node/install instead of node/run; use codecov action 7815ce2 [meta] do not publish github action workflow files 80ccb75 [Tests] run nyc on all tests c9ffb74 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape 7e84161 [readme] add actions and codecov badges 0c5ec7a [actions] add Require Allow Edits workflow dd0fb74 [Dev Deps] update eslint, @ljharb/eslint-config, aud, has-symbols, tape 2d36f80 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog 77d3140 [Dev Deps] update eslint, @ljharb/eslint-config, tape 75d4abf [Dev Deps] update eslint, @ljharb/eslint-config, tape 0c2a917 [Fix] do not use Object.prototype.toString when Symbol.toStringTag is shammed 8b6ebc4 [Dev Deps] update auto-changelog, tape; add aud 62045fc [actions] use checkout v2; remove unneeded env d48cd06 [meta] use prepublishOnly script for npm 7+ 827ab0d [actions] switch Automatic Rebase workflow to pull_request_target event bfed500 [meta] remove explicit audit level config ce23e5e [meta] gitignore coverage output f1ad981 v1.0.4 - 2019-12-18 Commits [Tests] use shared travis-ci configs 792b5aa [Tests] up to node v12.4, v11.15, v10.15, v9.11, v8.15, v7.10, v6.17, v5.12, v4.9; use nvm install-latest-npm dc66db7 Update eslint, tape, semver; use my personal shared eslint config 7660fed [Tests] remove jscs f1fee97 [meta] add auto-changelog 4b1c225 [meta] remove unused Makefile and associated utilities 379b979 Update covert, jscs, eslint, semver 16d2af8 [Dev Deps] update eslint, @ljharb/eslint-config, covert, is, replace, semver, tape 21c0f04 Update is, tape, covert, jscs, editorconfig-tools, nsp, eslint, semver. Add replace. Use ^ instead of ~. 19d6ee3 Update eslint d32754b [Dev Deps] update eslint, @ljharb/eslint-config, replace 1df8165 Update tape, jscs, eslint, @ljharb/eslint-config 675372b [readme] clean up readme; remove testling; fix repo URLs 80e29c4 [Tests] up to node v12.7, v10.16, v8.16 287a968 Test on latest iojs and node versions. 11c98a2 [actions] add automatic rebasing / merge commit blocking 022d026 [meta] create FUNDING.yml 7f52710 [Dev Deps] update is, jscs, nsp, eslint, @ljharb/eslint-config, semver bc8cd50 [Tests] use npx aud instead of nsp or npm audit with hoops 1f9200b [Tests] up to node v12.11 706d50a [Dev Deps] update jscs e3591a4 [Tests] up to io.js v3.3, node v4.1 baf4ee7 Update nsp, eslint 61b18d5 Update eslint, semver 52e61bd [Dev Deps] update eslint, @ljharb/eslint-config, has-symbols; add safe-publish-latest 79db7f6 Only apps should have lockfiles 677b9b4 Test on io.js v2.2 e8a38b2 [meta] add funding field 85315e7 [Dev Deps] update eslint, tape f3581aa [Tests] use eclint instead of editorconfig-tools 7b53680 [Dev Deps] update semver, tape d6b524a [Dev Deps] Update tape, eslint be19203 Test up to io.js v2.1 feb7ba6 Test up to io.js v3.0 7be1f0a [Dev Deps] update tape d9a2318 Switch from vb.teelaun.ch to versionbadg.es for the npm version badge SVG. a6cd411 Test on io.js v2.4 46c2e7f Test on io.js v2.3 9c344b0 Fix tests for faked @@toStringTag f8c446e v1.0.3 - 2015-01-29 Commits If @@toStringTag is not present, use the old-school Object#toString test. 9b2a4df v1.0.2 - 2015-01-29 Commits Improve optimizability of the non-try/catch part. 7e6be2f Fix package.json 4f2ebea v1.0.1 - 2015-01-29 Commits Use Object() instead of new Number() 1aaa746 Add early exits for typeof number, or typeof not \"object\". eae4337 v1.0.0 - 2015-01-28 Commits Dotfiles. 9c74e3e make release a99e5ae package.json 4fed9ef Read me c91d6ba Initial commit 629fb96 Tests. a39de62 Implementation. aedd91e"
  },
  "node_modules/is-number-object/README.html": {
    "href": "node_modules/is-number-object/README.html",
    "title": "is-number-object | accouter",
    "keywords": "is-number-object Is this value a JS Number object? This module works cross-realm/iframe, and despite ES6 @@toStringTag. Example var isNumber = require('is-number-object'); var assert = require('assert'); assert.notOk(isNumber(undefined)); assert.notOk(isNumber(null)); assert.notOk(isNumber(false)); assert.notOk(isNumber(true)); assert.notOk(isNumber('foo')); assert.notOk(isNumber(function () {})); assert.notOk(isNumber([])); assert.notOk(isNumber({})); assert.notOk(isNumber(/a/g)); assert.notOk(isNumber(new RegExp('a', 'g'))); assert.notOk(isNumber(new Date())); assert.ok(isNumber(42)); assert.ok(isNumber(NaN)); assert.ok(isNumber(Infinity)); assert.ok(isNumber(new Number(42))); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/is-number/README.html": {
    "href": "node_modules/is-number/README.html",
    "title": "is-number | accouter",
    "keywords": "is-number Returns true if the value is a finite number. Please consider following this project's author, Jon Schlinkert, and consider starring the project to show your ❤️ and support. Install Install with npm: $ npm install --save is-number Why is this needed? In JavaScript, it's not always as straightforward as it should be to reliably check if a value is a number. It's common for devs to use +, -, or Number() to cast a string value to a number (for example, when values are returned from user input, regex matches, parsers, etc). But there are many non-intuitive edge cases that yield unexpected results: console.log(+[]); //=> 0 console.log(+''); //=> 0 console.log(+' '); //=> 0 console.log(typeof NaN); //=> 'number' This library offers a performant way to smooth out edge cases like these. Usage const isNumber = require('is-number'); See the tests for more examples. true isNumber(5e3); // true isNumber(0xff); // true isNumber(-1.1); // true isNumber(0); // true isNumber(1); // true isNumber(1.1); // true isNumber(10); // true isNumber(10.10); // true isNumber(100); // true isNumber('-1.1'); // true isNumber('0'); // true isNumber('012'); // true isNumber('0xff'); // true isNumber('1'); // true isNumber('1.1'); // true isNumber('10'); // true isNumber('10.10'); // true isNumber('100'); // true isNumber('5e3'); // true isNumber(parseInt('012')); // true isNumber(parseFloat('012')); // true False Everything else is false, as you would expect: isNumber(Infinity); // false isNumber(NaN); // false isNumber(null); // false isNumber(undefined); // false isNumber(''); // false isNumber(' '); // false isNumber('foo'); // false isNumber([1]); // false isNumber([]); // false isNumber(function () {}); // false isNumber({}); // false Release history 7.0.0 Refactor. Now uses .isFinite if it exists. Performance is about the same as v6.0 when the value is a string or number. But it's now 3x-4x faster when the value is not a string or number. 6.0.0 Optimizations, thanks to @benaadams. 5.0.0 Breaking changes removed support for instanceof Number and instanceof String Benchmarks As with all benchmarks, take these with a grain of salt. See the benchmarks for more detail. # all v7.0 x 413,222 ops/sec ±2.02% (86 runs sampled) v6.0 x 111,061 ops/sec ±1.29% (85 runs sampled) parseFloat x 317,596 ops/sec ±1.36% (86 runs sampled) fastest is 'v7.0' # string v7.0 x 3,054,496 ops/sec ±1.05% (89 runs sampled) v6.0 x 2,957,781 ops/sec ±0.98% (88 runs sampled) parseFloat x 3,071,060 ops/sec ±1.13% (88 runs sampled) fastest is 'parseFloat,v7.0' # number v7.0 x 3,146,895 ops/sec ±0.89% (89 runs sampled) v6.0 x 3,214,038 ops/sec ±1.07% (89 runs sampled) parseFloat x 3,077,588 ops/sec ±1.07% (87 runs sampled) fastest is 'v6.0' About Contributing Pull requests and stars are always welcome. For bugs and feature requests, please create an issue. Running Tests Running and reviewing unit tests is a great way to get familiarized with a library and its API. You can install dependencies and run tests with the following command: $ npm install && npm test Building docs (This project's readme.md is generated by verb, please don't edit the readme directly. Any changes to the readme must be made in the .verb.md readme template.) To generate the readme, run the following command: $ npm install -g verbose/verb#dev verb-generate-readme && verb Related projects You might also be interested in these projects: is-plain-object: Returns true if an object was created by the Object constructor. | homepage is-primitive: Returns true if the value is a primitive. | homepage isobject: Returns true if the value is an object and not an array or null. | homepage kind-of: Get the native type of a value. | homepage Contributors Commits Contributor 49 jonschlinkert 5 charlike-old 1 benaadams 1 realityking Author Jon Schlinkert LinkedIn Profile GitHub Profile Twitter Profile License Copyright © 2018, Jon Schlinkert. Released under the MIT License. This file was generated by verb-generate-readme, v0.6.0, on June 15, 2018."
  },
  "node_modules/is-plain-obj/readme.html": {
    "href": "node_modules/is-plain-obj/readme.html",
    "title": "is-plain-obj | accouter",
    "keywords": "is-plain-obj Check if a value is a plain object An object is plain if it's created by either {}, new Object(), or Object.create(null). Install $ npm install is-plain-obj Usage const isPlainObject = require('is-plain-obj'); isPlainObject({foo: 'bar'}); //=> true isPlainObject(new Object()); //=> true isPlainObject(Object.create(null)); //=> true isPlainObject([1, 2, 3]); //=> false class Unicorn {} isPlainObject(new Unicorn()); //=> false Related is-obj - Check if a value is an object is - Type check values Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "node_modules/is-regex/CHANGELOG.html": {
    "href": "node_modules/is-regex/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.1.4 - 2021-08-05 Commits [Dev Deps] update auto-changelog, core-js, eslint, tape 4b17cad [Refactor] use has-tostringtag to behave correctly in the presence of symbol shams 2dad4af v1.1.3 - 2021-05-07 Commits [actions] use node/install instead of node/run; use codecov action c681ab9 [Fix] do not use Object.prototype.toString when Symbol.toStringTag is shammed ca019fd [Dev Deps] update eslint, @ljharb/eslint-config, aud, tape 605a66f [readme] add actions and codecov badges 8d7c6f0 [meta] use prepublishOnly script for npm 7+ 8e50e91 [Deps] update has-symbols 4742c81 v1.1.2 - 2021-02-01 Commits [Tests] migrate tests to Github Actions cc1686e [readme] fix repo URLs; remove travis badge d1d1da6 [meta] do not publish github action workflow files 9f84b99 [Tests] run nyc on all tests c37aab9 [Robustness] use call-bind fbb61bf [actions] add \"Allow Edits\" workflow 9022b53 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog d60f28f [Dev Deps] update eslint, @ljharb/eslint-config, tape 2c35c43 [actions] switch Automatic Rebase workflow to pull_request_target event 1009e25 [meta] gitignore coverage output 3b5fa9e [actions] update workflows 1843ef6 v1.1.1 - 2020-08-03 Commits [Performance] Re-add lastIndex check to improve performance d8495cd [Dev Deps] update auto-changelog, eslint 778fa6b v1.1.0 - 2020-06-03 Commits [New] use badStringifier‑based RegExp detection 31eff67 [Dev Deps] update eslint, @ljharb/eslint-config, aud, tape fc91458 [Dev Deps] update eslint, @ljharb/eslint-config, tape; add safe-publish-latest d43ed83 [Dev Deps] update auto-changelog, tape; add aud 56647d1 [meta] only run aud on prod deps e0865b8 v1.0.5 - 2019-12-15 Commits [Tests] use shared travis-ci configs af728b2 [Tests] remove jscs 1b8cfe8 [meta] add auto-changelog c3131d8 [Tests] up to node v8.1, v7.10, v6.11, v4.8; newer npm fails on older nodes 660b658 [Tests] up to node v9.3, v8.9, v6.12; use nvm install-latest-npm; pin included builds to LTS 7c25218 [Tests] up to node v12.10, v11.15, v10.16, v8.16, v6.17 fa95547 [meta] remove unused Makefile and associated utilities 9fd2a29 [Tests] up to node v11.3, v10.14, v8.14, v6.15 7f2ac41 [Tests] up to node v10.0, v9.11, v8.11, v6.14, v4.9 6fa2b0f [Dev Deps] update eslint, @ljharb/eslint-config 697e1de [actions] add automatic rebasing / merge commit blocking ad86dc9 [Dev Deps] update eslint, @ljharb/eslint-config, jscs, nsp, replace, semver, tape 5c99c8e [Dev Deps] update eslint, @ljharb/eslint-config, replace, semver, tape bb63686 [Dev Deps] update eslint, @ljharb/eslint-config@, replace, semver, tape ddf3670 [Dev Deps] update tape, nsp, eslint, @ljharb/eslint-config e7b5a62 [Dev Deps] update eslint, @ljharb/eslint-config, covert, tape c803db5 [Tests] switch from nsp to npm audit b7239be [Dev Deps] update eslint, nsp, semver, tape 347ee6c Only apps should have lockfiles. 3866575 [Tests] use npx aud instead of nsp or npm audit with hoops d099a39 [meta] add funding field 741aecd [Tests] use eclint instead of editorconfig-tools bc6aa75 [Tests] on node v10.1 262226f [Dev Deps] update eslint 31fd719 [Deps] update has e9e25a3 [Dev Deps] update replace aeeb968 [Tests] set audit level 2a6290e [Tests] remove nsp fc74c2b v1.0.4 - 2017-02-18 Fixed [Fix] ensure that lastIndex is not mutated #3 Commits Update eslint, tape, semver; use my personal shared eslint config c4a41c3 [Tests] on all node minors; improve test matrix 58d7508 [Dev Deps] update tape, jscs, nsp, eslint, @ljharb/eslint-config, semver 7290076 Update covert, jscs, eslint, semver dabc729 Update eslint a946b05 Update tape, jscs, eslint, @ljharb/eslint-config 1744dde [Refactor] when try/catch is needed, bail early if the value lacks an own lastIndex data property. 288ad93 Update editorconfig-tools, eslint, semver, replace 4d895c6 Update eslint, tape, semver f387f03 All grade A-supported node/iojs versions now ship with an npm that understands ^. 55e480f [Dev Deps] update jscs, nsp, eslint, @ljharb/eslint-config, semver 89d9528 [Dev Deps] update jscs eb222a8 [Tests] up to io.js v3.3, node v4.1 c65429c Update nsp, eslint c60fbd8 Update eslint, semver 6a62116 [Tests] on node v7.5, v4.7 e764651 Test up to io.js v2.1 3bf326a Test on the latest io.js versions. 693d047 [Refactor] use an early return instead of a ternary. 31eaca2 Test on io.js v2.2 c18c55a Run travis-ci tests on iojs and node v0.12; speed up builds; allow 0.8 failures. a1c237d [Dev Deps] update eslint, @ljharb/eslint-config aa3ea0f [Dev Deps] update eslint, @ljharb/eslint-config d97831d [Dev Deps] Update tape, eslint 95e6def Update eslint, nsp 3844c93 Update tape, jscs 0d6dac8 Fix tests for faked @@toStringTag 2ebef9f Test up to io.js v3.0 ec1d2d4 [Refactor] bail earlier when the value is falsy. a9e333e [Dev Deps] update tape 8cdcaae Switch from vb.teelaun.ch to versionbadg.es for the npm version badge SVG. 281c4ef Test on io.js v2.4 4d54c68 Test on io.js v2.3 23170f5 Test on iojs-v1.6 4487ad0 v1.0.3 - 2015-01-29 Commits Update npm run scripts. dc528dd Add toStringTag tests. f48a83a If @@toStringTag is not present, use the old-school Object#toString test. 50b0ffd v1.0.2 - 2015-01-29 Commits make release a1de7ec Improve optimization by separating the try/catch, and bailing out early when not typeof \"object\". 5ab7632 v1.0.1 - 2015-01-28 Commits Using my standard jscs.json file 1f1733a Adding npm run lint 51ea70f Use RegExp#exec to test if something is a regex, which works even with ES6 @@toStringTag. 042c8c7 Adding license and downloads badges 366d619 Use SVG badges instead of PNG 6a32e4f Update tape, jscs f1b9462 Update jscs 1bff23f Update tape, jscs c22ea2e Update tape, jscs b0479db Use consistent quotes 1a6e347 Make travis builds faster. 090a4ea Update tape 7d76129 Lock covert to v1.0.0. 9a90b03 Updating tape bfbc7f5 Updating jscs 13ad511 Updating jscs cda1945 Updating jscs de96c99 Running linter as part of tests 2cb6567 Updating covert a56ae74 Updating tape ffe47f7 v1.0.0 - 2014-05-19 Commits Make sure old and unstable nodes don't break Travis 05da747 toString is a reserved var name in old Opera 885c48c Updating deps 2ca0e79 Updating tape. 9678435 Updating covert c3bb898 Updating tape 7811708 Testing on node 0.6 again dec36ae Run code coverage as part of tests e6f4ebe v0.0.0 - 2014-01-15 Commits package.json aa60d43 read me 861e944 Initial commit d0cdd71 Tests. b533f74 Implementation. 3c9a8c0 Travis CI 742c440"
  },
  "node_modules/is-regex/README.html": {
    "href": "node_modules/is-regex/README.html",
    "title": "is-regex | accouter",
    "keywords": "is-regex Is this value a JS regex? This module works cross-realm/iframe, and despite ES6 @@toStringTag. Example var isRegex = require('is-regex'); var assert = require('assert'); assert.notOk(isRegex(undefined)); assert.notOk(isRegex(null)); assert.notOk(isRegex(false)); assert.notOk(isRegex(true)); assert.notOk(isRegex(42)); assert.notOk(isRegex('foo')); assert.notOk(isRegex(function () {})); assert.notOk(isRegex([])); assert.notOk(isRegex({})); assert.ok(isRegex(/a/g)); assert.ok(isRegex(new RegExp('a', 'g'))); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/is-shared-array-buffer/CHANGELOG.html": {
    "href": "node_modules/is-shared-array-buffer/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.3 - 2024-02-20 Commits [meta] use npmignore to autogenerate an npmignore file c4131f5 add types 41cb419 [actions] skip ls check on node < 10; remove redundant finisher 2655b01 [Dev Deps] update @ljharb/eslint-config, aud, available-typed-arrays, npmignore, object-inspect, tape 5917f9a [Tests] add tests that TypedArrays are not SABs 823dd7a [Dev Deps] update eslint, @ljharb/eslint-config, aud, es-value-fixtures, object-inspect, tape 6701ad4 [actions] update rebase action to use reusable workflow b5119f0 [Dev Deps] update @ljharb/eslint-config, aud 38a6d72 [meta] add missing engines.node aac97e1 [readme] remove dead badges 07c452d [Deps] update call-bind b8576fe [meta] add sideEffects flag 3e6730e v1.0.2 - 2022-04-01 Commits [actions] reuse common workflows 48d01e6 [actions] use node/install instead of node/run; use codecov action 7b0e12a [Dev Deps] update eslint, @ljharb/eslint-config, object-inspect, safe-publish-latest, tape 8d57a8e [readme] update URLs dca4d27 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, object-inspect, tape 2a7bb99 [Dev Deps] update eslint, @ljharb/eslint-config, auto-changelog, object-inspect, safe-publish-latest, tape 389c6db [actions] update codecov uploader b9661f9 [Dev Deps] update eslint, @ljharb/eslint-config, aud, object-inspect f99cd48 [readme] add actions and codecov badges 9515ed2 [Fix] add missing call-bind dependency cff5358 [meta] add safe-publish-latest; use prepublishOnly script for npm 7+ ba0b719 v1.0.1 - 2021-03-04 Commits [readme] fix repo URLs 37c38f3 v1.0.0 - 2021-03-04 Commits [Tests] add tests 9c7b806 Initial commit 4e65c5e [meta] do not publish github action workflow files ac3693d readme 7a984d0 npm init a586c99 [actions] add automatic rebasing / merge commit blocking 184fe62 Implementation 207e26d [meta] create FUNDING.yml; add \"funding\" field 3cad3fc [meta] add auto-changelog 31f1f2c [Tests] add npm run lint 2e5146e Only apps should have lockfiles 7b2adfa"
  },
  "node_modules/is-shared-array-buffer/README.html": {
    "href": "node_modules/is-shared-array-buffer/README.html",
    "title": "is-shared-array-buffer | accouter",
    "keywords": "is-shared-array-buffer Is this value a JS SharedArrayBuffer? This module works cross-realm/iframe, does not depend on instanceof or mutable properties, and despite ES6 Symbol.toStringTag. Example var assert = require('assert'); var isSharedArrayBuffer = require('is-shared-array-buffer'); assert(!isSharedArrayBuffer(function () {})); assert(!isSharedArrayBuffer(null)); assert(!isSharedArrayBuffer(function* () { yield 42; return Infinity; }); assert(!isSharedArrayBuffer(Symbol('foo'))); assert(!isSharedArrayBuffer(1n)); assert(!isSharedArrayBuffer(Object(1n))); assert(!isSharedArrayBuffer(new Set())); assert(!isSharedArrayBuffer(new WeakSet())); assert(!isSharedArrayBuffer(new Map())); assert(!isSharedArrayBuffer(new WeakMap())); assert(!isSharedArrayBuffer(new WeakRef({}))); assert(!isSharedArrayBuffer(new FinalizationRegistry(() => {}))); assert(!isSharedArrayBuffer(new ArrayBuffer())); assert(isSharedArrayBuffer(new SharedArrayBuffer())); class MySharedArrayBuffer extends SharedArrayBuffer {} assert(isSharedArrayBuffer(new MySharedArrayBuffer())); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/is-string/CHANGELOG.html": {
    "href": "node_modules/is-string/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. Generated by auto-changelog. v1.0.7 - 2021-08-05 Commits [Refactor] use has-tostringtag to behave correctly in the presence of symbol shams d973ffd [Dev Deps] update auto-changelog, core-js, eslint, tape 4bfaabf v1.0.6 - 2021-05-07 Commits [Tests] migrate tests to Github Actions c7790c8 [actions] use node/install instead of node/run; use codecov action 1e52bbd [Fix] do not use Object.prototype.toString when Symbol.toStringTag is shammed 83337eb [meta] do not publish github action workflow files b25aea2 [readme] update badges 759ccd9 [Tests] run nyc on all tests dc02f70 [Dev Deps] update eslint, @ljharb/eslint-config, auto-changelog, tape; add aud a0f76fa [actions] add \"Allow Edits\" workflow 9ec3902 [Dev Deps] update eslint, @ljharb/eslint-config, aud, tape 57fbe21 [Dev Deps] update eslint, @ljharb/eslint-config, tape 191e55f [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog 1ea2b81 [Dev Deps] update eslint, @ljharb/eslint-config, tape 105d1b9 [Dev Deps] update auto-changelog, tape; add aud 114cfad [meta] use prepublishOnly script for npm 7+ fc38f26 [meta] gitignore coverage output 3419127 [actions] update rebase action to use checkout v2 334eca0 [actions] switch Automatic Rebase workflow to pull_request_target event 7a332e9 [meta] remove explicit audit level config 04630b1 v1.0.5 - 2019-12-18 Commits [Tests] use shared travis-ci configs 4121d6b [Tests] up to node v12.4, v11.15, v10.15, v9.11, v8.15, v7.10, v6.17, v5.12, v4.9; use nvm install-latest-npm e7a3e89 Update eslint, tape, semver; use my personal shared eslint config 6c380a7 [Tests] remove jscs 3d49592 Update is, tape, covert, jscs, editorconfig-tools, eslint, nsp, semver. cc6983d [meta] add auto-changelog b857897 [meta] remove unused Makefile and associated utilities 3f0f51c [Dev Deps] update eslint, @ljharb/eslint-config, is, covert, tape, semver 9d4a95e Update eslint e861b4b Update tape, jscs, eslint, @ljharb/eslint-config 172e2dd Test on node and io.js latest. fd426cd [Dev Deps] update eslint, @ljharb/eslint-config, safe-publish-latest 23bdf83 [actions] add automatic rebasing / merge commit blocking 96153c0 [meta] create FUNDING.yml 66ae246 [Dev Deps] update is, jscs, nsp, eslint, @ljharb/eslint-config, semver 817361a [Dev Deps] update eslint, @ljharb/eslint-config, safe-publish-latest, semver, tape fc35d3f [Dev Deps] update jscs 886767e [Tests] use npx aud instead of nsp or npm audit with hoops 3410922 [Tests] up to io.js v3.3, node v4.1 4d6c73b Update nsp, eslint b11de49 Update eslint, semver 0777977 Only apps should have lockfiles 78b49ff [meta] add funding field 81328a6 [Dev Deps] update eslint, tape fc9a225 [Tests] use eclint instead of editorconfig-tools 59c2c61 [Dev Deps] Update tape, eslint a429816 Test on io.js v2.2 08b476e Test up to io.js v3.0 22637ef [meta] add safe-publish-latest 20ccb48 [Dev Deps] update tape 06b58a0 Switch from vb.teelaun.ch to versionbadg.es for the npm version badge SVG. ea7cf84 Test on io.js v2.4 66ec3ea Test on io.js v2.3 ca6e796 Fix tests for faked @@toStringTag 3cce832 v1.0.4 - 2015-01-29 Commits If @@toStringTag is not present, use the old-school Object#toString test. 30675ec v1.0.3 - 2015-01-29 Commits Refactor to aid optimization of non-try/catch code. 9b2772a v1.0.2 - 2015-01-29 Commits Fix broken package.json dc921d3 v1.0.1 - 2015-01-29 Commits Fix eslint config. c4e05bd Add early exits for typeof \"string\", or typeof not \"object\". 82f41d3 v1.0.0 - 2015-01-29 Commits Dotfiles. 45bc9dd make release 23707f5 package.json 575ad81 Read me 3f67c9a Initial commit 2c26a7a Tests. 38c987b Implementation. 0471d59"
  },
  "node_modules/is-string/README.html": {
    "href": "node_modules/is-string/README.html",
    "title": "is-string | accouter",
    "keywords": "is-string Is this value a JS String object or primitive? This module works cross-realm/iframe, and despite ES6 @@toStringTag. Example var isString = require('is-string'); var assert = require('assert'); assert.notOk(isString(undefined)); assert.notOk(isString(null)); assert.notOk(isString(false)); assert.notOk(isString(true)); assert.notOk(isString(function () {})); assert.notOk(isString([])); assert.notOk(isString({})); assert.notOk(isString(/a/g)); assert.notOk(isString(new RegExp('a', 'g'))); assert.notOk(isString(new Date())); assert.notOk(isString(42)); assert.notOk(isString(NaN)); assert.notOk(isString(Infinity)); assert.notOk(isString(new Number(42))); assert.ok(isString('foo')); assert.ok(isString(Object('foo'))); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/is-symbol/CHANGELOG.html": {
    "href": "node_modules/is-symbol/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.4 - 2021-05-08 Commits [Tests] migrate tests to Github Actions 997d43c [actions] use node/install instead of node/run; use codecov action fe0ccb7 [meta] remove unused Makefile and associated utilities 3ab2748 [meta] do not publish github action workflow files f20fafe [Tests] run nyc on all tests 5c332fc [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, object-inspect, tape c5a58a8 [readme] fix repo URLs; remove travis badge bcd9258 [actions] add \"Allow Edits\" workflow 33ae2d3 [Dev Deps] update eslint, @ljharb/eslint-config, aud, object-inspect, tape e53def0 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, object-inspect ae36504 [readme] add actions and codecov badges aae7f09 [Dev Deps] update eslint, @ljharb/eslint-config, tape d993fae [Dev Deps] update eslint, @ljharb/eslint-config, tape 51808a5 [Dev Deps] update auto-changelog, tape c90040f [Dev Deps] update eslint, tape 9fee159 [meta] use prepublishOnly script for npm 7+ b166afc [meta] gitignore coverage output 4a0fe3a [actions] update workflows fbcbc9e [Dev Deps] update auto-changelog; add aud e66ab98 [Deps] update has-symbols 6ce7de5 [actions] update rebase action to use checkout v2 1173c79 [actions] switch Automatic Rebase workflow to pull_request_target event 94a6348 [Tests] only audit prod deps 0692681 [meta] do not publish .nvmrc file ed47833 v1.0.3 - 2019-11-20 Commits [Tests] use shared travis-ci configs 034afdd [Tests] remove jscs 0c026a0 [meta] add auto-changelog 9a1776b [Tests] up to node v12.10, v11.15, v10.16, v8.16, v6.17 23a6db4 [Tests] up to node v11.7, v10.15, v8.15, v6.16 892d92e [Dev Deps] update eslint, @ljharb/eslint-config, safe-publish-latest, semver, tape c2e6d6a [readme] fix repo URLs 655c288 [actions] add automatic rebasing / merge commit blocking 97b1229 [meta] add FUNDING.yml 94c64a3 [Dev Deps] update eslint, @ljharb/eslint-config, covert, tape, semver 71ab543 [Dev Deps] update eslint, @ljharb/eslint-config, semver, tape c6212f9 [Dev Deps] update eslint, @ljharb/eslint-config, safe-publish-latest, object-inspect 91bc802 [Tests] use npx aud instead of nsp or npm audit with hoops 8cbe69c [Tests] use npm audit instead of nsp 741b51d [meta] add funding field 65b58d1 [Deps] update has-symbols 9cb5b2a v1.0.2 - 2018-09-20 Commits Update eslint, tape, semver; use my personal shared eslint config e86aaea [Tests] on all node minors; improve test matrix 50bc07f [Dev Deps] update tape, jscs, nsp, semver, eslint, @ljharb/eslint-config 45e17bd [Tests] up to node v10.0, v9.11, v8.11, v6.14, v4.9; use nvm install-latest-npm 44402cb [Tests] up to node v8.1, v7.10, v6.11, v4.8; improve matrix; old npm breaks on newer nodes 9047c23 Update tape, covert, jscs, semver d57d1ce Add npm run eslint 0d75a66 Update eslint 042fb3a [Refactor] use has-symbols and object-inspect 129bc68 [Tests] up to node v10.11, v8.12 c1822e8 Update tape, jscs, eslint, @ljharb/eslint-config 089d2cf [Tests] up to node v8.4; newer npm breaks on older node 05ce701 All grade A-supported node/iojs versions now ship with an npm that understands ^. 241e6a6 Test on latest node and io.js versions. 5c8d5de [Dev Deps] update eslint, @ljharb/eslint-config, nsp, semver, tape 06047bf [Dev Deps] update jscs, nsp, semver, eslint, @ljharb/eslint-config 9d25dd7 [Tests] up to io.js v3.3, node v4.1 ce173bd Update nsp, eslint 29e5214 Update semver, eslint 53be884 [Dev Deps] update eslint, nsp, semver, tape 3bd149c [Dev Deps] update jscs 69b4231 Test up to io.js v2.1 0b61ac7 [Dev Deps] update tape 5e1b200 Only apps should have lockfiles. a191ff5 [Dev Deps] update nsp, eslint, @ljharb/eslint-config 97c87ef Test on io.js v2.2 42560e4 [Dev Deps] Update tape, eslint 149b2f2 [Tests] fix test messages 28bd1ed Test up to io.js v3.0 c0dcc98 node now supports Symbols now. d1853ad [Dev Deps] update tape f7a6575 Switch from vb.teelaun.ch to versionbadg.es for the npm version badge SVG. aae9c6a Test on io.js v2.4 ab8f449 Test on io.js v2.3 58ce871 v1.0.1 - 2015-01-26 Commits Correct package description. f4d15b9 v1.0.0 - 2015-01-24 Commits Dotfiles. 5d9a744 Tests. 8af5663 make release 6293446 package.json 7d4082c Initial commit cbb179f Read me. 099a775 Implementation. cb51248"
  },
  "node_modules/is-symbol/README.html": {
    "href": "node_modules/is-symbol/README.html",
    "title": "is-symbol | accouter",
    "keywords": "is-symbol Is this an ES6 Symbol value? Example var isSymbol = require('is-symbol'); assert(!isSymbol(function () {})); assert(!isSymbol(null)); assert(!isSymbol(function* () { yield 42; return Infinity; }); assert(isSymbol(Symbol.iterator)); assert(isSymbol(Symbol('foo'))); assert(isSymbol(Symbol.for('foo'))); assert(isSymbol(Object(Symbol('foo')))); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/is-typed-array/CHANGELOG.html": {
    "href": "node_modules/is-typed-array/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.1.13 - 2024-02-01 Commits [patch] add types 8a8a679 [Dev Deps] update aud, has-tostringtag, npmignore, object-inspect, tape 8146b60 [actions] optimize finishers 34f875a [Deps] update which-typed-array 19c974f [meta] add sideEffects flag 0b68e5e v1.1.12 - 2023-07-17 Commits [Refactor] use which-typed-array for all internals 7619405 v1.1.11 - 2023-07-17 Commits [Fix] node &lt; v0.6 lacks proper Object toString behavior c94b90d [Robustness] use call-bind 573b00b [Dev Deps] update @ljharb/eslint-config, aud, object-inspect, tape c88c2d4 v1.1.10 - 2022-11-02 Commits [meta] add auto-changelog cf6d86b [actions] update rebase action to use reusable workflow 8da51a5 [Dev Deps] update aud, is-callable, object-inspect, tape 554e3de [Refactor] use gopd instead of an es-abstract helper [cdaa465`](https://github.com/inspect-js/is-typed-array/commit/cdaa465d5f94bfc9e32475e31209e1c2458a9603) [Deps] update es-abstract 677ae4b 1.1.9 / 2022-05-13 [Refactor] use foreach instead of for-each [readme] markdown URL cleanup [Deps] update es-abstract [meta] use npmignore to autogenerate an npmignore file [Dev Deps] update eslint, @ljharb/eslint-config, object-inspect, safe-publish-latest, tape [actions] reuse common workflows [actions] update codecov uploader 1.1.8 / 2021-08-30 [Refactor] use globalThis if available (#53) [Deps] update available-typed-arrays [Dev Deps] update @ljharb/eslint-config 1.1.7 / 2021-08-07 [Fix] if Symbol.toStringTag exists but is not present, use Object.prototype.toString [Dev Deps] update is-callable, tape 1.1.6 / 2021-08-05 [Fix] use has-tostringtag to behave correctly in the presence of symbol shams [readme] add actions and codecov badges [meta] use prepublishOnly script for npm 7+ [Deps] update available-typed-arrays, es-abstract [Dev Deps] update eslint, @ljharb/eslint-config, aud, object-inspect, tape [actions] use node/install instead of node/run; use codecov action 1.1.5 / 2021-02-14 [meta] do not publish github action workflow files or nyc output [Deps] update call-bind, es-abstract [Dev Deps] update eslint, @ljharb/eslint-config, aud, is-callable, tape 1.1.4 / 2020-12-05 [readme] fix repo URLs, remove defunct badges [Deps] update available-typed-arrays, es-abstract; use call-bind where applicable [meta] gitignore nyc output [meta] only audit prod deps [actions] add \"Allow Edits\" workflow [actions] switch Automatic Rebase workflow to pull_request_target event [Dev Deps] update eslint, @ljharb/eslint-config, is-callable, make-arrow-function, make-generator-function, object-inspect, tape; add aud [Tests] migrate tests to Github Actions [Tests] run nyc on all tests 1.1.3 / 2020-01-24 [Refactor] use es-abstract’s callBound, available-typed-arrays, has-symbols 1.1.2 / 2020-01-20 [Fix] in envs without Symbol.toStringTag, dc8a8cc made arrays return true [Tests] add evalmd to prelint 1.1.1 / 2020-01-18 [Robustness] don’t rely on Array.prototype.indexOf existing [meta] remove unused Makefile and associated utilities [meta] add funding field; create FUNDING.yml [actions] add automatic rebasing / merge commit blocking [Dev Deps] update eslint, @ljharb/eslint-config, is-callable, replace, semver, tape; add safe-publish-latest [Tests] use shared travis-ci configs [Tests] use npx aud instead of nsp or npm audit with hoops 1.1.0 / 2019-02-16 [New] add BigInt64Array and BigUint64Array [Refactor] use an array instead of an object for storing Typed Array names [meta] ignore test.html [Tests] up to node v11.10, v10.15, v8.15, v7.10, v6.16, v5.10, v4.9 [Tests] remove jscs [Tests] use npm audit instead of nsp [Dev Deps] update eslint, @ljharb/eslint-config, is-callable, tape, replace, semver [Dev Deps] remove unused eccheck script + dep 1.0.4 / 2016-03-19 [Fix] Symbol.toStringTag is on the super-[[Prototype]] of Float32Array, not the [[Prototype]] (#3) [Tests] up to node v5.9, v4.4 [Tests] use pretest/posttest for linting/security [Dev Deps] update tape, jscs, nsp, eslint, @ljharb/eslint-config, semver, is-callable 1.0.3 / 2015-10-13 [Deps] Add missing foreach dependency (#1) 1.0.2 / 2015-10-05 [Deps] Remove unneeded \"isarray\" dependency [Dev Deps] update eslint, @ljharb/eslint-config 1.0.1 / 2015-10-02 Rerelease: avoid instanceof and the constructor property; work cross-realm; work with Symbol.toStringTag. 1.0.0 / 2015-05-06 Initial release."
  },
  "node_modules/is-typed-array/README.html": {
    "href": "node_modules/is-typed-array/README.html",
    "title": "is-typed-array | accouter",
    "keywords": "is-typed-array [![dependency status][5]][6] [![dev dependency status][7]][8] Is this value a JS Typed Array? This module works cross-realm/iframe, does not depend on instanceof or mutable properties, and despite ES6 Symbol.toStringTag. Example var isTypedArray = require('is-typed-array'); var assert = require('assert'); assert.equal(false, isTypedArray(undefined)); assert.equal(false, isTypedArray(null)); assert.equal(false, isTypedArray(false)); assert.equal(false, isTypedArray(true)); assert.equal(false, isTypedArray([])); assert.equal(false, isTypedArray({})); assert.equal(false, isTypedArray(/a/g)); assert.equal(false, isTypedArray(new RegExp('a', 'g'))); assert.equal(false, isTypedArray(new Date())); assert.equal(false, isTypedArray(42)); assert.equal(false, isTypedArray(NaN)); assert.equal(false, isTypedArray(Infinity)); assert.equal(false, isTypedArray(new Number(42))); assert.equal(false, isTypedArray('foo')); assert.equal(false, isTypedArray(Object('foo'))); assert.equal(false, isTypedArray(function () {})); assert.equal(false, isTypedArray(function* () {})); assert.equal(false, isTypedArray(x => x * x)); assert.equal(false, isTypedArray([])); assert.ok(isTypedArray(new Int8Array())); assert.ok(isTypedArray(new Uint8Array())); assert.ok(isTypedArray(new Uint8ClampedArray())); assert.ok(isTypedArray(new Int16Array())); assert.ok(isTypedArray(new Uint16Array())); assert.ok(isTypedArray(new Int32Array())); assert.ok(isTypedArray(new Uint32Array())); assert.ok(isTypedArray(new Float32Array())); assert.ok(isTypedArray(new Float64Array())); assert.ok(isTypedArray(new BigInt64Array())); assert.ok(isTypedArray(new BigUint64Array())); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/is-unicode-supported/readme.html": {
    "href": "node_modules/is-unicode-supported/readme.html",
    "title": "is-unicode-supported | accouter",
    "keywords": "is-unicode-supported Detect whether the terminal supports Unicode This can be useful to decide whether to use Unicode characters or fallback ASCII characters in command-line output. Note that the check is quite naive. It just assumes all non-Windows terminals support Unicode and hard-codes which Windows terminals that do support Unicode. However, I have been using this logic in some popular packages for years without problems. Install $ npm install is-unicode-supported Usage const isUnicodeSupported = require('is-unicode-supported'); isUnicodeSupported(); //=> true API isUnicodeSupported() Returns a boolean for whether the terminal supports Unicode. Related is-interactive - Check if stdout or stderr is interactive supports-color - Detect whether a terminal supports color figures - Unicode symbols with Windows fallbacks log-symbols - Colored symbols for various log levels"
  },
  "node_modules/is-weakref/CHANGELOG.html": {
    "href": "node_modules/is-weakref/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.2 - 2021-12-10 Commits [actions] reuse common workflows 2375b1f [meta] do not publish workflow files 4c1be42 [actions] use node/install instead of node/run; use codecov action 7ec78ce [readme] update URLs 6306f09 [Dev Deps] update eslint, @ljharb/eslint-config, object-inspect, safe-publish-latest, tape 7a1601e [readme] add actions and codecov badges 67ecd14 [Dev Deps] update eslint, @ljharb/eslint-config, auto-changelog, object-inspect, safe-publish-latest, tape 1a5013b [actions] update codecov uploader b57b037 [Dev Deps] update eslint, @ljharb/eslint-config, aud, object-inspect, tape da49017 [meta] simplify \"exports\" 9b88835 [Dev Deps] update eslint, @ljharb/eslint-config, tape c7e77f4 [Dev Deps] update eslint 417b29e [meta] add safe-publish-latest; use prepublishOnly script for npm 7+ b1b99f4 [Deps] update call-bind aea342e [actions] update workflows 786c2d3 v1.0.1 - 2020-12-04 Commits [Tests] migrate tests to Github Actions 05b4faa [Tests] run nyc on all tests 8df2e4b [actions] add \"Allow Edits\" workflow 4a716b8 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, object-inspect be23cf3 [Refactor] use call-bind instead of es-abstract a933a96 [actions] switch Automatic Rebase workflow to pull_request_target event 4473ed2 [readme] remove travis badge bd3bfcd v1.0.0 - 2020-08-01 Commits Initial commit dd86394 readme f4defca Tests 13d8139 npm init 55a2bb7 Implementation 1ec84e3 [meta] add auto-changelog ab9ce44 [actions] add automatic rebasing / merge commit blocking 3d3f4d5 [meta] add \"funding\"; create FUNDING.yml f35ef3d [Tests] add npm run lint af2123d [Tests] use shared travis-ci configs 042b4de Only apps should have lockfiles fcae604"
  },
  "node_modules/is-weakref/README.html": {
    "href": "node_modules/is-weakref/README.html",
    "title": "is-weakref | accouter",
    "keywords": "is-weakref [![npm badge][11]][1] Is this value a JS WeakRef? This module works cross-realm/iframe, and despite ES6 @@toStringTag. Example var isWeakRef = require('is-weakref'); assert(!isWeakRef(function () {})); assert(!isWeakRef(null)); assert(!isWeakRef(function* () { yield 42; return Infinity; }); assert(!isWeakRef(Symbol('foo'))); assert(!isWeakRef(1n)); assert(!isWeakRef(Object(1n))); assert(!isWeakRef(new Set())); assert(!isWeakRef(new WeakSet())); assert(!isWeakRef(new Map())); assert(!isWeakRef(new WeakMap())); assert(isWeakRef(new WeakRef({}))); class MyWeakRef extends WeakRef {} assert(isWeakRef(new MyWeakRef({}))); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/is-wsl/readme.html": {
    "href": "node_modules/is-wsl/readme.html",
    "title": "is-wsl | accouter",
    "keywords": "is-wsl Check if the process is running inside Windows Subsystem for Linux (Bash on Windows) Can be useful if you need to work around unimplemented or buggy features in WSL. Install $ npm install --save is-wsl Usage const isWsl = require('is-wsl'); // When running inside Windows Subsystem for Linux console.log(isWsl); //=> true License MIT © Sindre Sorhus"
  },
  "node_modules/isarray/README.html": {
    "href": "node_modules/isarray/README.html",
    "title": "isarray | accouter",
    "keywords": "isarray Array#isArray for older browsers and deprecated Node.js versions. Just use Array.isArray directly, unless you need to support those older versions. Usage var isArray = require('isarray'); console.log(isArray([])); // => true console.log(isArray({})); // => false Installation With npm do $ npm install isarray Then bundle for the browser with browserify. Sponsors This module is proudly supported by my Sponsors! Do you want to support modules like this to improve their quality, stability and weigh in on new features? Then please consider donating to my Patreon. Not sure how much of my modules you're using? Try feross/thanks!"
  },
  "node_modules/isexe/README.html": {
    "href": "node_modules/isexe/README.html",
    "title": "isexe | accouter",
    "keywords": "isexe Minimal module to check if a file is executable, and a normal file. Uses fs.stat and tests against the PATHEXT environment variable on Windows. USAGE var isexe = require('isexe') isexe('some-file-name', function (err, isExe) { if (err) { console.error('probably file does not exist or something', err) } else if (isExe) { console.error('this thing can be run') } else { console.error('cannot be run') } }) // same thing but synchronous, throws errors var isExe = isexe.sync('some-file-name') // treat errors as just \"not executable\" isexe('maybe-missing-file', { ignoreErrors: true }, callback) var isExe = isexe.sync('maybe-missing-file', { ignoreErrors: true }) API isexe(path, [options], [callback]) Check if the path is executable. If no callback provided, and a global Promise object is available, then a Promise will be returned. Will raise whatever errors may be raised by fs.stat, unless options.ignoreErrors is set to true. isexe.sync(path, [options]) Same as isexe but returns the value and throws any errors raised. Options ignoreErrors Treat all errors as \"no, this is not executable\", but don't raise them. uid Number to use as the user id gid Number to use as the group id pathExt List of path extensions to use instead of PATHEXT environment variable on Windows."
  },
  "node_modules/jackspeak/LICENSE.html": {
    "href": "node_modules/jackspeak/LICENSE.html",
    "title": "Blue Oak Model License | accouter",
    "keywords": "Blue Oak Model License Version 1.0.0 Purpose This license gives everyone as much permission to work with this software as possible, while protecting contributors from liability. Acceptance In order to receive this license, you must agree to its rules. The rules of this license are both obligations under that agreement and conditions to your license. You must not do anything with this software that triggers a rule that you cannot or will not follow. Copyright Each contributor licenses you to do everything with this software that would otherwise infringe that contributor's copyright in it. Notices You must ensure that everyone who gets a copy of any part of this software from you, with or without changes, also gets the text of this license or a link to https://blueoakcouncil.org/license/1.0.0. Excuse If anyone notifies you in writing that you have not complied with Notices, you can keep your license by taking all practical steps to comply within 30 days after the notice. If you do not do so, your license ends immediately. Patent Each contributor licenses you to do everything with this software that would otherwise infringe any patent claims they can license or become able to license. Reliability No contributor can revoke this license. No Liability As far as the law allows, this software comes as is, without any warranty or condition, and no contributor will be liable to anyone for any damages related to this software or this license, under any kind of legal claim."
  },
  "node_modules/jackspeak/README.html": {
    "href": "node_modules/jackspeak/README.html",
    "title": "jackspeak | accouter",
    "keywords": "jackspeak A very strict and proper argument parser. Validate string, boolean, and number options, from the command line and the environment. Call the jack method with a config object, and then chain methods off of it. At the end, call the .parse() method, and you'll get an object with positionals and values members. Any unrecognized configs or invalid values will throw an error. As long as you define configs using object literals, types will be properly inferred and TypeScript will know what kinds of things you got. If you give it a prefix for environment variables, then defaults will be read from the environment, and parsed values written back to it, so you can easily pass configs through to child processes. Automatically generates a usage/help banner by calling the .usage() method. Unless otherwise noted, all methods return the object itself. USAGE import { jack } from 'jackspeak' // this works too: // const { jack } = require('jackspeak') const { positionals, values } = jack({ envPrefix: 'FOO' }) .flag({ asdf: { description: 'sets the asfd flag', short: 'a', default: true }, 'no-asdf': { description: 'unsets the asdf flag', short: 'A' }, foo: { description: 'another boolean', short: 'f' }, }) .optList({ 'ip-addrs': { description: 'addresses to ip things', delim: ',', // defaults to '\\n' default: ['127.0.0.1'], }, }) .parse([ 'some', 'positional', '--ip-addrs', '192.168.0.1', '--ip-addrs', '1.1.1.1', 'args', '--foo', // sets the foo flag '-A', // short for --no-asdf, sets asdf flag to false ]) console.log(process.env.FOO_ASDF) // '0' console.log(process.env.FOO_FOO) // '1' console.log(values) // { // 'ip-addrs': ['192.168.0.1', '1.1.1.1'], // foo: true, // asdf: false, // } console.log(process.env.FOO_IP_ADDRS) // '192.168.0.1,1.1.1.1' console.log(positionals) // ['some', 'positional', 'args'] jack(options: JackOptions = {}) => Jack Returns a Jack object that can be used to chain and add field definitions. The other methods (apart from validate(), parse(), and usage() obviously) return the same Jack object, updated with the new types, so they can be chained together as shown in the code examples. Options: allowPositionals Defaults to true. Set to false to not allow any positional arguments. envPrefix Set to a string to write configs to and read configs from the environment. For example, if set to MY_APP then the foo-bar config will default based on the value of env.MY_APP_FOO_BAR and will write back to that when parsed. Boolean values are written as '1' and '0', and will be treated as true if they're '1' or false otherwise. Number values are written with their toString() representation. Strings are just strings. Any value with multiple: true will be represented in the environment split by a delimiter, which defaults to \\n. env The place to read/write environment variables. Defaults to process.env. usage A short usage string to print at the top of the help banner. stopAtPositional Boolean, default false. Stop parsing opts and flags at the first positional argument. This is useful if you want to pass certain options to subcommands, like some programs do, so you can stop parsing and pass the positionals to the subcommand to parse. Jack.heading(text: string, level?: 1 | 2 | 3 | 4 | 5 | 6) Define a short string heading, used in the usage() output. Indentation of the heading and subsequent description/config usage entries (up until the next heading) is set by the heading level. If the first usage item defined is a heading, it is always treated as level 1, regardless of the argument provided. Headings level 1 and 2 will have a line of padding underneath them. Headings level 3 through 6 will not. Jack.description(text: string, { pre?: boolean } = {}) Define a long string description, used in the usage() output. If the pre option is set to true, then whitespace will not be normalized. However, if any line is too long for the width allotted, it will still be wrapped. Option Definitions Configs are defined by calling the appropriate field definition method with an object where the keys are the long option name, and the value defines the config. Options: type Only needed for the addFields method, as the others set it implicitly. Can be 'string', 'boolean', or 'number'. multiple Only needed for the addFields method, as the others set it implicitly. Set to true to define an array type. This means that it can be set on the CLI multiple times, set as an array in the values and it is represented in the environment as a delimited string. short A one-character shorthand for the option. description Some words to describe what this option is and why you'd set it. hint (Only relevant for non-boolean types) The thing to show in the usage output, like --option=<hint> validate A function that returns false (or throws) if an option value is invalid. validOptions An array of strings or numbers that define the valid values that can be set. This is not allowed on boolean (flag) options. May be used along with a validate() method. default A default value for the field. Note that this may be overridden by an environment variable, if present. Jack.flag({ [option: string]: definition, ... }) Define one or more boolean fields. Boolean options may be set to false by using a --no-${optionName} argument, which will be implicitly created if it's not defined to be something else. If a boolean option named no-${optionName} with the same multiple setting is in the configuration, then that will be treated as a negating flag. Jack.flagList({ [option: string]: definition, ... }) Define one or more boolean array fields. Jack.num({ [option: string]: definition, ... }) Define one or more number fields. These will be set in the environment as a stringified number, and included in the values object as a number. Jack.numList({ [option: string]: definition, ... }) Define one or more number list fields. These will be set in the environment as a delimited set of stringified numbers, and included in the values as a number array. Jack.opt({ [option: string]: definition, ... }) Define one or more string option fields. Jack.optList({ [option: string]: definition, ... }) Define one or more string list fields. Jack.addFields({ [option: string]: definition, ... }) Define one or more fields of any type. Note that type and multiple must be set explicitly on each definition when using this method. Actions Use these methods on a Jack object that's already had its config fields defined. Jack.parse(args: string[] = process.argv): { positionals: string[], values: OptionsResults } Parse the arguments list, write to the environment if envPrefix is set, and returned the parsed values and remaining positional arguments. Jack.validate(o: any): asserts o is OptionsResults Throws an error if the object provided is not a valid result set, for the configurations defined thusfar. Jack.usage(): string Returns the compiled usage string, with all option descriptions and heading/description text, wrapped to the appropriate width for the terminal. Jack.setConfigValues(options: OptionsResults, src?: string) Validate the options argument, and set the default value for each field that appears in the options. Values provided will be overridden by environment variables or command line arguments. Jack.usageMarkdown(): string Returns the compiled usage string, with all option descriptions and heading/description text, but as markdown instead of formatted for a terminal, for generating HTML documentation for your CLI. Some Example Code Also see the examples folder import { jack } from 'jackspeak' const j = jack({ // Optional // This will be auto-generated from the descriptions if not supplied // top level usage line, printed by -h // will be auto-generated if not specified usage: 'foo [options] <files>', }) .heading('The best Foo that ever Fooed') .description( ` Executes all the files and interprets their output as TAP formatted test result data. To parse TAP data from stdin, specify \"-\" as a filename. ` ) // flags don't take a value, they're boolean on or off, and can be // turned off by prefixing with `--no-` // so this adds support for -b to mean --bail, or -B to mean --no-bail .flag({ flag: { // specify a short value if you like. this must be a single char short: 'f', // description is optional as well. description: `Make the flags wave`, // default value for flags is 'false', unless you change it default: true, }, 'no-flag': { // you can can always negate a flag with `--no-flag` // specifying a negate option will let you define a short // single-char option for negation. short: 'F', description: `Do not wave the flags`, }, }) // Options that take a value are specified with `opt()` .opt({ reporter: { short: 'R', description: 'the style of report to display', }, }) // if you want a number, say so, and jackspeak will enforce it .num({ jobs: { short: 'j', description: 'how many jobs to run in parallel', default: 1, }, }) // A list is an option that can be specified multiple times, // to expand into an array of all the settings. Normal opts // will just give you the last value specified. .optList({ 'node-arg': {}, }) // a flagList is an array of booleans, so `-ddd` is [true, true, true] // count the `true` values to treat it as a counter. .flagList({ debug: { short: 'd' }, }) // opts take a value, and is set to the string in the results // you can combine multiple short-form flags together, but // an opt will end the combine chain, posix-style. So, // -bofilename would be like --bail --output-file=filename .opt({ 'output-file': { short: 'o', // optional: make it -o<file> in the help output insead of -o<value> hint: 'file', description: `Send the raw output to the specified file.`, }, }) // now we can parse argv like this: const { values, positionals } = j.parse(process.argv) // or decide to show the usage banner console.log(j.usage()) // or validate an object config we got from somewhere else try { j.validate(someConfig) } catch (er) { console.error('someConfig is not valid!', er) } Name The inspiration for this module is yargs, which is pirate talk themed. Yargs has all the features, and is infinitely flexible. \"Jackspeak\" is the slang of the royal navy. This module does not have all the features. It is declarative and rigid by design."
  },
  "node_modules/jest-diff/README.html": {
    "href": "node_modules/jest-diff/README.html",
    "title": "jest-diff | accouter",
    "keywords": "jest-diff Display differences clearly so people can review changes confidently. The diff named export serializes JavaScript values, compares them line-by-line, and returns a string which includes comparison lines. Two named exports compare strings character-by-character: diffStringsUnified returns a string. diffStringsRaw returns an array of Diff objects. Three named exports compare arrays of strings line-by-line: diffLinesUnified and diffLinesUnified2 return a string. diffLinesRaw returns an array of Diff objects. Installation To add this package as a dependency of a project, run either of the following commands: npm install jest-diff yarn add jest-diff Usage of diff() Given JavaScript values, diff(a, b, options?) does the following: serialize the values as strings using the pretty-format package compare the strings line-by-line using the diff-sequences package format the changed or common lines using the chalk package To use this function, write either of the following: const {diff} = require('jest-diff'); in CommonJS modules import {diff} from 'jest-diff'; in ECMAScript modules Example of diff() const a = ['delete', 'common', 'changed from']; const b = ['common', 'changed to', 'insert']; const difference = diff(a, b); The returned string consists of: annotation lines: describe the two change indicators with labels, and a blank line comparison lines: similar to “unified” view on GitHub, but Expected lines are green, Received lines are red, and common lines are dim (by default, see Options) - Expected + Received Array [ - \"delete\", \"common\", - \"changed from\", + \"changed to\", + \"insert\", ] Edge cases of diff() Here are edge cases for the return value: ' Comparing two different types of values. …' if the arguments have different types according to the jest-get-type package (instances of different classes have the same 'object' type) 'Compared values have no visual difference.' if the arguments have either referential identity according to Object.is method or same serialization according to the pretty-format package null if either argument is a so-called asymmetric matcher in Jasmine or Jest Usage of diffStringsUnified Given strings, diffStringsUnified(a, b, options?) does the following: compare the strings character-by-character using the diff-sequences package clean up small (often coincidental) common substrings, also known as chaff format the changed or common lines using the chalk package Although the function is mainly for multiline strings, it compares any strings. Write either of the following: const {diffStringsUnified} = require('jest-diff'); in CommonJS modules import {diffStringsUnified} from 'jest-diff'; in ECMAScript modules Example of diffStringsUnified const a = 'common\\nchanged from'; const b = 'common\\nchanged to'; const difference = diffStringsUnified(a, b); The returned string consists of: annotation lines: describe the two change indicators with labels, and a blank line comparison lines: similar to “unified” view on GitHub, and changed substrings have inverse foreground and background colors (that is, from has white-on-green and to has white-on-red, which the following example does not show) - Expected + Received common - changed from + changed to Performance of diffStringsUnified To get the benefit of changed substrings within the comparison lines, a character-by-character comparison has a higher computational cost (in time and space) than a line-by-line comparison. If the input strings can have arbitrary length, we recommend that the calling code set a limit, beyond which splits the strings, and then calls diffLinesUnified instead. For example, Jest falls back to line-by-line comparison if either string has length greater than 20K characters. Usage of diffLinesUnified Given arrays of strings, diffLinesUnified(aLines, bLines, options?) does the following: compare the arrays line-by-line using the diff-sequences package format the changed or common lines using the chalk package You might call this function when strings have been split into lines and you do not need to see changed substrings within lines. Example of diffLinesUnified const aLines = ['delete', 'common', 'changed from']; const bLines = ['common', 'changed to', 'insert']; const difference = diffLinesUnified(aLines, bLines); - Expected + Received - delete common - changed from + changed to + insert Edge cases of diffLinesUnified or diffStringsUnified Here are edge cases for arguments and return values: both a and b are empty strings: no comparison lines only a is empty string: all comparison lines have bColor and bIndicator (see Options) only b is empty string: all comparison lines have aColor and aIndicator (see Options) a and b are equal non-empty strings: all comparison lines have commonColor and commonIndicator (see Options) Usage of diffLinesUnified2 Given two pairs of arrays of strings, diffLinesUnified2(aLinesDisplay, bLinesDisplay, aLinesCompare, bLinesCompare, options?) does the following: compare the pair of Compare arrays line-by-line using the diff-sequences package format the corresponding lines in the pair of Display arrays using the chalk package Jest calls this function to consider lines as common instead of changed if the only difference is indentation. You might call this function for case insensitive or Unicode equivalence comparison of lines. Example of diffLinesUnified2 import {format} from 'pretty-format'; const a = { text: 'Ignore indentation in serialized object', time: '2019-09-19T12:34:56.000Z', type: 'CREATE_ITEM', }; const b = { payload: { text: 'Ignore indentation in serialized object', time: '2019-09-19T12:34:56.000Z', }, type: 'CREATE_ITEM', }; const difference = diffLinesUnified2( // serialize with indentation to display lines format(a).split('\\n'), format(b).split('\\n'), // serialize without indentation to compare lines format(a, {indent: 0}).split('\\n'), format(b, {indent: 0}).split('\\n'), ); The text and time properties are common, because their only difference is indentation: - Expected + Received Object { + payload: Object { text: 'Ignore indentation in serialized object', time: '2019-09-19T12:34:56.000Z', + }, type: 'CREATE_ITEM', } The preceding example illustrates why (at least for indentation) it seems more intuitive that the function returns the common line from the bLinesDisplay array instead of from the aLinesDisplay array. Usage of diffStringsRaw Given strings and a boolean option, diffStringsRaw(a, b, cleanup) does the following: compare the strings character-by-character using the diff-sequences package optionally clean up small (often coincidental) common substrings, also known as chaff Because diffStringsRaw returns the difference as data instead of a string, you can format it as your application requires (for example, enclosed in HTML markup for browser instead of escape sequences for console). The returned array describes substrings as instances of the Diff class, which calling code can access like array tuples: The value at index 0 is one of the following: value named export description 0 DIFF_EQUAL in a and in b -1 DIFF_DELETE in a but not in b 1 DIFF_INSERT in b but not in a The value at index 1 is a substring of a or b or both. Example of diffStringsRaw with cleanup const diffs = diffStringsRaw('changed from', 'changed to', true); i diffs[i][0] diffs[i][1] 0 0 'changed ' 1 -1 'from' 2 1 'to' Example of diffStringsRaw without cleanup const diffs = diffStringsRaw('changed from', 'changed to', false); i diffs[i][0] diffs[i][1] 0 0 'changed ' 1 -1 'fr' 2 1 't' 3 0 'o' 4 -1 'm' Advanced import for diffStringsRaw Here are all the named imports that you might need for the diffStringsRaw function: const {DIFF_DELETE, DIFF_EQUAL, DIFF_INSERT, Diff, diffStringsRaw} = require('jest-diff'); in CommonJS modules import {DIFF_DELETE, DIFF_EQUAL, DIFF_INSERT, Diff, diffStringsRaw} from 'jest-diff'; in ECMAScript modules To write a formatting function, you might need the named constants (and Diff in TypeScript annotations). If you write an application-specific cleanup algorithm, then you might need to call the Diff constructor: const diffCommon = new Diff(DIFF_EQUAL, 'changed '); const diffDelete = new Diff(DIFF_DELETE, 'from'); const diffInsert = new Diff(DIFF_INSERT, 'to'); Usage of diffLinesRaw Given arrays of strings, diffLinesRaw(aLines, bLines) does the following: compare the arrays line-by-line using the diff-sequences package Because diffLinesRaw returns the difference as data instead of a string, you can format it as your application requires. Example of diffLinesRaw const aLines = ['delete', 'common', 'changed from']; const bLines = ['common', 'changed to', 'insert']; const diffs = diffLinesRaw(aLines, bLines); i diffs[i][0] diffs[i][1] 0 -1 'delete' 1 0 'common' 2 -1 'changed from' 3 1 'changed to' 4 1 'insert' Edge case of diffLinesRaw If you call string.split('\\n') for an empty string: the result is [''] an array which contains an empty string instead of [] an empty array Depending of your application, you might call diffLinesRaw with either array. Example of split method import {diffLinesRaw} from 'jest-diff'; const a = 'non-empty string'; const b = ''; const diffs = diffLinesRaw(a.split('\\n'), b.split('\\n')); i diffs[i][0] diffs[i][1] 0 -1 'non-empty string' 1 1 '' Which you might format as follows: - Expected - 1 + Received + 1 - non-empty string + Example of splitLines0 function For edge case behavior like the diffLinesUnified function, you might define a splitLines0 function, which given an empty string, returns [] an empty array: export const splitLines0 = string => string.length === 0 ? [] : string.split('\\n'); import {diffLinesRaw} from 'jest-diff'; const a = ''; const b = 'line 1\\nline 2\\nline 3'; const diffs = diffLinesRaw(a.split('\\n'), b.split('\\n')); i diffs[i][0] diffs[i][1] 0 1 'line 1' 1 1 'line 2' 2 1 'line 3' Which you might format as follows: - Expected - 0 + Received + 3 + line 1 + line 2 + line 3 In contrast to the diffLinesRaw function, the diffLinesUnified and diffLinesUnified2 functions automatically convert array arguments computed by string split method, so callers do not need a splitLine0 function. Options The default options are for the report when an assertion fails from the expect package used by Jest. For other applications, you can provide an options object as a third argument: diff(a, b, options) diffStringsUnified(a, b, options) diffLinesUnified(aLines, bLines, options) diffLinesUnified2(aLinesDisplay, bLinesDisplay, aLinesCompare, bLinesCompare, options) Properties of options object name default aAnnotation 'Expected' aColor chalk.green aIndicator '-' bAnnotation 'Received' bColor chalk.red bIndicator '+' changeColor chalk.inverse changeLineTrailingSpaceColor string => string commonColor chalk.dim commonIndicator ' ' commonLineTrailingSpaceColor string => string compareKeys undefined contextLines 5 emptyFirstOrLastLinePlaceholder '' expand true includeChangeCounts false omitAnnotationLines false patchColor chalk.yellow For more information about the options, see the following examples. Example of options for labels If the application is code modification, you might replace the labels: const options = { aAnnotation: 'Original', bAnnotation: 'Modified', }; - Original + Modified common - changed from + changed to The jest-diff package does not assume that the 2 labels have equal length. Example of options for colors of changed lines For consistency with most diff tools, you might exchange the colors: import chalk = require('chalk'); const options = { aColor: chalk.red, bColor: chalk.green, }; Example of option for color of changed substrings Although the default inverse of foreground and background colors is hard to beat for changed substrings within lines, especially because it highlights spaces, if you want bold font weight on yellow background color: import chalk = require('chalk'); const options = { changeColor: chalk.bold.bgYellowBright, }; Example of option to format trailing spaces Because diff() does not display substring differences within lines, formatting can help you see when lines differ by the presence or absence of trailing spaces found by /\\s+$/ regular expression. If change lines have a background color, then you can see trailing spaces. If common lines have default dim color, then you cannot see trailing spaces. You might want yellowish background color to see them. const options = { aColor: chalk.rgb(128, 0, 128).bgRgb(255, 215, 255), // magenta bColor: chalk.rgb(0, 95, 0).bgRgb(215, 255, 215), // green commonLineTrailingSpaceColor: chalk.bgYellow, }; The value of a Color option is a function, which given a string, returns a string. If you want to replace trailing spaces with middle dot characters: const replaceSpacesWithMiddleDot = string => '·'.repeat(string.length); const options = { changeLineTrailingSpaceColor: replaceSpacesWithMiddleDot, commonLineTrailingSpaceColor: replaceSpacesWithMiddleDot, }; If you need the TypeScript type of a Color option: import {DiffOptionsColor} from 'jest-diff'; Example of options for no colors To store the difference in a file without escape codes for colors, provide an identity function: const noColor = string => string; const options = { aColor: noColor, bColor: noColor, changeColor: noColor, commonColor: noColor, patchColor: noColor, }; Example of options for indicators For consistency with the diff command, you might replace the indicators: const options = { aIndicator: '<', bIndicator: '>', }; The jest-diff package assumes (but does not enforce) that the 3 indicators have equal length. Example of options to limit common lines By default, the output includes all common lines. To emphasize the changes, you might limit the number of common “context” lines: const options = { contextLines: 1, expand: false, }; A patch mark like @@ -12,7 +12,9 @@ accounts for omitted common lines. Example of option for color of patch marks If you want patch marks to have the same dim color as common lines: import chalk = require('chalk'); const options = { expand: false, patchColor: chalk.dim, }; Example of option to include change counts To display the number of changed lines at the right of annotation lines: const a = ['common', 'changed from']; const b = ['common', 'changed to', 'insert']; const options = { includeChangeCounts: true, }; const difference = diff(a, b, options); - Expected - 1 + Received + 2 Array [ \"common\", - \"changed from\", + \"changed to\", + \"insert\", ] Example of option to omit annotation lines To display only the comparison lines: const a = 'common\\nchanged from'; const b = 'common\\nchanged to'; const options = { omitAnnotationLines: true, }; const difference = diffStringsUnified(a, b, options); common - changed from + changed to Example of option for empty first or last lines If the first or last comparison line is empty, because the content is empty and the indicator is a space, you might not notice it. The replacement option is a string whose default value is '' empty string. Because Jest trims the report when a matcher fails, it deletes an empty last line. Therefore, Jest uses as placeholder the downwards arrow with corner leftwards: const options = { emptyFirstOrLastLinePlaceholder: '↵', // U+21B5 }; If a content line is empty, then the corresponding comparison line is automatically trimmed to remove the margin space (represented as a middle dot below) for the default indicators: Indicator untrimmed trimmed aIndicator '-·' '-' bIndicator '+·' '+' commonIndicator ' ·' '' Example of option for sorting object keys When two objects are compared their keys are printed in alphabetical order by default. If this was not the original order of the keys the diff becomes harder to read as the keys are not in their original position. Use compareKeys to pass a function which will be used when sorting the object keys. const a = {c: 'c', b: 'b1', a: 'a'}; const b = {c: 'c', b: 'b2', a: 'a'}; const options = { // The keys will be in their original order compareKeys: () => 0, }; const difference = diff(a, b, options); - Expected + Received Object { \"c\": \"c\", - \"b\": \"b1\", + \"b\": \"b2\", \"a\": \"a\", } Depending on the implementation of compareKeys any sort order can be used. const a = {c: 'c', b: 'b1', a: 'a'}; const b = {c: 'c', b: 'b2', a: 'a'}; const options = { // The keys will be in reverse order compareKeys: (a, b) => (a > b ? -1 : 1), }; const difference = diff(a, b, options); - Expected + Received Object { \"a\": \"a\", - \"b\": \"b1\", + \"b\": \"b2\", \"c\": \"c\", }"
  },
  "node_modules/js-yaml/CHANGELOG.html": {
    "href": "node_modules/js-yaml/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog, and this project adheres to Semantic Versioning. 4.1.0 - 2021-04-15 Added Types are now exported as yaml.types.XXX. Every type now has options property with original arguments kept as they were (see yaml.types.int.options as an example). Changed Schema.extend() now keeps old type order in case of conflicts (e.g. Schema.extend([ a, b, c ]).extend([ b, a, d ]) is now ordered as abcd instead of cbad). 4.0.0 - 2021-01-03 Changed Check migration guide to see details for all breaking changes. Breaking: \"unsafe\" tags !!js/function, !!js/regexp, !!js/undefined are moved to js-yaml-js-types package. Breaking: removed safe* functions. Use load, loadAll, dump instead which are all now safe by default. yaml.DEFAULT_SAFE_SCHEMA and yaml.DEFAULT_FULL_SCHEMA are removed, use yaml.DEFAULT_SCHEMA instead. yaml.Schema.create(schema, tags) is removed, use schema.extend(tags) instead. !!binary now always mapped to Uint8Array on load. Reduced nesting of /lib folder. Parse numbers according to YAML 1.2 instead of YAML 1.1 (01234 is now decimal, 0o1234 is octal, 1:23 is parsed as string instead of base60). dump() no longer quotes :, [, ], (, ) except when necessary, #470, #557. Line and column in exceptions are now formatted as (X:Y) instead of at line X, column Y (also present in compact format), #332. Code snippet created in exceptions now contains multiple lines with line numbers. dump() now serializes undefined as null in collections and removes keys with undefined in mappings, #571. dump() with skipInvalid=true now serializes invalid items in collections as null. Custom tags starting with ! are now dumped as !tag instead of !<!tag>, #576. Custom tags starting with tag:yaml.org,2002: are now shorthanded using !!, #258. Added Added .mjs (es modules) support. Added quotingType and forceQuotes options for dumper to configure string literal style, #290, #529. Added styles: { '!!null': 'empty' } option for dumper (serializes { foo: null } as \"foo: \"), #570. Added replacer option (similar to option in JSON.stringify), #339. Custom Tag can now handle all tags or multiple tags with the same prefix, #385. Fixed Astral characters are no longer encoded by dump(), #587. \"duplicate mapping key\" exception now points at the correct column, #452. Extra commas in flow collections (e.g. [foo,,bar]) now throw an exception instead of producing null, #321. __proto__ key no longer overrides object prototype, #164. Removed bower.json. Tags are now url-decoded in load() and url-encoded in dump() (previously usage of custom non-ascii tags may have led to invalid YAML that can't be parsed). Anchors now work correctly with empty nodes, #301. Fix incorrect parsing of invalid block mapping syntax, #418. Throw an error if block sequence/mapping indent contains a tab, #80. [3.14.1] - 2020-12-07 Security Fix possible code execution in (already unsafe) .load() (in &anchor). 3.14.0 - 2020-05-22 Changed Support safe/loadAll(input, options) variant of call. CI: drop outdated nodejs versions. Dev deps bump. Fixed Quote = in plain scalars #519. Check the node type for !<?> tag in case user manually specifies it. Verify that there are no null-bytes in input. Fix wrong quote position when writing condensed flow, #526. 3.13.1 - 2019-04-05 Security Fix possible code execution in (already unsafe) .load(), #480. 3.13.0 - 2019-03-20 Security Security fix: safeLoad() can hang when arrays with nested refs used as key. Now throws exception for nested arrays. #475. 3.12.2 - 2019-02-26 Fixed Fix noArrayIndent option for root level, #468. 3.12.1 - 2019-01-05 Added Added noArrayIndent option, #432. 3.12.0 - 2018-06-02 Changed Support arrow functions without a block statement, #421. 3.11.0 - 2018-03-05 Added Add arrow functions suport for !!js/function. Fixed Fix dump in bin/octal/hex formats for negative integers, #399. 3.10.0 - 2017-09-10 Fixed Fix condenseFlow output (quote keys for sure, instead of spaces), #371, #370. Dump astrals as codepoints instead of surrogate pair, #368. 3.9.1 - 2017-07-08 Fixed Ensure stack is present for custom errors in node 7.+, #351. 3.9.0 - 2017-07-08 Added Add condenseFlow option (to create pretty URL query params), #346. Fixed Support array return from safeLoadAll/loadAll, #350. 3.8.4 - 2017-05-08 Fixed Dumper: prevent space after dash for arrays that wrap, #343. 3.8.3 - 2017-04-05 Fixed Should not allow numbers to begin and end with underscore, #335. 3.8.2 - 2017-03-02 Fixed Fix !!float 123 (integers) parse, #333. Don't allow leading zeros in floats (except 0, 0.xxx). Allow positive exponent without sign in floats. 3.8.1 - 2017-02-07 Changed Maintenance: update browserified build. 3.8.0 - 2017-02-07 Fixed Fix reported position for duplicated mapping key errors. Now points to block start instead of block end. (#243, thanks to @shockey). 3.7.0 - 2016-11-12 Added Support polymorphism for tags (#300, thanks to @monken). Fixed Fix parsing of quotes followed by newlines (#304, thanks to @dplepage). 3.6.1 - 2016-05-11 Fixed Fix output cut on a pipe, #286. 3.6.0 - 2016-04-16 Fixed Dumper rewrite, fix multiple bugs with trailing \\n. Big thanks to @aepsilon! Loader: fix leading/trailing newlines in block scalars, @aepsilon. 3.5.5 - 2016-03-17 Fixed Date parse fix: don't allow dates with on digit in month and day, #268. 3.5.4 - 2016-03-09 Added noCompatMode for dumper, to disable quoting YAML 1.1 values. 3.5.3 - 2016-02-11 Changed Maintenance release. 3.5.2 - 2016-01-11 Changed Maintenance: missed comma in bower config. 3.5.1 - 2016-01-11 Changed Removed inherit dependency, #239. Better browserify workaround for esprima load. Demo rewrite. 3.5.0 - 2016-01-10 Fixed Dumper. Fold strings only, #217. Dumper. norefs option, to clone linked objects, #229. Loader. Throw a warning for duplicate keys, #166. Improved browserify support (mark esprima & Buffer excluded). 3.4.6 - 2015-11-26 Changed Use standalone inherit to keep browserified files clear. 3.4.5 - 2015-11-23 Added Added lineWidth option to dumper. 3.4.4 - 2015-11-21 Fixed Fixed floats dump (missed dot for scientific format), #220. Allow non-printable characters inside quoted scalars, #192. 3.4.3 - 2015-10-10 Changed Maintenance release - deps bump (esprima, argparse). 3.4.2 - 2015-09-09 Fixed Fixed serialization of duplicated entries in sequences, #205. Thanks to @vogelsgesang. 3.4.1 - 2015-09-05 Fixed Fixed stacktrace handling in generated errors, for browsers (FF/IE). 3.4.0 - 2015-08-23 Changed Don't throw on warnings anymore. Use onWarning option to catch. Throw error on unknown tags (was warning before). Reworked internals of error class. Fixed Fixed multiline keys dump, #197. Thanks to @tcr. Fixed heading line breaks in some scalars (regression). 3.3.1 - 2015-05-13 Added Added .sortKeys dumper option, thanks to @rjmunro. Fixed Fixed astral characters support, #191. 3.3.0 - 2015-04-26 Changed Significantly improved long strings formatting in dumper, thanks to @isaacs. Strip BOM if exists. 3.2.7 - 2015-02-19 Changed Maintenance release. Updated dependencies. HISTORY.md -> CHANGELOG.md 3.2.6 - 2015-02-07 Fixed Fixed encoding of UTF-16 surrogate pairs. (e.g. \"\\U0001F431\" CAT FACE). Fixed demo dates dump (#113, thanks to @Hypercubed). 3.2.5 - 2014-12-28 Fixed Fixed resolving of all built-in types on empty nodes. Fixed invalid warning on empty lines within quoted scalars and flow collections. Fixed bug: Tag on an empty node didn't resolve in some cases. 3.2.4 - 2014-12-19 Fixed Fixed resolving of !!null tag on an empty node. 3.2.3 - 2014-11-08 Fixed Implemented dumping of objects with circular and cross references. Partially fixed aliasing of constructed objects. (see issue #141 for details) 3.2.2 - 2014-09-07 Fixed Fixed infinite loop on unindented block scalars. Rewritten base64 encode/decode in binary type, to keep code licence clear. 3.2.1 - 2014-08-24 Fixed Nothig new. Just fix npm publish error. 3.2.0 - 2014-08-24 Added Added input piping support to CLI. Fixed Fixed typo, that could cause hand on initial indent (#139). 3.1.0 - 2014-07-07 Changed 1.5x-2x speed boost. Removed deprecated require('xxx.yml') support. Significant code cleanup and refactoring. Internal API changed. If you used custom types - see updated examples. Others are not affected. Even if the input string has no trailing line break character, it will be parsed as if it has one. Added benchmark scripts. Moved bower files to /dist folder Bugfixes. 3.0.2 - 2014-02-27 Fixed Fixed bug: \"constructor\" string parsed as null. 3.0.1 - 2013-12-22 Fixed Fixed parsing of literal scalars. (issue #108) Prevented adding unnecessary spaces in object dumps. (issue #68) Fixed dumping of objects with very long (> 1024 in length) keys. 3.0.0 - 2013-12-16 Changed Refactored code. Changed API for custom types. Removed output colors in CLI, dump json by default. Removed big dependencies from browser version (esprima, buffer). Load esprima manually, if !!js/function needed. !!bin now returns Array in browser AMD support. Don't quote dumped strings because of - & ? (if not first char). Deprecated loading yaml files via require(), as not recommended behaviour for node. 2.1.3 - 2013-10-16 Fixed Fix wrong loading of empty block scalars. 2.1.2 - 2013-10-07 Fixed Fix unwanted line breaks in folded scalars. 2.1.1 - 2013-10-02 Fixed Dumper now respects deprecated booleans syntax from YAML 1.0/1.1 Fixed reader bug in JSON-like sequences/mappings. 2.1.0 - 2013-06-05 Added Add standard YAML schemas: Failsafe (FAILSAFE_SCHEMA), JSON (JSON_SCHEMA) and Core (CORE_SCHEMA). Add skipInvalid dumper option. Changed Rename DEFAULT_SCHEMA to DEFAULT_FULL_SCHEMA and SAFE_SCHEMA to DEFAULT_SAFE_SCHEMA. Use safeLoad for require extension. Fixed Bug fix: export NIL constant from the public interface. 2.0.5 - 2013-04-26 Security Close security issue in !!js/function constructor. Big thanks to @nealpoole for security audit. 2.0.4 - 2013-04-08 Changed Updated .npmignore to reduce package size 2.0.3 - 2013-02-26 Fixed Fixed dumping of empty arrays ans objects. ([] and {} instead of null) 2.0.2 - 2013-02-15 Fixed Fixed input validation: tabs are printable characters. 2.0.1 - 2013-02-09 Fixed Fixed error, when options not passed to function cass 2.0.0 - 2013-02-09 Changed Full rewrite. New architecture. Fast one-stage parsing. Changed custom types API. Added YAML dumper. 1.0.3 - 2012-11-05 Fixed Fixed utf-8 files loading. 1.0.2 - 2012-08-02 Fixed Pull out hand-written shims. Use ES5-Shims for old browsers support. See #44. Fix timstamps incorectly parsed in local time when no time part specified. 1.0.1 - 2012-07-07 Fixed Fixes TypeError: 'undefined' is not an object under Safari. Thanks Phuong. Fix timestamps incorrectly parsed in local time. Thanks @caolan. Closes #46. 1.0.0 - 2012-07-01 Changed y, yes, n, no, on, off are not converted to Booleans anymore. Fixes #42. require(filename) now returns a single document and throws an Error if file contains more than one document. CLI was merged back from js-yaml.bin 0.3.7 - 2012-02-28 Fixed Fix export of addConstructor(). Closes #39. 0.3.6 - 2012-02-22 Changed Removed AMD parts - too buggy to use. Need help to rewrite from scratch Fixed Removed YUI compressor warning (renamed double variable). Closes #40. 0.3.5 - 2012-01-10 Fixed Workagound for .npmignore fuckup under windows. Thanks to airportyh. 0.3.4 - 2011-12-24 Fixed Fixes str[] for oldIEs support. Adds better has change support for browserified demo. improves compact output of Error. Closes #33. 0.3.3 - 2011-12-20 Added adds compact stringification of Errors. Changed jsyaml executable moved to separate module. 0.3.2 - 2011-12-16 Added Added jsyaml executable. Added !!js/function support. Closes #12. Fixed Fixes ug with block style scalars. Closes #26. All sources are passing JSLint now. Fixes bug in Safari. Closes #28. Fixes bug in Opers. Closes #29. Improves browser support. Closes #20. 0.3.1 - 2011-11-18 Added Added AMD support for browserified version. Added permalinks for online demo YAML snippets. Now we have YPaste service, lol. Added !!js/regexp and !!js/undefined types. Partially solves #12. Changed Wrapped browserified js-yaml into closure. Fixed Fixed the resolvement of non-specific tags. Closes #17. Fixed !!set mapping. Fixed month parse in dates. Closes #19. 0.3.0 - 2011-11-09 Added Added browserified version. Closes #13. Added live demo of browserified version. Ported some of the PyYAML tests. See #14. Fixed Removed JS.Class dependency. Closes #3. Fixed timestamp bug when fraction was given. 0.2.2 - 2011-11-06 Fixed Fixed crash on docs without ---. Closes #8. Fixed multiline string parse Fixed tests/comments for using array as key 0.2.1 - 2011-11-02 Fixed Fixed short file read (<4k). Closes #9. 0.2.0 - 2011-11-02 Changed First public release"
  },
  "node_modules/js-yaml/README.html": {
    "href": "node_modules/js-yaml/README.html",
    "title": "JS-YAML - YAML 1.2 parser / writer for JavaScript | accouter",
    "keywords": "JS-YAML - YAML 1.2 parser / writer for JavaScript Online Demo This is an implementation of YAML, a human-friendly data serialization language. Started as PyYAML port, it was completely rewritten from scratch. Now it's very fast, and supports 1.2 spec. Installation YAML module for node.js npm install js-yaml CLI executable If you want to inspect your YAML files from CLI, install js-yaml globally: npm install -g js-yaml Usage usage: js-yaml [-h] [-v] [-c] [-t] file Positional arguments: file File with YAML document(s) Optional arguments: -h, --help Show this help message and exit. -v, --version Show program's version number and exit. -c, --compact Display errors in compact mode -t, --trace Show stack trace on error API Here we cover the most 'useful' methods. If you need advanced details (creating your own tags), see examples for more info. const yaml = require('js-yaml'); const fs = require('fs'); // Get document, or throw exception on error try { const doc = yaml.load(fs.readFileSync('/home/ixti/example.yml', 'utf8')); console.log(doc); } catch (e) { console.log(e); } load (string [ , options ]) Parses string as single YAML document. Returns either a plain object, a string, a number, null or undefined, or throws YAMLException on error. By default, does not support regexps, functions and undefined. options: filename (default: null) - string to be used as a file path in error/warning messages. onWarning (default: null) - function to call on warning messages. Loader will call this function with an instance of YAMLException for each warning. schema (default: DEFAULT_SCHEMA) - specifies a schema to use. FAILSAFE_SCHEMA - only strings, arrays and plain objects: http://www.yaml.org/spec/1.2/spec.html#id2802346 JSON_SCHEMA - all JSON-supported types: http://www.yaml.org/spec/1.2/spec.html#id2803231 CORE_SCHEMA - same as JSON_SCHEMA: http://www.yaml.org/spec/1.2/spec.html#id2804923 DEFAULT_SCHEMA - all supported YAML types. json (default: false) - compatibility with JSON.parse behaviour. If true, then duplicate keys in a mapping will override values rather than throwing an error. NOTE: This function does not understand multi-document sources, it throws exception on those. NOTE: JS-YAML does not support schema-specific tag resolution restrictions. So, the JSON schema is not as strictly defined in the YAML specification. It allows numbers in any notation, use Null and NULL as null, etc. The core schema also has no such restrictions. It allows binary notation for integers. loadAll (string [, iterator] [, options ]) Same as load(), but understands multi-document sources. Applies iterator to each document if specified, or returns array of documents. const yaml = require('js-yaml'); yaml.loadAll(data, function (doc) { console.log(doc); }); dump (object [ , options ]) Serializes object as a YAML document. Uses DEFAULT_SCHEMA, so it will throw an exception if you try to dump regexps or functions. However, you can disable exceptions by setting the skipInvalid option to true. options: indent (default: 2) - indentation width to use (in spaces). noArrayIndent (default: false) - when true, will not add an indentation level to array elements skipInvalid (default: false) - do not throw on invalid types (like function in the safe schema) and skip pairs and single values with such types. flowLevel (default: -1) - specifies level of nesting, when to switch from block to flow style for collections. -1 means block style everwhere styles - \"tag\" => \"style\" map. Each tag may have own set of styles. schema (default: DEFAULT_SCHEMA) specifies a schema to use. sortKeys (default: false) - if true, sort keys when dumping YAML. If a function, use the function to sort the keys. lineWidth (default: 80) - set max line width. Set -1 for unlimited width. noRefs (default: false) - if true, don't convert duplicate objects into references noCompatMode (default: false) - if true don't try to be compatible with older yaml versions. Currently: don't quote \"yes\", \"no\" and so on, as required for YAML 1.1 condenseFlow (default: false) - if true flow sequences will be condensed, omitting the space between a, b. Eg. '[a,b]', and omitting the space between key: value and quoting the key. Eg. '{\"a\":b}' Can be useful when using yaml for pretty URL query params as spaces are %-encoded. quotingType (' or \", default: ') - strings will be quoted using this quoting style. If you specify single quotes, double quotes will still be used for non-printable characters. forceQuotes (default: false) - if true, all non-key strings will be quoted even if they normally don't need to. replacer - callback function (key, value) called recursively on each key/value in source object (see replacer docs for JSON.stringify). The following table show availlable styles (e.g. \"canonical\", \"binary\"...) available for each tag (.e.g. !!null, !!int ...). Yaml output is shown on the right side after => (default setting) or ->: !!null \"canonical\" -> \"~\" \"lowercase\" => \"null\" \"uppercase\" -> \"NULL\" \"camelcase\" -> \"Null\" !!int \"binary\" -> \"0b1\", \"0b101010\", \"0b1110001111010\" \"octal\" -> \"0o1\", \"0o52\", \"0o16172\" \"decimal\" => \"1\", \"42\", \"7290\" \"hexadecimal\" -> \"0x1\", \"0x2A\", \"0x1C7A\" !!bool \"lowercase\" => \"true\", \"false\" \"uppercase\" -> \"TRUE\", \"FALSE\" \"camelcase\" -> \"True\", \"False\" !!float \"lowercase\" => \".nan\", '.inf' \"uppercase\" -> \".NAN\", '.INF' \"camelcase\" -> \".NaN\", '.Inf' Example: dump(object, { 'styles': { '!!null': 'canonical' // dump null as ~ }, 'sortKeys': true // sort object keys }); Supported YAML types The list of standard YAML tags and corresponding JavaScript types. See also YAML tag discussion and YAML types repository. !!null '' # null !!bool 'yes' # bool !!int '3...' # number !!float '3.14...' # number !!binary '...base64...' # buffer !!timestamp 'YYYY-...' # date !!omap [ ... ] # array of key-value pairs !!pairs [ ... ] # array or array pairs !!set { ... } # array of objects with given keys and null values !!str '...' # string !!seq [ ... ] # array !!map { ... } # object JavaScript-specific tags See js-yaml-js-types for extra types. Caveats Note, that you use arrays or objects as key in JS-YAML. JS does not allow objects or arrays as keys, and stringifies (by calling toString() method) them at the moment of adding them. --- ? [ foo, bar ] : - baz ? { foo: bar } : - baz - baz { \"foo,bar\": [\"baz\"], \"[object Object]\": [\"baz\", \"baz\"] } Also, reading of properties on implicit block mapping keys is not supported yet. So, the following YAML document cannot be loaded. &anchor foo: foo: bar *anchor: duplicate key baz: bat *anchor: duplicate key js-yaml for enterprise Available as part of the Tidelift Subscription The maintainers of js-yaml and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more."
  },
  "node_modules/json-parse-better-errors/CHANGELOG.html": {
    "href": "node_modules/json-parse-better-errors/CHANGELOG.html",
    "title": "Change Log | accouter",
    "keywords": "Change Log All notable changes to this project will be documented in this file. See standard-version for commit guidelines. 1.0.2 (2018-03-30) Bug Fixes messages: More friendly messages for non-string (#1) (a476d42) 1.0.1 (2017-08-16) Bug Fixes license: oops. Forgot to update license.md (efe2958) 1.0.0 (2017-08-15) Features init: Initial Commit (562c977) BREAKING CHANGES init: This is the first commit! 0.1.0 (2017-08-15) Features init: Initial Commit (9dd1a19)"
  },
  "node_modules/json-parse-better-errors/LICENSE.html": {
    "href": "node_modules/json-parse-better-errors/LICENSE.html",
    "title": "| accouter",
    "keywords": "Copyright 2017 Kat Marchán Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/json-parse-better-errors/README.html": {
    "href": "node_modules/json-parse-better-errors/README.html",
    "title": "json-parse-better-errors | accouter",
    "keywords": "json-parse-better-errors json-parse-better-errors is a Node.js library for getting nicer errors out of JSON.parse(), including context and position of the parse errors. Install $ npm install --save json-parse-better-errors Table of Contents Example Features Contributing API parse Example const parseJson = require('json-parse-better-errors') parseJson('\"foo\"') parseJson('garbage') // more useful error message Features Like JSON.parse, but the errors are better. Contributing The npm team enthusiastically welcomes contributions and project participation! There's a bunch of things you can do if you want to contribute! The Contributor Guide has all the information you need for everything from reporting bugs to contributing entire new features. Please don't hesitate to jump in if you'd like to, or even ask us questions if something isn't clear. All participants and maintainers in this project are expected to follow Code of Conduct, and just generally be excellent to each other. Please refer to the Changelog for project history details, too. Happy hacking! API > parse(txt, ?reviver, ?context=20) Works just like JSON.parse, but will include a bit more information when an error happens."
  },
  "node_modules/jsonfile/CHANGELOG.html": {
    "href": "node_modules/jsonfile/CHANGELOG.html",
    "title": "| accouter",
    "keywords": "3.0.1 / 2017-07-05 Fixed bug in writeFile when there was a serialization error & no callback was passed. In previous versions, an empty file would be written; now no file is written. 3.0.0 / 2017-04-25 Changed behavior of throws option for readFileSync; now does not throw filesystem errors when throws is false 2.4.0 / 2016-09-15 Changed added optional support for graceful-fs [#62] 2.3.1 / 2016-05-13 fix to support BOM. #45 2.3.0 / 2016-04-16 add throws to readFile(). See #39 add support for any arbitrary fs module. Useful with mock-fs 2.2.3 / 2015-10-14 include file name in parse error. See: https://github.com/jprichardson/node-jsonfile/pull/34 2.2.2 / 2015-09-16 split out tests into separate files fixed throws when set to true in readFileSync(). See: https://github.com/jprichardson/node-jsonfile/pull/33 2.2.1 / 2015-06-25 fixed regression when passing in string as encoding for options in writeFile() and writeFileSync(). See: https://github.com/jprichardson/node-jsonfile/issues/28 2.2.0 / 2015-06-25 added options.spaces to writeFile() and writeFileSync() 2.1.2 / 2015-06-22 fixed if passed readFileSync(file, 'utf8'). See: https://github.com/jprichardson/node-jsonfile/issues/25 2.1.1 / 2015-06-19 fixed regressions if null is passed for options. See: https://github.com/jprichardson/node-jsonfile/issues/24 2.1.0 / 2015-06-19 cleanup: JavaScript Standard Style, rename files, dropped terst for assert methods now support JSON revivers/replacers 2.0.1 / 2015-05-24 update license attribute https://github.com/jprichardson/node-jsonfile/pull/21 2.0.0 / 2014-07-28 added \\n to end of file on write. #14 added options.throws to readFileSync() dropped support for Node v0.8 1.2.0 / 2014-06-29 removed semicolons bugfix: passed options to fs.readFile and fs.readFileSync. This technically changes behavior, but changes it according to docs. #12 1.1.1 / 2013-11-11 fixed catching of callback bug (ffissore / #5) 1.1.0 / 2013-10-11 added options param to methods, (seanodell / #4) 1.0.1 / 2013-09-05 removed homepage field from package.json to remove NPM warning 1.0.0 / 2013-06-28 added .npmignore, #1 changed spacing default from 4 to 2 to follow Node conventions 0.0.1 / 2012-09-10 Initial release."
  },
  "node_modules/jsonfile/README.html": {
    "href": "node_modules/jsonfile/README.html",
    "title": "Node.js - jsonfile | accouter",
    "keywords": "Node.js - jsonfile Easily read/write JSON files. Why? Writing JSON.stringify() and then fs.writeFile() and JSON.parse() with fs.readFile() enclosed in try/catch blocks became annoying. Installation npm install --save jsonfile API readFile(filename, [options], callback) options (object, default undefined): Pass in any fs.readFile options or set reviver for a JSON reviver. throws (boolean, default: true). If JSON.parse throws an error, pass this error to the callback. If false, returns null for the object. var jsonfile = require('jsonfile') var file = '/tmp/data.json' jsonfile.readFile(file, function(err, obj) { console.dir(obj) }) readFileSync(filename, [options]) options (object, default undefined): Pass in any fs.readFileSync options or set reviver for a JSON reviver. throws (boolean, default: true). If an error is encountered reading or parsing the file, throw the error. If false, returns null for the object. var jsonfile = require('jsonfile') var file = '/tmp/data.json' console.dir(jsonfile.readFileSync(file)) writeFile(filename, obj, [options], callback) options: Pass in any fs.writeFile options or set replacer for a JSON replacer. Can also pass in spaces. var jsonfile = require('jsonfile') var file = '/tmp/data.json' var obj = {name: 'JP'} jsonfile.writeFile(file, obj, function (err) { console.error(err) }) formatting with spaces: var jsonfile = require('jsonfile') var file = '/tmp/data.json' var obj = {name: 'JP'} jsonfile.writeFile(file, obj, {spaces: 2}, function(err) { console.error(err) }) appending to an existing JSON file: You can use fs.writeFile option {flag: 'a'} to achieve this. var jsonfile = require('jsonfile') var file = '/tmp/mayAlreadyExistedData.json' var obj = {name: 'JP'} jsonfile.writeFile(file, obj, {flag: 'a'}, function (err) { console.error(err) }) writeFileSync(filename, obj, [options]) options: Pass in any fs.writeFileSync options or set replacer for a JSON replacer. Can also pass in spaces. var jsonfile = require('jsonfile') var file = '/tmp/data.json' var obj = {name: 'JP'} jsonfile.writeFileSync(file, obj) formatting with spaces: var jsonfile = require('jsonfile') var file = '/tmp/data.json' var obj = {name: 'JP'} jsonfile.writeFileSync(file, obj, {spaces: 2}) appending to an existing JSON file: You can use fs.writeFileSync option {flag: 'a'} to achieve this. var jsonfile = require('jsonfile') var file = '/tmp/mayAlreadyExistedData.json' var obj = {name: 'JP'} jsonfile.writeFileSync(file, obj, {flag: 'a'}) spaces Global configuration to set spaces to indent JSON files. default: null var jsonfile = require('jsonfile') jsonfile.spaces = 4 var file = '/tmp/data.json' var obj = {name: 'JP'} // json file has four space indenting now jsonfile.writeFile(file, obj, function (err) { console.error(err) }) Note, it's bound to this.spaces. So, if you do this: var myObj = {} myObj.writeJsonSync = jsonfile.writeFileSync // => this.spaces = null Could do the following: var jsonfile = require('jsonfile') jsonfile.spaces = 4 jsonfile.writeFileSync(file, obj) // will have 4 spaces indentation var myCrazyObj = {spaces: 32} myCrazyObj.writeJsonSync = jsonfile.writeFileSync myCrazyObj.writeJsonSync(file, obj) // will have 32 space indentation myCrazyObj.writeJsonSync(file, obj, {spaces: 2}) // will have only 2 License (MIT License) Copyright 2012-2016, JP Richardson jprichardson@gmail.com"
  },
  "node_modules/junk/readme.html": {
    "href": "node_modules/junk/readme.html",
    "title": "junk | accouter",
    "keywords": "junk Filter out system junk files like .DS_Store and Thumbs.db Install $ npm install junk Usage import fs from 'node:fs/promises'; import {isNotJunk} from 'junk'; const files = await fs.readdir('some/path'); console.log(files); //=> ['.DS_Store', 'test.jpg'] console.log(files.filter(isNotJunk)); //=> ['test.jpg'] API isJunk(filename) Returns true if filename matches a junk file. isNotJunk(filename) Returns true if filename does not match a junk file. junkRegex Regex used for matching junk files."
  },
  "node_modules/lilconfig/readme.html": {
    "href": "node_modules/lilconfig/readme.html",
    "title": "Lilconfig ⚙️ | accouter",
    "keywords": "Lilconfig ⚙️ A zero-dependency alternative to cosmiconfig with the same API. Installation npm install lilconfig Usage import {lilconfig, lilconfigSync} from 'lilconfig'; // all keys are optional const options = { stopDir: '/Users/you/some/dir', searchPlaces: ['package.json', 'myapp.conf.js'], ignoreEmptySearchPlaces: false } lilconfig( 'myapp', options // optional ).search() // Promise<LilconfigResult> lilconfigSync( 'myapp', options // optional ).load(pathToConfig) // LilconfigResult /** * LilconfigResult * { * config: any; // your config * filepath: string; * } */ ESM ESM configs can be loaded with async API only. Specifically js files in projects with \"type\": \"module\" in package.json or mjs files. Difference to cosmiconfig Lilconfig does not intend to be 100% compatible with cosmiconfig but tries to mimic it where possible. The key difference is no support for yaml files out of the box(lilconfig attempts to parse files with no extension as JSON instead of YAML). You can still add the support for YAML files by providing a loader, see an example below. Options difference between the two. cosmiconfig option lilconfig cache ✅ loaders ✅ ignoreEmptySearchPlaces ✅ packageProp ✅ searchPlaces ✅ stopDir ✅ transform ✅ Loaders examples Yaml loader If you need the YAML support you can provide your own loader import {lilconfig} from 'lilconfig'; import yaml from 'yaml'; function loadYaml(filepath, content) { return yaml.parse(content); } const options = { loaders: { '.yaml': loadYaml, '.yml': loadYaml, // loader for files with no extension noExt: loadYaml } }; lilconfig('myapp', options) .search() .then(result => { result // {config, filepath} }); Version correlation lilconig v1 → cosmiconfig v6 lilconig v2 → cosmiconfig v7 lilconig v3 → cosmiconfig v8"
  },
  "node_modules/limiter/README.html": {
    "href": "node_modules/limiter/README.html",
    "title": "limiter | accouter",
    "keywords": "limiter Provides a generic rate limiter for node.js. Useful for API clients, web crawling, or other tasks that need to be throttled. Two classes are exposed, RateLimiter and TokenBucket. TokenBucket provides a lower level interface to rate limiting with a configurable burst rate and drip rate. RateLimiter sits on top of the token bucket and adds a restriction on the maximum number of tokens that can be removed each interval to comply with common API restrictions like \"150 requests per hour maximum\". Installation Use NPM to install: npm install limiter Usage A simple example allowing 150 requests per hour: var RateLimiter = require('limiter').RateLimiter; // Allow 150 requests per hour (the Twitter search limit). Also understands // 'second', 'minute', 'day', or a number of milliseconds var limiter = new RateLimiter(150, 'hour'); // Throttle requests limiter.removeTokens(1, function(err, remainingRequests) { // err will only be set if we request more than the maximum number of // requests we set in the constructor // remainingRequests tells us how many additional requests could be sent // right this moment callMyRequestSendingFunction(...); }); Another example allowing one message to be sent every 250ms: var RateLimiter = require('limiter').RateLimiter; var limiter = new RateLimiter(1, 250); limiter.removeTokens(1, function() { callMyMessageSendingFunction(...); }); The default behaviour is to wait for the duration of the rate limiting that’s currently in effect before the callback is fired, but if you pass in true as the third parameter, the callback will be fired immediately with remainingRequests set to -1: var RateLimiter = require('limiter').RateLimiter; var limiter = new RateLimiter(150, 'hour', true); // fire CB immediately // Immediately send 429 header to client when rate limiting is in effect limiter.removeTokens(1, function(err, remainingRequests) { if (remainingRequests < 1) { response.writeHead(429, {'Content-Type': 'text/plain;charset=UTF-8'}); response.end('429 Too Many Requests - your IP is being rate limited'); } else { callMyMessageSendingFunction(...); } }); A synchronous method, tryRemoveTokens(), is available in both RateLimiter and TokenBucket. This will return immediately with a boolean value indicating if the token removal was successful. var RateLimiter = require('limiter').RateLimiter; var limiter = new RateLimiter(10, 'second'); if (limiter.tryRemoveTokens(5)) console.log('Tokens removed'); else console.log('No tokens removed'); To get the number of remaining tokens outside the removeTokens-callback simply use the getTokensRemaining-method. var RateLimiter = require('limiter').RateLimiter; var limiter = new RateLimiter(1, 250); // returns 1 since we did not remove a token and our number of tokens per interval is 1 limiter.getTokensRemaining(); Using the token bucket directly to throttle at the byte level: var BURST_RATE = 1024 * 1024 * 150; // 150KB/sec burst rate var FILL_RATE = 1024 * 1024 * 50; // 50KB/sec sustained rate var TokenBucket = require('limiter').TokenBucket; // We could also pass a parent token bucket in as the last parameter to // create a hierarchical token bucket var bucket = new TokenBucket(BURST_RATE, FILL_RATE, 'second', null); bucket.removeTokens(myData.byteLength, function() { sendMyData(myData); }); Additional Notes Both the token bucket and rate limiter should be used with a message queue or some way of preventing multiple simultaneous calls to removeTokens(). Otherwise, earlier messages may get held up for long periods of time if more recent messages are continually draining the token bucket. This can lead to out of order messages or the appearance of \"lost\" messages under heavy load. License (The MIT License) Copyright (c) 2013 John Hurliman. <jhurliman@jhurliman.org&gt; Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/load-json-file/node_modules/pify/readme.html": {
    "href": "node_modules/load-json-file/node_modules/pify/readme.html",
    "title": "pify | accouter",
    "keywords": "pify Promisify a callback-style function Install $ npm install --save pify Usage const fs = require('fs'); const pify = require('pify'); // Promisify a single function pify(fs.readFile)('package.json', 'utf8').then(data => { console.log(JSON.parse(data).name); //=> 'pify' }); // Promisify all methods in a module pify(fs).readFile('package.json', 'utf8').then(data => { console.log(JSON.parse(data).name); //=> 'pify' }); API pify(input, [options]) Returns a Promise wrapped version of the supplied function or module. input Type: Function Object Callback-style function or module whose methods you want to promisify. options multiArgs Type: boolean Default: false By default, the promisified function will only return the second argument from the callback, which works fine for most APIs. This option can be useful for modules like request that return multiple arguments. Turning this on will make it return an array of all arguments from the callback, excluding the error argument, instead of just the second argument. This also applies to rejections, where it returns an array of all the callback arguments, including the error. const request = require('request'); const pify = require('pify'); pify(request, {multiArgs: true})('https://sindresorhus.com').then(result => { const [httpResponse, body] = result; }); include Type: string[] RegExp[] Methods in a module to promisify. Remaining methods will be left untouched. exclude Type: string[] RegExp[] Default: [/.+(Sync|Stream)$/] Methods in a module not to promisify. Methods with names ending with 'Sync' are excluded by default. excludeMain Type: boolean Default: false If given module is a function itself, it will be promisified. Turn this option on if you want to promisify only methods of the module. const pify = require('pify'); function fn() { return true; } fn.method = (data, callback) => { setImmediate(() => { callback(null, data); }); }; // Promisify methods but not `fn()` const promiseFn = pify(fn, {excludeMain: true}); if (promiseFn()) { promiseFn.method('hi').then(data => { console.log(data); }); } errorFirst Type: boolean Default: true Whether the callback has an error as the first argument. You'll want to set this to false if you're dealing with an API that doesn't have an error as the first argument, like fs.exists(), some browser APIs, Chrome Extension APIs, etc. promiseModule Type: Function Custom promise module to use instead of the native one. Check out pinkie-promise if you need a tiny promise polyfill. Related p-event - Promisify an event by waiting for it to be emitted p-map - Map over promises concurrently More… License MIT © Sindre Sorhus"
  },
  "node_modules/load-json-file/readme.html": {
    "href": "node_modules/load-json-file/readme.html",
    "title": "load-json-file | accouter",
    "keywords": "load-json-file Read and parse a JSON file Strips UTF-8 BOM, uses graceful-fs, and throws more helpful JSON errors. Install $ npm install --save load-json-file Usage const loadJsonFile = require('load-json-file'); loadJsonFile('foo.json').then(json => { console.log(json); //=> {foo: true} }); API loadJsonFile(filepath) Returns a promise for the parsed JSON. loadJsonFile.sync(filepath) Returns the parsed JSON. Related write-json-file - Stringify and write JSON to a file atomically License MIT © Sindre Sorhus"
  },
  "node_modules/locate-path/readme.html": {
    "href": "node_modules/locate-path/readme.html",
    "title": "locate-path | accouter",
    "keywords": "locate-path Get the first path that exists on disk of multiple paths Install $ npm install locate-path Usage Here we find the first file that exists on disk, in array order. const locatePath = require('locate-path'); const files = [ 'unicorn.png', 'rainbow.png', // Only this one actually exists on disk 'pony.png' ]; (async () => { console(await locatePath(files)); //=> 'rainbow' })(); API locatePath(paths, options?) Returns a Promise<string> for the first path that exists or undefined if none exists. paths Type: Iterable<string> Paths to check. options Type: object concurrency Type: number Default: Infinity Minimum: 1 Number of concurrently pending promises. preserveOrder Type: boolean Default: true Preserve paths order when searching. Disable this to improve performance if you don't care about the order. cwd Type: string Default: process.cwd() Current working directory. type Type: string Default: 'file' Values: 'file' | 'directory' The type of paths that can match. allowSymlinks Type: boolean Default: true Allow symbolic links to match if they point to the chosen path type. locatePath.sync(paths, options?) Returns the first path that exists or undefined if none exists. paths Type: Iterable<string> Paths to check. options Type: object cwd Same as above. type Same as above. allowSymlinks Same as above. Related path-exists - Check if a path exists Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "node_modules/lodash.isfinite/README.html": {
    "href": "node_modules/lodash.isfinite/README.html",
    "title": "lodash.isfinite v3.3.2 | accouter",
    "keywords": "lodash.isfinite v3.3.2 The lodash method _.isFinite exported as a Node.js module. Installation Using npm: $ {sudo -H} npm i -g npm $ npm i --save lodash.isfinite In Node.js: var isFinite = require('lodash.isfinite'); See the documentation or package source for more details."
  },
  "node_modules/lodash.memoize/README.html": {
    "href": "node_modules/lodash.memoize/README.html",
    "title": "lodash.memoize v4.1.2 | accouter",
    "keywords": "lodash.memoize v4.1.2 The lodash method _.memoize exported as a Node.js module. Installation Using npm: $ {sudo -H} npm i -g npm $ npm i --save lodash.memoize In Node.js: var memoize = require('lodash.memoize'); See the documentation or package source for more details."
  },
  "node_modules/lodash.uniq/README.html": {
    "href": "node_modules/lodash.uniq/README.html",
    "title": "lodash.uniq v4.5.0 | accouter",
    "keywords": "lodash.uniq v4.5.0 The lodash method _.uniq exported as a Node.js module. Installation Using npm: $ {sudo -H} npm i -g npm $ npm i --save lodash.uniq In Node.js: var uniq = require('lodash.uniq'); See the documentation or package source for more details."
  },
  "node_modules/lodash/README.html": {
    "href": "node_modules/lodash/README.html",
    "title": "lodash v4.17.21 | accouter",
    "keywords": "lodash v4.17.21 The Lodash library exported as Node.js modules. Installation Using npm: $ npm i -g npm $ npm i --save lodash In Node.js: // Load the full build. var _ = require('lodash'); // Load the core build. var _ = require('lodash/core'); // Load the FP build for immutable auto-curried iteratee-first data-last methods. var fp = require('lodash/fp'); // Load method categories. var array = require('lodash/array'); var object = require('lodash/fp/object'); // Cherry-pick methods for smaller browserify/rollup/webpack bundles. var at = require('lodash/at'); var curryN = require('lodash/fp/curryN'); See the package source for more details. Note: Install n_ for Lodash use in the Node.js < 6 REPL. Support Tested in Chrome 74-75, Firefox 66-67, IE 11, Edge 18, Safari 11-12, & Node.js 8-12. Automated browser & CI test runs are available."
  },
  "node_modules/lodash/release.html": {
    "href": "node_modules/lodash/release.html",
    "title": "| accouter",
    "keywords": "npm run build npm run doc npm i git clone --depth=10 --branch=master git@github.com:lodash-archive/lodash-cli.git ./node_modules/lodash-cli mkdir -p ./node_modules/lodash-cli/node_modules/lodash; cd $_; cp ../../../../lodash.js ./lodash.js; cp ../../../../package.json ./package.json cd ../../; npm i --production; cd ../../ node ./node_modules/lodash-cli/bin/lodash core exports=node -o ./npm-package/core.js node ./node_modules/lodash-cli/bin/lodash modularize exports=node -o ./npm-package cp lodash.js npm-package/lodash.js cp dist/lodash.min.js npm-package/lodash.min.js cp LICENSE npm-package/LICENSE Clone two repos Bump lodash version in package.json, readme, package=locak, lodash.js npm run build npm run doc update mappings in ldoash-cli copy ldoash into lodash-cli node modules and package json. node ./node_modules/lodash-cli/bin/lodash core exports=node -o ./npm-package/core.js node ./node_modules/lodash-cli/bin/lodash modularize exports=node -o ./npm-package Clone the two repositories: $ git clone https://github.com/lodash/lodash.git $ git clone https://github.com/bnjmnt4n/lodash-cli.git Update lodash-cli to accomdate changes in lodash source. This can typically involve adding new function dependency mappings in lib/mappings.js. Sometimes, additional changes might be needed for more involved functions. In the lodash repository, update references to the lodash version in README.md, lodash.js, package.jsona nd package-lock.json Run: npm run build npm run doc node ../lodash-cli/bin/lodash core -o ./dist/lodash.core.js Add a commit and tag the release mkdir ../lodash-temp cp lodash.js dist/lodash.min.js dist/lodash.core.js dist/lodash.core.min.js ../lodash-temp/ node ../lodash-cli/bin/lodash modularize exports=node -o . cp ../lodash-temp/lodash.core.js core.js cp ../lodash-temp/lodash.core.min.js core.min.js cp ../lodash-temp/lodash.js lodash.js cp ../lodash-temp/lodash.min.js lodash.min.js ❯ node ../lodash-cli/bin/lodash modularize exports=es -o ."
  },
  "node_modules/log-symbols/readme.html": {
    "href": "node_modules/log-symbols/readme.html",
    "title": "log-symbols | accouter",
    "keywords": "log-symbols Colored symbols for various log levels Includes fallbacks for Windows CMD which only supports a limited character set. Install $ npm install log-symbols Usage const logSymbols = require('log-symbols'); console.log(logSymbols.success, 'Finished successfully!'); // Terminals with Unicode support: ✔ Finished successfully! // Terminals without Unicode support: √ Finished successfully! API logSymbols info success warning error Related figures - Unicode symbols with Windows CMD fallbacks py-log-symbols - Python port log-symbols - Ruby port guumaster/logsymbols - Golang port Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "node_modules/lru-cache/README.html": {
    "href": "node_modules/lru-cache/README.html",
    "title": "lru-cache | accouter",
    "keywords": "lru-cache A cache object that deletes the least-recently-used items. Specify a max number of the most recently used items that you want to keep, and this cache will keep that many of the most recently accessed items. This is not primarily a TTL cache, and does not make strong TTL guarantees. There is no preemptive pruning of expired items by default, but you may set a TTL on the cache or on a single set. If you do so, it will treat expired items as missing, and delete them when fetched. If you are more interested in TTL caching than LRU caching, check out @isaacs/ttlcache. As of version 7, this is one of the most performant LRU implementations available in JavaScript, and supports a wide diversity of use cases. However, note that using some of the features will necessarily impact performance, by causing the cache to have to do more work. See the \"Performance\" section below. Installation npm install lru-cache --save Usage // hybrid module, either works import { LRUCache } from 'lru-cache' // or: const { LRUCache } = require('lru-cache') // or in minified form for web browsers: import { LRUCache } from 'http://unpkg.com/lru-cache@9/dist/mjs/index.min.mjs' // At least one of 'max', 'ttl', or 'maxSize' is required, to prevent // unsafe unbounded storage. // // In most cases, it's best to specify a max for performance, so all // the required memory allocation is done up-front. // // All the other options are optional, see the sections below for // documentation on what each one does. Most of them can be // overridden for specific items in get()/set() const options = { max: 500, // for use with tracking overall storage size maxSize: 5000, sizeCalculation: (value, key) => { return 1 }, // for use when you need to clean up something when objects // are evicted from the cache dispose: (value, key) => { freeFromMemoryOrWhatever(value) }, // how long to live in ms ttl: 1000 * 60 * 5, // return stale items before removing from cache? allowStale: false, updateAgeOnGet: false, updateAgeOnHas: false, // async method to use for cache.fetch(), for // stale-while-revalidate type of behavior fetchMethod: async ( key, staleValue, { options, signal, context } ) => {}, } const cache = new LRUCache(options) cache.set('key', 'value') cache.get('key') // \"value\" // non-string keys ARE fully supported // but note that it must be THE SAME object, not // just a JSON-equivalent object. var someObject = { a: 1 } cache.set(someObject, 'a value') // Object keys are not toString()-ed cache.set('[object Object]', 'a different value') assert.equal(cache.get(someObject), 'a value') // A similar object with same keys/values won't work, // because it's a different object identity assert.equal(cache.get({ a: 1 }), undefined) cache.clear() // empty the cache If you put more stuff in the cache, then less recently used items will fall out. That's what an LRU cache is. class LRUCache<K, V, FC = unknown>(options) Create a new LRUCache object. When using TypeScript, set the K and V types to the key and value types, respectively. The FC (\"fetch context\") generic type defaults to unknown. If set to a value other than void or undefined, then any calls to cache.fetch() must provide a context option matching the FC type. If FC is set to void or undefined, then cache.fetch() must not provide a context option. See the documentation on async fetch() below. Options All options are available on the LRUCache instance, making it safe to pass an LRUCache instance as the options argument to make another empty cache of the same type. Some options are marked read-only because changing them after instantiation is not safe. Changing any of the other options will of course only have an effect on subsequent method calls. max (read only) The maximum number of items that remain in the cache (assuming no TTL pruning or explicit deletions). Note that fewer items may be stored if size calculation is used, and maxSize is exceeded. This must be a positive finite intger. At least one of max, maxSize, or TTL is required. This must be a positive integer if set. It is strongly recommended to set a max to prevent unbounded growth of the cache. See \"Storage Bounds Safety\" below. maxSize (read only) Set to a positive integer to track the sizes of items added to the cache, and automatically evict items in order to stay below this size. Note that this may result in fewer than max items being stored. Attempting to add an item to the cache whose calculated size is greater that this amount will be a no-op. The item will not be cached, and no other items will be evicted. Optional, must be a positive integer if provided. Sets maxEntrySize to the same value, unless a different value is provided for maxEntrySize. At least one of max, maxSize, or TTL is required. This must be a positive integer if set. Even if size tracking is enabled, it is strongly recommended to set a max to prevent unbounded growth of the cache. See \"Storage Bounds Safety\" below. maxEntrySize Set to a positive integer to track the sizes of items added to the cache, and prevent caching any item over a given size. Attempting to add an item whose calculated size is greater than this amount will be a no-op. The item will not be cached, and no other items will be evicted. Optional, must be a positive integer if provided. Defaults to the value of maxSize if provided. sizeCalculation Function used to calculate the size of stored items. If you're storing strings or buffers, then you probably want to do something like n => n.length. The item is passed as the first argument, and the key is passed as the second argument. This may be overridden by passing an options object to cache.set(). Requires maxSize to be set. If the size (or return value of sizeCalculation) for a given entry is greater than maxEntrySize, then the item will not be added to the cache. fetchMethod (read only) Function that is used to make background asynchronous fetches. Called with fetchMethod(key, staleValue, { signal, options, context }). May return a Promise. If fetchMethod is not provided, then cache.fetch(key) is equivalent to Promise.resolve(cache.get(key)). If at any time, signal.aborted is set to true, or if the signal.onabort method is called, or if it emits an 'abort' event which you can listen to with addEventListener, then that means that the fetch should be abandoned. This may be passed along to async functions aware of AbortController/AbortSignal behavior. The fetchMethod should only return undefined or a Promise resolving to undefined if the AbortController signaled an abort event. In all other cases, it should return or resolve to a value suitable for adding to the cache. The options object is a union of the options that may be provided to set() and get(). If they are modified, then that will result in modifying the settings to cache.set() when the value is resolved, and in the case of noDeleteOnFetchRejection and allowStaleOnFetchRejection, the handling of fetchMethod failures. For example, a DNS cache may update the TTL based on the value returned from a remote DNS server by changing options.ttl in the fetchMethod. noDeleteOnFetchRejection If a fetchMethod throws an error or returns a rejected promise, then by default, any existing stale value will be removed from the cache. If noDeleteOnFetchRejection is set to true, then this behavior is suppressed, and the stale value remains in the cache in the case of a rejected fetchMethod. This is important in cases where a fetchMethod is only called as a background update while the stale value is returned, when allowStale is used. This is implicitly in effect when allowStaleOnFetchRejection is set. This may be set in calls to fetch(), or defaulted on the constructor, or overridden by modifying the options object in the fetchMethod. allowStaleOnFetchRejection Set to true to return a stale value from the cache when a fetchMethod throws an error or returns a rejected Promise. If a fetchMethod fails, and there is no stale value available, the fetch() will resolve to undefined. Ie, all fetchMethod errors are suppressed. Implies noDeleteOnFetchRejection. This may be set in calls to fetch(), or defaulted on the constructor, or overridden by modifying the options object in the fetchMethod. allowStaleOnFetchAbort Set to true to return a stale value from the cache when the AbortSignal passed to the fetchMethod dispatches an 'abort' event, whether user-triggered, or due to internal cache behavior. Unless ignoreFetchAbort is also set, the underlying fetchMethod will still be considered canceled, and any value it returns will be ignored and not cached. Caveat: since fetches are aborted when a new value is explicitly set in the cache, this can lead to fetch returning a stale value, since that was the fallback value at the moment the fetch() was initiated, even though the new updated value is now present in the cache. For example: const cache = new LRUCache<string, any>({ ttl: 100, fetchMethod: async (url, oldValue, { signal }) => { const res = await fetch(url, { signal }) return await res.json() }, }) cache.set('https://example.com/', { some: 'data' }) // 100ms go by... const result = cache.fetch('https://example.com/') cache.set('https://example.com/', { other: 'thing' }) console.log(await result) // { some: 'data' } console.log(cache.get('https://example.com/')) // { other: 'thing' } ignoreFetchAbort Set to true to ignore the abort event emitted by the AbortSignal object passed to fetchMethod, and still cache the resulting resolution value, as long as it is not undefined. When used on its own, this means aborted fetch() calls are not immediately resolved or rejected when they are aborted, and instead take the full time to await. When used with allowStaleOnFetchAbort, aborted fetch() calls will resolve immediately to their stale cached value or undefined, and will continue to process and eventually update the cache when they resolve, as long as the resulting value is not undefined, thus supporting a \"return stale on timeout while refreshing\" mechanism by passing AbortSignal.timeout(n) as the signal. For example: const c = new LRUCache({ ttl: 100, ignoreFetchAbort: true, allowStaleOnFetchAbort: true, fetchMethod: async (key, oldValue, { signal }) => { // note: do NOT pass the signal to fetch()! // let's say this fetch can take a long time. const res = await fetch(`https://slow-backend-server/${key}`) return await res.json() }, }) // this will return the stale value after 100ms, while still // updating in the background for next time. const val = await c.fetch('key', { signal: AbortSignal.timeout(100) }) Note: regardless of this setting, an abort event is still emitted on the AbortSignal object, so may result in invalid results when passed to other underlying APIs that use AbortSignals. This may be overridden on the fetch() call or in the fetchMethod itself. dispose (read only) Function that is called on items when they are dropped from the cache, as this.dispose(value, key, reason). This can be handy if you want to close file descriptors or do other cleanup tasks when items are no longer stored in the cache. NOTE: It is called before the item has been fully removed from the cache, so if you want to put it right back in, you need to wait until the next tick. If you try to add it back in during the dispose() function call, it will break things in subtle and weird ways. Unlike several other options, this may not be overridden by passing an option to set(), for performance reasons. The reason will be one of the following strings, corresponding to the reason for the item's deletion: evict Item was evicted to make space for a new addition set Item was overwritten by a new value delete Item was removed by explicit cache.delete(key) or by calling cache.clear(), which deletes everything. The dispose() method is not called for canceled calls to fetchMethod(). If you wish to handle evictions, overwrites, and deletes of in-flight asynchronous fetches, you must use the AbortSignal provided. Optional, must be a function. disposeAfter (read only) The same as dispose, but called after the entry is completely removed and the cache is once again in a clean state. It is safe to add an item right back into the cache at this point. However, note that it is very easy to inadvertently create infinite recursion in this way. The disposeAfter() method is not called for canceled calls to fetchMethod(). If you wish to handle evictions, overwrites, and deletes of in-flight asynchronous fetches, you must use the AbortSignal provided. noDisposeOnSet Set to true to suppress calling the dispose() function if the entry key is still accessible within the cache. This may be overridden by passing an options object to cache.set(). Boolean, default false. Only relevant if dispose or disposeAfter options are set. ttl Max time to live for items before they are considered stale. Note that stale items are NOT preemptively removed by default, and MAY live in the cache, contributing to its LRU max, long after they have expired. Also, as this cache is optimized for LRU/MRU operations, some of the staleness/TTL checks will reduce performance. This is not primarily a TTL cache, and does not make strong TTL guarantees. There is no pre-emptive pruning of expired items, but you may set a TTL on the cache, and it will treat expired items as missing when they are fetched, and delete them. Optional, but must be a positive integer in ms if specified. This may be overridden by passing an options object to cache.set(). At least one of max, maxSize, or TTL is required. This must be a positive integer if set. Even if ttl tracking is enabled, it is strongly recommended to set a max to prevent unbounded growth of the cache. See \"Storage Bounds Safety\" below. If ttl tracking is enabled, and max and maxSize are not set, and ttlAutopurge is not set, then a warning will be emitted cautioning about the potential for unbounded memory consumption. (The TypeScript definitions will also discourage this.) noUpdateTTL Boolean flag to tell the cache to not update the TTL when setting a new value for an existing key (ie, when updating a value rather than inserting a new value). Note that the TTL value is always set (if provided) when adding a new entry into the cache. This may be passed as an option to cache.set(). Boolean, default false. ttlResolution Minimum amount of time in ms in which to check for staleness. Defaults to 1, which means that the current time is checked at most once per millisecond. Set to 0 to check the current time every time staleness is tested. Note that setting this to a higher value will improve performance somewhat while using ttl tracking, albeit at the expense of keeping stale items around a bit longer than intended. ttlAutopurge Preemptively remove stale items from the cache. Note that this may significantly degrade performance, especially if the cache is storing a large number of items. It is almost always best to just leave the stale items in the cache, and let them fall out as new items are added. Note that this means that allowStale is a bit pointless, as stale items will be deleted almost as soon as they expire. Use with caution! Boolean, default false allowStale By default, if you set ttl, it'll only delete stale items from the cache when you get(key). That is, it's not preemptively pruning items. If you set allowStale:true, it'll return the stale value as well as deleting it. If you don't set this, then it'll return undefined when you try to get a stale entry. Note that when a stale entry is fetched, even if it is returned due to allowStale being set, it is removed from the cache immediately. You can immediately put it back in the cache if you wish, thus resetting the TTL. This may be overridden by passing an options object to cache.get(). The cache.has() method will always return false for stale items. Boolean, default false, only relevant if ttl is set. noDeleteOnStaleGet When using time-expiring entries with ttl, by default stale items will be removed from the cache when the key is accessed with cache.get(). Setting noDeleteOnStaleGet to true will cause stale items to remain in the cache, until they are explicitly deleted with cache.delete(key), or retrieved with noDeleteOnStaleGet set to false. This may be overridden by passing an options object to cache.get(). Boolean, default false, only relevant if ttl is set. updateAgeOnGet When using time-expiring entries with ttl, setting this to true will make each item's age reset to 0 whenever it is retrieved from cache with get(), causing it to not expire. (It can still fall out of cache based on recency of use, of course.) This may be overridden by passing an options object to cache.get(). Boolean, default false, only relevant if ttl is set. updateAgeOnHas When using time-expiring entries with ttl, setting this to true will make each item's age reset to 0 whenever its presence in the cache is checked with has(), causing it to not expire. (It can still fall out of cache based on recency of use, of course.) This may be overridden by passing an options object to cache.has(). Boolean, default false, only relevant if ttl is set. API new LRUCache<K, V, FC = unknown>(options) Create a new LRUCache. All options are documented above, and are on the cache as public members. The K and V types define the key and value types, respectively. The optional FC type defines the type of the context object passed to cache.fetch(). Keys and values must not be null or undefined. cache.max, cache.maxSize, cache.allowStale, cache.noDisposeOnSet, cache.sizeCalculation, cache.dispose, cache.maxSize, cache.ttl, cache.updateAgeOnGet, cache.updateAgeOnHas All option names are exposed as public members on the cache object. These are intended for read access only. Changing them during program operation can cause undefined behavior. cache.size The total number of items held in the cache at the current moment. cache.calculatedSize The total size of items in cache when using size tracking. set(key, value, [{ size, sizeCalculation, ttl, noDisposeOnSet, start, status }]) Add a value to the cache. Optional options object may contain ttl and sizeCalculation as described above, which default to the settings on the cache object. If start is provided, then that will set the effective start time for the TTL calculation. Note that this must be a previous value of performance.now() if supported, or a previous value of Date.now() if not. Options object may also include size, which will prevent calling the sizeCalculation function and just use the specified number if it is a positive integer, and noDisposeOnSet which will prevent calling a dispose function in the case of overwrites. If the size (or return value of sizeCalculation) for a given entry is greater than maxEntrySize, then the item will not be added to the cache. Will update the recency of the entry. Returns the cache object. For the usage of the status option, see Status Tracking below. If the value is undefined, then this is an alias for cache.delete(key). undefined is never stored in the cache. See Storing Undefined Values below. get(key, { updateAgeOnGet, allowStale, status } = {}) => value Return a value from the cache. Will update the recency of the cache entry found. If the key is not found, get() will return undefined. For the usage of the status option, see Status Tracking below. info(key) => Entry | undefined Return an Entry object containing the currently cached value, as well as ttl and size information if available. Returns undefined if the key is not found in the cache. Unlike dump() (which is designed to be portable and survive serialization), the start value is always the current timestamp, and the ttl is a calculated remaining time to live (negative if expired). Note that stale values are always returned, rather than being pruned and treated as if they were not in the cache. If you wish to exclude stale entries, guard against a negative ttl value. async fetch(key, options = {}) => Promise The following options are supported: updateAgeOnGet allowStale size sizeCalculation ttl noDisposeOnSet forceRefresh status - See Status Tracking below. signal - AbortSignal can be used to cancel the fetch(). Note that the signal option provided to the fetchMethod is a different object, because it must also respond to internal cache state changes, but aborting this signal will abort the one passed to fetchMethod as well. context - sets the context option passed to the underlying fetchMethod. If the value is in the cache and not stale, then the returned Promise resolves to the value. If not in the cache, or beyond its TTL staleness, then fetchMethod(key, staleValue, { options, signal, context }) is called, and the value returned will be added to the cache once resolved. If called with allowStale, and an asynchronous fetch is currently in progress to reload a stale value, then the former stale value will be returned. If called with forceRefresh, then the cached item will be re-fetched, even if it is not stale. However, if allowStale is set, then the old value will still be returned. This is useful in cases where you want to force a reload of a cached value. If a background fetch is already in progress, then forceRefresh has no effect. Multiple fetches for the same key will only call fetchMethod a single time, and all will be resolved when the value is resolved, even if different options are used. If fetchMethod is not specified, then this is effectively an alias for Promise.resolve(cache.get(key)). When the fetch method resolves to a value, if the fetch has not been aborted due to deletion, eviction, or being overwritten, then it is added to the cache using the options provided. If the key is evicted or deleted before the fetchMethod resolves, then the AbortSignal passed to the fetchMethod will receive an abort event, and the promise returned by fetch() will reject with the reason for the abort. If a signal is passed to the fetch() call, then aborting the signal will abort the fetch and cause the fetch() promise to reject with the reason provided. Setting context If an FC type is set to a type other than unknown, void, or undefined in the LRUCache constructor, then all calls to cache.fetch() must provide a context option. If set to undefined or void, then calls to fetch must not provide a context option. The context param allows you to provide arbitrary data that might be relevant in the course of fetching the data. It is only relevant for the course of a single fetch() operation, and discarded afterwards. Note: fetch() calls are inflight-unique If you call fetch() multiple times with the same key value, then every call after the first will resolve on the same promise1, even if they have different settings that would otherwise change the behvavior of the fetch, such as noDeleteOnFetchRejection or ignoreFetchAbort. In most cases, this is not a problem (in fact, only fetching something once is what you probably want, if you're caching in the first place). If you are changing the fetch() options dramatically between runs, there's a good chance that you might be trying to fit divergent semantics into a single object, and would be better off with multiple cache instances. 1: Ie, they're not the \"same Promise\", but they resolve at the same time, because they're both waiting on the same underlying fetchMethod response. peek(key, { allowStale } = {}) => value Like get() but doesn't update recency or delete stale items. Returns undefined if the item is stale, unless allowStale is set either on the cache or in the options object. has(key, { updateAgeOnHas, status } = {}) => Boolean Check if a key is in the cache, without updating the recency of use. Age is updated if updateAgeOnHas is set to true in either the options or the constructor. Will return false if the item is stale, even though it is technically in the cache. The difference can be determined (if it matters) by using a status argument, and inspecting the has field. For the usage of the status option, see Status Tracking below. delete(key) Deletes a key out of the cache. Returns true if the key was deleted, false otherwise. clear() Clear the cache entirely, throwing away all values. keys() Return a generator yielding the keys in the cache, in order from most recently used to least recently used. rkeys() Return a generator yielding the keys in the cache, in order from least recently used to most recently used. values() Return a generator yielding the values in the cache, in order from most recently used to least recently used. rvalues() Return a generator yielding the values in the cache, in order from least recently used to most recently used. entries() Return a generator yielding [key, value] pairs, in order from most recently used to least recently used. rentries() Return a generator yielding [key, value] pairs, in order from least recently used to most recently used. find(fn, [getOptions]) Find a value for which the supplied fn method returns a truthy value, similar to Array.find(). fn is called as fn(value, key, cache). The optional getOptions are applied to the resulting get() of the item found. dump() Return an array of [key, entry] objects which can be passed to cache.load() The start fields are calculated relative to a portable Date.now() timestamp, even if performance.now() is available. Stale entries are always included in the dump, even if allowStale is false. Note: this returns an actual array, not a generator, so it can be more easily passed around. load(entries) Reset the cache and load in the items in entries in the order listed. Note that the shape of the resulting cache may be different if the same options are not used in both caches. The start fields are assumed to be calculated relative to a portable Date.now() timestamp, even if performance.now() is available. purgeStale() Delete any stale entries. Returns true if anything was removed, false otherwise. getRemainingTTL(key) Return the number of ms left in the item's TTL. If item is not in cache, returns 0. Returns Infinity if item is in cache without a defined TTL. forEach(fn, [thisp]) Call the fn function with each set of fn(value, key, cache) in the LRU cache, from most recent to least recently used. Does not affect recency of use. If thisp is provided, function will be called in the this-context of the provided object. rforEach(fn, [thisp]) Same as cache.forEach(fn, thisp), but in order from least recently used to most recently used. pop() Evict the least recently used item, returning its value. Returns undefined if cache is empty. Status Tracking Occasionally, it may be useful to track the internal behavior of the cache, particularly for logging, debugging, or for behavior within the fetchMethod. To do this, you can pass a status object to the get(), set(), has(), and fetch() methods. The status option should be a plain JavaScript object. The following fields will be set appropriately: interface Status<V> { /** * The status of a set() operation. * * - add: the item was not found in the cache, and was added * - update: the item was in the cache, with the same value provided * - replace: the item was in the cache, and replaced * - miss: the item was not added to the cache for some reason */ set?: 'add' | 'update' | 'replace' | 'miss' /** * the ttl stored for the item, or undefined if ttls are not used. */ ttl?: LRUMilliseconds /** * the start time for the item, or undefined if ttls are not used. */ start?: LRUMilliseconds /** * The timestamp used for TTL calculation */ now?: LRUMilliseconds /** * the remaining ttl for the item, or undefined if ttls are not used. */ remainingTTL?: LRUMilliseconds /** * The calculated size for the item, if sizes are used. */ size?: LRUSize /** * A flag indicating that the item was not stored, due to exceeding the * {@link maxEntrySize} */ maxEntrySizeExceeded?: true /** * The old value, specified in the case of `set:'update'` or * `set:'replace'` */ oldValue?: V /** * The results of a {@link has} operation * * - hit: the item was found in the cache * - stale: the item was found in the cache, but is stale * - miss: the item was not found in the cache */ has?: 'hit' | 'stale' | 'miss' /** * The status of a {@link fetch} operation. * Note that this can change as the underlying fetch() moves through * various states. * * - inflight: there is another fetch() for this key which is in process * - get: there is no fetchMethod, so {@link get} was called. * - miss: the item is not in cache, and will be fetched. * - hit: the item is in the cache, and was resolved immediately. * - stale: the item is in the cache, but stale. * - refresh: the item is in the cache, and not stale, but * {@link forceRefresh} was specified. */ fetch?: 'get' | 'inflight' | 'miss' | 'hit' | 'stale' | 'refresh' /** * The {@link fetchMethod} was called */ fetchDispatched?: true /** * The cached value was updated after a successful call to fetchMethod */ fetchUpdated?: true /** * The reason for a fetch() rejection. Either the error raised by the * {@link fetchMethod}, or the reason for an AbortSignal. */ fetchError?: Error /** * The fetch received an abort signal */ fetchAborted?: true /** * The abort signal received was ignored, and the fetch was allowed to * continue. */ fetchAbortIgnored?: true /** * The fetchMethod promise resolved successfully */ fetchResolved?: true /** * The results of the fetchMethod promise were stored in the cache */ fetchUpdated?: true /** * The fetchMethod promise was rejected */ fetchRejected?: true /** * The status of a {@link get} operation. * * - fetching: The item is currently being fetched. If a previous value is * present and allowed, that will be returned. * - stale: The item is in the cache, and is stale. * - hit: the item is in the cache * - miss: the item is not in the cache */ get?: 'stale' | 'hit' | 'miss' /** * A fetch or get operation returned a stale value. */ returnedStale?: true } Storage Bounds Safety This implementation aims to be as flexible as possible, within the limits of safe memory consumption and optimal performance. At initial object creation, storage is allocated for max items. If max is set to zero, then some performance is lost, and item count is unbounded. Either maxSize or ttl must be set if max is not specified. If maxSize is set, then this creates a safe limit on the maximum storage consumed, but without the performance benefits of pre-allocation. When maxSize is set, every item must provide a size, either via the sizeCalculation method provided to the constructor, or via a size or sizeCalculation option provided to cache.set(). The size of every item must be a positive integer. If neither max nor maxSize are set, then ttl tracking must be enabled. Note that, even when tracking item ttl, items are not preemptively deleted when they become stale, unless ttlAutopurge is enabled. Instead, they are only purged the next time the key is requested. Thus, if ttlAutopurge, max, and maxSize are all not set, then the cache will potentially grow unbounded. In this case, a warning is printed to standard error. Future versions may require the use of ttlAutopurge if max and maxSize are not specified. If you truly wish to use a cache that is bound only by TTL expiration, consider using a Map object, and calling setTimeout to delete entries when they expire. It will perform much better than an LRU cache. Here is an implementation you may use, under the same license as this package: // a storage-unbounded ttl cache that is not an lru-cache const cache = { data: new Map(), timers: new Map(), set: (k, v, ttl) => { if (cache.timers.has(k)) { clearTimeout(cache.timers.get(k)) } cache.timers.set( k, setTimeout(() => cache.delete(k), ttl) ) cache.data.set(k, v) }, get: k => cache.data.get(k), has: k => cache.data.has(k), delete: k => { if (cache.timers.has(k)) { clearTimeout(cache.timers.get(k)) } cache.timers.delete(k) return cache.data.delete(k) }, clear: () => { cache.data.clear() for (const v of cache.timers.values()) { clearTimeout(v) } cache.timers.clear() }, } If that isn't to your liking, check out @isaacs/ttlcache. Storing Undefined Values This cache never stores undefined values, as undefined is used internally in a few places to indicate that a key is not in the cache. You may call cache.set(key, undefined), but this is just an an alias for cache.delete(key). Note that this has the effect that cache.has(key) will return false after setting it to undefined. cache.set(myKey, undefined) cache.has(myKey) // false! If you need to track undefined values, and still note that the key is in the cache, an easy workaround is to use a sigil object of your own. import { LRUCache } from 'lru-cache' const undefinedValue = Symbol('undefined') const cache = new LRUCache(...) const mySet = (key, value) => cache.set(key, value === undefined ? undefinedValue : value) const myGet = (key, value) => { const v = cache.get(key) return v === undefinedValue ? undefined : v } Performance As of January 2022, version 7 of this library is one of the most performant LRU cache implementations in JavaScript. Benchmarks can be extremely difficult to get right. In particular, the performance of set/get/delete operations on objects will vary wildly depending on the type of key used. V8 is highly optimized for objects with keys that are short strings, especially integer numeric strings. Thus any benchmark which tests solely using numbers as keys will tend to find that an object-based approach performs the best. Note that coercing anything to strings to use as object keys is unsafe, unless you can be 100% certain that no other type of value will be used. For example: const myCache = {} const set = (k, v) => (myCache[k] = v) const get = k => myCache[k] set({}, 'please hang onto this for me') set('[object Object]', 'oopsie') Also beware of \"Just So\" stories regarding performance. Garbage collection of large (especially: deep) object graphs can be incredibly costly, with several \"tipping points\" where it increases exponentially. As a result, putting that off until later can make it much worse, and less predictable. If a library performs well, but only in a scenario where the object graph is kept shallow, then that won't help you if you are using large objects as keys. In general, when attempting to use a library to improve performance (such as a cache like this one), it's best to choose an option that will perform well in the sorts of scenarios where you'll actually use it. This library is optimized for repeated gets and minimizing eviction time, since that is the expected need of a LRU. Set operations are somewhat slower on average than a few other options, in part because of that optimization. It is assumed that you'll be caching some costly operation, ideally as rarely as possible, so optimizing set over get would be unwise. If performance matters to you: If it's at all possible to use small integer values as keys, and you can guarantee that no other types of values will be used as keys, then do that, and use a cache such as lru-fast, or mnemonist's LRUCache which uses an Object as its data store. Failing that, if at all possible, use short non-numeric strings (ie, less than 256 characters) as your keys, and use mnemonist's LRUCache. If the types of your keys will be anything else, especially long strings, strings that look like floats, objects, or some mix of types, or if you aren't sure, then this library will work well for you. If you do not need the features that this library provides (like asynchronous fetching, a variety of TTL staleness options, and so on), then mnemonist's LRUMap is a very good option, and just slightly faster than this module (since it does considerably less). Do not use a dispose function, size tracking, or especially ttl behavior, unless absolutely needed. These features are convenient, and necessary in some use cases, and every attempt has been made to make the performance impact minimal, but it isn't nothing. Breaking Changes in Version 7 This library changed to a different algorithm and internal data structure in version 7, yielding significantly better performance, albeit with some subtle changes as a result. If you were relying on the internals of LRUCache in version 6 or before, it probably will not work in version 7 and above. Breaking Changes in Version 8 The fetchContext option was renamed to context, and may no longer be set on the cache instance itself. Rewritten in TypeScript, so pretty much all the types moved around a lot. The AbortController/AbortSignal polyfill was removed. For this reason, Node version 16.14.0 or higher is now required. Internal properties were moved to actual private class properties. Keys and values must not be null or undefined. Minified export available at 'lru-cache/min', for both CJS and MJS builds. Changes in Version 9 Named export only, no default export. AbortController polyfill returned, albeit with a warning when used. For more info, see the change log."
  },
  "node_modules/mdn-data/CHANGELOG.html": {
    "href": "node_modules/mdn-data/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog 2.0.30 (2022-10-28) Bug Fixes correct mask-repeat initial value (b36469e) correct scroll-timeline-axis and mask-repeat initial value (#622) (e48302d) correct scroll-timeline-axis initial value (5144622) 2.0.29 (2022-08-30) Miscellaneous Chores release 2.0.29 (da9510f) 2.0.28 (2022-07-12) Bug Fixes css: correct two syntax examples in selectors (#589) (91ab33a) 2.0.27 (2022-02-24) Miscellaneous Chores release (a99ae2e) 2.0.26 (2022-01-19) Miscellaneous Chores release 2.0.26 (8b1045d) 2.0.25 (2021-12-21) Bug Fixes change branch reference to main (a473261) remove old clashing workflow (af9a18c) Miscellaneous Chores release 2.0.25 (db5a54b) release 2.0.25 (0f453ee) 2.0.24 (2021-12-17) Miscellaneous Chores release 2.0.24 (4d00c38) 2.0.24 (2021-12-15) Miscellaneous Chores release 2.0.24 (abff6ff)"
  },
  "node_modules/mdn-data/README.html": {
    "href": "node_modules/mdn-data/README.html",
    "title": "MDN data | accouter",
    "keywords": "MDN data Note: We are in the process of deprecating the mdn/data package in favor of w3c/webref. If this could present a problem to your project, please contact us via our GitHub discussions. Thank you. https://github.com/mdn/data Maintained by the MDN team at Mozilla. This repository contains general data for Web technologies. This data is used in MDN documentation, to build information boxes or sidebar navigation. External tools have started to make use of this data as well. For example, the CSSTree CSS parser. Repository contents There's a top-level directory for each broad area covered: for example, api and css. Inside each of these directories is one or more JSON files containing the data. api Contains data about Web APIs: API inheritance (interface inheritance and mixin implementations) css Contains data about: CSS at-rules CSS properties CSS selectors CSS syntaxes CSS types CSS units Read more about CSS data and the format of the files. l10n The l10n folder contains localization strings that are used in the various json files throughout this repository. Problems? If you find a problem, please file an issue. Contributing We're very happy to accept contributions to this data. Please familiarize yourself with the schema for the data you're editing, and send us a pull request. See also the Contributing file for more information. See also https://github.com/mdn/browser-compat-data for compatibility data for Web technologies"
  },
  "node_modules/mdn-data/css/readme.html": {
    "href": "node_modules/mdn-data/css/readme.html",
    "title": "MDN CSS data | accouter",
    "keywords": "MDN CSS data This folder contains data about the different features of the CSS language. Different types of CSS data The CSS data is split into these parts: at-rules: data | schema | docs properties: data | schema | docs selectors: data | schema | docs syntaxes: data | schema | docs types: data | schema | docs units: data | schema | docs"
  },
  "node_modules/memorystream/README.html": {
    "href": "node_modules/memorystream/README.html",
    "title": "Introduction | accouter",
    "keywords": "Introduction node-memorystream - this module allow create streams in memory. It can be used for emulating file streams, filtering/mutating data between one stream and another, buffering incoming data, being the gap between two data/network streams of variable rates, etc. MemoryStream support read/write states or only read state or only write state. The API is meant to follow node's Stream implementation. Module supports streams for node > 0.10 now. Original module is here git://github.com/ollym/memstream.git was remade and improved. Installation If you have npm installed, you can simply type: npm install memorystream Or you can clone this repository using the git command: git clone git://github.com/JSBizon/node-memorystream.git Usage Some examples how to use memorystream module. Basic I/O Operation In this example I illustrate the basic I/O operations of the memory stream. var MemoryStream = require('memorystream'); var memStream = new MemoryStream(['Hello',' ']); var data = ''; memStream.on('data', function(chunk) { data += chunk.toString(); }); memStream.write('World'); memStream.on('end', function() { // outputs 'Hello World!' console.log(data); }); memStream.end('!'); Piping In this example I'm piping all data from the memory stream to the process's stdout stream. var MemoryStream = require('memorystream'); var memStream = new MemoryStream(); memStream.pipe(process.stdout, { end: false }); memStream.write('Hello World!'); In this example I'm piping all data from the response stream to the memory stream. var http = require('http'), MemoryStream = require('memorystream'); var options = { host: 'google.com' }; var memStream = new MemoryStream(null, { readable : false }); var req = http.get(options, function(res) { res.pipe(memStream); res.on('end', function() { console.log(memStream.toString()); }); }); Delayed Response In the example below, we first pause the stream before writing the data to it. The stream is then resumed after 1 second, and the data is written to the console. var MemoryStream = require('memorystream'); var memStream = new MemoryStream('Hello'); var data = ''; memStream.on('data', function(chunk) { data += chunk; }); memStream.pause(); memStream.write('World!'); setTimeout(function() { memStream.resume(); }, 1000); Documentation The memory stream adopts all the same methods and events as node's Stream implementation. Documentation is available here."
  },
  "node_modules/meow/build/licenses.html": {
    "href": "node_modules/meow/build/licenses.html",
    "title": "Name: yargs-parser Version: 21.1.1 License: ISC Private: false Description: the mighty option parser used by yargs Repository: https://github.com/yargs/yargs-parser.git Author: Ben Coe ben@npmjs.com License Copyright: | accouter",
    "keywords": "Name: yargs-parser Version: 21.1.1 License: ISC Private: false Description: the mighty option parser used by yargs Repository: https://github.com/yargs/yargs-parser.git Author: Ben Coe ben@npmjs.com License Copyright: Copyright (c) 2016, Contributors Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies. THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE. Name: map-obj Version: 4.3.0 License: MIT Private: false Description: Map object keys and values into a new object Repository: undefined Author: Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) License Copyright: MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: camelcase Version: 7.0.1 License: MIT Private: false Description: Convert a dash/dot/underscore/space separated string to camelCase or PascalCase: foo-bar → fooBar Repository: undefined Author: Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) License Copyright: MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: quick-lru Version: 6.1.2 License: MIT Private: false Description: Simple “Least Recently Used” (LRU) cache Repository: undefined Author: Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) License Copyright: MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: camelcase-keys Version: 8.0.2 License: MIT Private: false Description: Convert object keys to camel case Repository: undefined Author: Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) License Copyright: MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: trim-newlines Version: 5.0.0 License: MIT Private: false Description: Trim newlines from the start and/or end of a string Repository: undefined Author: Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) License Copyright: MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: min-indent Version: 1.0.1 License: MIT Private: false Description: Get the shortest leading whitespace from lines in a string Repository: undefined Author: James Kyle me@thejameskyle.com (thejameskyle.com) License Copyright: The MIT License (MIT) Copyright (c) Sindre Sorhus sindresorhus@gmail.com (sindresorhus.com), James Kyle me@thejameskyle.com (thejameskyle.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: strip-indent Version: 4.0.0 License: MIT Private: false Description: Strip leading whitespace from each line in a string Repository: undefined Author: Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) License Copyright: MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: indent-string Version: 5.0.0 License: MIT Private: false Description: Indent each line in a string Repository: undefined Author: Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) License Copyright: MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: redent Version: 4.0.0 License: MIT Private: false Description: Strip redundant indentation and indent the string Repository: undefined Author: Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) License Copyright: MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: hard-rejection Version: 2.1.0 License: MIT Private: false Description: Make unhandled promise rejections fail hard right away instead of the default silent fail Repository: undefined Author: Sindre Sorhus sindresorhus@gmail.com (sindresorhus.com) License Copyright: MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: semver Version: 7.5.4 License: ISC Private: false Description: The semantic version parser used by npm. Repository: https://github.com/npm/node-semver.git Author: GitHub Inc. License Copyright: The ISC License Copyright (c) Isaac Z. Schlueter and Contributors Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies. THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE. Name: spdx-license-ids Version: 3.0.13 License: CC0-1.0 Private: false Description: A list of SPDX license identifiers Repository: undefined Author: Shinnosuke Watanabe (https://github.com/shinnn) Name: spdx-exceptions Version: 2.3.0 License: CC-BY-3.0 Private: false Description: list of SPDX standard license exceptions Repository: undefined Author: The Linux Foundation Contributors: Kyle E. Mitchell kyle@kemitchell.com (https://kemitchell.com/) Name: spdx-expression-parse Version: 3.0.1 License: MIT Private: false Description: parse SPDX license expressions Repository: undefined Author: Kyle E. Mitchell kyle@kemitchell.com (https://kemitchell.com) License Copyright: The MIT License Copyright (c) 2015 Kyle E. Mitchell & other authors listed in AUTHORS Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: spdx-correct Version: 3.2.0 License: Apache-2.0 Private: false Description: correct invalid SPDX expressions Repository: undefined License Copyright: Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright [yyyy] [name of copyright owner] Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. Name: validate-npm-package-license Version: 3.0.4 License: Apache-2.0 Private: false Description: Give me a string and I'll tell you if it's a valid npm package license string Repository: undefined Author: Kyle E. Mitchell kyle@kemitchell.com (https://kemitchell.com) Contributors: Mark Stacey markjstacey@gmail.com License Copyright: Apache License Version 2.0, January 2004 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION Definitions. \"License\" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document. \"Licensor\" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License. \"Legal Entity\" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, \"control\" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity. \"You\" (or \"Your\") shall mean an individual or Legal Entity exercising permissions granted by this License. \"Source\" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files. \"Object\" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types. \"Work\" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below). \"Derivative Works\" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof. \"Contribution\" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, \"submitted\" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as \"Not a Contribution.\" \"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions: (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and (b) You must cause any modified files to carry prominent notices stating that You changed the files; and (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and (d) If the Work includes a \"NOTICE\" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License. You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS APPENDIX: How to apply the Apache License to your work. To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets \"[]\" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same \"printed page\" as the copyright notice for easier identification within third-party archives. Copyright [yyyy] [name of copyright owner] Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. Name: lru-cache Version: 7.18.3 License: ISC Private: false Description: A cache object that deletes the least-recently-used items. Repository: undefined Author: Isaac Z. Schlueter i@izs.me License Copyright: The ISC License Copyright (c) 2010-2023 Isaac Z. Schlueter and Contributors Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies. THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE. Name: hosted-git-info Version: 6.1.1 License: ISC Private: false Description: Provides metadata and conversions from repository urls for GitHub, Bitbucket and GitLab Repository: https://github.com/npm/hosted-git-info.git Homepage: https://github.com/npm/hosted-git-info Author: GitHub Inc. License Copyright: Copyright (c) 2015, Rebecca Turner Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies. THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE. Name: function-bind Version: 1.1.1 License: MIT Private: false Description: Implementation of Function.prototype.bind Repository: undefined Homepage: https://github.com/Raynos/function-bind Author: Raynos raynos2@gmail.com Contributors: Raynos Jordan Harband (https://github.com/ljharb) License Copyright: Copyright (c) 2013 Raynos. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: has Version: 1.0.3 License: MIT Private: false Description: Object.prototype.hasOwnProperty.call shortcut Repository: git://github.com/tarruda/has.git Homepage: https://github.com/tarruda/has Author: Thiago de Arruda tpadilha84@gmail.com Contributors: Jordan Harband ljharb@gmail.com (http://ljharb.codes) License Copyright: Copyright (c) 2013 Thiago de Arruda Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: is-core-module Version: 2.13.0 License: MIT Private: false Description: Is this specifier a node.js core module? Repository: git+https://github.com/inspect-js/is-core-module.git Homepage: https://github.com/inspect-js/is-core-module Author: Jordan Harband ljharb@gmail.com License Copyright: The MIT License (MIT) Copyright (c) 2014 Dave Justice Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: normalize-package-data Version: 5.0.0 License: BSD-2-Clause Private: false Description: Normalizes data that can be found in package.json files. Repository: https://github.com/npm/normalize-package-data.git Author: GitHub Inc. License Copyright: This package contains code originally written by Isaac Z. Schlueter. Used with permission. Copyright (c) Meryn Stol (\"Author\") All rights reserved. The BSD License Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. Name: locate-path Version: 7.2.0 License: MIT Private: false Description: Get the first path that exists on disk of multiple paths Repository: undefined Author: Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) License Copyright: MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: find-up Version: 6.3.0 License: MIT Private: false Description: Find a file or directory by walking up parent directories Repository: undefined Author: Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) License Copyright: MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: is-arrayish Version: 0.2.1 License: MIT Private: false Description: Determines if an object can be used as an array Repository: https://github.com/qix-/node-is-arrayish.git Author: Qix (http://github.com/qix-) License Copyright: The MIT License (MIT) Copyright (c) 2015 JD Ballard Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: error-ex Version: 1.3.2 License: MIT Private: false Description: Easy error subclassing and stack customization Repository: undefined License Copyright: The MIT License (MIT) Copyright (c) 2015 JD Ballard Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: json-parse-even-better-errors Version: 3.0.0 License: MIT Private: false Description: JSON.parse with context information on error Repository: https://github.com/npm/json-parse-even-better-errors.git Author: GitHub Inc. License Copyright: Copyright 2017 Kat Marchán Copyright npm, Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. This library is a fork of 'better-json-errors' by Kat Marchán, extended and distributed under the terms of the MIT license above. Name: @babel/code-frame Version: 7.22.10 License: MIT Private: false Description: Generate errors that contain a code frame that point to source locations. Repository: https://github.com/babel/babel.git Homepage: https://babel.dev/docs/en/next/babel-code-frame Author: The Babel Team (https://babel.dev/team) License Copyright: MIT License Copyright (c) 2014-present Sebastian McKenzie and other contributors Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: @babel/highlight Version: 7.22.10 License: MIT Private: false Description: Syntax highlight JavaScript strings for output in terminals. Repository: https://github.com/babel/babel.git Homepage: https://babel.dev/docs/en/next/babel-highlight Author: The Babel Team (https://babel.dev/team) License Copyright: MIT License Copyright (c) 2014-present Sebastian McKenzie and other contributors Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: js-tokens Version: 4.0.0 License: MIT Private: false Description: A regex that tokenizes JavaScript. Repository: undefined Author: Simon Lydell License Copyright: The MIT License (MIT) Copyright (c) 2014, 2015, 2016, 2017, 2018 Simon Lydell Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: @babel/helper-validator-identifier Version: 7.22.5 License: MIT Private: false Description: Validate identifier/keywords name Repository: https://github.com/babel/babel.git Author: The Babel Team (https://babel.dev/team) License Copyright: MIT License Copyright (c) 2014-present Sebastian McKenzie and other contributors Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: chalk Version: 2.4.2 License: MIT Private: false Description: Terminal string styling done right Repository: undefined License Copyright: MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: escape-string-regexp Version: 1.0.5 License: MIT Private: false Description: Escape RegExp special characters Repository: undefined Author: Sindre Sorhus sindresorhus@gmail.com (sindresorhus.com) License Copyright: The MIT License (MIT) Copyright (c) Sindre Sorhus sindresorhus@gmail.com (sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: ansi-styles Version: 3.2.1 License: MIT Private: false Description: ANSI escape codes for styling strings in the terminal Repository: undefined Author: Sindre Sorhus sindresorhus@gmail.com (sindresorhus.com) License Copyright: MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: color-convert Version: 1.9.3 License: MIT Private: false Description: Plain color conversion functions Repository: undefined Author: Heather Arthur fayearthur@gmail.com License Copyright: Copyright (c) 2011-2016 Heather Arthur fayearthur@gmail.com Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: color-name Version: 1.1.3 License: MIT Private: false Description: A list of color names and its values Repository: git@github.com:dfcreative/color-name.git Homepage: https://github.com/dfcreative/color-name Author: DY dfcreative@gmail.com License Copyright: The MIT License (MIT) Copyright (c) 2015 Dmitry Ivanov Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: has-flag Version: 3.0.0 License: MIT Private: false Description: Check if argv has a specific flag Repository: undefined Author: Sindre Sorhus sindresorhus@gmail.com (sindresorhus.com) License Copyright: MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: supports-color Version: 5.5.0 License: MIT Private: false Description: Detect whether a terminal supports color Repository: undefined Author: Sindre Sorhus sindresorhus@gmail.com (sindresorhus.com) License Copyright: MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: lines-and-columns Version: 2.0.3 License: MIT Private: false Description: Maps lines and columns to character offsets and back. Repository: https://github.com/eventualbuddha/lines-and-columns.git Homepage: https://github.com/eventualbuddha/lines-and-columns#readme Author: Brian Donovan brian@donovans.cc License Copyright: The MIT License (MIT) Copyright (c) 2015 Brian Donovan Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: parse-json Version: 7.0.0 License: MIT Private: false Description: Parse JSON with more helpful errors Repository: undefined Author: Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) License Copyright: MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: read-pkg Version: 8.1.0 License: MIT Private: false Description: Read a package.json file Repository: undefined Author: Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) License Copyright: MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: read-pkg-up Version: 10.1.0 License: MIT Private: false Description: Read the closest package.json file Repository: undefined Author: Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) License Copyright: MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: decamelize Version: 6.0.0 License: MIT Private: false Description: Convert a camelized string into a lowercased one with a custom separator: unicornRainbow → unicorn_rainbow Repository: undefined Author: Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) License Copyright: MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: minimist-options Version: 4.1.0 License: MIT Private: false Description: Pretty options for minimist Repository: undefined Author: Vadim Demedes vdemedes@gmail.com License Copyright: The MIT License (MIT) Copyright (c) Vadim Demedes vdemedes@gmail.com (vadimdemedes.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: is-plain-obj Version: 1.1.0 License: MIT Private: false Description: Check if a value is a plain object Repository: undefined Author: Sindre Sorhus sindresorhus@gmail.com (sindresorhus.com) License Copyright: The MIT License (MIT) Copyright (c) Sindre Sorhus sindresorhus@gmail.com (sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: arrify Version: 1.0.1 License: MIT Private: false Description: Convert a value to an array Repository: undefined Author: Sindre Sorhus sindresorhus@gmail.com (sindresorhus.com) License Copyright: The MIT License (MIT) Copyright (c) Sindre Sorhus sindresorhus@gmail.com (sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: kind-of Version: 6.0.3 License: MIT Private: false Description: Get the native type of a value. Repository: undefined Homepage: https://github.com/jonschlinkert/kind-of Author: Jon Schlinkert (https://github.com/jonschlinkert) Contributors: David Fox-Powell (https://dtothefp.github.io/me) James (https://twitter.com/aretecode) Jon Schlinkert (http://twitter.com/jonschlinkert) Ken Sheedlo (kensheedlo.com) laggingreflex (https://github.com/laggingreflex) Miguel Mota (https://miguelmota.com) Peter deHaan (http://about.me/peterdehaan) tunnckoCore (https://i.am.charlike.online) License Copyright: The MIT License (MIT) Copyright (c) 2014-2017, Jon Schlinkert. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. Name: decamelize-keys Version: 2.0.1 License: MIT Private: false Description: Convert object keys from camel case Repository: undefined Author: Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) License Copyright: MIT License Copyright (c) Sindre Sorhus sindresorhus@gmail.com (https://sindresorhus.com) Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/meow/readme.html": {
    "href": "node_modules/meow/readme.html",
    "title": "meow | accouter",
    "keywords": "meow CLI app helper I would recommend reading this guide on how to make user-friendly command-line tools. Features Parses arguments Converts flags to camelCase Negates flags when using the --no- prefix Outputs version when --version Outputs description and supplied help text when --help Makes unhandled rejected promises fail hard instead of the default silent fail Sets the process title to the binary name defined in package.json No dependencies! Install npm install meow Usage ./foo-app.js unicorns --rainbow #!/usr/bin/env node import meow from 'meow'; import foo from './lib/index.js'; const cli = meow(` Usage $ foo <input> Options --rainbow, -r Include a rainbow Examples $ foo unicorns --rainbow 🌈 unicorns 🌈 `, { importMeta: import.meta, flags: { rainbow: { type: 'boolean', shortFlag: 'r' } } }); /* { input: ['unicorns'], flags: {rainbow: true}, ... } */ foo(cli.input.at(0), cli.flags); API meow(helpText, options?) meow(options) Returns an object with: input (Array) - Non-flag arguments flags (Object) - Flags converted to camelCase excluding aliases unnormalizedFlags (Object) - Flags converted to camelCase including aliases pkg (Object) - The package.json object help (string) - The help text used with --help showHelp([exitCode=2]) (Function) - Show the help text and exit with exitCode showVersion() (Function) - Show the version text and exit helpText Type: string Shortcut for the help option. options Type: object importMeta Type: object Pass in import.meta. This is used to find the correct package.json file. flags Type: object Define argument flags. The key is the flag name in camel-case and the value is an object with any of: type: Type of value. (Possible values: string boolean number) choices: Limit valid values to a predefined set of choices. default: Default value when the flag is not specified. shortFlag: A short flag alias. aliases: Other names for the flag. isMultiple: Indicates a flag can be set multiple times. Values are turned into an array. (Default: false) Multiple values are provided by specifying the flag multiple times, for example, $ foo -u rainbow -u cat. Space- or comma-separated values are currently not supported. isRequired: Determine if the flag is required. (Default: false) If it's only known at runtime whether the flag is required or not, you can pass a Function instead of a boolean, which based on the given flags and other non-flag arguments, should decide if the flag is required. Two arguments are passed to the function: The first argument is the flags object, which contains the flags converted to camel-case excluding aliases. The second argument is the input string array, which contains the non-flag arguments. The function should return a boolean, true if the flag is required, otherwise false. Note that flags are always defined using a camel-case key (myKey), but will match arguments in kebab-case (--my-key). Example: flags: { unicorn: { type: 'string', choices: ['rainbow', 'cat', 'unicorn'], default: ['rainbow', 'cat'], shortFlag: 'u', aliases: ['unicorns'], isMultiple: true, isRequired: (flags, input) => { if (flags.otherFlag) { return true; } return false; } } } description Type: string | boolean Default: The package.json \"description\" property Description to show above the help text. Set it to false to disable it altogether. help Type: string | boolean The help text you want shown. The input is reindented and starting/ending newlines are trimmed which means you can use a template literal without having to care about using the correct amount of indent. The description will be shown above your help text automatically. version Type: string | boolean Default: The package.json \"version\" property Set a custom version output. autoHelp Type: boolean Default: true Automatically show the help text when the --help flag is present. Useful to set this value to false when a CLI manages child CLIs with their own help text. This option is only considered when there is only one argument in process.argv. autoVersion Type: boolean Default: true Automatically show the version text when the --version flag is present. Useful to set this value to false when a CLI manages child CLIs with their own version text. This option is only considered when there is only one argument in process.argv. pkg Type: object Default: Closest package.json upwards package.json as an object. Note: Setting this stops meow from finding a package.json. You most likely don't need this option. argv Type: string[] Default: process.argv.slice(2) Custom arguments object. inferType Type: boolean Default: false Infer the argument type. By default, the argument 5 in $ foo 5 becomes a string. Enabling this would infer it as a number. booleanDefault Type: boolean | null | undefined Default: false Value of boolean flags not defined in argv. If set to undefined, the flags not defined in argv will be excluded from the result. The default value set in boolean flags take precedence over booleanDefault. Note: If used in conjunction with isMultiple, the default flag value is set to []. Caution: Explicitly specifying undefined for booleanDefault has different meaning from omitting key itself. Example: import meow from 'meow'; const cli = meow(` Usage $ foo Options --rainbow, -r Include a rainbow --unicorn, -u Include a unicorn --no-sparkles Exclude sparkles Examples $ foo 🌈 unicorns✨🌈 `, { importMeta: import.meta, booleanDefault: undefined, flags: { rainbow: { type: 'boolean', default: true, shortFlag: 'r' }, unicorn: { type: 'boolean', default: false, shortFlag: 'u' }, cake: { type: 'boolean', shortFlag: 'c' }, sparkles: { type: 'boolean', default: true } } }); /* { flags: { rainbow: true, unicorn: false, sparkles: true }, unnormalizedFlags: { rainbow: true, r: true, unicorn: false, u: false, sparkles: true }, … } */ hardRejection Type: boolean Default: true Whether to use hard-rejection or not. Disabling this can be useful if you need to handle process.on('unhandledRejection') yourself. allowUnknownFlags Type boolean Default: true Whether to allow unknown flags or not. Promises Meow will make unhandled rejected promises fail hard instead of the default silent fail. Meaning you don't have to manually .catch() promises used in your CLI. Tips See chalk if you want to colorize the terminal output. See get-stdin if you want to accept input from stdin. See conf if you need to persist some data. More useful CLI utilities…"
  },
  "node_modules/merge2/README.html": {
    "href": "node_modules/merge2/README.html",
    "title": "merge2 | accouter",
    "keywords": "merge2 Merge multiple streams into one stream in sequence or parallel. Install Install with npm npm install merge2 Usage const gulp = require('gulp') const merge2 = require('merge2') const concat = require('gulp-concat') const minifyHtml = require('gulp-minify-html') const ngtemplate = require('gulp-ngtemplate') gulp.task('app-js', function () { return merge2( gulp.src('static/src/tpl/*.html') .pipe(minifyHtml({empty: true})) .pipe(ngtemplate({ module: 'genTemplates', standalone: true }) ), gulp.src([ 'static/src/js/app.js', 'static/src/js/locale_zh-cn.js', 'static/src/js/router.js', 'static/src/js/tools.js', 'static/src/js/services.js', 'static/src/js/filters.js', 'static/src/js/directives.js', 'static/src/js/controllers.js' ]) ) .pipe(concat('app.js')) .pipe(gulp.dest('static/dist/js/')) }) const stream = merge2([stream1, stream2], stream3, {end: false}) //... stream.add(stream4, stream5) //.. stream.end() // equal to merge2([stream1, stream2], stream3) const stream = merge2() stream.add([stream1, stream2]) stream.add(stream3) // merge order: // 1. merge `stream1`; // 2. merge `stream2` and `stream3` in parallel after `stream1` merged; // 3. merge 'stream4' after `stream2` and `stream3` merged; const stream = merge2(stream1, [stream2, stream3], stream4) // merge order: // 1. merge `stream5` and `stream6` in parallel after `stream4` merged; // 2. merge 'stream7' after `stream5` and `stream6` merged; stream.add([stream5, stream6], stream7) // nest merge // equal to merge2(stream1, stream2, stream6, stream3, [stream4, stream5]); const streamA = merge2(stream1, stream2) const streamB = merge2(stream3, [stream4, stream5]) const stream = merge2(streamA, streamB) streamA.add(stream6) API const merge2 = require('merge2') merge2() merge2(options) merge2(stream1, stream2, ..., streamN) merge2(stream1, stream2, ..., streamN, options) merge2(stream1, [stream2, stream3, ...], streamN, options) return a duplex stream (mergedStream). streams in array will be merged in parallel. mergedStream.add(stream) mergedStream.add(stream1, [stream2, stream3, ...], ...) return the mergedStream. mergedStream.on('queueDrain', function() {}) It will emit 'queueDrain' when all streams merged. If you set end === false in options, this event give you a notice that should add more streams to merge or end the mergedStream. stream option Type: Readable or Duplex or Transform stream. options option Type: Object. end - Boolean - if end === false then mergedStream will not be auto ended, you should end by yourself. Default: undefined pipeError - Boolean - if pipeError === true then mergedStream will emit error event from source streams. Default: undefined objectMode - Boolean . Default: true objectMode and other options(highWaterMark, defaultEncoding ...) is same as Node.js Stream. License MIT © Teambition"
  },
  "node_modules/micromatch/README.html": {
    "href": "node_modules/micromatch/README.html",
    "title": "micromatch | accouter",
    "keywords": "micromatch Glob matching for javascript/node.js. A replacement and faster alternative to minimatch and multimatch. Please consider following this project's author, Jon Schlinkert, and consider starring the project to show your ❤️ and support. Table of Contents Details Install Sponsors Gold Sponsors Quickstart Why use micromatch? Matching features Switching to micromatch From minimatch From multimatch API Options Options Examples options.basename options.bash options.expandRange options.format options.ignore options.matchBase options.noextglob options.nonegate options.noglobstar options.nonull options.nullglob options.onIgnore options.onMatch options.onResult options.posixSlashes options.unescape Extended globbing Extglobs Braces Regex character classes Regex groups POSIX bracket expressions Notes Bash 4.3 parity Backslashes Benchmarks Running benchmarks Latest results Contributing About Install Install with npm (requires Node.js >=8.6): $ npm install --save micromatch Sponsors Become a Sponsor to add your logo to this README, or any of my other projects Quickstart const micromatch = require('micromatch'); // micromatch(list, patterns[, options]); The main export takes a list of strings and one or more glob patterns: console.log(micromatch(['foo', 'bar', 'baz', 'qux'], ['f*', 'b*'])) //=> ['foo', 'bar', 'baz'] console.log(micromatch(['foo', 'bar', 'baz', 'qux'], ['*', '!b*'])) //=> ['foo', 'qux'] Use .isMatch() to for boolean matching: console.log(micromatch.isMatch('foo', 'f*')) //=> true console.log(micromatch.isMatch('foo', ['b*', 'f*'])) //=> true Switching from minimatch and multimatch is easy! Why use micromatch? micromatch is a replacement for minimatch and multimatch Supports all of the same matching features as minimatch and multimatch More complete support for the Bash 4.3 specification than minimatch and multimatch. Micromatch passes all of the spec tests from bash, including some that bash still fails. Fast & Performant - Loads in about 5ms and performs fast matches. Glob matching - Using wildcards (* and ?), globstars (**) for nested directories Advanced globbing - Supports extglobs, braces, and POSIX brackets, and support for escaping special characters with \\ or quotes. Accurate - Covers more scenarios than minimatch Well tested - More than 5,000 test assertions Windows support - More reliable windows support than minimatch and multimatch. Safe{#braces-is-safe} - Micromatch is not subject to DoS with brace patterns like minimatch and multimatch. Matching features Support for multiple glob patterns (no need for wrappers like multimatch) Wildcards (**, *.js) Negation ('!a/*.js', '*!(b).js') extglobs (+(x|y), !(a|b)) POSIX character classes ([[:alpha:][:digit:]]) brace expansion (foo/{1..5}.md, bar/{a,b,c}.js) regex character classes (foo-[1-5].js) regex logical \"or\" (foo/(abc|xyz).js) You can mix and match these features to create whatever patterns you need! Switching to micromatch (There is one notable difference between micromatch and minimatch in regards to how backslashes are handled. See the notes about backslashes for more information.) From minimatch Use micromatch.isMatch() instead of minimatch(): console.log(micromatch.isMatch('foo', 'b*')); //=> false Use micromatch.match() instead of minimatch.match(): console.log(micromatch.match(['foo', 'bar'], 'b*')); //=> 'bar' From multimatch Same signature: console.log(micromatch(['foo', 'bar', 'baz'], ['f*', '*z'])); //=> ['foo', 'baz'] API Params list {String|Array } : List of strings to match. patterns {String|Array } : One or more glob patterns to use for matching. options {Object}: See available options returns {Array}: Returns an array of matches Example const mm = require('micromatch'); // mm(list, patterns[, options]); console.log(mm(['a.js', 'a.txt'], ['*.js'])); //=> [ 'a.js' ] .matcher Returns a matcher function from the given glob pattern and options. The returned function takes a string to match as its only argument and returns true if the string is a match. Params pattern {String}: Glob pattern options {Object} returns {Function}: Returns a matcher function. Example const mm = require('micromatch'); // mm.matcher(pattern[, options]); const isMatch = mm.matcher('*.!(*a)'); console.log(isMatch('a.a')); //=> false console.log(isMatch('a.b')); //=> true .isMatch Returns true if any of the given glob patterns match the specified string. Params str {String}: The string to test. patterns {String|Array}: One or more glob patterns to use for matching. [options] {Object}: See available options. returns {Boolean}: Returns true if any patterns match str Example const mm = require('micromatch'); // mm.isMatch(string, patterns[, options]); console.log(mm.isMatch('a.a', ['b.*', '*.a'])); //=> true console.log(mm.isMatch('a.a', 'b.*')); //=> false .not Returns a list of strings that do not match any of the given patterns. Params list {Array}: Array of strings to match. patterns {String|Array}: One or more glob pattern to use for matching. options {Object}: See available options for changing how matches are performed returns {Array}: Returns an array of strings that do not match the given patterns. Example const mm = require('micromatch'); // mm.not(list, patterns[, options]); console.log(mm.not(['a.a', 'b.b', 'c.c'], '*.a')); //=> ['b.b', 'c.c'] .contains Returns true if the given string contains the given pattern. Similar to .isMatch but the pattern can match any part of the string. Params str {String}: The string to match. patterns {String|Array}: Glob pattern to use for matching. options {Object}: See available options for changing how matches are performed returns {Boolean}: Returns true if any of the patterns matches any part of str. Example var mm = require('micromatch'); // mm.contains(string, pattern[, options]); console.log(mm.contains('aa/bb/cc', '*b')); //=> true console.log(mm.contains('aa/bb/cc', '*d')); //=> false .matchKeys Filter the keys of the given object with the given glob pattern and options. Does not attempt to match nested keys. If you need this feature, use glob-object instead. Params object {Object}: The object with keys to filter. patterns {String|Array}: One or more glob patterns to use for matching. options {Object}: See available options for changing how matches are performed returns {Object}: Returns an object with only keys that match the given patterns. Example const mm = require('micromatch'); // mm.matchKeys(object, patterns[, options]); const obj = { aa: 'a', ab: 'b', ac: 'c' }; console.log(mm.matchKeys(obj, '*b')); //=> { ab: 'b' } .some Returns true if some of the strings in the given list match any of the given glob patterns. Params list {String|Array}: The string or array of strings to test. Returns as soon as the first match is found. patterns {String|Array}: One or more glob patterns to use for matching. options {Object}: See available options for changing how matches are performed returns {Boolean}: Returns true if any patterns matches any of the strings in list Example const mm = require('micromatch'); // mm.some(list, patterns[, options]); console.log(mm.some(['foo.js', 'bar.js'], ['*.js', '!foo.js'])); // true console.log(mm.some(['foo.js'], ['*.js', '!foo.js'])); // false .every Returns true if every string in the given list matches any of the given glob patterns. Params list {String|Array}: The string or array of strings to test. patterns {String|Array}: One or more glob patterns to use for matching. options {Object}: See available options for changing how matches are performed returns {Boolean}: Returns true if all patterns matches all of the strings in list Example const mm = require('micromatch'); // mm.every(list, patterns[, options]); console.log(mm.every('foo.js', ['foo.js'])); // true console.log(mm.every(['foo.js', 'bar.js'], ['*.js'])); // true console.log(mm.every(['foo.js', 'bar.js'], ['*.js', '!foo.js'])); // false console.log(mm.every(['foo.js'], ['*.js', '!foo.js'])); // false .all Returns true if all of the given patterns match the specified string. Params str {String|Array}: The string to test. patterns {String|Array}: One or more glob patterns to use for matching. options {Object}: See available options for changing how matches are performed returns {Boolean}: Returns true if any patterns match str Example const mm = require('micromatch'); // mm.all(string, patterns[, options]); console.log(mm.all('foo.js', ['foo.js'])); // true console.log(mm.all('foo.js', ['*.js', '!foo.js'])); // false console.log(mm.all('foo.js', ['*.js', 'foo.js'])); // true console.log(mm.all('foo.js', ['*.js', 'f*', '*o*', '*o.js'])); // true .capture Returns an array of matches captured by pattern in string, or null` if the pattern did not match. Params glob {String}: Glob pattern to use for matching. input {String}: String to match options {Object}: See available options for changing how matches are performed returns {Array|null}: Returns an array of captures if the input matches the glob pattern, otherwise null. Example const mm = require('micromatch'); // mm.capture(pattern, string[, options]); console.log(mm.capture('test/*.js', 'test/foo.js')); //=> ['foo'] console.log(mm.capture('test/*.js', 'foo/bar.css')); //=> null .makeRe Create a regular expression from the given glob pattern. Params pattern {String}: A glob pattern to convert to regex. options {Object} returns {RegExp}: Returns a regex created from the given pattern. Example const mm = require('micromatch'); // mm.makeRe(pattern[, options]); console.log(mm.makeRe('*.js')); //=> /^(?:(\\.[\\\\\\/])?(?!\\.)(?=.)[^\\/]*?\\.js)$/ .scan Scan a glob pattern to separate the pattern into segments. Used by the split method. Params pattern {String} options {Object} returns {Object}: Returns an object with Example const mm = require('micromatch'); const state = mm.scan(pattern[, options]); .parse Parse a glob pattern to create the source string for a regular expression. Params glob {String} options {Object} returns {Object}: Returns an object with useful properties and output to be used as regex source string. Example const mm = require('micromatch'); const state = mm.parse(pattern[, options]); .braces Process the given brace pattern. Params pattern {String}: String with brace pattern to process. options {Object}: Any options to change how expansion is performed. See the braces library for all available options. returns {Array} Example const { braces } = require('micromatch'); console.log(braces('foo/{a,b,c}/bar')); //=> [ 'foo/(a|b|c)/bar' ] console.log(braces('foo/{a,b,c}/bar', { expand: true })); //=> [ 'foo/a/bar', 'foo/b/bar', 'foo/c/bar' ] Options Option Type Default value Description basename boolean false If set, then patterns without slashes will be matched against the basename of the path if it contains slashes. For example, a?b would match the path /xyz/123/acb, but not /xyz/acb/123. bash boolean false Follow bash matching rules more strictly - disallows backslashes as escape characters, and treats single stars as globstars (**). capture boolean undefined Return regex matches in supporting methods. contains boolean undefined Allows glob to match any part of the given string(s). cwd string process.cwd() Current working directory. Used by picomatch.split() debug boolean undefined Debug regular expressions when an error is thrown. dot boolean false Match dotfiles. Otherwise dotfiles are ignored unless a . is explicitly defined in the pattern. expandRange function undefined Custom function for expanding ranges in brace patterns, such as {a..z}. The function receives the range values as two arguments, and it must return a string to be used in the generated regex. It's recommended that returned strings be wrapped in parentheses. This option is overridden by the expandBrace option. failglob boolean false Similar to the failglob behavior in Bash, throws an error when no matches are found. Based on the bash option of the same name. fastpaths boolean true To speed up processing, full parsing is skipped for a handful common glob patterns. Disable this behavior by setting this option to false. flags boolean undefined Regex flags to use in the generated regex. If defined, the nocase option will be overridden. format function undefined Custom function for formatting the returned string. This is useful for removing leading slashes, converting Windows paths to Posix paths, etc. ignore array\\|string undefined One or more glob patterns for excluding strings that should not be matched from the result. keepQuotes boolean false Retain quotes in the generated regex, since quotes may also be used as an alternative to backslashes. literalBrackets boolean undefined When true, brackets in the glob pattern will be escaped so that only literal brackets will be matched. lookbehinds boolean true Support regex positive and negative lookbehinds. Note that you must be using Node 8.1.10 or higher to enable regex lookbehinds. matchBase boolean false Alias for basename maxLength boolean 65536 Limit the max length of the input string. An error is thrown if the input string is longer than this value. nobrace boolean false Disable brace matching, so that {a,b} and {1..3} would be treated as literal characters. nobracket boolean undefined Disable matching with regex brackets. nocase boolean false Perform case-insensitive matching. Equivalent to the regex i flag. Note that this option is ignored when the flags option is defined. nodupes boolean true Deprecated, use nounique instead. This option will be removed in a future major release. By default duplicates are removed. Disable uniquification by setting this option to false. noext boolean false Alias for noextglob noextglob boolean false Disable support for matching with extglobs (like +(a\\|b)) noglobstar boolean false Disable support for matching nested directories with globstars (**) nonegate boolean false Disable support for negating with leading ! noquantifiers boolean false Disable support for regex quantifiers (like a{1,2}) and treat them as brace patterns to be expanded. onIgnore function undefined Function to be called on ignored items. onMatch function undefined Function to be called on matched items. onResult function undefined Function to be called on all items, regardless of whether or not they are matched or ignored. posix boolean false Support POSIX character classes (\"posix brackets\"). posixSlashes boolean undefined Convert all slashes in file paths to forward slashes. This does not convert slashes in the glob pattern itself prepend string undefined String to prepend to the generated regex used for matching. regex boolean false Use regular expression rules for + (instead of matching literal +), and for stars that follow closing parentheses or brackets (as in )* and ]*). strictBrackets boolean undefined Throw an error if brackets, braces, or parens are imbalanced. strictSlashes boolean undefined When true, picomatch won't match trailing slashes with single stars. unescape boolean undefined Remove preceding backslashes from escaped glob characters before creating the regular expression to perform matches. unixify boolean undefined Alias for posixSlashes, for backwards compatitibility. Options Examples options.basename Allow glob patterns without slashes to match a file path based on its basename. Same behavior as minimatch option matchBase. Type: Boolean Default: false Example micromatch(['a/b.js', 'a/c.md'], '*.js'); //=> [] micromatch(['a/b.js', 'a/c.md'], '*.js', { basename: true }); //=> ['a/b.js'] options.bash Enabled by default, this option enforces bash-like behavior with stars immediately following a bracket expression. Bash bracket expressions are similar to regex character classes, but unlike regex, a star following a bracket expression does not repeat the bracketed characters. Instead, the star is treated the same as any other star. Type: Boolean Default: true Example const files = ['abc', 'ajz']; console.log(micromatch(files, '[a-c]*')); //=> ['abc', 'ajz'] console.log(micromatch(files, '[a-c]*', { bash: false })); options.expandRange Type: function Default: undefined Custom function for expanding ranges in brace patterns. The fill-range library is ideal for this purpose, or you can use custom code to do whatever you need. Example The following example shows how to create a glob that matches a numeric folder name between 01 and 25, with leading zeros. const fill = require('fill-range'); const regex = micromatch.makeRe('foo/{01..25}/bar', { expandRange(a, b) { return `(${fill(a, b, { toRegex: true })})`; } }); console.log(regex) //=> /^(?:foo\\/((?:0[1-9]|1[0-9]|2[0-5]))\\/bar)$/ console.log(regex.test('foo/00/bar')) // false console.log(regex.test('foo/01/bar')) // true console.log(regex.test('foo/10/bar')) // true console.log(regex.test('foo/22/bar')) // true console.log(regex.test('foo/25/bar')) // true console.log(regex.test('foo/26/bar')) // false options.format Type: function Default: undefined Custom function for formatting strings before they're matched. Example // strip leading './' from strings const format = str => str.replace(/^\\.\\//, ''); const isMatch = picomatch('foo/*.js', { format }); console.log(isMatch('./foo/bar.js')) //=> true options.ignore String or array of glob patterns to match files to ignore. Type: String|Array Default: undefined const isMatch = micromatch.matcher('*', { ignore: 'f*' }); console.log(isMatch('foo')) //=> false console.log(isMatch('bar')) //=> true console.log(isMatch('baz')) //=> true options.matchBase Alias for options.basename. options.noextglob Disable extglob support, so that extglobs are regarded as literal characters. Type: Boolean Default: undefined Examples console.log(micromatch(['a/z', 'a/b', 'a/!(z)'], 'a/!(z)')); //=> ['a/b', 'a/!(z)'] console.log(micromatch(['a/z', 'a/b', 'a/!(z)'], 'a/!(z)', { noextglob: true })); //=> ['a/!(z)'] (matches only as literal characters) options.nonegate Disallow negation (!) patterns, and treat leading ! as a literal character to match. Type: Boolean Default: undefined options.noglobstar Disable matching with globstars (**). Type: Boolean Default: undefined micromatch(['a/b', 'a/b/c', 'a/b/c/d'], 'a/**'); //=> ['a/b', 'a/b/c', 'a/b/c/d'] micromatch(['a/b', 'a/b/c', 'a/b/c/d'], 'a/**', {noglobstar: true}); //=> ['a/b'] options.nonull Alias for options.nullglob. options.nullglob If true, when no matches are found the actual (arrayified) glob pattern is returned instead of an empty array. Same behavior as minimatch option nonull. Type: Boolean Default: undefined options.onIgnore const onIgnore = ({ glob, regex, input, output }) => { console.log({ glob, regex, input, output }); // { glob: '*', regex: /^(?:(?!\\.)(?=.)[^\\/]*?\\/?)$/, input: 'foo', output: 'foo' } }; const isMatch = micromatch.matcher('*', { onIgnore, ignore: 'f*' }); isMatch('foo'); isMatch('bar'); isMatch('baz'); options.onMatch const onMatch = ({ glob, regex, input, output }) => { console.log({ input, output }); // { input: 'some\\\\path', output: 'some/path' } // { input: 'some\\\\path', output: 'some/path' } // { input: 'some\\\\path', output: 'some/path' } }; const isMatch = micromatch.matcher('**', { onMatch, posixSlashes: true }); isMatch('some\\\\path'); isMatch('some\\\\path'); isMatch('some\\\\path'); options.onResult const onResult = ({ glob, regex, input, output }) => { console.log({ glob, regex, input, output }); }; const isMatch = micromatch('*', { onResult, ignore: 'f*' }); isMatch('foo'); isMatch('bar'); isMatch('baz'); options.posixSlashes Convert path separators on returned files to posix/unix-style forward slashes. Aliased as unixify for backwards compatibility. Type: Boolean Default: true on windows, false everywhere else. Example console.log(micromatch.match(['a\\\\b\\\\c'], 'a/**')); //=> ['a/b/c'] console.log(micromatch.match(['a\\\\b\\\\c'], { posixSlashes: false })); //=> ['a\\\\b\\\\c'] options.unescape Remove backslashes from escaped glob characters before creating the regular expression to perform matches. Type: Boolean Default: undefined Example In this example we want to match a literal *: console.log(micromatch.match(['abc', 'a\\\\*c'], 'a\\\\*c')); //=> ['a\\\\*c'] console.log(micromatch.match(['abc', 'a\\\\*c'], 'a\\\\*c', { unescape: true })); //=> ['a*c'] Extended globbing Micromatch supports the following extended globbing features. Extglobs Extended globbing, as described by the bash man page: pattern regex equivalent description ?(pattern) (pattern)? Matches zero or one occurrence of the given patterns *(pattern) (pattern)* Matches zero or more occurrences of the given patterns +(pattern) (pattern)+ Matches one or more occurrences of the given patterns @(pattern) (pattern) * Matches one of the given patterns !(pattern) N/A (equivalent regex is much more complicated) Matches anything except one of the given patterns * Note that @ isn't a regex character. Braces Brace patterns can be used to match specific ranges or sets of characters. Example The pattern {f,b}*/{1..3}/{b,q}* would match any of following strings: foo/1/bar foo/2/bar foo/3/bar baz/1/qux baz/2/qux baz/3/qux Visit braces to see the full range of features and options related to brace expansion, or to create brace matching or expansion related issues. Regex character classes Given the list: ['a.js', 'b.js', 'c.js', 'd.js', 'E.js']: [ac].js: matches both a and c, returning ['a.js', 'c.js'] [b-d].js: matches from b to d, returning ['b.js', 'c.js', 'd.js'] a/[A-Z].js: matches and uppercase letter, returning ['a/E.md'] Learn about regex character classes. Regex groups Given ['a.js', 'b.js', 'c.js', 'd.js', 'E.js']: (a|c).js: would match either a or c, returning ['a.js', 'c.js'] (b|d).js: would match either b or d, returning ['b.js', 'd.js'] (b|[A-Z]).js: would match either b or an uppercase letter, returning ['b.js', 'E.js'] As with regex, parens can be nested, so patterns like ((a|b)|c)/b will work. Although brace expansion might be friendlier to use, depending on preference. POSIX bracket expressions POSIX brackets are intended to be more user-friendly than regex character classes. This of course is in the eye of the beholder. Example console.log(micromatch.isMatch('a1', '[[:alpha:][:digit:]]')) //=> true console.log(micromatch.isMatch('a1', '[[:alpha:][:alpha:]]')) //=> false Notes Bash 4.3 parity Whenever possible matching behavior is based on behavior Bash 4.3, which is mostly consistent with minimatch. However, it's suprising how many edge cases and rabbit holes there are with glob matching, and since there is no real glob specification, and micromatch is more accurate than both Bash and minimatch, there are cases where best-guesses were made for behavior. In a few cases where Bash had no answers, we used wildmatch (used by git) as a fallback. Backslashes There is an important, notable difference between minimatch and micromatch in regards to how backslashes are handled in glob patterns. Micromatch exclusively and explicitly reserves backslashes for escaping characters in a glob pattern, even on windows, which is consistent with bash behavior. More importantly, unescaping globs can result in unsafe regular expressions. Minimatch converts all backslashes to forward slashes, which means you can't use backslashes to escape any characters in your glob patterns. We made this decision for micromatch for a couple of reasons: Consistency with bash conventions. Glob patterns are not filepaths. They are a type of regular language that is converted to a JavaScript regular expression. Thus, when forward slashes are defined in a glob pattern, the resulting regular expression will match windows or POSIX path separators just fine. A note about joining paths to globs Note that when you pass something like path.join('foo', '*') to micromatch, you are creating a filepath and expecting it to still work as a glob pattern. This causes problems on windows, since the path.sep is \\\\. In other words, since \\\\ is reserved as an escape character in globs, on windows path.join('foo', '*') would result in foo\\\\*, which tells micromatch to match * as a literal character. This is the same behavior as bash. To solve this, you might be inspired to do something like 'foo\\\\*'.replace(/\\\\/g, '/'), but this causes another, potentially much more serious, problem. Benchmarks Running benchmarks Install dependencies for running benchmarks: $ cd bench && npm install Run the benchmarks: $ npm run bench Latest results As of July 12, 2023 (longer bars are better): # .makeRe star micromatch x 2,232,802 ops/sec ±2.34% (89 runs sampled)) minimatch x 781,018 ops/sec ±6.74% (92 runs sampled)) # .makeRe star; dot=true micromatch x 1,863,453 ops/sec ±0.74% (93 runs sampled) minimatch x 723,105 ops/sec ±0.75% (93 runs sampled) # .makeRe globstar micromatch x 1,624,179 ops/sec ±2.22% (91 runs sampled) minimatch x 1,117,230 ops/sec ±2.78% (86 runs sampled)) # .makeRe globstars micromatch x 1,658,642 ops/sec ±0.86% (92 runs sampled) minimatch x 741,224 ops/sec ±1.24% (89 runs sampled)) # .makeRe with leading star micromatch x 1,525,014 ops/sec ±1.63% (90 runs sampled) minimatch x 561,074 ops/sec ±3.07% (89 runs sampled) # .makeRe - braces micromatch x 172,478 ops/sec ±2.37% (78 runs sampled) minimatch x 96,087 ops/sec ±2.34% (88 runs sampled))) # .makeRe braces - range (expanded) micromatch x 26,973 ops/sec ±0.84% (89 runs sampled) minimatch x 3,023 ops/sec ±0.99% (90 runs sampled)) # .makeRe braces - range (compiled) micromatch x 152,892 ops/sec ±1.67% (83 runs sampled) minimatch x 992 ops/sec ±3.50% (89 runs sampled)d)) # .makeRe braces - nested ranges (expanded) micromatch x 15,816 ops/sec ±13.05% (80 runs sampled) minimatch x 2,953 ops/sec ±1.64% (91 runs sampled) # .makeRe braces - nested ranges (compiled) micromatch x 110,881 ops/sec ±1.85% (82 runs sampled) minimatch x 1,008 ops/sec ±1.51% (91 runs sampled) # .makeRe braces - set (compiled) micromatch x 134,930 ops/sec ±3.54% (63 runs sampled)) minimatch x 43,242 ops/sec ±0.60% (93 runs sampled) # .makeRe braces - nested sets (compiled) micromatch x 94,455 ops/sec ±1.74% (69 runs sampled)) minimatch x 27,720 ops/sec ±1.84% (93 runs sampled)) Contributing All contributions are welcome! Please read the contributing guide to get started. Bug reports Please create an issue if you encounter a bug or matching behavior that doesn't seem correct. If you find a matching-related issue, please: research existing issues first (open and closed) visit the GNU Bash documentation to see how Bash deals with the pattern visit the minimatch documentation to cross-check expected behavior in node.js if all else fails, since there is no real specification for globs we will probably need to discuss expected behavior and decide how to resolve it. which means any detail you can provide to help with this discussion would be greatly appreciated. Platform issues It's important to us that micromatch work consistently on all platforms. If you encounter any platform-specific matching or path related issues, please let us know (pull requests are also greatly appreciated). About Contributing Pull requests and stars are always welcome. For bugs and feature requests, please create an issue. Please read the contributing guide for advice on opening issues, pull requests, and coding standards. Running Tests Running and reviewing unit tests is a great way to get familiarized with a library and its API. You can install dependencies and run tests with the following command: $ npm install && npm test Building docs (This project's readme.md is generated by verb, please don't edit the readme directly. Any changes to the readme must be made in the .verb.md readme template.) To generate the readme, run the following command: $ npm install -g verbose/verb#dev verb-generate-readme && verb Related projects You might also be interested in these projects: braces: Bash-like brace expansion, implemented in JavaScript. Safer than other brace expansion libs, with complete support… more | homepage expand-brackets: Expand POSIX bracket expressions (character classes) in glob patterns. | homepage extglob: Extended glob support for JavaScript. Adds (almost) the expressive power of regular expressions to glob… more | homepage fill-range: Fill in a range of numbers or letters, optionally passing an increment or step to… more | homepage nanomatch: Fast, minimal glob matcher for node.js. Similar to micromatch, minimatch and multimatch, but complete Bash… more | homepage Contributors Commits Contributor 515 jonschlinkert 12 es128 9 danez 8 doowb 6 paulmillr 5 mrmlnc 3 DrPizza 2 TrySound 2 mceIdo 2 Glazy 2 MartinKolarik 2 antonyk 2 Tvrqvoise 1 amilajack 1 Cslove 1 devongovett 1 DianeLooney 1 UltCombo 1 frangio 1 joyceerhl 1 juszczykjakub 1 muescha 1 sebdeckers 1 tomByrer 1 fidian 1 curbengh 1 simlu 1 wtgtybhertgeghgtwtg 1 yvele Author Jon Schlinkert GitHub Profile Twitter Profile LinkedIn Profile License Copyright © 2023, Jon Schlinkert. Released under the MIT License. This file was generated by verb-generate-readme, v0.8.0, on July 12, 2023."
  },
  "node_modules/mime-db/HISTORY.html": {
    "href": "node_modules/mime-db/HISTORY.html",
    "title": "1.52.0 / 2022-02-21 | accouter",
    "keywords": "1.52.0 / 2022-02-21 Add extensions from IANA for more image/* types Add extension .asc to application/pgp-keys Add extensions to various XML types Add new upstream MIME types 1.51.0 / 2021-11-08 Add new upstream MIME types Mark image/vnd.microsoft.icon as compressible Mark image/vnd.ms-dds as compressible 1.50.0 / 2021-09-15 Add deprecated iWorks mime types and extensions Add new upstream MIME types 1.49.0 / 2021-07-26 Add extension .trig to application/trig Add new upstream MIME types 1.48.0 / 2021-05-30 Add extension .mvt to application/vnd.mapbox-vector-tile Add new upstream MIME types Mark text/yaml as compressible 1.47.0 / 2021-04-01 Add new upstream MIME types Remove ambigious extensions from IANA for application/*+xml types Update primary extension to .es for application/ecmascript 1.46.0 / 2021-02-13 Add extension .amr to audio/amr Add extension .m4s to video/iso.segment Add extension .opus to audio/ogg Add new upstream MIME types 1.45.0 / 2020-09-22 Add application/ubjson with extension .ubj Add image/avif with extension .avif Add image/ktx2 with extension .ktx2 Add extension .dbf to application/vnd.dbf Add extension .rar to application/vnd.rar Add extension .td to application/urc-targetdesc+xml Add new upstream MIME types Fix extension of application/vnd.apple.keynote to be .key 1.44.0 / 2020-04-22 Add charsets from IANA Add extension .cjs to application/node Add new upstream MIME types 1.43.0 / 2020-01-05 Add application/x-keepass2 with extension .kdbx Add extension .mxmf to audio/mobile-xmf Add extensions from IANA for application/*+xml types Add new upstream MIME types 1.42.0 / 2019-09-25 Add image/vnd.ms-dds with extension .dds Add new upstream MIME types Remove compressible from multipart/mixed 1.41.0 / 2019-08-30 Add new upstream MIME types Add application/toml with extension .toml Mark font/ttf as compressible 1.40.0 / 2019-04-20 Add extensions from IANA for model/* types Add text/mdx with extension .mdx 1.39.0 / 2019-04-04 Add extensions .siv and .sieve to application/sieve Add new upstream MIME types 1.38.0 / 2019-02-04 Add extension .nq to application/n-quads Add extension .nt to application/n-triples Add new upstream MIME types Mark text/less as compressible 1.37.0 / 2018-10-19 Add extensions to HEIC image types Add new upstream MIME types 1.36.0 / 2018-08-20 Add Apple file extensions from IANA Add extensions from IANA for image/* types Add new upstream MIME types 1.35.0 / 2018-07-15 Add extension .owl to application/rdf+xml Add new upstream MIME types Removes extension .woff from application/font-woff 1.34.0 / 2018-06-03 Add extension .csl to application/vnd.citationstyles.style+xml Add extension .es to application/ecmascript Add new upstream MIME types Add UTF-8 as default charset for text/turtle Mark all XML-derived types as compressible 1.33.0 / 2018-02-15 Add extensions from IANA for message/* types Add new upstream MIME types Fix some incorrect OOXML types Remove application/font-woff2 1.32.0 / 2017-11-29 Add new upstream MIME types Update text/hjson to registered application/hjson Add text/shex with extension .shex 1.31.0 / 2017-10-25 Add application/raml+yaml with extension .raml Add application/wasm with extension .wasm Add new font type from IANA Add new upstream font extensions Add new upstream MIME types Add extensions for JPEG-2000 images 1.30.0 / 2017-08-27 Add application/vnd.ms-outlook Add application/x-arj Add extension .mjs to application/javascript Add glTF types and extensions Add new upstream MIME types Add text/x-org Add VirtualBox MIME types Fix source records for video/* types that are IANA Update font/opentype to registered font/otf 1.29.0 / 2017-07-10 Add application/fido.trusted-apps+json Add extension .wadl to application/vnd.sun.wadl+xml Add new upstream MIME types Add UTF-8 as default charset for text/css 1.28.0 / 2017-05-14 Add new upstream MIME types Add extension .gz to application/gzip Update extensions .md and .markdown to be text/markdown 1.27.0 / 2017-03-16 Add new upstream MIME types Add image/apng with extension .apng 1.26.0 / 2017-01-14 Add new upstream MIME types Add extension .geojson to application/geo+json 1.25.0 / 2016-11-11 Add new upstream MIME types 1.24.0 / 2016-09-18 Add audio/mp3 Add new upstream MIME types 1.23.0 / 2016-05-01 Add new upstream MIME types Add extension .3gpp to audio/3gpp 1.22.0 / 2016-02-15 Add text/slim Add extension .rng to application/xml Add new upstream MIME types Fix extension of application/dash+xml to be .mpd Update primary extension to .m4a for audio/mp4 1.21.0 / 2016-01-06 Add Google document types Add new upstream MIME types 1.20.0 / 2015-11-10 Add text/x-suse-ymp Add new upstream MIME types 1.19.0 / 2015-09-17 Add application/vnd.apple.pkpass Add new upstream MIME types 1.18.0 / 2015-09-03 Add new upstream MIME types 1.17.0 / 2015-08-13 Add application/x-msdos-program Add audio/g711-0 Add image/vnd.mozilla.apng Add extension .exe to application/x-msdos-program 1.16.0 / 2015-07-29 Add application/vnd.uri-map 1.15.0 / 2015-07-13 Add application/x-httpd-php 1.14.0 / 2015-06-25 Add application/scim+json Add application/vnd.3gpp.ussd+xml Add application/vnd.biopax.rdf+xml Add text/x-processing 1.13.0 / 2015-06-07 Add nginx as a source Add application/x-cocoa Add application/x-java-archive-diff Add application/x-makeself Add application/x-perl Add application/x-pilot Add application/x-redhat-package-manager Add application/x-sea Add audio/x-m4a Add audio/x-realaudio Add image/x-jng Add text/mathml 1.12.0 / 2015-06-05 Add application/bdoc Add application/vnd.hyperdrive+json Add application/x-bdoc Add extension .rtf to text/rtf 1.11.0 / 2015-05-31 Add audio/wav Add audio/wave Add extension .litcoffee to text/coffeescript Add extension .sfd-hdstx to application/vnd.hydrostatix.sof-data Add extension .n-gage to application/vnd.nokia.n-gage.symbian.install 1.10.0 / 2015-05-19 Add application/vnd.balsamiq.bmpr Add application/vnd.microsoft.portable-executable Add application/x-ns-proxy-autoconfig 1.9.1 / 2015-04-19 Remove .json extension from application/manifest+json This is causing bugs downstream 1.9.0 / 2015-04-19 Add application/manifest+json Add application/vnd.micro+json Add image/vnd.zbrush.pcx Add image/x-ms-bmp 1.8.0 / 2015-03-13 Add application/vnd.citationstyles.style+xml Add application/vnd.fastcopy-disk-image Add application/vnd.gov.sk.xmldatacontainer+xml Add extension .jsonld to application/ld+json 1.7.0 / 2015-02-08 Add application/vnd.gerber Add application/vnd.msa-disk-image 1.6.1 / 2015-02-05 Community extensions ownership transferred from node-mime 1.6.0 / 2015-01-29 Add application/jose Add application/jose+json Add application/json-seq Add application/jwk+json Add application/jwk-set+json Add application/jwt Add application/rdap+json Add application/vnd.gov.sk.e-form+xml Add application/vnd.ims.imsccv1p3 1.5.0 / 2014-12-30 Add application/vnd.oracle.resource+json Fix various invalid MIME type entries application/mbox+xml application/oscp-response application/vwg-multiplexed audio/g721 1.4.0 / 2014-12-21 Add application/vnd.ims.imsccv1p2 Fix various invalid MIME type entries application/vnd-acucobol application/vnd-curl application/vnd-dart application/vnd-dxr application/vnd-fdf application/vnd-mif application/vnd-sema application/vnd-wap-wmlc application/vnd.adobe.flash-movie application/vnd.dece-zip application/vnd.dvb_service application/vnd.micrografx-igx application/vnd.sealed-doc application/vnd.sealed-eml application/vnd.sealed-mht application/vnd.sealed-ppt application/vnd.sealed-tiff application/vnd.sealed-xls application/vnd.sealedmedia.softseal-html application/vnd.sealedmedia.softseal-pdf application/vnd.wap-slc application/vnd.wap-wbxml audio/vnd.sealedmedia.softseal-mpeg image/vnd-djvu image/vnd-svf image/vnd-wap-wbmp image/vnd.sealed-png image/vnd.sealedmedia.softseal-gif image/vnd.sealedmedia.softseal-jpg model/vnd-dwf model/vnd.parasolid.transmit-binary model/vnd.parasolid.transmit-text text/vnd-a text/vnd-curl text/vnd.wap-wml Remove example template MIME types application/example audio/example image/example message/example model/example multipart/example text/example video/example 1.3.1 / 2014-12-16 Fix missing extensions application/json5 text/hjson 1.3.0 / 2014-12-07 Add application/a2l Add application/aml Add application/atfx Add application/atxml Add application/cdfx+xml Add application/dii Add application/json5 Add application/lxf Add application/mf4 Add application/vnd.apache.thrift.compact Add application/vnd.apache.thrift.json Add application/vnd.coffeescript Add application/vnd.enphase.envoy Add application/vnd.ims.imsccv1p1 Add text/csv-schema Add text/hjson Add text/markdown Add text/yaml 1.2.0 / 2014-11-09 Add application/cea Add application/dit Add application/vnd.gov.sk.e-form+zip Add application/vnd.tmd.mediaflex.api+xml Type application/epub+zip is now IANA-registered 1.1.2 / 2014-10-23 Rebuild database for application/x-www-form-urlencoded change 1.1.1 / 2014-10-20 Mark application/x-www-form-urlencoded as compressible. 1.1.0 / 2014-09-28 Add application/font-woff2 1.0.3 / 2014-09-25 Fix engine requirement in package 1.0.2 / 2014-09-25 Add application/coap-group+json Add application/dcd Add application/vnd.apache.thrift.binary Add image/vnd.tencent.tap Mark all JSON-derived types as compressible Update text/vtt data 1.0.1 / 2014-08-30 Fix extension ordering 1.0.0 / 2014-08-30 Add application/atf Add application/merge-patch+json Add multipart/x-mixed-replace Add source: 'apache' metadata Add source: 'iana' metadata Remove badly-assumed charset data"
  },
  "node_modules/mime-db/README.html": {
    "href": "node_modules/mime-db/README.html",
    "title": "mime-db | accouter",
    "keywords": "mime-db This is a large database of mime types and information about them. It consists of a single, public JSON file and does not include any logic, allowing it to remain as un-opinionated as possible with an API. It aggregates data from the following sources: http://www.iana.org/assignments/media-types/media-types.xhtml http://svn.apache.org/repos/asf/httpd/httpd/trunk/docs/conf/mime.types http://hg.nginx.org/nginx/raw-file/default/conf/mime.types Installation npm install mime-db Database Download If you're crazy enough to use this in the browser, you can just grab the JSON file using jsDelivr. It is recommended to replace master with a release tag as the JSON format may change in the future. https://cdn.jsdelivr.net/gh/jshttp/mime-db@master/db.json Usage var db = require('mime-db') // grab data on .js files var data = db['application/javascript'] Data Structure The JSON file is a map lookup for lowercased mime types. Each mime type has the following properties: .source - where the mime type is defined. If not set, it's probably a custom media type. apache - Apache common media types iana - IANA-defined media types nginx - nginx media types .extensions[] - known extensions associated with this mime type. .compressible - whether a file of this type can be gzipped. .charset - the default charset associated with this type, if any. If unknown, every property could be undefined. Contributing To edit the database, only make PRs against src/custom-types.json or src/custom-suffix.json. The src/custom-types.json file is a JSON object with the MIME type as the keys and the values being an object with the following keys: compressible - leave out if you don't know, otherwise true/false to indicate whether the data represented by the type is typically compressible. extensions - include an array of file extensions that are associated with the type. notes - human-readable notes about the type, typically what the type is. sources - include an array of URLs of where the MIME type and the associated extensions are sourced from. This needs to be a primary source; links to type aggregating sites and Wikipedia are not acceptable. To update the build, run npm run build. Adding Custom Media Types The best way to get new media types included in this library is to register them with the IANA. The community registration procedure is outlined in RFC 6838 section 5. Types registered with the IANA are automatically pulled into this library. If that is not possible / feasible, they can be added directly here as a \"custom\" type. To do this, it is required to have a primary source that definitively lists the media type. If an extension is going to be listed as associateed with this media type, the source must definitively link the media type and extension as well."
  },
  "node_modules/mime-types/HISTORY.html": {
    "href": "node_modules/mime-types/HISTORY.html",
    "title": "2.1.35 / 2022-03-12 | accouter",
    "keywords": "2.1.35 / 2022-03-12 deps: mime-db@1.52.0 Add extensions from IANA for more image/* types Add extension .asc to application/pgp-keys Add extensions to various XML types Add new upstream MIME types 2.1.34 / 2021-11-08 deps: mime-db@1.51.0 Add new upstream MIME types 2.1.33 / 2021-10-01 deps: mime-db@1.50.0 Add deprecated iWorks mime types and extensions Add new upstream MIME types 2.1.32 / 2021-07-27 deps: mime-db@1.49.0 Add extension .trig to application/trig Add new upstream MIME types 2.1.31 / 2021-06-01 deps: mime-db@1.48.0 Add extension .mvt to application/vnd.mapbox-vector-tile Add new upstream MIME types 2.1.30 / 2021-04-02 deps: mime-db@1.47.0 Add extension .amr to audio/amr Remove ambigious extensions from IANA for application/*+xml types Update primary extension to .es for application/ecmascript 2.1.29 / 2021-02-17 deps: mime-db@1.46.0 Add extension .amr to audio/amr Add extension .m4s to video/iso.segment Add extension .opus to audio/ogg Add new upstream MIME types 2.1.28 / 2021-01-01 deps: mime-db@1.45.0 Add application/ubjson with extension .ubj Add image/avif with extension .avif Add image/ktx2 with extension .ktx2 Add extension .dbf to application/vnd.dbf Add extension .rar to application/vnd.rar Add extension .td to application/urc-targetdesc+xml Add new upstream MIME types Fix extension of application/vnd.apple.keynote to be .key 2.1.27 / 2020-04-23 deps: mime-db@1.44.0 Add charsets from IANA Add extension .cjs to application/node Add new upstream MIME types 2.1.26 / 2020-01-05 deps: mime-db@1.43.0 Add application/x-keepass2 with extension .kdbx Add extension .mxmf to audio/mobile-xmf Add extensions from IANA for application/*+xml types Add new upstream MIME types 2.1.25 / 2019-11-12 deps: mime-db@1.42.0 Add new upstream MIME types Add application/toml with extension .toml Add image/vnd.ms-dds with extension .dds 2.1.24 / 2019-04-20 deps: mime-db@1.40.0 Add extensions from IANA for model/* types Add text/mdx with extension .mdx 2.1.23 / 2019-04-17 deps: mime-db@~1.39.0 Add extensions .siv and .sieve to application/sieve Add new upstream MIME types 2.1.22 / 2019-02-14 deps: mime-db@~1.38.0 Add extension .nq to application/n-quads Add extension .nt to application/n-triples Add new upstream MIME types 2.1.21 / 2018-10-19 deps: mime-db@~1.37.0 Add extensions to HEIC image types Add new upstream MIME types 2.1.20 / 2018-08-26 deps: mime-db@~1.36.0 Add Apple file extensions from IANA Add extensions from IANA for image/* types Add new upstream MIME types 2.1.19 / 2018-07-17 deps: mime-db@~1.35.0 Add extension .csl to application/vnd.citationstyles.style+xml Add extension .es to application/ecmascript Add extension .owl to application/rdf+xml Add new upstream MIME types Add UTF-8 as default charset for text/turtle 2.1.18 / 2018-02-16 deps: mime-db@~1.33.0 Add application/raml+yaml with extension .raml Add application/wasm with extension .wasm Add text/shex with extension .shex Add extensions for JPEG-2000 images Add extensions from IANA for message/* types Add new upstream MIME types Update font MIME types Update text/hjson to registered application/hjson 2.1.17 / 2017-09-01 deps: mime-db@~1.30.0 Add application/vnd.ms-outlook Add application/x-arj Add extension .mjs to application/javascript Add glTF types and extensions Add new upstream MIME types Add text/x-org Add VirtualBox MIME types Fix source records for video/* types that are IANA Update font/opentype to registered font/otf 2.1.16 / 2017-07-24 deps: mime-db@~1.29.0 Add application/fido.trusted-apps+json Add extension .wadl to application/vnd.sun.wadl+xml Add extension .gz to application/gzip Add new upstream MIME types Update extensions .md and .markdown to be text/markdown 2.1.15 / 2017-03-23 deps: mime-db@~1.27.0 Add new mime types Add image/apng 2.1.14 / 2017-01-14 deps: mime-db@~1.26.0 Add new mime types 2.1.13 / 2016-11-18 deps: mime-db@~1.25.0 Add new mime types 2.1.12 / 2016-09-18 deps: mime-db@~1.24.0 Add new mime types Add audio/mp3 2.1.11 / 2016-05-01 deps: mime-db@~1.23.0 Add new mime types 2.1.10 / 2016-02-15 deps: mime-db@~1.22.0 Add new mime types Fix extension of application/dash+xml Update primary extension for audio/mp4 2.1.9 / 2016-01-06 deps: mime-db@~1.21.0 Add new mime types 2.1.8 / 2015-11-30 deps: mime-db@~1.20.0 Add new mime types 2.1.7 / 2015-09-20 deps: mime-db@~1.19.0 Add new mime types 2.1.6 / 2015-09-03 deps: mime-db@~1.18.0 Add new mime types 2.1.5 / 2015-08-20 deps: mime-db@~1.17.0 Add new mime types 2.1.4 / 2015-07-30 deps: mime-db@~1.16.0 Add new mime types 2.1.3 / 2015-07-13 deps: mime-db@~1.15.0 Add new mime types 2.1.2 / 2015-06-25 deps: mime-db@~1.14.0 Add new mime types 2.1.1 / 2015-06-08 perf: fix deopt during mapping 2.1.0 / 2015-06-07 Fix incorrectly treating extension-less file name as extension i.e. 'path/to/json' will no longer return application/json Fix .charset(type) to accept parameters Fix .charset(type) to match case-insensitive Improve generation of extension to MIME mapping Refactor internals for readability and no argument reassignment Prefer application/* MIME types from the same source Prefer any type over application/octet-stream deps: mime-db@~1.13.0 Add nginx as a source Add new mime types 2.0.14 / 2015-06-06 deps: mime-db@~1.12.0 Add new mime types 2.0.13 / 2015-05-31 deps: mime-db@~1.11.0 Add new mime types 2.0.12 / 2015-05-19 deps: mime-db@~1.10.0 Add new mime types 2.0.11 / 2015-05-05 deps: mime-db@~1.9.1 Add new mime types 2.0.10 / 2015-03-13 deps: mime-db@~1.8.0 Add new mime types 2.0.9 / 2015-02-09 deps: mime-db@~1.7.0 Add new mime types Community extensions ownership transferred from node-mime 2.0.8 / 2015-01-29 deps: mime-db@~1.6.0 Add new mime types 2.0.7 / 2014-12-30 deps: mime-db@~1.5.0 Add new mime types Fix various invalid MIME type entries 2.0.6 / 2014-12-30 deps: mime-db@~1.4.0 Add new mime types Fix various invalid MIME type entries Remove example template MIME types 2.0.5 / 2014-12-29 deps: mime-db@~1.3.1 Fix missing extensions 2.0.4 / 2014-12-10 deps: mime-db@~1.3.0 Add new mime types 2.0.3 / 2014-11-09 deps: mime-db@~1.2.0 Add new mime types 2.0.2 / 2014-09-28 deps: mime-db@~1.1.0 Add new mime types Update charsets 2.0.1 / 2014-09-07 Support Node.js 0.6 2.0.0 / 2014-09-02 Use mime-db Remove .define() 1.0.2 / 2014-08-04 Set charset=utf-8 for text/javascript 1.0.1 / 2014-06-24 Add text/jsx type 1.0.0 / 2014-05-12 Return false for unknown types Set charset=utf-8 for application/json 0.1.0 / 2014-05-02 Initial release"
  },
  "node_modules/mime-types/README.html": {
    "href": "node_modules/mime-types/README.html",
    "title": "mime-types | accouter",
    "keywords": "mime-types The ultimate javascript content-type utility. Similar to the mime@1.x module, except: No fallbacks. Instead of naively returning the first available type, mime-types simply returns false, so do var type = mime.lookup('unrecognized') || 'application/octet-stream'. No new Mime() business, so you could do var lookup = require('mime-types').lookup. No .define() functionality Bug fixes for .lookup(path) Otherwise, the API is compatible with mime 1.x. Install This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install mime-types Adding Types All mime types are based on mime-db, so open a PR there if you'd like to add mime types. API var mime = require('mime-types') All functions return false if input is invalid or not found. mime.lookup(path) Lookup the content-type associated with a file. mime.lookup('json') // 'application/json' mime.lookup('.md') // 'text/markdown' mime.lookup('file.html') // 'text/html' mime.lookup('folder/file.js') // 'application/javascript' mime.lookup('folder/.htaccess') // false mime.lookup('cats') // false mime.contentType(type) Create a full content-type header given a content-type or extension. When given an extension, mime.lookup is used to get the matching content-type, otherwise the given content-type is used. Then if the content-type does not already have a charset parameter, mime.charset is used to get the default charset and add to the returned content-type. mime.contentType('markdown') // 'text/x-markdown; charset=utf-8' mime.contentType('file.json') // 'application/json; charset=utf-8' mime.contentType('text/html') // 'text/html; charset=utf-8' mime.contentType('text/html; charset=iso-8859-1') // 'text/html; charset=iso-8859-1' // from a full path mime.contentType(path.extname('/path/to/file.json')) // 'application/json; charset=utf-8' mime.extension(type) Get the default extension for a content-type. mime.extension('application/octet-stream') // 'bin' mime.charset(type) Lookup the implied default charset of a content-type. mime.charset('text/markdown') // 'UTF-8' var type = mime.types[extension] A map of content-types by extension. [extensions...] = mime.extensions[type] A map of extensions by content-type. License MIT"
  },
  "node_modules/mime/README.html": {
    "href": "node_modules/mime/README.html",
    "title": "mime | accouter",
    "keywords": "mime Comprehensive MIME type mapping API based on mime-db module. Install Install with npm: npm install mime Contributing / Testing npm run test Command Line mime [path_string] E.g. > mime scripts/jquery.js application/javascript API - Queries mime.lookup(path) Get the mime type associated with a file, if no mime type is found application/octet-stream is returned. Performs a case-insensitive lookup using the extension in path (the substring after the last '/' or '.'). E.g. var mime = require('mime'); mime.lookup('/path/to/file.txt'); // => 'text/plain' mime.lookup('file.txt'); // => 'text/plain' mime.lookup('.TXT'); // => 'text/plain' mime.lookup('htm'); // => 'text/html' mime.default_type Sets the mime type returned when mime.lookup fails to find the extension searched for. (Default is application/octet-stream.) mime.extension(type) Get the default extension for type mime.extension('text/html'); // => 'html' mime.extension('application/octet-stream'); // => 'bin' mime.charsets.lookup() Map mime-type to charset mime.charsets.lookup('text/plain'); // => 'UTF-8' (The logic for charset lookups is pretty rudimentary. Feel free to suggest improvements.) API - Defining Custom Types Custom type mappings can be added on a per-project basis via the following APIs. mime.define() Add custom mime/extension mappings mime.define({ 'text/x-some-format': ['x-sf', 'x-sft', 'x-sfml'], 'application/x-my-type': ['x-mt', 'x-mtt'], // etc ... }); mime.lookup('x-sft'); // => 'text/x-some-format' The first entry in the extensions array is returned by mime.extension(). E.g. mime.extension('text/x-some-format'); // => 'x-sf' mime.load(filepath) Load mappings from an Apache \".types\" format file mime.load('./my_project.types'); The .types file format is simple - See the types dir for examples."
  },
  "node_modules/minimatch/README.html": {
    "href": "node_modules/minimatch/README.html",
    "title": "minimatch | accouter",
    "keywords": "minimatch A minimal matching utility. This is the matching library used internally by npm. It works by converting glob expressions into JavaScript RegExp objects. Usage var minimatch = require(\"minimatch\") minimatch(\"bar.foo\", \"*.foo\") // true! minimatch(\"bar.foo\", \"*.bar\") // false! minimatch(\"bar.foo\", \"*.+(bar|foo)\", { debug: true }) // true, and noisy! Features Supports these glob features: Brace Expansion Extended glob matching \"Globstar\" ** matching See: man sh man bash man 3 fnmatch man 5 gitignore Windows Please only use forward-slashes in glob expressions. Though windows uses either / or \\ as its path separator, only / characters are used by this glob implementation. You must use forward-slashes only in glob expressions. Back-slashes in patterns will always be interpreted as escape characters, not path separators. Note that \\ or / will be interpreted as path separators in paths on Windows, and will match against / in glob expressions. So just always use / in patterns. Minimatch Class Create a minimatch object by instantiating the minimatch.Minimatch class. var Minimatch = require(\"minimatch\").Minimatch var mm = new Minimatch(pattern, options) Properties pattern The original pattern the minimatch object represents. options The options supplied to the constructor. set A 2-dimensional array of regexp or string expressions. Each row in the array corresponds to a brace-expanded pattern. Each item in the row corresponds to a single path-part. For example, the pattern {a,b/c}/d would expand to a set of patterns like: [ [ a, d ] , [ b, c, d ] ] If a portion of the pattern doesn't have any \"magic\" in it (that is, it's something like \"foo\" rather than fo*o?), then it will be left as a string rather than converted to a regular expression. regexp Created by the makeRe method. A single regular expression expressing the entire pattern. This is useful in cases where you wish to use the pattern somewhat like fnmatch(3) with FNM_PATH enabled. negate True if the pattern is negated. comment True if the pattern is a comment. empty True if the pattern is \"\". Methods makeRe Generate the regexp member if necessary, and return it. Will return false if the pattern is invalid. match(fname) Return true if the filename matches the pattern, or false otherwise. matchOne(fileArray, patternArray, partial) Take a /-split filename, and match it against a single row in the regExpSet. This method is mainly for internal use, but is exposed so that it can be used by a glob-walker that needs to avoid excessive filesystem calls. All other methods are internal, and will be called as necessary. minimatch(path, pattern, options) Main export. Tests a path against the pattern using the options. var isJS = minimatch(file, \"*.js\", { matchBase: true }) minimatch.filter(pattern, options) Returns a function that tests its supplied argument, suitable for use with Array.filter. Example: var javascripts = fileList.filter(minimatch.filter(\"*.js\", {matchBase: true})) minimatch.match(list, pattern, options) Match against the list of files, in the style of fnmatch or glob. If nothing is matched, and options.nonull is set, then return a list containing the pattern itself. var javascripts = minimatch.match(fileList, \"*.js\", {matchBase: true})) minimatch.makeRe(pattern, options) Make a regular expression object from the pattern. Options All options are false by default. debug Dump a ton of stuff to stderr. nobrace Do not expand {a,b} and {1..3} brace sets. noglobstar Disable ** matching against multiple folder names. dot Allow patterns to match filenames starting with a period, even if the pattern does not explicitly have a period in that spot. Note that by default, a/**/b will not match a/.d/b, unless dot is set. noext Disable \"extglob\" style patterns like +(a|b). nocase Perform a case-insensitive match. nonull When a match is not found by minimatch.match, return a list containing the pattern itself if this option is set. When not set, an empty list is returned if there are no matches. matchBase If set, then patterns without slashes will be matched against the basename of the path if it contains slashes. For example, a?b would match the path /xyz/123/acb, but not /xyz/acb/123. nocomment Suppress the behavior of treating # at the start of a pattern as a comment. nonegate Suppress the behavior of treating a leading ! character as negation. flipNegate Returns from negate expressions the same as if they were not negated. (Ie, true on a hit, false on a miss.) partial Compare a partial path to a pattern. As long as the parts of the path that are present are not contradicted by the pattern, it will be treated as a match. This is useful in applications where you're walking through a folder structure, and don't yet have the full path, but want to ensure that you do not walk down paths that can never be a match. For example, minimatch('/a/b', '/a/*/c/d', { partial: true }) // true, might be /a/b/c/d minimatch('/a/b', '/**/d', { partial: true }) // true, might be /a/b/.../d minimatch('/x/y/z', '/a/**/z', { partial: true }) // false, because x !== a Comparisons to other fnmatch/glob implementations While strict compliance with the existing standards is a worthwhile goal, some discrepancies exist between minimatch and other implementations, and are intentional. If the pattern starts with a ! character, then it is negated. Set the nonegate flag to suppress this behavior, and treat leading ! characters normally. This is perhaps relevant if you wish to start the pattern with a negative extglob pattern like !(a|B). Multiple ! characters at the start of a pattern will negate the pattern multiple times. If a pattern starts with #, then it is treated as a comment, and will not match anything. Use \\# to match a literal # at the start of a line, or set the nocomment flag to suppress this behavior. The double-star character ** is supported by default, unless the noglobstar flag is set. This is supported in the manner of bsdglob and bash 4.1, where ** only has special significance if it is the only thing in a path part. That is, a/**/b will match a/x/y/b, but a/**b will not. If an escaped pattern has no matches, and the nonull flag is set, then minimatch.match returns the pattern as-provided, rather than interpreting the character escapes. For example, minimatch.match([], \"\\\\*a\\\\?\") will return \"\\\\*a\\\\?\" rather than \"*a?\". This is akin to setting the nullglob option in bash, except that it does not resolve escaped pattern characters. If brace expansion is not disabled, then it is performed before any other interpretation of the glob pattern. Thus, a pattern like +(a|{b),c)}, which would not be valid in bash or zsh, is expanded first into the set of +(a|b) and +(a|c), and those patterns are checked for validity. Since those two are valid, matching proceeds. Note that fnmatch(3) in libc is an extremely naive string comparison matcher, which does not do anything special for slashes. This library is designed to be used in glob searching and file walkers, and so it does do special things with /. Thus, foo* will not match foo/bar in this library, even though it would in fnmatch(3)."
  },
  "node_modules/minipass/README.html": {
    "href": "node_modules/minipass/README.html",
    "title": "minipass | accouter",
    "keywords": "minipass A very minimal implementation of a PassThrough stream It's very fast for objects, strings, and buffers. Supports pipe()ing (including multi-pipe() and backpressure transmission), buffering data until either a data event handler or pipe() is added (so you don't lose the first chunk), and most other cases where PassThrough is a good idea. There is a read() method, but it's much more efficient to consume data from this stream via 'data' events or by calling pipe() into some other stream. Calling read() requires the buffer to be flattened in some cases, which requires copying memory. If you set objectMode: true in the options, then whatever is written will be emitted. Otherwise, it'll do a minimal amount of Buffer copying to ensure proper Streams semantics when read(n) is called. objectMode can only be set at instantiation. Attempting to write something other than a String or Buffer without having set objectMode in the options will throw an error. This is not a through or through2 stream. It doesn't transform the data, it just passes it right through. If you want to transform the data, extend the class, and override the write() method. Once you're done transforming the data however you want, call super.write() with the transform output. For some examples of streams that extend Minipass in various ways, check out: minizlib fs-minipass tar minipass-collect minipass-flush minipass-pipeline tap tap-parser treport minipass-fetch pacote make-fetch-happen cacache ssri npm-registry-fetch minipass-json-stream minipass-sized Usage in TypeScript The Minipass class takes three type template definitions: RType the type being read, which defaults to Buffer. If RType is string, then the constructor must get an options object specifying either an encoding or objectMode: true. If it's anything other than string or Buffer, then it must get an options object specifying objectMode: true. WType the type being written. If RType is Buffer or string, then this defaults to ContiguousData (Buffer, string, ArrayBuffer, or ArrayBufferView). Otherwise, it defaults to RType. Events type mapping event names to the arguments emitted with that event, which extends Minipass.Events. To declare types for custom events in subclasses, extend the third parameter with your own event signatures. For example: import { Minipass } from 'minipass' // a NDJSON stream that emits 'jsonError' when it can't stringify export interface Events extends Minipass.Events { jsonError: [e: Error] } export class NDJSONStream extends Minipass<string, any, Events> { constructor() { super({ objectMode: true }) } // data is type `any` because that's WType write(data, encoding, cb) { try { const json = JSON.stringify(data) return super.write(json + '\\n', encoding, cb) } catch (er) { if (!er instanceof Error) { er = Object.assign(new Error('json stringify failed'), { cause: er, }) } // trying to emit with something OTHER than an error will // fail, because we declared the event arguments type. this.emit('jsonError', er) } } } const s = new NDJSONStream() s.on('jsonError', e => { // here, TS knows that e is an Error }) Emitting/handling events that aren't declared in this way is fine, but the arguments will be typed as unknown. Differences from Node.js Streams There are several things that make Minipass streams different from (and in some ways superior to) Node.js core streams. Please read these caveats if you are familiar with node-core streams and intend to use Minipass streams in your programs. You can avoid most of these differences entirely (for a very small performance penalty) by setting {async: true} in the constructor options. Timing Minipass streams are designed to support synchronous use-cases. Thus, data is emitted as soon as it is available, always. It is buffered until read, but no longer. Another way to look at it is that Minipass streams are exactly as synchronous as the logic that writes into them. This can be surprising if your code relies on PassThrough.write() always providing data on the next tick rather than the current one, or being able to call resume() and not have the entire buffer disappear immediately. However, without this synchronicity guarantee, there would be no way for Minipass to achieve the speeds it does, or support the synchronous use cases that it does. Simply put, waiting takes time. This non-deferring approach makes Minipass streams much easier to reason about, especially in the context of Promises and other flow-control mechanisms. Example: // hybrid module, either works import { Minipass } from 'minipass' // or: const { Minipass } = require('minipass') const stream = new Minipass() stream.on('data', () => console.log('data event')) console.log('before write') stream.write('hello') console.log('after write') // output: // before write // data event // after write Exception: Async Opt-In If you wish to have a Minipass stream with behavior that more closely mimics Node.js core streams, you can set the stream in async mode either by setting async: true in the constructor options, or by setting stream.async = true later on. // hybrid module, either works import { Minipass } from 'minipass' // or: const { Minipass } = require('minipass') const asyncStream = new Minipass({ async: true }) asyncStream.on('data', () => console.log('data event')) console.log('before write') asyncStream.write('hello') console.log('after write') // output: // before write // after write // data event <-- this is deferred until the next tick Switching out of async mode is unsafe, as it could cause data corruption, and so is not enabled. Example: import { Minipass } from 'minipass' const stream = new Minipass({ encoding: 'utf8' }) stream.on('data', chunk => console.log(chunk)) stream.async = true console.log('before writes') stream.write('hello') setStreamSyncAgainSomehow(stream) // <-- this doesn't actually exist! stream.write('world') console.log('after writes') // hypothetical output would be: // before writes // world // after writes // hello // NOT GOOD! To avoid this problem, once set into async mode, any attempt to make the stream sync again will be ignored. const { Minipass } = require('minipass') const stream = new Minipass({ encoding: 'utf8' }) stream.on('data', chunk => console.log(chunk)) stream.async = true console.log('before writes') stream.write('hello') stream.async = false // <-- no-op, stream already async stream.write('world') console.log('after writes') // actual output: // before writes // after writes // hello // world No High/Low Water Marks Node.js core streams will optimistically fill up a buffer, returning true on all writes until the limit is hit, even if the data has nowhere to go. Then, they will not attempt to draw more data in until the buffer size dips below a minimum value. Minipass streams are much simpler. The write() method will return true if the data has somewhere to go (which is to say, given the timing guarantees, that the data is already there by the time write() returns). If the data has nowhere to go, then write() returns false, and the data sits in a buffer, to be drained out immediately as soon as anyone consumes it. Since nothing is ever buffered unnecessarily, there is much less copying data, and less bookkeeping about buffer capacity levels. Hazards of Buffering (or: Why Minipass Is So Fast) Since data written to a Minipass stream is immediately written all the way through the pipeline, and write() always returns true/false based on whether the data was fully flushed, backpressure is communicated immediately to the upstream caller. This minimizes buffering. Consider this case: const { PassThrough } = require('stream') const p1 = new PassThrough({ highWaterMark: 1024 }) const p2 = new PassThrough({ highWaterMark: 1024 }) const p3 = new PassThrough({ highWaterMark: 1024 }) const p4 = new PassThrough({ highWaterMark: 1024 }) p1.pipe(p2).pipe(p3).pipe(p4) p4.on('data', () => console.log('made it through')) // this returns false and buffers, then writes to p2 on next tick (1) // p2 returns false and buffers, pausing p1, then writes to p3 on next tick (2) // p3 returns false and buffers, pausing p2, then writes to p4 on next tick (3) // p4 returns false and buffers, pausing p3, then emits 'data' and 'drain' // on next tick (4) // p3 sees p4's 'drain' event, and calls resume(), emitting 'resume' and // 'drain' on next tick (5) // p2 sees p3's 'drain', calls resume(), emits 'resume' and 'drain' on next tick (6) // p1 sees p2's 'drain', calls resume(), emits 'resume' and 'drain' on next // tick (7) p1.write(Buffer.alloc(2048)) // returns false Along the way, the data was buffered and deferred at each stage, and multiple event deferrals happened, for an unblocked pipeline where it was perfectly safe to write all the way through! Furthermore, setting a highWaterMark of 1024 might lead someone reading the code to think an advisory maximum of 1KiB is being set for the pipeline. However, the actual advisory buffering level is the sum of highWaterMark values, since each one has its own bucket. Consider the Minipass case: const m1 = new Minipass() const m2 = new Minipass() const m3 = new Minipass() const m4 = new Minipass() m1.pipe(m2).pipe(m3).pipe(m4) m4.on('data', () => console.log('made it through')) // m1 is flowing, so it writes the data to m2 immediately // m2 is flowing, so it writes the data to m3 immediately // m3 is flowing, so it writes the data to m4 immediately // m4 is flowing, so it fires the 'data' event immediately, returns true // m4's write returned true, so m3 is still flowing, returns true // m3's write returned true, so m2 is still flowing, returns true // m2's write returned true, so m1 is still flowing, returns true // No event deferrals or buffering along the way! m1.write(Buffer.alloc(2048)) // returns true It is extremely unlikely that you don't want to buffer any data written, or ever buffer data that can be flushed all the way through. Neither node-core streams nor Minipass ever fail to buffer written data, but node-core streams do a lot of unnecessary buffering and pausing. As always, the faster implementation is the one that does less stuff and waits less time to do it. Immediately emit end for empty streams (when not paused) If a stream is not paused, and end() is called before writing any data into it, then it will emit end immediately. If you have logic that occurs on the end event which you don't want to potentially happen immediately (for example, closing file descriptors, moving on to the next entry in an archive parse stream, etc.) then be sure to call stream.pause() on creation, and then stream.resume() once you are ready to respond to the end event. However, this is usually not a problem because: Emit end When Asked One hazard of immediately emitting 'end' is that you may not yet have had a chance to add a listener. In order to avoid this hazard, Minipass streams safely re-emit the 'end' event if a new listener is added after 'end' has been emitted. Ie, if you do stream.on('end', someFunction), and the stream has already emitted end, then it will call the handler right away. (You can think of this somewhat like attaching a new .then(fn) to a previously-resolved Promise.) To prevent calling handlers multiple times who would not expect multiple ends to occur, all listeners are removed from the 'end' event whenever it is emitted. Emit error When Asked The most recent error object passed to the 'error' event is stored on the stream. If a new 'error' event handler is added, and an error was previously emitted, then the event handler will be called immediately (or on process.nextTick in the case of async streams). This makes it much more difficult to end up trying to interact with a broken stream, if the error handler is added after an error was previously emitted. Impact of \"immediate flow\" on Tee-streams A \"tee stream\" is a stream piping to multiple destinations: const tee = new Minipass() t.pipe(dest1) t.pipe(dest2) t.write('foo') // goes to both destinations Since Minipass streams immediately process any pending data through the pipeline when a new pipe destination is added, this can have surprising effects, especially when a stream comes in from some other function and may or may not have data in its buffer. // WARNING! WILL LOSE DATA! const src = new Minipass() src.write('foo') src.pipe(dest1) // 'foo' chunk flows to dest1 immediately, and is gone src.pipe(dest2) // gets nothing! One solution is to create a dedicated tee-stream junction that pipes to both locations, and then pipe to that instead. // Safe example: tee to both places const src = new Minipass() src.write('foo') const tee = new Minipass() tee.pipe(dest1) tee.pipe(dest2) src.pipe(tee) // tee gets 'foo', pipes to both locations The same caveat applies to on('data') event listeners. The first one added will immediately receive all of the data, leaving nothing for the second: // WARNING! WILL LOSE DATA! const src = new Minipass() src.write('foo') src.on('data', handler1) // receives 'foo' right away src.on('data', handler2) // nothing to see here! Using a dedicated tee-stream can be used in this case as well: // Safe example: tee to both data handlers const src = new Minipass() src.write('foo') const tee = new Minipass() tee.on('data', handler1) tee.on('data', handler2) src.pipe(tee) All of the hazards in this section are avoided by setting { async: true } in the Minipass constructor, or by setting stream.async = true afterwards. Note that this does add some overhead, so should only be done in cases where you are willing to lose a bit of performance in order to avoid having to refactor program logic. USAGE It's a stream! Use it like a stream and it'll most likely do what you want. import { Minipass } from 'minipass' const mp = new Minipass(options) // options is optional mp.write('foo') mp.pipe(someOtherStream) mp.end('bar') OPTIONS encoding How would you like the data coming out of the stream to be encoded? Accepts any values that can be passed to Buffer.toString(). objectMode Emit data exactly as it comes in. This will be flipped on by default if you write() something other than a string or Buffer at any point. Setting objectMode: true will prevent setting any encoding value. async Defaults to false. Set to true to defer data emission until next tick. This reduces performance slightly, but makes Minipass streams use timing behavior closer to Node core streams. See Timing for more details. signal An AbortSignal that will cause the stream to unhook itself from everything and become as inert as possible. Note that providing a signal parameter will make 'error' events no longer throw if they are unhandled, but they will still be emitted to handlers if any are attached. API Implements the user-facing portions of Node.js's Readable and Writable streams. Methods write(chunk, [encoding], [callback]) - Put data in. (Note that, in the base Minipass class, the same data will come out.) Returns false if the stream will buffer the next write, or true if it's still in \"flowing\" mode. end([chunk, [encoding]], [callback]) - Signal that you have no more data to write. This will queue an end event to be fired when all the data has been consumed. pause() - No more data for a while, please. This also prevents end from being emitted for empty streams until the stream is resumed. resume() - Resume the stream. If there's data in the buffer, it is all discarded. Any buffered events are immediately emitted. pipe(dest) - Send all output to the stream provided. When data is emitted, it is immediately written to any and all pipe destinations. (Or written on next tick in async mode.) unpipe(dest) - Stop piping to the destination stream. This is immediate, meaning that any asynchronously queued data will not make it to the destination when running in async mode. options.end - Boolean, end the destination stream when the source stream ends. Default true. options.proxyErrors - Boolean, proxy error events from the source stream to the destination stream. Note that errors are not proxied after the pipeline terminates, either due to the source emitting 'end' or manually unpiping with src.unpipe(dest). Default false. on(ev, fn), emit(ev, fn) - Minipass streams are EventEmitters. Some events are given special treatment, however. (See below under \"events\".) promise() - Returns a Promise that resolves when the stream emits end, or rejects if the stream emits error. collect() - Return a Promise that resolves on end with an array containing each chunk of data that was emitted, or rejects if the stream emits error. Note that this consumes the stream data. concat() - Same as collect(), but concatenates the data into a single Buffer object. Will reject the returned promise if the stream is in objectMode, or if it goes into objectMode by the end of the data. read(n) - Consume n bytes of data out of the buffer. If n is not provided, then consume all of it. If n bytes are not available, then it returns null. Note consuming streams in this way is less efficient, and can lead to unnecessary Buffer copying. destroy([er]) - Destroy the stream. If an error is provided, then an 'error' event is emitted. If the stream has a close() method, and has not emitted a 'close' event yet, then stream.close() will be called. Any Promises returned by .promise(), .collect() or .concat() will be rejected. After being destroyed, writing to the stream will emit an error. No more data will be emitted if the stream is destroyed, even if it was previously buffered. Properties bufferLength Read-only. Total number of bytes buffered, or in the case of objectMode, the total number of objects. encoding Read-only. The encoding that has been set. flowing Read-only. Boolean indicating whether a chunk written to the stream will be immediately emitted. emittedEnd Read-only. Boolean indicating whether the end-ish events (ie, end, prefinish, finish) have been emitted. Note that listening on any end-ish event will immediateyl re-emit it if it has already been emitted. writable Whether the stream is writable. Default true. Set to false when end() readable Whether the stream is readable. Default true. pipes An array of Pipe objects referencing streams that this stream is piping into. destroyed A getter that indicates whether the stream was destroyed. paused True if the stream has been explicitly paused, otherwise false. objectMode Indicates whether the stream is in objectMode. aborted Readonly property set when the AbortSignal dispatches an abort event. Events data Emitted when there's data to read. Argument is the data to read. This is never emitted while not flowing. If a listener is attached, that will resume the stream. end Emitted when there's no more data to read. This will be emitted immediately for empty streams when end() is called. If a listener is attached, and end was already emitted, then it will be emitted again. All listeners are removed when end is emitted. prefinish An end-ish event that follows the same logic as end and is emitted in the same conditions where end is emitted. Emitted after 'end'. finish An end-ish event that follows the same logic as end and is emitted in the same conditions where end is emitted. Emitted after 'prefinish'. close An indication that an underlying resource has been released. Minipass does not emit this event, but will defer it until after end has been emitted, since it throws off some stream libraries otherwise. drain Emitted when the internal buffer empties, and it is again suitable to write() into the stream. readable Emitted when data is buffered and ready to be read by a consumer. resume Emitted when stream changes state from buffering to flowing mode. (Ie, when resume is called, pipe is called, or a data event listener is added.) Static Methods Minipass.isStream(stream) Returns true if the argument is a stream, and false otherwise. To be considered a stream, the object must be either an instance of Minipass, or an EventEmitter that has either a pipe() method, or both write() and end() methods. (Pretty much any stream in node-land will return true for this.) EXAMPLES Here are some examples of things you can do with Minipass streams. simple \"are you done yet\" promise mp.promise().then( () => { // stream is finished }, er => { // stream emitted an error } ) collecting mp.collect().then(all => { // all is an array of all the data emitted // encoding is supported in this case, so // so the result will be a collection of strings if // an encoding is specified, or buffers/objects if not. // // In an async function, you may do // const data = await stream.collect() }) collecting into a single blob This is a bit slower because it concatenates the data into one chunk for you, but if you're going to do it yourself anyway, it's convenient this way: mp.concat().then(onebigchunk => { // onebigchunk is a string if the stream // had an encoding set, or a buffer otherwise. }) iteration You can iterate over streams synchronously or asynchronously in platforms that support it. Synchronous iteration will end when the currently available data is consumed, even if the end event has not been reached. In string and buffer mode, the data is concatenated, so unless multiple writes are occurring in the same tick as the read(), sync iteration loops will generally only have a single iteration. To consume chunks in this way exactly as they have been written, with no flattening, create the stream with the { objectMode: true } option. const mp = new Minipass({ objectMode: true }) mp.write('a') mp.write('b') for (let letter of mp) { console.log(letter) // a, b } mp.write('c') mp.write('d') for (let letter of mp) { console.log(letter) // c, d } mp.write('e') mp.end() for (let letter of mp) { console.log(letter) // e } for (let letter of mp) { console.log(letter) // nothing } Asynchronous iteration will continue until the end event is reached, consuming all of the data. const mp = new Minipass({ encoding: 'utf8' }) // some source of some data let i = 5 const inter = setInterval(() => { if (i-- > 0) mp.write(Buffer.from('foo\\n', 'utf8')) else { mp.end() clearInterval(inter) } }, 100) // consume the data with asynchronous iteration async function consume() { for await (let chunk of mp) { console.log(chunk) } return 'ok' } consume().then(res => console.log(res)) // logs `foo\\n` 5 times, and then `ok` subclass that console.log()s everything written into it class Logger extends Minipass { write(chunk, encoding, callback) { console.log('WRITE', chunk, encoding) return super.write(chunk, encoding, callback) } end(chunk, encoding, callback) { console.log('END', chunk, encoding) return super.end(chunk, encoding, callback) } } someSource.pipe(new Logger()).pipe(someDest) same thing, but using an inline anonymous class // js classes are fun someSource .pipe( new (class extends Minipass { emit(ev, ...data) { // let's also log events, because debugging some weird thing console.log('EMIT', ev) return super.emit(ev, ...data) } write(chunk, encoding, callback) { console.log('WRITE', chunk, encoding) return super.write(chunk, encoding, callback) } end(chunk, encoding, callback) { console.log('END', chunk, encoding) return super.end(chunk, encoding, callback) } })() ) .pipe(someDest) subclass that defers 'end' for some reason class SlowEnd extends Minipass { emit(ev, ...args) { if (ev === 'end') { console.log('going to end, hold on a sec') setTimeout(() => { console.log('ok, ready to end now') super.emit('end', ...args) }, 100) return true } else { return super.emit(ev, ...args) } } } transform that creates newline-delimited JSON class NDJSONEncode extends Minipass { write(obj, cb) { try { // JSON.stringify can throw, emit an error on that return super.write(JSON.stringify(obj) + '\\n', 'utf8', cb) } catch (er) { this.emit('error', er) } } end(obj, cb) { if (typeof obj === 'function') { cb = obj obj = undefined } if (obj !== undefined) { this.write(obj) } return super.end(cb) } } transform that parses newline-delimited JSON class NDJSONDecode extends Minipass { constructor(options) { // always be in object mode, as far as Minipass is concerned super({ objectMode: true }) this._jsonBuffer = '' } write(chunk, encoding, cb) { if ( typeof chunk === 'string' && typeof encoding === 'string' && encoding !== 'utf8' ) { chunk = Buffer.from(chunk, encoding).toString() } else if (Buffer.isBuffer(chunk)) { chunk = chunk.toString() } if (typeof encoding === 'function') { cb = encoding } const jsonData = (this._jsonBuffer + chunk).split('\\n') this._jsonBuffer = jsonData.pop() for (let i = 0; i < jsonData.length; i++) { try { // JSON.parse can throw, emit an error on that super.write(JSON.parse(jsonData[i])) } catch (er) { this.emit('error', er) continue } } if (cb) cb() } }"
  },
  "node_modules/mitt/CHANGELOG.html": {
    "href": "node_modules/mitt/CHANGELOG.html",
    "title": "Change Log | accouter",
    "keywords": "Change Log All notable changes to this project will be documented in this file. See standard-version for commit guidelines. 1.2.1 (2019-10-21) 1.1.3 (2017-12-07) 1.1.2 (2017-04-17) Bug Fixes builds: point jsnext:main to the ESM build instead of src, which contains things like Flowtype annotations that are not stripped by most build tools (0cad092) 1.1.1 (2017-04-15)"
  },
  "node_modules/mitt/README.html": {
    "href": "node_modules/mitt/README.html",
    "title": "Mitt | accouter",
    "keywords": "Mitt Tiny 200b functional event emitter / pubsub. Microscopic: weighs less than 200 bytes gzipped Useful: a wildcard \"*\" event type listens to all events Familiar: same names & ideas as Node's EventEmitter Functional: methods don't rely on this Great Name: somehow mitt wasn't taken Mitt was made for the browser, but works in any JavaScript runtime. It has no dependencies and supports IE9+. Table of Contents Install Usage Examples & Demos API Contribute License Install This project uses node and npm. Go check them out if you don't have them locally installed. $ npm install --save mitt Then with a module bundler like rollup or webpack, use as you would anything else: // using ES6 modules import mitt from 'mitt' // using CommonJS modules var mitt = require('mitt') The UMD build is also available on unpkg: <script src=\"https://unpkg.com/mitt/dist/mitt.umd.js\"></script> You can find the library on window.mitt. Usage import mitt from 'mitt' const emitter = mitt() // listen to an event emitter.on('foo', e => console.log('foo', e) ) // listen to all events emitter.on('*', (type, e) => console.log(type, e) ) // fire an event emitter.emit('foo', { a: 'b' }) // working with handler references: function onFoo() {} emitter.on('foo', onFoo) // listen emitter.off('foo', onFoo) // unlisten Typescript import mitt from 'mitt'; const emitter: mitt.Emitter = mitt(); Examples & Demos Preact + Mitt Codepen Demo API mitt Mitt: Tiny (~200b) functional event emitter / pubsub. Parameters all EventHandlerMap Returns Mitt on Register an event handler for the given type. Parameters type String Type of event to listen for, or \"*\" for all events handler Function Function to call in response to given event off Remove an event handler for the given type. Parameters type String Type of event to unregister handler from, or \"*\" handler Function Handler function to remove emit Invoke all handlers for the given type. If present, \"*\" handlers are invoked after type-matched handlers. Parameters type String The event type to invoke evt Any? Any value (object is recommended and powerful), passed to each handler Contribute First off, thanks for taking the time to contribute! Now, take a moment to be sure your contributions make sense to everyone else. Development Start: This project is typed with Flow Type annotations. To ensure you have the proper typings for this project run flow-typed install Reporting Issues Found a problem? Want a new feature? First of all see if your issue or idea has already been reported. If don't, just open a new clear and descriptive issue. Submitting pull requests Pull requests are the greatest contributions, so be sure they are focused in scope, and do avoid unrelated commits. Fork it! Clone your fork: git clone https://github.com/<your-username>/mitt Navigate to the newly cloned directory: cd mitt Create a new branch for the new feature: git checkout -b my-new-feature Install the tools necessary for development: npm install Make your changes. Commit your changes: git commit -am 'Add some feature' Push to the branch: git push origin my-new-feature Submit a pull request with full remarks documenting your changes. License MIT License © Jason Miller"
  },
  "node_modules/mocha/README.html": {
    "href": "node_modules/mocha/README.html",
    "title": "| accouter",
    "keywords": "☕️ Simple, flexible, fun JavaScript test framework for Node.js & The Browser ☕️ Links Documentation Release Notes / History / Changes Code of Conduct Contributing Development Discord (ask questions here!) Issue Tracker Backers Become a backer and show your support to our open source project on our site. Sponsors Does your company use Mocha? Ask your manager or marketing team if your company would be interested in supporting our project. Support will allow the maintainers to dedicate more time for maintenance and new features for everyone. Also, your company's logo will show on GitHub and on our site - who doesn't want a little extra exposure? Here's the info. Development You might want to know that: Mocha is one of the most-depended-upon modules on npm (source: libraries.io), and Mocha is an independent open-source project, maintained exclusively by volunteers. You might want to help: New to contributing to Mocha? Check out this list of good first issues Mocha could use a hand with these issues The maintainer's handbook explains how things get done Finally, come chat with the maintainers on Discord if you want to help with: Triaging issues, answering questions Review, merging, and closing pull requests Other project-maintenance-y things License Copyright 2011-2022 OpenJS Foundation and contributors. Licensed MIT."
  },
  "node_modules/mocha/node_modules/chokidar/README.html": {
    "href": "node_modules/mocha/node_modules/chokidar/README.html",
    "title": "Chokidar | accouter",
    "keywords": "Chokidar Minimal and efficient cross-platform file watching library Why? Node.js fs.watch: Doesn't report filenames on MacOS. Doesn't report events at all when using editors like Sublime on MacOS. Often reports events twice. Emits most changes as rename. Does not provide an easy way to recursively watch file trees. Does not support recursive watching on Linux. Node.js fs.watchFile: Almost as bad at event handling. Also does not provide any recursive watching. Results in high CPU utilization. Chokidar resolves these problems. Initially made for Brunch (an ultra-swift web app build tool), it is now used in Microsoft's Visual Studio Code, gulp, karma, PM2, browserify, webpack, BrowserSync, and many others. It has proven itself in production environments. Version 3 is out! Check out our blog post about it: Chokidar 3: How to save 32TB of traffic every week How? Chokidar does still rely on the Node.js core fs module, but when using fs.watch and fs.watchFile for watching, it normalizes the events it receives, often checking for truth by getting file stats and/or dir contents. On MacOS, chokidar by default uses a native extension exposing the Darwin FSEvents API. This provides very efficient recursive watching compared with implementations like kqueue available on most *nix platforms. Chokidar still does have to do some work to normalize the events received that way as well. On most other platforms, the fs.watch-based implementation is the default, which avoids polling and keeps CPU usage down. Be advised that chokidar will initiate watchers recursively for everything within scope of the paths that have been specified, so be judicious about not wasting system resources by watching much more than needed. Getting started Install with npm: npm install chokidar Then require and use it in your code: const chokidar = require('chokidar'); // One-liner for current directory chokidar.watch('.').on('all', (event, path) => { console.log(event, path); }); API // Example of a more typical implementation structure // Initialize watcher. const watcher = chokidar.watch('file, dir, glob, or array', { ignored: /(^|[\\/\\\\])\\../, // ignore dotfiles persistent: true }); // Something to use when events are received. const log = console.log.bind(console); // Add event listeners. watcher .on('add', path => log(`File ${path} has been added`)) .on('change', path => log(`File ${path} has been changed`)) .on('unlink', path => log(`File ${path} has been removed`)); // More possible events. watcher .on('addDir', path => log(`Directory ${path} has been added`)) .on('unlinkDir', path => log(`Directory ${path} has been removed`)) .on('error', error => log(`Watcher error: ${error}`)) .on('ready', () => log('Initial scan complete. Ready for changes')) .on('raw', (event, path, details) => { // internal log('Raw event info:', event, path, details); }); // 'add', 'addDir' and 'change' events also receive stat() results as second // argument when available: https://nodejs.org/api/fs.html#fs_class_fs_stats watcher.on('change', (path, stats) => { if (stats) console.log(`File ${path} changed size to ${stats.size}`); }); // Watch new files. watcher.add('new-file'); watcher.add(['new-file-2', 'new-file-3', '**/other-file*']); // Get list of actual paths being watched on the filesystem var watchedPaths = watcher.getWatched(); // Un-watch some files. await watcher.unwatch('new-file*'); // Stop watching. // The method is async! watcher.close().then(() => console.log('closed')); // Full list of options. See below for descriptions. // Do not use this example! chokidar.watch('file', { persistent: true, ignored: '*.txt', ignoreInitial: false, followSymlinks: true, cwd: '.', disableGlobbing: false, usePolling: false, interval: 100, binaryInterval: 300, alwaysStat: false, depth: 99, awaitWriteFinish: { stabilityThreshold: 2000, pollInterval: 100 }, ignorePermissionErrors: false, atomic: true // or a custom 'atomicity delay', in milliseconds (default 100) }); chokidar.watch(paths, [options]) paths (string or array of strings). Paths to files, dirs to be watched recursively, or glob patterns. Note: globs must not contain windows separators (\\), because that's how they work by the standard — you'll need to replace them with forward slashes (/). Note 2: for additional glob documentation, check out low-level library: picomatch. options (object) Options object as defined below: Persistence persistent (default: true). Indicates whether the process should continue to run as long as files are being watched. If set to false when using fsevents to watch, no more events will be emitted after ready, even if the process continues to run. Path filtering ignored (anymatch-compatible definition) Defines files/paths to be ignored. The whole relative or absolute path is tested, not just filename. If a function with two arguments is provided, it gets called twice per path - once with a single argument (the path), second time with two arguments (the path and the fs.Stats object of that path). ignoreInitial (default: false). If set to false then add/addDir events are also emitted for matching paths while instantiating the watching as chokidar discovers these file paths (before the ready event). followSymlinks (default: true). When false, only the symlinks themselves will be watched for changes instead of following the link references and bubbling events through the link's path. cwd (no default). The base directory from which watch paths are to be derived. Paths emitted with events will be relative to this. disableGlobbing (default: false). If set to true then the strings passed to .watch() and .add() are treated as literal path names, even if they look like globs. Performance usePolling (default: false). Whether to use fs.watchFile (backed by polling), or fs.watch. If polling leads to high CPU utilization, consider setting this to false. It is typically necessary to set this to true to successfully watch files over a network, and it may be necessary to successfully watch files in other non-standard situations. Setting to true explicitly on MacOS overrides the useFsEvents default. You may also set the CHOKIDAR_USEPOLLING env variable to true (1) or false (0) in order to override this option. Polling-specific settings (effective when usePolling: true) interval (default: 100). Interval of file system polling, in milliseconds. You may also set the CHOKIDAR_INTERVAL env variable to override this option. binaryInterval (default: 300). Interval of file system polling for binary files. (see list of binary extensions) useFsEvents (default: true on MacOS). Whether to use the fsevents watching interface if available. When set to true explicitly and fsevents is available this supercedes the usePolling setting. When set to false on MacOS, usePolling: true becomes the default. alwaysStat (default: false). If relying upon the fs.Stats object that may get passed with add, addDir, and change events, set this to true to ensure it is provided even in cases where it wasn't already available from the underlying watch events. depth (default: undefined). If set, limits how many levels of subdirectories will be traversed. awaitWriteFinish (default: false). By default, the add event will fire when a file first appears on disk, before the entire file has been written. Furthermore, in some cases some change events will be emitted while the file is being written. In some cases, especially when watching for large files there will be a need to wait for the write operation to finish before responding to a file creation or modification. Setting awaitWriteFinish to true (or a truthy value) will poll file size, holding its add and change events until the size does not change for a configurable amount of time. The appropriate duration setting is heavily dependent on the OS and hardware. For accurate detection this parameter should be relatively high, making file watching much less responsive. Use with caution. options.awaitWriteFinish can be set to an object in order to adjust timing params: awaitWriteFinish.stabilityThreshold (default: 2000). Amount of time in milliseconds for a file size to remain constant before emitting its event. awaitWriteFinish.pollInterval (default: 100). File size polling interval, in milliseconds. Errors ignorePermissionErrors (default: false). Indicates whether to watch files that don't have read permissions if possible. If watching fails due to EPERM or EACCES with this set to true, the errors will be suppressed silently. atomic (default: true if useFsEvents and usePolling are false). Automatically filters out artifacts that occur when using editors that use \"atomic writes\" instead of writing directly to the source file. If a file is re-added within 100 ms of being deleted, Chokidar emits a change event rather than unlink then add. If the default of 100 ms does not work well for you, you can override it by setting atomic to a custom value, in milliseconds. Methods & Events chokidar.watch() produces an instance of FSWatcher. Methods of FSWatcher: .add(path / paths): Add files, directories, or glob patterns for tracking. Takes an array of strings or just one string. .on(event, callback): Listen for an FS event. Available events: add, addDir, change, unlink, unlinkDir, ready, raw, error. Additionally all is available which gets emitted with the underlying event name and path for every event other than ready, raw, and error. raw is internal, use it carefully. .unwatch(path / paths): Stop watching files, directories, or glob patterns. Takes an array of strings or just one string. .close(): async Removes all listeners from watched files. Asynchronous, returns Promise. Use with await to ensure bugs don't happen. .getWatched(): Returns an object representing all the paths on the file system being watched by this FSWatcher instance. The object's keys are all the directories (using absolute paths unless the cwd option was used), and the values are arrays of the names of the items contained in each directory. CLI If you need a CLI interface for your file watching, check out chokidar-cli, allowing you to execute a command on each change, or get a stdio stream of change events. Install Troubleshooting npm WARN optional dep failed, continuing fsevents@n.n.n This message is normal part of how npm handles optional dependencies and is not indicative of a problem. Even if accompanied by other related error messages, Chokidar should function properly. TypeError: fsevents is not a constructor Update chokidar by doing rm -rf node_modules package-lock.json yarn.lock && npm install, or update your dependency that uses chokidar. Chokidar is producing ENOSP error on Linux, like this: bash: cannot set terminal process group (-1): Inappropriate ioctl for device bash: no job control in this shell Error: watch /home/ ENOSPC This means Chokidar ran out of file handles and you'll need to increase their count by executing the following command in Terminal: echo fs.inotify.max_user_watches=524288 | sudo tee -a /etc/sysctl.conf && sudo sysctl -p Changelog For more detailed changelog, see full_changelog.md. v3.5 (Jan 6, 2021): Support for ARM Macs with Apple Silicon. Fixes for deleted symlinks. v3.4 (Apr 26, 2020): Support for directory-based symlinks. Fixes for macos file replacement. v3.3 (Nov 2, 2019): FSWatcher#close() method became async. That fixes IO race conditions related to close method. v3.2 (Oct 1, 2019): Improve Linux RAM usage by 50%. Race condition fixes. Windows glob fixes. Improve stability by using tight range of dependency versions. v3.1 (Sep 16, 2019): dotfiles are no longer filtered out by default. Use ignored option if needed. Improve initial Linux scan time by 50%. v3 (Apr 30, 2019): massive CPU & RAM consumption improvements; reduces deps / package size by a factor of 17x and bumps Node.js requirement to v8.16 and higher. v2 (Dec 29, 2017): Globs are now posix-style-only; without windows support. Tons of bugfixes. v1 (Apr 7, 2015): Glob support, symlink support, tons of bugfixes. Node 0.8+ is supported v0.1 (Apr 20, 2012): Initial release, extracted from Brunch Also Why was chokidar named this way? What's the meaning behind it? Chowkidar is a transliteration of a Hindi word meaning 'watchman, gatekeeper', चौकीदार. This ultimately comes from Sanskrit _ चतुष्क_ (crossway, quadrangle, consisting-of-four). License MIT (c) Paul Miller (https://paulmillr.com), see LICENSE file."
  },
  "node_modules/mocha/node_modules/cliui/CHANGELOG.html": {
    "href": "node_modules/mocha/node_modules/cliui/CHANGELOG.html",
    "title": "Change Log | accouter",
    "keywords": "Change Log All notable changes to this project will be documented in this file. See standard-version for commit guidelines. 7.0.4 (2020-11-08) Bug Fixes deno: import UIOptions from definitions (#97) (f04f343) 7.0.3 (2020-10-16) Bug Fixes exports: node 13.0 and 13.1 require the dotted object form with a string fallback (#93) (eca16fc) 7.0.2 (2020-10-14) Bug Fixes exports: node 13.0-13.6 require a string fallback (#91) (b529d7e) 7.0.1 (2020-08-16) Bug Fixes build: main should be build/index.cjs (dc29a3c) 7.0.0 (2020-08-16) ⚠ BREAKING CHANGES tsc/ESM/Deno support (#82) modernize deps and build (#80) Build System modernize deps and build (#80) (339d08d) Code Refactoring tsc/ESM/Deno support (#82) (4b777a5) 6.0.0 (2019-11-10) ⚠ BREAKING CHANGES update deps, drop Node 6 Code Refactoring update deps, drop Node 6 (62056df) 5.0.0 (2019-04-10) Bug Fixes Update wrap-ansi to fix compatibility with latest versions of chalk. (#60) (7bf79ae) BREAKING CHANGES Drop support for node < 6. 4.1.0 (2018-04-23) Features add resetOutput method (#57) (7246902) 4.0.0 (2017-12-18) Bug Fixes downgrades strip-ansi to version 3.0.1 (#54) (5764c46) set env variable FORCE_COLOR. (#56) (7350e36) Chores drop support for node < 4 (#53) (b105376) Features add fallback for window width (#45) (d064922) BREAKING CHANGES officially drop support for Node < 4 3.2.0 (2016-04-11) Bug Fixes reduces tarball size (acc6c33) Features adds standard-version for release management (ff84e32)"
  },
  "node_modules/mocha/node_modules/cliui/README.html": {
    "href": "node_modules/mocha/node_modules/cliui/README.html",
    "title": "cliui | accouter",
    "keywords": "cliui easily create complex multi-column command-line-interfaces. Example const ui = require('cliui')() ui.div('Usage: $0 [command] [options]') ui.div({ text: 'Options:', padding: [2, 0, 1, 0] }) ui.div( { text: \"-f, --file\", width: 20, padding: [0, 4, 0, 4] }, { text: \"the file to load.\" + chalk.green(\"(if this description is long it wraps).\") , width: 20 }, { text: chalk.red(\"[required]\"), align: 'right' } ) console.log(ui.toString()) Deno/ESM Support As of v7 cliui supports Deno and ESM: import cliui from \"https://deno.land/x/cliui/deno.ts\"; const ui = cliui({}) ui.div('Usage: $0 [command] [options]') ui.div({ text: 'Options:', padding: [2, 0, 1, 0] }) ui.div({ text: \"-f, --file\", width: 20, padding: [0, 4, 0, 4] }) console.log(ui.toString()) Layout DSL cliui exposes a simple layout DSL: If you create a single ui.div, passing a string rather than an object: \\n: characters will be interpreted as new rows. \\t: characters will be interpreted as new columns. \\s: characters will be interpreted as padding. as an example... var ui = require('./')({ width: 60 }) ui.div( 'Usage: node ./bin/foo.js\\n' + ' <regex>\\t provide a regex\\n' + ' <glob>\\t provide a glob\\t [required]' ) console.log(ui.toString()) will output: Usage: node ./bin/foo.js <regex> provide a regex <glob> provide a glob [required] Methods cliui = require('cliui') cliui({width: integer}) Specify the maximum width of the UI being generated. If no width is provided, cliui will try to get the current window's width and use it, and if that doesn't work, width will be set to 80. cliui({wrap: boolean}) Enable or disable the wrapping of text in a column. cliui.div(column, column, column) Create a row with any number of columns, a column can either be a string, or an object with the following options: text: some text to place in the column. width: the width of a column. align: alignment, right or center. padding: [top, right, bottom, left]. border: should a border be placed around the div? cliui.span(column, column, column) Similar to div, except the next row will be appended without a new line being created. cliui.resetOutput() Resets the UI elements of the current cliui instance, maintaining the values set for width and wrap."
  },
  "node_modules/mocha/node_modules/debug/README.html": {
    "href": "node_modules/mocha/node_modules/debug/README.html",
    "title": "debug | accouter",
    "keywords": "debug A tiny JavaScript debugging utility modelled after Node.js core's debugging technique. Works in Node.js and web browsers. Installation $ npm install debug Usage debug exposes a function; simply pass this function the name of your module, and it will return a decorated version of console.error for you to pass debug statements to. This will allow you to toggle the debug output for different parts of your module as well as the module as a whole. Example app.js: var debug = require('debug')('http') , http = require('http') , name = 'My App'; // fake app debug('booting %o', name); http.createServer(function(req, res){ debug(req.method + ' ' + req.url); res.end('hello\\n'); }).listen(3000, function(){ debug('listening'); }); // fake worker of some kind require('./worker'); Example worker.js: var a = require('debug')('worker:a') , b = require('debug')('worker:b'); function work() { a('doing lots of uninteresting work'); setTimeout(work, Math.random() * 1000); } work(); function workb() { b('doing some work'); setTimeout(workb, Math.random() * 2000); } workb(); The DEBUG environment variable is then used to enable these based on space or comma-delimited names. Here are some examples: Windows command prompt notes CMD On Windows the environment variable is set using the set command. set DEBUG=*,-not_this Example: set DEBUG=* & node app.js PowerShell (VS Code default) PowerShell uses different syntax to set environment variables. $env:DEBUG = \"*,-not_this\" Example: $env:DEBUG='app';node app.js Then, run the program to be debugged as usual. npm script example: \"windowsDebug\": \"@powershell -Command $env:DEBUG='*';node app.js\", Namespace Colors Every debug instance has a color generated for it based on its namespace name. This helps when visually parsing the debug output to identify which debug instance a debug line belongs to. Node.js In Node.js, colors are enabled when stderr is a TTY. You also should install the supports-color module alongside debug, otherwise debug will only use a small handful of basic colors. Web Browser Colors are also enabled on \"Web Inspectors\" that understand the %c formatting option. These are WebKit web inspectors, Firefox (since version 31) and the Firebug plugin for Firefox (any version). Millisecond diff When actively developing an application it can be useful to see when the time spent between one debug() call and the next. Suppose for example you invoke debug() before requesting a resource, and after as well, the \"+NNNms\" will show you how much time was spent between calls. When stdout is not a TTY, Date#toISOString() is used, making it more useful for logging the debug information as shown below: Conventions If you're using this in one or more of your libraries, you should use the name of your library so that developers may toggle debugging as desired without guessing names. If you have more than one debuggers you should prefix them with your library name and use \":\" to separate features. For example \"bodyParser\" from Connect would then be \"connect:bodyParser\". If you append a \"*\" to the end of your name, it will always be enabled regardless of the setting of the DEBUG environment variable. You can then use it for normal output as well as debug output. Wildcards The * character may be used as a wildcard. Suppose for example your library has debuggers named \"connect:bodyParser\", \"connect:compress\", \"connect:session\", instead of listing all three with DEBUG=connect:bodyParser,connect:compress,connect:session, you may simply do DEBUG=connect:*, or to run everything using this module simply use DEBUG=*. You can also exclude specific debuggers by prefixing them with a \"-\" character. For example, DEBUG=*,-connect:* would include all debuggers except those starting with \"connect:\". Environment Variables When running through Node.js, you can set a few environment variables that will change the behavior of the debug logging: Name Purpose DEBUG Enables/disables specific debugging namespaces. DEBUG_HIDE_DATE Hide date from debug output (non-TTY). DEBUG_COLORS Whether or not to use colors in the debug output. DEBUG_DEPTH Object inspection depth. DEBUG_SHOW_HIDDEN Shows hidden properties on inspected objects. Note: The environment variables beginning with DEBUG_ end up being converted into an Options object that gets used with %o/%O formatters. See the Node.js documentation for util.inspect() for the complete list. Formatters Debug uses printf-style formatting. Below are the officially supported formatters: Formatter Representation %O Pretty-print an Object on multiple lines. %o Pretty-print an Object all on a single line. %s String. %d Number (both integer and float). %j JSON. Replaced with the string '[Circular]' if the argument contains circular references. %% Single percent sign ('%'). This does not consume an argument. Custom formatters You can add custom formatters by extending the debug.formatters object. For example, if you wanted to add support for rendering a Buffer as hex with %h, you could do something like: const createDebug = require('debug') createDebug.formatters.h = (v) => { return v.toString('hex') } // …elsewhere const debug = createDebug('foo') debug('this is hex: %h', new Buffer('hello world')) // foo this is hex: 68656c6c6f20776f726c6421 +0ms Browser Support You can build a browser-ready script using browserify, or just use the browserify-as-a-service build, if you don't want to build it yourself. Debug's enable state is currently persisted by localStorage. Consider the situation shown below where you have worker:a and worker:b, and wish to debug both. You can enable this using localStorage.debug: localStorage.debug = 'worker:*' And then refresh the page. a = debug('worker:a'); b = debug('worker:b'); setInterval(function(){ a('doing some work'); }, 1000); setInterval(function(){ b('doing some work'); }, 1200); In Chromium-based web browsers (e.g. Brave, Chrome, and Electron), the JavaScript console will—by default—only show messages logged by debug if the \"Verbose\" log level is enabled. Output streams By default debug will log to stderr, however this can be configured per-namespace by overriding the log method: Example stdout.js: var debug = require('debug'); var error = debug('app:error'); // by default stderr is used error('goes to stderr!'); var log = debug('app:log'); // set this namespace to log via console.log log.log = console.log.bind(console); // don't forget to bind to console! log('goes to stdout'); error('still goes to stderr!'); // set all output to go via console.info // overrides all per-namespace log settings debug.log = console.info.bind(console); error('now goes to stdout via console.info'); log('still goes to stdout, but via console.info now'); Extend You can simply extend debugger const log = require('debug')('auth'); //creates new debug instance with extended namespace const logSign = log.extend('sign'); const logLogin = log.extend('login'); log('hello'); // auth hello logSign('hello'); //auth:sign hello logLogin('hello'); //auth:login hello Set dynamically You can also enable debug dynamically by calling the enable() method : let debug = require('debug'); console.log(1, debug.enabled('test')); debug.enable('test'); console.log(2, debug.enabled('test')); debug.disable(); console.log(3, debug.enabled('test')); print : 1 false 2 true 3 false Usage : enable(namespaces) namespaces can include modes separated by a colon and wildcards. Note that calling enable() completely overrides previously set DEBUG variable : $ DEBUG=foo node -e 'var dbg = require(\"debug\"); dbg.enable(\"bar\"); console.log(dbg.enabled(\"foo\"))' => false disable() Will disable all namespaces. The functions returns the namespaces currently enabled (and skipped). This can be useful if you want to disable debugging temporarily without knowing what was enabled to begin with. For example: let debug = require('debug'); debug.enable('foo:*,-foo:bar'); let namespaces = debug.disable(); debug.enable(namespaces); Note: There is no guarantee that the string will be identical to the initial enable string, but semantically they will be identical. Checking whether a debug target is enabled After you've created a debug instance, you can determine whether or not it is enabled by checking the enabled property: const debug = require('debug')('http'); if (debug.enabled) { // do stuff... } You can also manually toggle this property to force the debug instance to be enabled or disabled. Usage in child processes Due to the way debug detects if the output is a TTY or not, colors are not shown in child processes when stderr is piped. A solution is to pass the DEBUG_COLORS=1 environment variable to the child process. For example: worker = fork(WORKER_WRAP_PATH, [workerPath], { stdio: [ /* stdin: */ 0, /* stdout: */ 'pipe', /* stderr: */ 'pipe', 'ipc', ], env: Object.assign({}, process.env, { DEBUG_COLORS: 1 // without this settings, colors won't be shown }), }); worker.stderr.pipe(process.stderr, { end: false }); Authors TJ Holowaychuk Nathan Rajlich Andrew Rhyne Josh Junon Backers Support us with a monthly donation and help us continue our activities. [Become a backer] Sponsors Become a sponsor and get your logo on our README on Github with a link to your site. [Become a sponsor] License (The MIT License) Copyright (c) 2014-2017 TJ Holowaychuk <tj@vision-media.ca&gt; Copyright (c) 2018-2021 Josh Junon Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/mocha/node_modules/debug/node_modules/ms/license.html": {
    "href": "node_modules/mocha/node_modules/debug/node_modules/ms/license.html",
    "title": "| accouter",
    "keywords": "The MIT License (MIT) Copyright (c) 2016 Zeit, Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/mocha/node_modules/debug/node_modules/ms/readme.html": {
    "href": "node_modules/mocha/node_modules/debug/node_modules/ms/readme.html",
    "title": "ms | accouter",
    "keywords": "ms Use this package to easily convert various time formats to milliseconds. Examples ms('2 days') // 172800000 ms('1d') // 86400000 ms('10h') // 36000000 ms('2.5 hrs') // 9000000 ms('2h') // 7200000 ms('1m') // 60000 ms('5s') // 5000 ms('1y') // 31557600000 ms('100') // 100 ms('-3 days') // -259200000 ms('-1h') // -3600000 ms('-200') // -200 Convert from Milliseconds ms(60000) // \"1m\" ms(2 * 60000) // \"2m\" ms(-3 * 60000) // \"-3m\" ms(ms('10 hours')) // \"10h\" Time Format Written-Out ms(60000, { long: true }) // \"1 minute\" ms(2 * 60000, { long: true }) // \"2 minutes\" ms(-3 * 60000, { long: true }) // \"-3 minutes\" ms(ms('10 hours'), { long: true }) // \"10 hours\" Features Works both in Node.js and in the browser If a number is supplied to ms, a string with a unit is returned If a string that contains the number is supplied, it returns it as a number (e.g.: it returns 100 for '100') If you pass a string with a number and a valid unit, the number of equivalent milliseconds is returned Related Packages ms.macro - Run ms as a macro at build-time. Caught a Bug? Fork this repository to your own GitHub account and then clone it to your local device Link the package to the global module directory: npm link Within the module you want to test your local development instance of ms, just link it to the dependencies: npm link ms. Instead of the default one from npm, Node.js will now use your clone of ms! As always, you can run the tests using: npm test"
  },
  "node_modules/mocha/node_modules/ms/license.html": {
    "href": "node_modules/mocha/node_modules/ms/license.html",
    "title": "| accouter",
    "keywords": "The MIT License (MIT) Copyright (c) 2020 Vercel, Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/mocha/node_modules/ms/readme.html": {
    "href": "node_modules/mocha/node_modules/ms/readme.html",
    "title": "ms | accouter",
    "keywords": "ms Use this package to easily convert various time formats to milliseconds. Examples ms('2 days') // 172800000 ms('1d') // 86400000 ms('10h') // 36000000 ms('2.5 hrs') // 9000000 ms('2h') // 7200000 ms('1m') // 60000 ms('5s') // 5000 ms('1y') // 31557600000 ms('100') // 100 ms('-3 days') // -259200000 ms('-1h') // -3600000 ms('-200') // -200 Convert from Milliseconds ms(60000) // \"1m\" ms(2 * 60000) // \"2m\" ms(-3 * 60000) // \"-3m\" ms(ms('10 hours')) // \"10h\" Time Format Written-Out ms(60000, { long: true }) // \"1 minute\" ms(2 * 60000, { long: true }) // \"2 minutes\" ms(-3 * 60000, { long: true }) // \"-3 minutes\" ms(ms('10 hours'), { long: true }) // \"10 hours\" Features Works both in Node.js and in the browser If a number is supplied to ms, a string with a unit is returned If a string that contains the number is supplied, it returns it as a number (e.g.: it returns 100 for '100') If you pass a string with a number and a valid unit, the number of equivalent milliseconds is returned Related Packages ms.macro - Run ms as a macro at build-time. Caught a Bug? Fork this repository to your own GitHub account and then clone it to your local device Link the package to the global module directory: npm link Within the module you want to test your local development instance of ms, just link it to the dependencies: npm link ms. Instead of the default one from npm, Node.js will now use your clone of ms! As always, you can run the tests using: npm test"
  },
  "node_modules/mocha/node_modules/supports-color/readme.html": {
    "href": "node_modules/mocha/node_modules/supports-color/readme.html",
    "title": "supports-color | accouter",
    "keywords": "supports-color Detect whether a terminal supports color Install $ npm install supports-color Usage const supportsColor = require('supports-color'); if (supportsColor.stdout) { console.log('Terminal stdout supports color'); } if (supportsColor.stdout.has256) { console.log('Terminal stdout supports 256 colors'); } if (supportsColor.stderr.has16m) { console.log('Terminal stderr supports 16 million colors (truecolor)'); } API Returns an Object with a stdout and stderr property for testing either streams. Each property is an Object, or false if color is not supported. The stdout/stderr objects specifies a level of support for color through a .level property and a corresponding flag: .level = 1 and .hasBasic = true: Basic color support (16 colors) .level = 2 and .has256 = true: 256 color support .level = 3 and .has16m = true: Truecolor support (16 million colors) require('supports-color').supportsColor(stream, options?) Additionally, supports-color exposes the .supportsColor() function that takes an arbitrary write stream (e.g. process.stdout) and an optional options object to (re-)evaluate color support for an arbitrary stream. For example, require('supports-color').stdout is the equivalent of require('supports-color').supportsColor(process.stdout). The options object supports a single boolean property sniffFlags. By default it is true, which instructs supportsColor() to sniff process.argv for the multitude of --color flags (see Info below). If false, then process.argv is not considered when determining color support. Info It obeys the --color and --no-color CLI flags. For situations where using --color is not possible, use the environment variable FORCE_COLOR=1 (level 1), FORCE_COLOR=2 (level 2), or FORCE_COLOR=3 (level 3) to forcefully enable color, or FORCE_COLOR=0 to forcefully disable. The use of FORCE_COLOR overrides all other color support checks. Explicit 256/Truecolor mode can be enabled using the --color=256 and --color=16m flags, respectively. Related supports-color-cli - CLI for this module chalk - Terminal string styling done right Maintainers Sindre Sorhus Josh Junon Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "node_modules/mocha/node_modules/yargs/CHANGELOG.html": {
    "href": "node_modules/mocha/node_modules/yargs/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. See standard-version for commit guidelines. 16.2.0 (2020-12-05) Features command() now accepts an array of modules (f415388) Bug Fixes add package.json to module exports (#1818) (d783a49), closes #1817 16.1.1 (2020-11-15) Bug Fixes expose helpers for legacy versions of Node.js (#1801) (107deaa) deno: get yargs working on deno@1.5.x (#1799) (cb01c98) 16.1.0 (2020-10-15) Features expose hideBin helper for CJS (#1768) (63e1173) Bug Fixes deno: update types for deno ^1.4.0 (#1772) (0801752) exports: node 13.0-13.6 require a string fallback (#1776) (b45c43a) modules: module path was incorrect (#1759) (95a4a0a) positional: positional strings no longer drop decimals (#1761) (e1a300f) make positionals in -- count towards validation (#1752) (eb2b29d) 16.0.3 (2020-09-10) Bug Fixes move yargs.cjs to yargs to fix Node 10 imports (#1747) (5bfb85b) 16.0.2 (2020-09-09) Bug Fixes typescript: yargs-parser was breaking @types/yargs (#1745) (2253284) 16.0.1 (2020-09-09) Bug Fixes code was not passed to process.exit (#1742) (d1a9930) 16.0.0 (2020-09-09) ⚠ BREAKING CHANGES tweaks to ESM/Deno API surface: now exports yargs function by default; getProcessArgvWithoutBin becomes hideBin; types now exported for Deno. find-up replaced with escalade; export map added (limits importable files in Node >= 12); yarser-parser@19.x.x (new decamelize/camelcase implementation). usage: single character aliases are now shown first in help output rebase helper is no longer provided on yargs instance. drop support for EOL Node 8 (#1686) Features adds strictOptions() (#1738) (b215fba) helpers: rebase, Parser, applyExtends now blessed helpers (#1733) (c7debe8) adds support for ESM and Deno (#1708) (ac6d5d1) drop support for EOL Node 8 (#1686) (863937f) i18n for ESM and Deno (#1735) (c71783a) tweaks to API surface based on user feedback (#1726) (4151fee) usage: single char aliases first in help (#1574) (a552990) Bug Fixes yargs: add missing command(module) signature (#1707) (0f81024), closes #1704 Older CHANGELOG Entries"
  },
  "node_modules/mocha/node_modules/yargs/README.html": {
    "href": "node_modules/mocha/node_modules/yargs/README.html",
    "title": "Yargs | accouter",
    "keywords": "Yargs Yargs be a node.js library fer hearties tryin' ter parse optstrings Description Yargs helps you build interactive command line tools, by parsing arguments and generating an elegant user interface. It gives you: commands and (grouped) options (my-program.js serve --port=5000). a dynamically generated help menu based on your arguments: mocha [spec..] Run tests with Mocha Commands mocha inspect [spec..] Run tests with Mocha [default] mocha init <path> create a client-side Mocha setup at <path> Rules & Behavior --allow-uncaught Allow uncaught errors to propagate [boolean] --async-only, -A Require all tests to use a callback (async) or return a Promise [boolean] bash-completion shortcuts for commands and options. and tons more. Installation Stable version: npm i yargs Bleeding edge version with the most recent features: npm i yargs@next Usage Simple Example #!/usr/bin/env node const yargs = require('yargs/yargs') const { hideBin } = require('yargs/helpers') const argv = yargs(hideBin(process.argv)).argv if (argv.ships > 3 && argv.distance < 53.5) { console.log('Plunder more riffiwobbles!') } else { console.log('Retreat from the xupptumblers!') } $ ./plunder.js --ships=4 --distance=22 Plunder more riffiwobbles! $ ./plunder.js --ships 12 --distance 98.7 Retreat from the xupptumblers! Complex Example #!/usr/bin/env node const yargs = require('yargs/yargs') const { hideBin } = require('yargs/helpers') yargs(hideBin(process.argv)) .command('serve [port]', 'start the server', (yargs) => { yargs .positional('port', { describe: 'port to bind on', default: 5000 }) }, (argv) => { if (argv.verbose) console.info(`start server on :${argv.port}`) serve(argv.port) }) .option('verbose', { alias: 'v', type: 'boolean', description: 'Run with verbose logging' }) .argv Run the example above with --help to see the help for the application. Supported Platforms TypeScript yargs has type definitions at @types/yargs. npm i @types/yargs --save-dev See usage examples in docs. Deno As of v16, yargs supports Deno: import yargs from 'https://deno.land/x/yargs/deno.ts' import { Arguments } from 'https://deno.land/x/yargs/deno-types.ts' yargs(Deno.args) .command('download <files...>', 'download a list of files', (yargs: any) => { return yargs.positional('files', { describe: 'a list of files to do something with' }) }, (argv: Arguments) => { console.info(argv) }) .strictCommands() .demandCommand(1) .argv ESM As of v16,yargs supports ESM imports: import yargs from 'yargs' import { hideBin } from 'yargs/helpers' yargs(hideBin(process.argv)) .command('curl <url>', 'fetch the contents of the URL', () => {}, (argv) => { console.info(argv) }) .demandCommand(1) .argv Usage in Browser See examples of using yargs in the browser in docs. Community Having problems? want to contribute? join our community slack. Documentation Table of Contents Yargs' API Examples Parsing Tricks Stop the Parser Negating Boolean Arguments Numbers Arrays Objects Quotes Advanced Topics Composing Your App Using Commands Building Configurable CLI Apps Customizing Yargs' Parser Bundling yargs Contributing Supported Node.js Versions Libraries in this ecosystem make a best effort to track Node.js' release schedule. Here's a post on why we think this is important."
  },
  "node_modules/ms/license.html": {
    "href": "node_modules/ms/license.html",
    "title": "| accouter",
    "keywords": "The MIT License (MIT) Copyright (c) 2016 Zeit, Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/ms/readme.html": {
    "href": "node_modules/ms/readme.html",
    "title": "ms | accouter",
    "keywords": "ms Use this package to easily convert various time formats to milliseconds. Examples ms('2 days') // 172800000 ms('1d') // 86400000 ms('10h') // 36000000 ms('2.5 hrs') // 9000000 ms('2h') // 7200000 ms('1m') // 60000 ms('5s') // 5000 ms('1y') // 31557600000 ms('100') // 100 Convert from milliseconds ms(60000) // \"1m\" ms(2 * 60000) // \"2m\" ms(ms('10 hours')) // \"10h\" Time format written-out ms(60000, { long: true }) // \"1 minute\" ms(2 * 60000, { long: true }) // \"2 minutes\" ms(ms('10 hours'), { long: true }) // \"10 hours\" Features Works both in node and in the browser. If a number is supplied to ms, a string with a unit is returned. If a string that contains the number is supplied, it returns it as a number (e.g.: it returns 100 for '100'). If you pass a string with a number and a valid unit, the number of equivalent ms is returned. Caught a bug? Fork this repository to your own GitHub account and then clone it to your local device Link the package to the global module directory: npm link Within the module you want to test your local development instance of ms, just link it to the dependencies: npm link ms. Instead of the default one from npm, node will now use your clone of ms! As always, you can run the tests using: npm test"
  },
  "node_modules/nanoid/README.html": {
    "href": "node_modules/nanoid/README.html",
    "title": "Nano ID | accouter",
    "keywords": "Nano ID English | Русский | 简体中文 | Bahasa Indonesia A tiny, secure, URL-friendly, unique string ID generator for JavaScript. “An amazing level of senseless perfectionism, which is simply impossible not to respect.” Small. 130 bytes (minified and gzipped). No dependencies. Size Limit controls the size. Fast. It is 2 times faster than UUID. Safe. It uses hardware random generator. Can be used in clusters. Short IDs. It uses a larger alphabet than UUID (A-Za-z0-9_-). So ID size was reduced from 36 to 21 symbols. Portable. Nano ID was ported to 20 programming languages. import { nanoid } from 'nanoid' model.id = nanoid() //=> \"V1StGXR8_Z5jdHi6B-myT\" Supports modern browsers, IE with Babel, Node.js and React Native. Docs Read full docs here."
  },
  "node_modules/negotiator/HISTORY.html": {
    "href": "node_modules/negotiator/HISTORY.html",
    "title": "0.6.3 / 2022-01-22 | accouter",
    "keywords": "0.6.3 / 2022-01-22 Revert \"Lazy-load modules from main entry point\" 0.6.2 / 2019-04-29 Fix sorting charset, encoding, and language with extra parameters 0.6.1 / 2016-05-02 perf: improve Accept parsing speed perf: improve Accept-Charset parsing speed perf: improve Accept-Encoding parsing speed perf: improve Accept-Language parsing speed 0.6.0 / 2015-09-29 Fix including type extensions in parameters in Accept parsing Fix parsing Accept parameters with quoted equals Fix parsing Accept parameters with quoted semicolons Lazy-load modules from main entry point perf: delay type concatenation until needed perf: enable strict mode perf: hoist regular expressions perf: remove closures getting spec properties perf: remove a closure from media type parsing perf: remove property delete from media type parsing 0.5.3 / 2015-05-10 Fix media type parameter matching to be case-insensitive 0.5.2 / 2015-05-06 Fix comparing media types with quoted values Fix splitting media types with quoted commas 0.5.1 / 2015-02-14 Fix preference sorting to be stable for long acceptable lists 0.5.0 / 2014-12-18 Fix list return order when large accepted list Fix missing identity encoding when q=0 exists Remove dynamic building of Negotiator class 0.4.9 / 2014-10-14 Fix error when media type has invalid parameter 0.4.8 / 2014-09-28 Fix all negotiations to be case-insensitive Stable sort preferences of same quality according to client order Support Node.js 0.6 0.4.7 / 2014-06-24 Handle invalid provided languages Handle invalid provided media types 0.4.6 / 2014-06-11 Order by specificity when quality is the same 0.4.5 / 2014-05-29 Fix regression in empty header handling 0.4.4 / 2014-05-29 Fix behaviors when headers are not present 0.4.3 / 2014-04-16 Handle slashes on media params correctly 0.4.2 / 2014-02-28 Fix media type sorting Handle media types params strictly 0.4.1 / 2014-01-16 Use most specific matches 0.4.0 / 2014-01-09 Remove preferred prefix from methods"
  },
  "node_modules/negotiator/README.html": {
    "href": "node_modules/negotiator/README.html",
    "title": "negotiator | accouter",
    "keywords": "negotiator An HTTP content negotiator for Node.js Installation $ npm install negotiator API var Negotiator = require('negotiator') Accept Negotiation availableMediaTypes = ['text/html', 'text/plain', 'application/json'] // The negotiator constructor receives a request object negotiator = new Negotiator(request) // Let's say Accept header is 'text/html, application/*;q=0.2, image/jpeg;q=0.8' negotiator.mediaTypes() // -> ['text/html', 'image/jpeg', 'application/*'] negotiator.mediaTypes(availableMediaTypes) // -> ['text/html', 'application/json'] negotiator.mediaType(availableMediaTypes) // -> 'text/html' You can check a working example at examples/accept.js. Methods mediaType() Returns the most preferred media type from the client. mediaType(availableMediaType) Returns the most preferred media type from a list of available media types. mediaTypes() Returns an array of preferred media types ordered by the client preference. mediaTypes(availableMediaTypes) Returns an array of preferred media types ordered by priority from a list of available media types. Accept-Language Negotiation negotiator = new Negotiator(request) availableLanguages = ['en', 'es', 'fr'] // Let's say Accept-Language header is 'en;q=0.8, es, pt' negotiator.languages() // -> ['es', 'pt', 'en'] negotiator.languages(availableLanguages) // -> ['es', 'en'] language = negotiator.language(availableLanguages) // -> 'es' You can check a working example at examples/language.js. Methods language() Returns the most preferred language from the client. language(availableLanguages) Returns the most preferred language from a list of available languages. languages() Returns an array of preferred languages ordered by the client preference. languages(availableLanguages) Returns an array of preferred languages ordered by priority from a list of available languages. Accept-Charset Negotiation availableCharsets = ['utf-8', 'iso-8859-1', 'iso-8859-5'] negotiator = new Negotiator(request) // Let's say Accept-Charset header is 'utf-8, iso-8859-1;q=0.8, utf-7;q=0.2' negotiator.charsets() // -> ['utf-8', 'iso-8859-1', 'utf-7'] negotiator.charsets(availableCharsets) // -> ['utf-8', 'iso-8859-1'] negotiator.charset(availableCharsets) // -> 'utf-8' You can check a working example at examples/charset.js. Methods charset() Returns the most preferred charset from the client. charset(availableCharsets) Returns the most preferred charset from a list of available charsets. charsets() Returns an array of preferred charsets ordered by the client preference. charsets(availableCharsets) Returns an array of preferred charsets ordered by priority from a list of available charsets. Accept-Encoding Negotiation availableEncodings = ['identity', 'gzip'] negotiator = new Negotiator(request) // Let's say Accept-Encoding header is 'gzip, compress;q=0.2, identity;q=0.5' negotiator.encodings() // -> ['gzip', 'identity', 'compress'] negotiator.encodings(availableEncodings) // -> ['gzip', 'identity'] negotiator.encoding(availableEncodings) // -> 'gzip' You can check a working example at examples/encoding.js. Methods encoding() Returns the most preferred encoding from the client. encoding(availableEncodings) Returns the most preferred encoding from a list of available encodings. encodings() Returns an array of preferred encodings ordered by the client preference. encodings(availableEncodings) Returns an array of preferred encodings ordered by priority from a list of available encodings. See Also The accepts module builds on this module and provides an alternative interface, mime type validation, and more. License MIT"
  },
  "node_modules/nested-error-stacks/CHANGELOG.html": {
    "href": "node_modules/nested-error-stacks/CHANGELOG.html",
    "title": "| accouter",
    "keywords": "2.0.0 Added support for node v7 Dropped support for node v0.8 and v0.6"
  },
  "node_modules/nested-error-stacks/README.html": {
    "href": "node_modules/nested-error-stacks/README.html",
    "title": "Nested stacktraces for Node.js! | accouter",
    "keywords": "Nested stacktraces for Node.js! With this module, you can wrap a caught exception with extra context for better debugging. For example, a network error's stack would normally look like this: Error: connect ECONNREFUSED at errnoException (net.js:904:11) at Object.afterConnect [as oncomplete] (net.js:895:19) Using this module, you can wrap the Error with more context to get a stack that looks like this: NestedError: Failed to communicate with localhost:8080 at Socket.<anonymous> (/Users/mattlavin/Projects/nested-stacks/demo.js:6:18) at Socket.EventEmitter.emit (events.js:95:17) at net.js:440:14 at process._tickCallback (node.js:415:13) Caused By: Error: connect ECONNREFUSED at errnoException (net.js:904:11) at Object.afterConnect [as oncomplete] (net.js:895:19) How to wrap errors Here is an example program that uses this module to add more context to errors: var NestedError = require('nested-error-stacks'); var net = require('net'); var client = net.connect({port: 8080}); client.on('error', function (err) { var newErr = new NestedError(\"Failed to communicate with localhost:8080\", err); console.log(newErr.stack); }); How to inherit It is recommended to use explicit names for Error classes. You can do it like this: var util = require('util'); var NestedError = require('nested-error-stacks'); function MyError(message, nested) { NestedError.call(this, message, nested); } util.inherits(MyError, NestedError); MyError.prototype.name = 'MyError';"
  },
  "node_modules/nice-try/CHANGELOG.html": {
    "href": "node_modules/nice-try/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. [1.0.5] - 2018-08-25 Changed Removed prepublish script from package.json [1.0.4] - 2017-08-08 New Added a changelog Changed Ignore yarn.lock and package-lock.json files"
  },
  "node_modules/nice-try/README.html": {
    "href": "node_modules/nice-try/README.html",
    "title": "nice-try | accouter",
    "keywords": "nice-try A function that tries to execute a function and discards any error that occurs. Install npm install nice-try Usage const niceTry = require('nice-try') niceTry(() => JSON.parse('true')) // true niceTry(() => JSON.parse('truee')) // undefined niceTry() // undefined niceTry(true) // undefined API Parameters fn {Function} Function that might or might not throw an error. Returns {?*} Return-value of the function when no error occurred."
  },
  "node_modules/node-releases/README.html": {
    "href": "node_modules/node-releases/README.html",
    "title": "Node.js releases data | accouter",
    "keywords": "Node.js releases data All data is located in data directory. data/processed contains envs.json with node.js releases data preprocessed to be used by Browserslist and other projects. Each version in this file contains only necessary info: version, release date, LTS flag/name, and security flag. data/release-schedule contains release-schedule.json with node.js releases date and end of life date. Installation npm install node-releases"
  },
  "node_modules/nodemon/README.html": {
    "href": "node_modules/nodemon/README.html",
    "title": "nodemon | accouter",
    "keywords": "nodemon nodemon is a tool that helps develop Node.js based applications by automatically restarting the node application when file changes in the directory are detected. nodemon does not require any additional changes to your code or method of development. nodemon is a replacement wrapper for node. To use nodemon, replace the word node on the command line when executing your script. Installation Either through cloning with git or by using npm (the recommended way): npm install -g nodemon # or using yarn: yarn global add nodemon And nodemon will be installed globally to your system path. You can also install nodemon as a development dependency: npm install --save-dev nodemon # or using yarn: yarn add nodemon -D With a local installation, nodemon will not be available in your system path or you can't use it directly from the command line. Instead, the local installation of nodemon can be run by calling it from within an npm script (such as npm start) or using npx nodemon. Usage nodemon wraps your application, so you can pass all the arguments you would normally pass to your app: nodemon [your node app] For CLI options, use the -h (or --help) argument: nodemon -h Using nodemon is simple, if my application accepted a host and port as the arguments, I would start it as so: nodemon ./server.js localhost 8080 Any output from this script is prefixed with [nodemon], otherwise all output from your application, errors included, will be echoed out as expected. You can also pass the inspect flag to node through the command line as you would normally: nodemon --inspect ./server.js 80 If you have a package.json file for your app, you can omit the main script entirely and nodemon will read the package.json for the main property and use that value as the app (ref). nodemon will also search for the scripts.start property in package.json (as of nodemon 1.1.x). Also check out the FAQ or issues for nodemon. Automatic re-running nodemon was originally written to restart hanging processes such as web servers, but now supports apps that cleanly exit. If your script exits cleanly, nodemon will continue to monitor the directory (or directories) and restart the script if there are any changes. Manual restarting Whilst nodemon is running, if you need to manually restart your application, instead of stopping and restart nodemon, you can type rs with a carriage return, and nodemon will restart your process. Config files nodemon supports local and global configuration files. These are usually named nodemon.json and can be located in the current working directory or in your home directory. An alternative local configuration file can be specified with the --config <file> option. The specificity is as follows, so that a command line argument will always override the config file settings: command line arguments local config global config A config file can take any of the command line arguments as JSON key values, for example: { \"verbose\": true, \"ignore\": [\"*.test.js\", \"**/fixtures/**\"], \"execMap\": { \"rb\": \"ruby\", \"pde\": \"processing --sketch={{pwd}} --run\" } } The above nodemon.json file might be my global config so that I have support for ruby files and processing files, and I can run nodemon demo.pde and nodemon will automatically know how to run the script even though out of the box support for processing scripts. A further example of options can be seen in sample-nodemon.md package.json If you want to keep all your package configurations in one place, nodemon supports using package.json for configuration. Specify the config in the same format as you would for a config file but under nodemonConfig in the package.json file, for example, take the following package.json: { \"name\": \"nodemon\", \"homepage\": \"http://nodemon.io\", \"...\": \"... other standard package.json values\", \"nodemonConfig\": { \"ignore\": [\"**/test/**\", \"**/docs/**\"], \"delay\": 2500 } } Note that if you specify a --config file or provide a local nodemon.json any package.json config is ignored. This section needs better documentation, but for now you can also see nodemon --help config (also here). Using nodemon as a module Please see doc/requireable.md Using nodemon as child process Please see doc/events.md Running non-node scripts nodemon can also be used to execute and monitor other programs. nodemon will read the file extension of the script being run and monitor that extension instead of .js if there's no nodemon.json: nodemon --exec \"python -v\" ./app.py Now nodemon will run app.py with python in verbose mode (note that if you're not passing args to the exec program, you don't need the quotes), and look for new or modified files with the .py extension. Default executables Using the nodemon.json config file, you can define your own default executables using the execMap property. This is particularly useful if you're working with a language that isn't supported by default by nodemon. To add support for nodemon to know about the .pl extension (for Perl), the nodemon.json file would add: { \"execMap\": { \"pl\": \"perl\" } } Now running the following, nodemon will know to use perl as the executable: nodemon script.pl It's generally recommended to use the global nodemon.json to add your own execMap options. However, if there's a common default that's missing, this can be merged in to the project so that nodemon supports it by default, by changing default.js and sending a pull request. Monitoring multiple directories By default nodemon monitors the current working directory. If you want to take control of that option, use the --watch option to add specific paths: nodemon --watch app --watch libs app/server.js Now nodemon will only restart if there are changes in the ./app or ./libs directory. By default nodemon will traverse sub-directories, so there's no need in explicitly including sub-directories. Nodemon also supports unix globbing, e.g --watch './lib/*'. The globbing pattern must be quoted. For advanced globbing, see picomatch documentation, the library that nodemon uses through chokidar (which in turn uses it through anymatch). Specifying extension watch list By default, nodemon looks for files with the .js, .mjs, .coffee, .litcoffee, and .json extensions. If you use the --exec option and monitor app.py nodemon will monitor files with the extension of .py. However, you can specify your own list with the -e (or --ext) switch like so: nodemon -e js,pug Now nodemon will restart on any changes to files in the directory (or subdirectories) with the extensions .js, .pug. Ignoring files By default, nodemon will only restart when a .js JavaScript file changes. In some cases you will want to ignore some specific files, directories or file patterns, to prevent nodemon from prematurely restarting your application. This can be done via the command line: nodemon --ignore lib/ --ignore tests/ Or specific files can be ignored: nodemon --ignore lib/app.js Patterns can also be ignored (but be sure to quote the arguments): nodemon --ignore 'lib/*.js' Important the ignore rules are patterns matched to the full absolute path, and this determines how many files are monitored. If using a wild card glob pattern, it needs to be used as ** or omitted entirely. For example, nodemon --ignore '**/test/**' will work, whereas --ignore '*/test/*' will not. Note that by default, nodemon will ignore the .git, node_modules, bower_components, .nyc_output, coverage and .sass-cache directories and add your ignored patterns to the list. If you want to indeed watch a directory like node_modules, you need to override the underlying default ignore rules. Application isn't restarting In some networked environments (such as a container running nodemon reading across a mounted drive), you will need to use the legacyWatch: true which enables Chokidar's polling. Via the CLI, use either --legacy-watch or -L for short: nodemon -L Though this should be a last resort as it will poll every file it can find. Delaying restarting In some situations, you may want to wait until a number of files have changed. The timeout before checking for new file changes is 1 second. If you're uploading a number of files and it's taking some number of seconds, this could cause your app to restart multiple times unnecessarily. To add an extra throttle, or delay restarting, use the --delay command: nodemon --delay 10 server.js For more precision, milliseconds can be specified. Either as a float: nodemon --delay 2.5 server.js Or using the time specifier (ms): nodemon --delay 2500ms server.js The delay figure is number of seconds (or milliseconds, if specified) to delay before restarting. So nodemon will only restart your app the given number of seconds after the last file change. If you are setting this value in nodemon.json, the value will always be interpreted in milliseconds. E.g., the following are equivalent: nodemon --delay 2.5 { \"delay\": 2500 } Gracefully reloading down your script It is possible to have nodemon send any signal that you specify to your application. nodemon --signal SIGHUP server.js Your application can handle the signal as follows. process.once(\"SIGHUP\", function () { reloadSomeConfiguration(); }) Please note that nodemon will send this signal to every process in the process tree. If you are using cluster, then each workers (as well as the master) will receive the signal. If you wish to terminate all workers on receiving a SIGHUP, a common pattern is to catch the SIGHUP in the master, and forward SIGTERM to all workers, while ensuring that all workers ignore SIGHUP. if (cluster.isMaster) { process.on(\"SIGHUP\", function () { for (const worker of Object.values(cluster.workers)) { worker.process.kill(\"SIGTERM\"); } }); } else { process.on(\"SIGHUP\", function() {}) } Controlling shutdown of your script nodemon sends a kill signal to your application when it sees a file update. If you need to clean up on shutdown inside your script you can capture the kill signal and handle it yourself. The following example will listen once for the SIGUSR2 signal (used by nodemon to restart), run the clean up process and then kill itself for nodemon to continue control: process.once('SIGUSR2', function () { gracefulShutdown(function () { process.kill(process.pid, 'SIGUSR2'); }); }); Note that the process.kill is only called once your shutdown jobs are complete. Hat tip to Benjie Gillam for writing this technique up. Triggering events when nodemon state changes If you want growl like notifications when nodemon restarts or to trigger an action when an event happens, then you can either require nodemon or add event actions to your nodemon.json file. For example, to trigger a notification on a Mac when nodemon restarts, nodemon.json looks like this: { \"events\": { \"restart\": \"osascript -e 'display notification \\\"app restarted\\\" with title \\\"nodemon\\\"'\" } } A full list of available events is listed on the event states wiki. Note that you can bind to both states and messages. Pipe output to somewhere else nodemon({ script: ..., stdout: false // important: this tells nodemon not to output to console }).on('readable', function() { // the `readable` event indicates that data is ready to pick up this.stdout.pipe(fs.createWriteStream('output.txt')); this.stderr.pipe(fs.createWriteStream('err.txt')); }); Using nodemon in your gulp workflow Check out the gulp-nodemon plugin to integrate nodemon with the rest of your project's gulp workflow. Using nodemon in your Grunt workflow Check out the grunt-nodemon plugin to integrate nodemon with the rest of your project's grunt workflow. Pronunciation nodemon, is it pronounced: node-mon, no-demon or node-e-mon (like pokémon)? Well...I've been asked this many times before. I like that I've been asked this before. There's been bets as to which one it actually is. The answer is simple, but possibly frustrating. I'm not saying (how I pronounce it). It's up to you to call it as you like. All answers are correct :) Design principles Fewer flags is better Works across all platforms Fewer features Let individuals build on top of nodemon Offer all CLI functionality as an API Contributions must have and pass tests Nodemon is not perfect, and CLI arguments has sprawled beyond where I'm completely happy, but perhaps it can be reduced a little one day. FAQ See the FAQ and please add your own questions if you think they would help others. Backers Thank you to all our backers! 🙏 Sponsors Support this project by becoming a sponsor. Your logo will show up here with a link to your website. Sponsor this project today ❤️ Please note that links to the sponsors above are not direct endorsements nor affiliated with any of contributors of the nodemon project. License MIT http://rem.mit-license.org"
  },
  "node_modules/nodemon/node_modules/brace-expansion/README.html": {
    "href": "node_modules/nodemon/node_modules/brace-expansion/README.html",
    "title": "brace-expansion | accouter",
    "keywords": "brace-expansion Brace expansion, as known from sh/bash, in JavaScript. Example var expand = require('brace-expansion'); expand('file-{a,b,c}.jpg') // => ['file-a.jpg', 'file-b.jpg', 'file-c.jpg'] expand('-v{,,}') // => ['-v', '-v', '-v'] expand('file{0..2}.jpg') // => ['file0.jpg', 'file1.jpg', 'file2.jpg'] expand('file-{a..c}.jpg') // => ['file-a.jpg', 'file-b.jpg', 'file-c.jpg'] expand('file{2..0}.jpg') // => ['file2.jpg', 'file1.jpg', 'file0.jpg'] expand('file{0..4..2}.jpg') // => ['file0.jpg', 'file2.jpg', 'file4.jpg'] expand('file-{a..e..2}.jpg') // => ['file-a.jpg', 'file-c.jpg', 'file-e.jpg'] expand('file{00..10..5}.jpg') // => ['file00.jpg', 'file05.jpg', 'file10.jpg'] expand('{{A..C},{a..c}}') // => ['A', 'B', 'C', 'a', 'b', 'c'] expand('ppp{,config,oe{,conf}}') // => ['ppp', 'pppconfig', 'pppoe', 'pppoeconf'] API var expand = require('brace-expansion'); var expanded = expand(str) Return an array of all possible and valid expansions of str. If none are found, [str] is returned. Valid expansions are: /^(.*,)+(.+)?$/ // {a,b,...} A comma separated list of options, like {a,b} or {a,{b,c}} or {,a,}. /^-?\\d+\\.\\.-?\\d+(\\.\\.-?\\d+)?$/ // {x..y[..incr]} A numeric sequence from x to y inclusive, with optional increment. If x or y start with a leading 0, all the numbers will be padded to have equal length. Negative numbers and backwards iteration work too. /^-?\\d+\\.\\.-?\\d+(\\.\\.-?\\d+)?$/ // {x..y[..incr]} An alphabetic sequence from x to y inclusive, with optional increment. x and y must be exactly one character, and if given, incr must be a number. For compatibility reasons, the string ${ is not eligible for brace expansion. Installation With npm do: npm install brace-expansion Contributors Julian Gruber Isaac Z. Schlueter Sponsors This module is proudly supported by my Sponsors! Do you want to support modules like this to improve their quality, stability and weigh in on new features? Then please consider donating to my Patreon. Not sure how much of my modules you're using? Try feross/thanks! License (MIT) Copyright (c) 2013 Julian Gruber <julian@juliangruber.com&gt; Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/nodemon/node_modules/debug/README.html": {
    "href": "node_modules/nodemon/node_modules/debug/README.html",
    "title": "debug | accouter",
    "keywords": "debug A tiny JavaScript debugging utility modelled after Node.js core's debugging technique. Works in Node.js and web browsers. Installation $ npm install debug Usage debug exposes a function; simply pass this function the name of your module, and it will return a decorated version of console.error for you to pass debug statements to. This will allow you to toggle the debug output for different parts of your module as well as the module as a whole. Example app.js: var debug = require('debug')('http') , http = require('http') , name = 'My App'; // fake app debug('booting %o', name); http.createServer(function(req, res){ debug(req.method + ' ' + req.url); res.end('hello\\n'); }).listen(3000, function(){ debug('listening'); }); // fake worker of some kind require('./worker'); Example worker.js: var a = require('debug')('worker:a') , b = require('debug')('worker:b'); function work() { a('doing lots of uninteresting work'); setTimeout(work, Math.random() * 1000); } work(); function workb() { b('doing some work'); setTimeout(workb, Math.random() * 2000); } workb(); The DEBUG environment variable is then used to enable these based on space or comma-delimited names. Here are some examples: Windows command prompt notes CMD On Windows the environment variable is set using the set command. set DEBUG=*,-not_this Example: set DEBUG=* & node app.js PowerShell (VS Code default) PowerShell uses different syntax to set environment variables. $env:DEBUG = \"*,-not_this\" Example: $env:DEBUG='app';node app.js Then, run the program to be debugged as usual. npm script example: \"windowsDebug\": \"@powershell -Command $env:DEBUG='*';node app.js\", Namespace Colors Every debug instance has a color generated for it based on its namespace name. This helps when visually parsing the debug output to identify which debug instance a debug line belongs to. Node.js In Node.js, colors are enabled when stderr is a TTY. You also should install the supports-color module alongside debug, otherwise debug will only use a small handful of basic colors. Web Browser Colors are also enabled on \"Web Inspectors\" that understand the %c formatting option. These are WebKit web inspectors, Firefox (since version 31) and the Firebug plugin for Firefox (any version). Millisecond diff When actively developing an application it can be useful to see when the time spent between one debug() call and the next. Suppose for example you invoke debug() before requesting a resource, and after as well, the \"+NNNms\" will show you how much time was spent between calls. When stdout is not a TTY, Date#toISOString() is used, making it more useful for logging the debug information as shown below: Conventions If you're using this in one or more of your libraries, you should use the name of your library so that developers may toggle debugging as desired without guessing names. If you have more than one debuggers you should prefix them with your library name and use \":\" to separate features. For example \"bodyParser\" from Connect would then be \"connect:bodyParser\". If you append a \"*\" to the end of your name, it will always be enabled regardless of the setting of the DEBUG environment variable. You can then use it for normal output as well as debug output. Wildcards The * character may be used as a wildcard. Suppose for example your library has debuggers named \"connect:bodyParser\", \"connect:compress\", \"connect:session\", instead of listing all three with DEBUG=connect:bodyParser,connect:compress,connect:session, you may simply do DEBUG=connect:*, or to run everything using this module simply use DEBUG=*. You can also exclude specific debuggers by prefixing them with a \"-\" character. For example, DEBUG=*,-connect:* would include all debuggers except those starting with \"connect:\". Environment Variables When running through Node.js, you can set a few environment variables that will change the behavior of the debug logging: Name Purpose DEBUG Enables/disables specific debugging namespaces. DEBUG_HIDE_DATE Hide date from debug output (non-TTY). DEBUG_COLORS Whether or not to use colors in the debug output. DEBUG_DEPTH Object inspection depth. DEBUG_SHOW_HIDDEN Shows hidden properties on inspected objects. Note: The environment variables beginning with DEBUG_ end up being converted into an Options object that gets used with %o/%O formatters. See the Node.js documentation for util.inspect() for the complete list. Formatters Debug uses printf-style formatting. Below are the officially supported formatters: Formatter Representation %O Pretty-print an Object on multiple lines. %o Pretty-print an Object all on a single line. %s String. %d Number (both integer and float). %j JSON. Replaced with the string '[Circular]' if the argument contains circular references. %% Single percent sign ('%'). This does not consume an argument. Custom formatters You can add custom formatters by extending the debug.formatters object. For example, if you wanted to add support for rendering a Buffer as hex with %h, you could do something like: const createDebug = require('debug') createDebug.formatters.h = (v) => { return v.toString('hex') } // …elsewhere const debug = createDebug('foo') debug('this is hex: %h', new Buffer('hello world')) // foo this is hex: 68656c6c6f20776f726c6421 +0ms Browser Support You can build a browser-ready script using browserify, or just use the browserify-as-a-service build, if you don't want to build it yourself. Debug's enable state is currently persisted by localStorage. Consider the situation shown below where you have worker:a and worker:b, and wish to debug both. You can enable this using localStorage.debug: localStorage.debug = 'worker:*' And then refresh the page. a = debug('worker:a'); b = debug('worker:b'); setInterval(function(){ a('doing some work'); }, 1000); setInterval(function(){ b('doing some work'); }, 1200); In Chromium-based web browsers (e.g. Brave, Chrome, and Electron), the JavaScript console will—by default—only show messages logged by debug if the \"Verbose\" log level is enabled. Output streams By default debug will log to stderr, however this can be configured per-namespace by overriding the log method: Example stdout.js: var debug = require('debug'); var error = debug('app:error'); // by default stderr is used error('goes to stderr!'); var log = debug('app:log'); // set this namespace to log via console.log log.log = console.log.bind(console); // don't forget to bind to console! log('goes to stdout'); error('still goes to stderr!'); // set all output to go via console.info // overrides all per-namespace log settings debug.log = console.info.bind(console); error('now goes to stdout via console.info'); log('still goes to stdout, but via console.info now'); Extend You can simply extend debugger const log = require('debug')('auth'); //creates new debug instance with extended namespace const logSign = log.extend('sign'); const logLogin = log.extend('login'); log('hello'); // auth hello logSign('hello'); //auth:sign hello logLogin('hello'); //auth:login hello Set dynamically You can also enable debug dynamically by calling the enable() method : let debug = require('debug'); console.log(1, debug.enabled('test')); debug.enable('test'); console.log(2, debug.enabled('test')); debug.disable(); console.log(3, debug.enabled('test')); print : 1 false 2 true 3 false Usage : enable(namespaces) namespaces can include modes separated by a colon and wildcards. Note that calling enable() completely overrides previously set DEBUG variable : $ DEBUG=foo node -e 'var dbg = require(\"debug\"); dbg.enable(\"bar\"); console.log(dbg.enabled(\"foo\"))' => false disable() Will disable all namespaces. The functions returns the namespaces currently enabled (and skipped). This can be useful if you want to disable debugging temporarily without knowing what was enabled to begin with. For example: let debug = require('debug'); debug.enable('foo:*,-foo:bar'); let namespaces = debug.disable(); debug.enable(namespaces); Note: There is no guarantee that the string will be identical to the initial enable string, but semantically they will be identical. Checking whether a debug target is enabled After you've created a debug instance, you can determine whether or not it is enabled by checking the enabled property: const debug = require('debug')('http'); if (debug.enabled) { // do stuff... } You can also manually toggle this property to force the debug instance to be enabled or disabled. Usage in child processes Due to the way debug detects if the output is a TTY or not, colors are not shown in child processes when stderr is piped. A solution is to pass the DEBUG_COLORS=1 environment variable to the child process. For example: worker = fork(WORKER_WRAP_PATH, [workerPath], { stdio: [ /* stdin: */ 0, /* stdout: */ 'pipe', /* stderr: */ 'pipe', 'ipc', ], env: Object.assign({}, process.env, { DEBUG_COLORS: 1 // without this settings, colors won't be shown }), }); worker.stderr.pipe(process.stderr, { end: false }); Authors TJ Holowaychuk Nathan Rajlich Andrew Rhyne Josh Junon Backers Support us with a monthly donation and help us continue our activities. [Become a backer] Sponsors Become a sponsor and get your logo on our README on Github with a link to your site. [Become a sponsor] License (The MIT License) Copyright (c) 2014-2017 TJ Holowaychuk <tj@vision-media.ca&gt; Copyright (c) 2018-2021 Josh Junon Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/nodemon/node_modules/has-flag/readme.html": {
    "href": "node_modules/nodemon/node_modules/has-flag/readme.html",
    "title": "has-flag | accouter",
    "keywords": "has-flag Check if argv has a specific flag Correctly stops looking after an -- argument terminator. Install $ npm install has-flag Usage // foo.js const hasFlag = require('has-flag'); hasFlag('unicorn'); //=> true hasFlag('--unicorn'); //=> true hasFlag('f'); //=> true hasFlag('-f'); //=> true hasFlag('foo=bar'); //=> true hasFlag('foo'); //=> false hasFlag('rainbow'); //=> false $ node foo.js -f --unicorn --foo=bar -- --rainbow API hasFlag(flag, [argv]) Returns a boolean for whether the flag exists. flag Type: string CLI flag to look for. The -- prefix is optional. argv Type: string[] Default: process.argv CLI arguments. License MIT © Sindre Sorhus"
  },
  "node_modules/nodemon/node_modules/minimatch/README.html": {
    "href": "node_modules/nodemon/node_modules/minimatch/README.html",
    "title": "minimatch | accouter",
    "keywords": "minimatch A minimal matching utility. This is the matching library used internally by npm. It works by converting glob expressions into JavaScript RegExp objects. Usage var minimatch = require(\"minimatch\") minimatch(\"bar.foo\", \"*.foo\") // true! minimatch(\"bar.foo\", \"*.bar\") // false! minimatch(\"bar.foo\", \"*.+(bar|foo)\", { debug: true }) // true, and noisy! Features Supports these glob features: Brace Expansion Extended glob matching \"Globstar\" ** matching See: man sh man bash man 3 fnmatch man 5 gitignore Minimatch Class Create a minimatch object by instantiating the minimatch.Minimatch class. var Minimatch = require(\"minimatch\").Minimatch var mm = new Minimatch(pattern, options) Properties pattern The original pattern the minimatch object represents. options The options supplied to the constructor. set A 2-dimensional array of regexp or string expressions. Each row in the array corresponds to a brace-expanded pattern. Each item in the row corresponds to a single path-part. For example, the pattern {a,b/c}/d would expand to a set of patterns like: [ [ a, d ] , [ b, c, d ] ] If a portion of the pattern doesn't have any \"magic\" in it (that is, it's something like \"foo\" rather than fo*o?), then it will be left as a string rather than converted to a regular expression. regexp Created by the makeRe method. A single regular expression expressing the entire pattern. This is useful in cases where you wish to use the pattern somewhat like fnmatch(3) with FNM_PATH enabled. negate True if the pattern is negated. comment True if the pattern is a comment. empty True if the pattern is \"\". Methods makeRe Generate the regexp member if necessary, and return it. Will return false if the pattern is invalid. match(fname) Return true if the filename matches the pattern, or false otherwise. matchOne(fileArray, patternArray, partial) Take a /-split filename, and match it against a single row in the regExpSet. This method is mainly for internal use, but is exposed so that it can be used by a glob-walker that needs to avoid excessive filesystem calls. All other methods are internal, and will be called as necessary. minimatch(path, pattern, options) Main export. Tests a path against the pattern using the options. var isJS = minimatch(file, \"*.js\", { matchBase: true }) minimatch.filter(pattern, options) Returns a function that tests its supplied argument, suitable for use with Array.filter. Example: var javascripts = fileList.filter(minimatch.filter(\"*.js\", {matchBase: true})) minimatch.match(list, pattern, options) Match against the list of files, in the style of fnmatch or glob. If nothing is matched, and options.nonull is set, then return a list containing the pattern itself. var javascripts = minimatch.match(fileList, \"*.js\", {matchBase: true})) minimatch.makeRe(pattern, options) Make a regular expression object from the pattern. Options All options are false by default. debug Dump a ton of stuff to stderr. nobrace Do not expand {a,b} and {1..3} brace sets. noglobstar Disable ** matching against multiple folder names. dot Allow patterns to match filenames starting with a period, even if the pattern does not explicitly have a period in that spot. Note that by default, a/**/b will not match a/.d/b, unless dot is set. noext Disable \"extglob\" style patterns like +(a|b). nocase Perform a case-insensitive match. nonull When a match is not found by minimatch.match, return a list containing the pattern itself if this option is set. When not set, an empty list is returned if there are no matches. matchBase If set, then patterns without slashes will be matched against the basename of the path if it contains slashes. For example, a?b would match the path /xyz/123/acb, but not /xyz/acb/123. nocomment Suppress the behavior of treating # at the start of a pattern as a comment. nonegate Suppress the behavior of treating a leading ! character as negation. flipNegate Returns from negate expressions the same as if they were not negated. (Ie, true on a hit, false on a miss.) partial Compare a partial path to a pattern. As long as the parts of the path that are present are not contradicted by the pattern, it will be treated as a match. This is useful in applications where you're walking through a folder structure, and don't yet have the full path, but want to ensure that you do not walk down paths that can never be a match. For example, minimatch('/a/b', '/a/*/c/d', { partial: true }) // true, might be /a/b/c/d minimatch('/a/b', '/**/d', { partial: true }) // true, might be /a/b/.../d minimatch('/x/y/z', '/a/**/z', { partial: true }) // false, because x !== a allowWindowsEscape Windows path separator \\ is by default converted to /, which prohibits the usage of \\ as a escape character. This flag skips that behavior and allows using the escape character. Comparisons to other fnmatch/glob implementations While strict compliance with the existing standards is a worthwhile goal, some discrepancies exist between minimatch and other implementations, and are intentional. If the pattern starts with a ! character, then it is negated. Set the nonegate flag to suppress this behavior, and treat leading ! characters normally. This is perhaps relevant if you wish to start the pattern with a negative extglob pattern like !(a|B). Multiple ! characters at the start of a pattern will negate the pattern multiple times. If a pattern starts with #, then it is treated as a comment, and will not match anything. Use \\# to match a literal # at the start of a line, or set the nocomment flag to suppress this behavior. The double-star character ** is supported by default, unless the noglobstar flag is set. This is supported in the manner of bsdglob and bash 4.1, where ** only has special significance if it is the only thing in a path part. That is, a/**/b will match a/x/y/b, but a/**b will not. If an escaped pattern has no matches, and the nonull flag is set, then minimatch.match returns the pattern as-provided, rather than interpreting the character escapes. For example, minimatch.match([], \"\\\\*a\\\\?\") will return \"\\\\*a\\\\?\" rather than \"*a?\". This is akin to setting the nullglob option in bash, except that it does not resolve escaped pattern characters. If brace expansion is not disabled, then it is performed before any other interpretation of the glob pattern. Thus, a pattern like +(a|{b),c)}, which would not be valid in bash or zsh, is expanded first into the set of +(a|b) and +(a|c), and those patterns are checked for validity. Since those two are valid, matching proceeds."
  },
  "node_modules/nodemon/node_modules/ms/license.html": {
    "href": "node_modules/nodemon/node_modules/ms/license.html",
    "title": "| accouter",
    "keywords": "The MIT License (MIT) Copyright (c) 2016 Zeit, Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/nodemon/node_modules/ms/readme.html": {
    "href": "node_modules/nodemon/node_modules/ms/readme.html",
    "title": "ms | accouter",
    "keywords": "ms Use this package to easily convert various time formats to milliseconds. Examples ms('2 days') // 172800000 ms('1d') // 86400000 ms('10h') // 36000000 ms('2.5 hrs') // 9000000 ms('2h') // 7200000 ms('1m') // 60000 ms('5s') // 5000 ms('1y') // 31557600000 ms('100') // 100 ms('-3 days') // -259200000 ms('-1h') // -3600000 ms('-200') // -200 Convert from Milliseconds ms(60000) // \"1m\" ms(2 * 60000) // \"2m\" ms(-3 * 60000) // \"-3m\" ms(ms('10 hours')) // \"10h\" Time Format Written-Out ms(60000, { long: true }) // \"1 minute\" ms(2 * 60000, { long: true }) // \"2 minutes\" ms(-3 * 60000, { long: true }) // \"-3 minutes\" ms(ms('10 hours'), { long: true }) // \"10 hours\" Features Works both in Node.js and in the browser If a number is supplied to ms, a string with a unit is returned If a string that contains the number is supplied, it returns it as a number (e.g.: it returns 100 for '100') If you pass a string with a number and a valid unit, the number of equivalent milliseconds is returned Related Packages ms.macro - Run ms as a macro at build-time. Caught a Bug? Fork this repository to your own GitHub account and then clone it to your local device Link the package to the global module directory: npm link Within the module you want to test your local development instance of ms, just link it to the dependencies: npm link ms. Instead of the default one from npm, Node.js will now use your clone of ms! As always, you can run the tests using: npm test"
  },
  "node_modules/nodemon/node_modules/supports-color/readme.html": {
    "href": "node_modules/nodemon/node_modules/supports-color/readme.html",
    "title": "supports-color | accouter",
    "keywords": "supports-color Detect whether a terminal supports color Install $ npm install supports-color Usage const supportsColor = require('supports-color'); if (supportsColor.stdout) { console.log('Terminal stdout supports color'); } if (supportsColor.stdout.has256) { console.log('Terminal stdout supports 256 colors'); } if (supportsColor.stderr.has16m) { console.log('Terminal stderr supports 16 million colors (truecolor)'); } API Returns an Object with a stdout and stderr property for testing either streams. Each property is an Object, or false if color is not supported. The stdout/stderr objects specifies a level of support for color through a .level property and a corresponding flag: .level = 1 and .hasBasic = true: Basic color support (16 colors) .level = 2 and .has256 = true: 256 color support .level = 3 and .has16m = true: Truecolor support (16 million colors) Info It obeys the --color and --no-color CLI flags. Can be overridden by the user with the flags --color and --no-color. For situations where using --color is not possible, add the environment variable FORCE_COLOR=1 to forcefully enable color or FORCE_COLOR=0 to forcefully disable. The use of FORCE_COLOR overrides all other color support checks. Explicit 256/Truecolor mode can be enabled using the --color=256 and --color=16m flags, respectively. Related supports-color-cli - CLI for this module chalk - Terminal string styling done right Maintainers Sindre Sorhus Josh Junon License MIT"
  },
  "node_modules/normalize-package-data/README.html": {
    "href": "node_modules/normalize-package-data/README.html",
    "title": "normalize-package-data | accouter",
    "keywords": "normalize-package-data normalize-package-data exports a function that normalizes package metadata. This data is typically found in a package.json file, but in principle could come from any source - for example the npm registry. normalize-package-data is used by read-package-json to normalize the data it reads from a package.json file. In turn, read-package-json is used by npm and various npm-related tools. Installation npm install normalize-package-data Usage Basic usage is really simple. You call the function that normalize-package-data exports. Let's call it normalizeData. normalizeData = require('normalize-package-data') packageData = require(\"./package.json\") normalizeData(packageData) // packageData is now normalized Strict mode You may activate strict validation by passing true as the second argument. normalizeData = require('normalize-package-data') packageData = require(\"./package.json\") normalizeData(packageData, true) // packageData is now normalized If strict mode is activated, only Semver 2.0 version strings are accepted. Otherwise, Semver 1.0 strings are accepted as well. Packages must have a name, and the name field must not have contain leading or trailing whitespace. Warnings Optionally, you may pass a \"warning\" function. It gets called whenever the normalizeData function encounters something that doesn't look right. It indicates less than perfect input data. normalizeData = require('normalize-package-data') packageData = require(\"./package.json\") warnFn = function(msg) { console.error(msg) } normalizeData(packageData, warnFn) // packageData is now normalized. Any number of warnings may have been logged. You may combine strict validation with warnings by passing true as the second argument, and warnFn as third. When private field is set to true, warnings will be suppressed. Potential exceptions If the supplied data has an invalid name or version vield, normalizeData will throw an error. Depending on where you call normalizeData, you may want to catch these errors so can pass them to a callback. What normalization (currently) entails The value of name field gets trimmed (unless in strict mode). The value of the version field gets cleaned by semver.clean. See documentation for the semver module. If name and/or version fields are missing, they are set to empty strings. If files field is not an array, it will be removed. If bin field is a string, then bin field will become an object with name set to the value of the name field, and bin set to the original string value. If man field is a string, it will become an array with the original string as its sole member. If keywords field is string, it is considered to be a list of keywords separated by one or more white-space characters. It gets converted to an array by splitting on \\s+. All people fields (author, maintainers, contributors) get converted into objects with name, email and url properties. If bundledDependencies field (a typo) exists and bundleDependencies field does not, bundledDependencies will get renamed to bundleDependencies. If the value of any of the dependencies fields (dependencies, devDependencies, optionalDependencies) is a string, it gets converted into an object with familiar name=>value pairs. The values in optionalDependencies get added to dependencies. The optionalDependencies array is left untouched. As of v2: Dependencies that point at known hosted git providers (currently: github, bitbucket, gitlab) will have their URLs canonicalized, but protocols will be preserved. As of v2: Dependencies that use shortcuts for hosted git providers (org/proj, github:org/proj, bitbucket:org/proj, gitlab:org/proj, gist:docid) will have the shortcut left in place. (In the case of github, the org/proj form will be expanded to github:org/proj.) THIS MARKS A BREAKING CHANGE FROM V1, where the shorcut was previously expanded to a URL. If description field does not exist, but readme field does, then (more or less) the first paragraph of text that's found in the readme is taken as value for description. If repository field is a string, it will become an object with url set to the original string value, and type set to \"git\". If repository.url is not a valid url, but in the style of \"[owner-name]/[repo-name]\", repository.url will be set to git+https://github.com/[owner-name]/[repo-name].git If bugs field is a string, the value of bugs field is changed into an object with url set to the original string value. If bugs field does not exist, but repository field points to a repository hosted on GitHub, the value of the bugs field gets set to an url in the form of https://github.com/[owner-name]/[repo-name]/issues . If the repository field points to a GitHub Gist repo url, the associated http url is chosen. If bugs field is an object, the resulting value only has email and url properties. If email and url properties are not strings, they are ignored. If no valid values for either email or url is found, bugs field will be removed. If homepage field is not a string, it will be removed. If the url in the homepage field does not specify a protocol, then http is assumed. For example, myproject.org will be changed to http://myproject.org. If homepage field does not exist, but repository field points to a repository hosted on GitHub, the value of the homepage field gets set to an url in the form of https://github.com/[owner-name]/[repo-name]#readme . If the repository field points to a GitHub Gist repo url, the associated http url is chosen. Rules for name field If name field is given, the value of the name field must be a string. The string may not: start with a period. contain the following characters: /@\\s+% contain any characters that would need to be encoded for use in urls. resemble the word node_modules or favicon.ico (case doesn't matter). Rules for version field If version field is given, the value of the version field must be a valid semver string, as determined by the semver.valid method. See documentation for the semver module. Rules for license field The license field should be a valid SPDX license expression or one of the special values allowed by validate-npm-package-license. See documentation for the license field in package.json. Credits This package contains code based on read-package-json written by Isaac Z. Schlueter. Used with permisson. License normalize-package-data is released under the BSD 2-Clause License. Copyright (c) 2013 Meryn Stol"
  },
  "node_modules/normalize-package-data/node_modules/semver/README.html": {
    "href": "node_modules/normalize-package-data/node_modules/semver/README.html",
    "title": "semver(1) -- The semantic versioner for npm | accouter",
    "keywords": "semver(1) -- The semantic versioner for npm Install npm install --save semver Usage As a node module: const semver = require('semver') semver.valid('1.2.3') // '1.2.3' semver.valid('a.b.c') // null semver.clean(' =v1.2.3 ') // '1.2.3' semver.satisfies('1.2.3', '1.x || >=2.5.0 || 5.0.0 - 7.2.3') // true semver.gt('1.2.3', '9.8.7') // false semver.lt('1.2.3', '9.8.7') // true semver.minVersion('>=1.0.0') // '1.0.0' semver.valid(semver.coerce('v2')) // '2.0.0' semver.valid(semver.coerce('42.6.7.9.3-alpha')) // '42.6.7' As a command-line utility: $ semver -h A JavaScript implementation of the https://semver.org/ specification Copyright Isaac Z. Schlueter Usage: semver [options] <version> [<version> [...]] Prints valid versions sorted by SemVer precedence Options: -r --range <range> Print versions that match the specified range. -i --increment [<level>] Increment a version by the specified level. Level can be one of: major, minor, patch, premajor, preminor, prepatch, or prerelease. Default level is 'patch'. Only one version may be specified. --preid <identifier> Identifier to be used to prefix premajor, preminor, prepatch or prerelease version increments. -l --loose Interpret versions and ranges loosely -p --include-prerelease Always include prerelease versions in range matching -c --coerce Coerce a string into SemVer if possible (does not imply --loose) Program exits successfully if any valid version satisfies all supplied ranges, and prints all satisfying versions. If no satisfying versions are found, then exits failure. Versions are printed in ascending order, so supplying multiple versions to the utility will just sort them. Versions A \"version\" is described by the v2.0.0 specification found at https://semver.org/. A leading \"=\" or \"v\" character is stripped off and ignored. Ranges A version range is a set of comparators which specify versions that satisfy the range. A comparator is composed of an operator and a version. The set of primitive operators is: < Less than <= Less than or equal to > Greater than >= Greater than or equal to = Equal. If no operator is specified, then equality is assumed, so this operator is optional, but MAY be included. For example, the comparator >=1.2.7 would match the versions 1.2.7, 1.2.8, 2.5.3, and 1.3.9, but not the versions 1.2.6 or 1.1.0. Comparators can be joined by whitespace to form a comparator set, which is satisfied by the intersection of all of the comparators it includes. A range is composed of one or more comparator sets, joined by ||. A version matches a range if and only if every comparator in at least one of the ||-separated comparator sets is satisfied by the version. For example, the range >=1.2.7 <1.3.0 would match the versions 1.2.7, 1.2.8, and 1.2.99, but not the versions 1.2.6, 1.3.0, or 1.1.0. The range 1.2.7 || >=1.2.9 <2.0.0 would match the versions 1.2.7, 1.2.9, and 1.4.6, but not the versions 1.2.8 or 2.0.0. Prerelease Tags If a version has a prerelease tag (for example, 1.2.3-alpha.3) then it will only be allowed to satisfy comparator sets if at least one comparator with the same [major, minor, patch] tuple also has a prerelease tag. For example, the range >1.2.3-alpha.3 would be allowed to match the version 1.2.3-alpha.7, but it would not be satisfied by 3.4.5-alpha.9, even though 3.4.5-alpha.9 is technically \"greater than\" 1.2.3-alpha.3 according to the SemVer sort rules. The version range only accepts prerelease tags on the 1.2.3 version. The version 3.4.5 would satisfy the range, because it does not have a prerelease flag, and 3.4.5 is greater than 1.2.3-alpha.7. The purpose for this behavior is twofold. First, prerelease versions frequently are updated very quickly, and contain many breaking changes that are (by the author's design) not yet fit for public consumption. Therefore, by default, they are excluded from range matching semantics. Second, a user who has opted into using a prerelease version has clearly indicated the intent to use that specific set of alpha/beta/rc versions. By including a prerelease tag in the range, the user is indicating that they are aware of the risk. However, it is still not appropriate to assume that they have opted into taking a similar risk on the next set of prerelease versions. Note that this behavior can be suppressed (treating all prerelease versions as if they were normal versions, for the purpose of range matching) by setting the includePrerelease flag on the options object to any functions that do range matching. Prerelease Identifiers The method .inc takes an additional identifier string argument that will append the value of the string as a prerelease identifier: semver.inc('1.2.3', 'prerelease', 'beta') // '1.2.4-beta.0' command-line example: $ semver 1.2.3 -i prerelease --preid beta 1.2.4-beta.0 Which then can be used to increment further: $ semver 1.2.4-beta.0 -i prerelease 1.2.4-beta.1 Advanced Range Syntax Advanced range syntax desugars to primitive comparators in deterministic ways. Advanced ranges may be combined in the same way as primitive comparators using white space or ||. Hyphen Ranges X.Y.Z - A.B.C Specifies an inclusive set. 1.2.3 - 2.3.4 := >=1.2.3 <=2.3.4 If a partial version is provided as the first version in the inclusive range, then the missing pieces are replaced with zeroes. 1.2 - 2.3.4 := >=1.2.0 <=2.3.4 If a partial version is provided as the second version in the inclusive range, then all versions that start with the supplied parts of the tuple are accepted, but nothing that would be greater than the provided tuple parts. 1.2.3 - 2.3 := >=1.2.3 <2.4.0 1.2.3 - 2 := >=1.2.3 <3.0.0 X-Ranges 1.2.x 1.X 1.2.* * Any of X, x, or * may be used to \"stand in\" for one of the numeric values in the [major, minor, patch] tuple. * := >=0.0.0 (Any version satisfies) 1.x := >=1.0.0 <2.0.0 (Matching major version) 1.2.x := >=1.2.0 <1.3.0 (Matching major and minor versions) A partial version range is treated as an X-Range, so the special character is in fact optional. \"\" (empty string) := * := >=0.0.0 1 := 1.x.x := >=1.0.0 <2.0.0 1.2 := 1.2.x := >=1.2.0 <1.3.0 Tilde Ranges ~1.2.3 ~1.2 ~1 Allows patch-level changes if a minor version is specified on the comparator. Allows minor-level changes if not. ~1.2.3 := >=1.2.3 <1.(2+1).0 := >=1.2.3 <1.3.0 ~1.2 := >=1.2.0 <1.(2+1).0 := >=1.2.0 <1.3.0 (Same as 1.2.x) ~1 := >=1.0.0 <(1+1).0.0 := >=1.0.0 <2.0.0 (Same as 1.x) ~0.2.3 := >=0.2.3 <0.(2+1).0 := >=0.2.3 <0.3.0 ~0.2 := >=0.2.0 <0.(2+1).0 := >=0.2.0 <0.3.0 (Same as 0.2.x) ~0 := >=0.0.0 <(0+1).0.0 := >=0.0.0 <1.0.0 (Same as 0.x) ~1.2.3-beta.2 := >=1.2.3-beta.2 <1.3.0 Note that prereleases in the 1.2.3 version will be allowed, if they are greater than or equal to beta.2. So, 1.2.3-beta.4 would be allowed, but 1.2.4-beta.2 would not, because it is a prerelease of a different [major, minor, patch] tuple. Caret Ranges ^1.2.3 ^0.2.5 ^0.0.4 Allows changes that do not modify the left-most non-zero digit in the [major, minor, patch] tuple. In other words, this allows patch and minor updates for versions 1.0.0 and above, patch updates for versions 0.X >=0.1.0, and no updates for versions 0.0.X. Many authors treat a 0.x version as if the x were the major \"breaking-change\" indicator. Caret ranges are ideal when an author may make breaking changes between 0.2.4 and 0.3.0 releases, which is a common practice. However, it presumes that there will not be breaking changes between 0.2.4 and 0.2.5. It allows for changes that are presumed to be additive (but non-breaking), according to commonly observed practices. ^1.2.3 := >=1.2.3 <2.0.0 ^0.2.3 := >=0.2.3 <0.3.0 ^0.0.3 := >=0.0.3 <0.0.4 ^1.2.3-beta.2 := >=1.2.3-beta.2 <2.0.0 Note that prereleases in the 1.2.3 version will be allowed, if they are greater than or equal to beta.2. So, 1.2.3-beta.4 would be allowed, but 1.2.4-beta.2 would not, because it is a prerelease of a different [major, minor, patch] tuple. ^0.0.3-beta := >=0.0.3-beta <0.0.4 Note that prereleases in the 0.0.3 version only will be allowed, if they are greater than or equal to beta. So, 0.0.3-pr.2 would be allowed. When parsing caret ranges, a missing patch value desugars to the number 0, but will allow flexibility within that value, even if the major and minor versions are both 0. ^1.2.x := >=1.2.0 <2.0.0 ^0.0.x := >=0.0.0 <0.1.0 ^0.0 := >=0.0.0 <0.1.0 A missing minor and patch values will desugar to zero, but also allow flexibility within those values, even if the major version is zero. ^1.x := >=1.0.0 <2.0.0 ^0.x := >=0.0.0 <1.0.0 Range Grammar Putting all this together, here is a Backus-Naur grammar for ranges, for the benefit of parser authors: range-set ::= range ( logical-or range ) * logical-or ::= ( ' ' ) * '||' ( ' ' ) * range ::= hyphen | simple ( ' ' simple ) * | '' hyphen ::= partial ' - ' partial simple ::= primitive | partial | tilde | caret primitive ::= ( '<' | '>' | '>=' | '<=' | '=' ) partial partial ::= xr ( '.' xr ( '.' xr qualifier ? )? )? xr ::= 'x' | 'X' | '*' | nr nr ::= '0' | ['1'-'9'] ( ['0'-'9'] ) * tilde ::= '~' partial caret ::= '^' partial qualifier ::= ( '-' pre )? ( '+' build )? pre ::= parts build ::= parts parts ::= part ( '.' part ) * part ::= nr | [-0-9A-Za-z]+ Functions All methods and classes take a final options object argument. All options in this object are false by default. The options supported are: loose Be more forgiving about not-quite-valid semver strings. (Any resulting output will always be 100% strict compliant, of course.) For backwards compatibility reasons, if the options argument is a boolean value instead of an object, it is interpreted to be the loose param. includePrerelease Set to suppress the default behavior of excluding prerelease tagged versions from ranges unless they are explicitly opted into. Strict-mode Comparators and Ranges will be strict about the SemVer strings that they parse. valid(v): Return the parsed version, or null if it's not valid. inc(v, release): Return the version incremented by the release type (major, premajor, minor, preminor, patch, prepatch, or prerelease), or null if it's not valid premajor in one call will bump the version up to the next major version and down to a prerelease of that major version. preminor, and prepatch work the same way. If called from a non-prerelease version, the prerelease will work the same as prepatch. It increments the patch version, then makes a prerelease. If the input version is already a prerelease it simply increments it. prerelease(v): Returns an array of prerelease components, or null if none exist. Example: prerelease('1.2.3-alpha.1') -> ['alpha', 1] major(v): Return the major version number. minor(v): Return the minor version number. patch(v): Return the patch version number. intersects(r1, r2, loose): Return true if the two supplied ranges or comparators intersect. parse(v): Attempt to parse a string as a semantic version, returning either a SemVer object or null. Comparison gt(v1, v2): v1 > v2 gte(v1, v2): v1 >= v2 lt(v1, v2): v1 < v2 lte(v1, v2): v1 <= v2 eq(v1, v2): v1 == v2 This is true if they're logically equivalent, even if they're not the exact same string. You already know how to compare strings. neq(v1, v2): v1 != v2 The opposite of eq. cmp(v1, comparator, v2): Pass in a comparison string, and it'll call the corresponding function above. \"===\" and \"!==\" do simple string comparison, but are included for completeness. Throws if an invalid comparison string is provided. compare(v1, v2): Return 0 if v1 == v2, or 1 if v1 is greater, or -1 if v2 is greater. Sorts in ascending order if passed to Array.sort(). rcompare(v1, v2): The reverse of compare. Sorts an array of versions in descending order when passed to Array.sort(). diff(v1, v2): Returns difference between two versions by the release type (major, premajor, minor, preminor, patch, prepatch, or prerelease), or null if the versions are the same. Comparators intersects(comparator): Return true if the comparators intersect Ranges validRange(range): Return the valid range or null if it's not valid satisfies(version, range): Return true if the version satisfies the range. maxSatisfying(versions, range): Return the highest version in the list that satisfies the range, or null if none of them do. minSatisfying(versions, range): Return the lowest version in the list that satisfies the range, or null if none of them do. minVersion(range): Return the lowest version that can possibly match the given range. gtr(version, range): Return true if version is greater than all the versions possible in the range. ltr(version, range): Return true if version is less than all the versions possible in the range. outside(version, range, hilo): Return true if the version is outside the bounds of the range in either the high or low direction. The hilo argument must be either the string '>' or '<'. (This is the function called by gtr and ltr.) intersects(range): Return true if any of the ranges comparators intersect Note that, since ranges may be non-contiguous, a version might not be greater than a range, less than a range, or satisfy a range! For example, the range 1.2 <1.2.9 || >2.0.0 would have a hole from 1.2.9 until 2.0.0, so the version 1.2.10 would not be greater than the range (because 2.0.1 satisfies, which is higher), nor less than the range (since 1.2.8 satisfies, which is lower), and it also does not satisfy the range. If you want to know if a version satisfies or does not satisfy a range, use the satisfies(version, range) function. Coercion coerce(version): Coerces a string to semver if possible This aims to provide a very forgiving translation of a non-semver string to semver. It looks for the first digit in a string, and consumes all remaining characters which satisfy at least a partial semver (e.g., 1, 1.2, 1.2.3) up to the max permitted length (256 characters). Longer versions are simply truncated (4.6.3.9.2-alpha2 becomes 4.6.3). All surrounding text is simply ignored (v3.4 replaces v3.3.1 becomes 3.4.0). Only text which lacks digits will fail coercion (version one is not valid). The maximum length for any semver component considered for coercion is 16 characters; longer components will be ignored (10000000000000000.4.7.4 becomes 4.7.4). The maximum value for any semver component is Number.MAX_SAFE_INTEGER || (2**53 - 1); higher value components are invalid (9999999999999999.4.7.4 is likely invalid)."
  },
  "node_modules/normalize-path/README.html": {
    "href": "node_modules/normalize-path/README.html",
    "title": "normalize-path | accouter",
    "keywords": "normalize-path Normalize slashes in a file path to be posix/unix-like forward slashes. Also condenses repeat slashes to a single slash and removes and trailing slashes, unless disabled. Please consider following this project's author, Jon Schlinkert, and consider starring the project to show your ❤️ and support. Install Install with npm: $ npm install --save normalize-path Usage const normalize = require('normalize-path'); console.log(normalize('\\\\foo\\\\bar\\\\baz\\\\')); //=> '/foo/bar/baz' win32 namespaces console.log(normalize('\\\\\\\\?\\\\UNC\\\\Server01\\\\user\\\\docs\\\\Letter.txt')); //=> '//?/UNC/Server01/user/docs/Letter.txt' console.log(normalize('\\\\\\\\.\\\\CdRomX')); //=> '//./CdRomX' Consecutive slashes Condenses multiple consecutive forward slashes (except for leading slashes in win32 namespaces) to a single slash. console.log(normalize('.//foo//bar///////baz/')); //=> './foo/bar/baz' Trailing slashes By default trailing slashes are removed. Pass false as the last argument to disable this behavior and keep trailing slashes: console.log(normalize('foo\\\\bar\\\\baz\\\\', false)); //=> 'foo/bar/baz/' console.log(normalize('./foo/bar/baz/', false)); //=> './foo/bar/baz/' Release history v3.0 No breaking changes in this release. a check was added to ensure that win32 namespaces are handled properly by win32 path.parse() after a path has been normalized by this library. a minor optimization was made to simplify how the trailing separator was handled About Contributing Pull requests and stars are always welcome. For bugs and feature requests, please create an issue. Running Tests Running and reviewing unit tests is a great way to get familiarized with a library and its API. You can install dependencies and run tests with the following command: $ npm install && npm test Building docs (This project's readme.md is generated by verb, please don't edit the readme directly. Any changes to the readme must be made in the .verb.md readme template.) To generate the readme, run the following command: $ npm install -g verbose/verb#dev verb-generate-readme && verb Related projects Other useful path-related libraries: contains-path: Return true if a file path contains the given path. | homepage is-absolute: Returns true if a file path is absolute. Does not rely on the path module… more | homepage is-relative: Returns true if the path appears to be relative. | homepage parse-filepath: Pollyfill for node.js path.parse, parses a filepath into an object. | homepage path-ends-with: Return true if a file path ends with the given string/suffix. | homepage unixify: Convert Windows file paths to unix paths. | homepage Contributors Commits Contributor 35 jonschlinkert 1 phated Author Jon Schlinkert LinkedIn Profile GitHub Profile Twitter Profile License Copyright © 2018, Jon Schlinkert. Released under the MIT License. This file was generated by verb-generate-readme, v0.6.0, on April 19, 2018."
  },
  "node_modules/npm-run-all/README.html": {
    "href": "node_modules/npm-run-all/README.html",
    "title": "npm-run-all | accouter",
    "keywords": "index npm-run-all run-s run-p Node API npm-run-all A CLI tool to run multiple npm-scripts in parallel or sequential. ⤴️ Motivation Simplify. The official npm run-script command cannot run multiple scripts, so if we want to run multiple scripts, it's redundant a bit. Let's shorten it by glob-like patterns. Before: npm run clean && npm run build:css && npm run build:js && npm run build:html After: npm-run-all clean build:* Cross platform. We sometimes use & to run multiple command in parallel, but cmd.exe (npm run-script uses it by default) does not support the &. Half of Node.js users are using it on Windows, so the use of & might block contributions. npm-run-all --parallel works well on Windows as well. 💿 Installation $ npm install npm-run-all --save-dev # or $ yarn add npm-run-all --dev It requires Node@>=4. 📖 Usage CLI Commands This npm-run-all package provides 3 CLI commands. npm-run-all run-s run-p The main command is npm-run-all. We can make complex plans with npm-run-all command. Both run-s and run-p are shorthand commands. run-s is for sequential, run-p is for parallel. We can make simple plans with those commands. Yarn Compatibility If a script is invoked with Yarn, npm-run-all will correctly use Yarn to execute the plan's child scripts. Node API This npm-run-all package provides Node API. Node API 📰 Changelog https://github.com/mysticatea/npm-run-all/releases 🍻 Contributing Welcome♡ Bug Reports or Feature Requests Please use GitHub Issues. Correct Documents Please use GitHub Pull Requests. I'm not familiar with English, so I especially thank you for documents' corrections. Implementing Please use GitHub Pull Requests. There are some npm-scripts to help developments. npm test - Run tests and collect coverage. npm run clean - Delete temporary files. npm run lint - Run ESLint. npm run watch - Run tests (not collect coverage) on every file change."
  },
  "node_modules/npm-run-all/docs/node-api.html": {
    "href": "node_modules/npm-run-all/docs/node-api.html",
    "title": "Node API | accouter",
    "keywords": "index npm-run-all run-s run-p Node API Node API A Node module to run given npm-scripts in parallel or sequential. const runAll = require(\"npm-run-all\"); runAll([\"clean\", \"lint\", \"build:*\"], {parallel: false}) .then(() => { console.log(\"done!\"); }) .catch(err => { console.log(\"failed!\"); }); runAll([\"build:* -- --watch\"], {parallel: true}) .then(() => { console.log(\"done!\"); }) .catch(err => { console.log(\"failed!\"); }); runAll let promise = runAll(patterns, options); Run npm-scripts. patterns string|string[] -- Glob-like patterns for script names. options object options.aggregateOutput boolean -- The flag to avoid interleaving output by delaying printing of each command's output until it has finished. This option is valid only with options.parallel option. Default is false. options.arguments string[] -- An argument list to replace argument placeholders (such as {1}, {2}). If pattern text has {1}, it's replaced by options.arguments[0]. Default is an empty array. options.continueOnError boolean -- The flag to continue executing other/subsequent scripts even if a script threw an error. Returned Promise object will be rejected if one or more scripts threw error(s). Default is false. options.parallel boolean -- The flag to run scripts in parallel. Default is false. options.maxParallel number -- The maximum number of parallelism. This option is valid only with options.parallel option. Default is Number.POSITIVE_INFINITY. options.npmPath string -- The path to npm. Default is process.env.npm_execpath or \"npm\". options.packageConfig object|null -- The map-like object to overwrite package configs. Keys are package names. Every value is a map-like object (Pairs of variable name and value). e.g. {\"npm-run-all\": {\"test\": 777, \"test2\": 333}} Default is null. options.printLabel boolean -- Set the flag to print the task name as a prefix on each line of output. Tools in scripts may stop coloring their output if this option is given. Default is false. options.printName boolean -- Set the flag to print the task name before running each task. Default is false. options.race boolean -- Set the flag to kill all npm-scripts when a npm-script finished with zero. This option is valid only with options.parallel option. Default is false. options.silent boolean -- The flag to set silent to the log level of npm. Default is false. options.stdin stream.Readable|null -- The readable stream to send to the stdin of npm-scripts. Default is nothing. Set process.stdin in order to send from stdin. options.stdout stream.Writable|null -- The writable stream to receive from the stdout of npm-scripts. Default is nothing. Set process.stdout in order to print to stdout. options.stderr stream.Writable|null -- The writable stream to receive from the stderr of npm-scripts Default is nothing. Set process.stderr in order to print to stderr. options.taskList string[]|null -- The string array of all script names. If this is null, it reads from package.json in the current directory. Default is null. runAll returns a promise that will becomes fulfilled when all scripts are completed. The promise will become rejected when any of the scripts exit with a non-zero code. The promise gives results to the fulfilled handler. results is an array of objects which have 2 properties: name and code. The name property is the name of a npm-script. The code property is the exit code of the npm-script. If the npm-script was not executed, the code property is undefined. runAll([\"clean\", \"lint\", \"build\"]) .then(results => { console.log(`${results[0].name}: ${results[0].code}`); // clean: 0 console.log(`${results[1].name}: ${results[1].code}`); // lint: 0 console.log(`${results[2].name}: ${results[2].code}`); // build: 0 }); About MaxListenersExceededWarning If you use options.stdin, options.stdout, or options.stderr in parallel mode, please configure max listeners by emitter.setMaxListeners(n) properly. If you don't use those options and process.stdXXX.isTTY is false, please configure max listeners of the process.stdXXX properly. In that case, npm-run-all uses piping to connect to child processes. On the other hand, if process.stdXXX.isTTY is true, npm-run-all uses inherit option, so the configuration is unnecessary."
  },
  "node_modules/npm-run-all/docs/npm-run-all.html": {
    "href": "node_modules/npm-run-all/docs/npm-run-all.html",
    "title": "npm-run-all command | accouter",
    "keywords": "index npm-run-all run-s run-p Node API npm-run-all command Usage: $ npm-run-all [--help | -h | --version | -v] $ npm-run-all [tasks] [OPTIONS] Run given npm-scripts in parallel or sequential. <tasks> : A list of npm-scripts' names and Glob-like patterns. Options: --aggregate-output - - - Avoid interleaving output by delaying printing of each command's output until it has finished. -c, --continue-on-error - Set the flag to continue executing other/subsequent tasks even if a task threw an error. 'npm-run-all' itself will exit with non-zero code if one or more tasks threw error(s) --max-parallel <number> - Set the maximum number of parallelism. Default is unlimited. --npm-path <string> - - - Set the path to npm. Default is the value of environment variable npm_execpath. If the variable is not defined, then it's \"npm.\" In this case, the \"npm\" command must be found in environment variable PATH. -l, --print-label - - - - Set the flag to print the task name as a prefix on each line of output. Tools in tasks may stop coloring their output if this option was given. -n, --print-name - - - - Set the flag to print the task name before running each task. -p, --parallel <tasks> - Run a group of tasks in parallel. e.g. 'npm-run-all -p foo bar' is similar to 'npm run foo & npm run bar'. -r, --race - - - - - - - Set the flag to kill all tasks when a task finished with zero. This option is valid only with 'parallel' option. -s, --sequential <tasks> - Run a group of tasks sequentially. --serial <tasks> e.g. 'npm-run-all -s foo bar' is similar to 'npm run foo && npm run bar'. '--serial' is a synonym of '--sequential'. --silent - - - - - - - - Set 'silent' to the log level of npm. Examples: $ npm-run-all --serial clean lint build:** $ npm-run-all --parallel watch:** $ npm-run-all clean lint --parallel \"build:** -- --watch\" $ npm-run-all -l -p start-server start-browser start-electron npm-scripts It's \"scripts\" field of package.json. For example: { \"scripts\": { \"clean\": \"rimraf dist\", \"lint\": \"eslint src\", \"build\": \"babel src -o lib\" } } We can run a script with npm run command. On the other hand, this npm-run-all command runs multiple scripts in parallel or sequential. Run scripts sequentially $ npm-run-all clean lint build This is same as npm run clean && npm run lint && npm run build. Note: If a script exited with non zero code, the following scripts are not run. If --continue-on-error option is given, this behavior will be disabled. Run scripts in parallel $ npm-run-all --parallel lint build This is similar to npm run lint & npm run build. Note1: If a script exited with a non-zero code, the other scripts and those descendant processes are killed with SIGTERM (On Windows, with taskkill.exe /F /T). If --continue-on-error option is given, this behavior will be disabled. Note2: & operator does not work on Windows' cmd.exe. But npm-run-all --parallel works fine there. Run a mix of sequential and parallel scripts $ npm-run-all clean lint --parallel watch:html watch:js First, this runs clean and lint sequentially / serially. Next, runs watch:html and watch:js in parallel. $ npm-run-all a b --parallel c d --sequential e f --parallel g h i or $ npm-run-all a b --parallel c d --serial e f --parallel g h i First, runs a and b sequentially / serially. Second, runs c and d in parallel. Third, runs e and f sequentially / serially. Lastly, runs g, h, and i in parallel. Glob-like pattern matching for script names We can use glob-like patterns to specify npm-scripts. The difference is one -- the separator is : instead of /. $ npm-run-all --parallel watch:* In this case, runs sub scripts of watch. For example: watch:html, watch:js. But, doesn't run sub-sub scripts. For example: watch:js:index. $ npm-run-all --parallel watch:** If we use a globstar **, runs both sub scripts and sub-sub scripts. npm-run-all reads the actual npm-script list from package.json in the current directory, then filters the scripts by glob-like patterns, then runs those. Run with arguments We can enclose a script name or a pattern in quotes to use arguments. The following 2 commands are similar. $ npm-run-all --parallel \"build:* -- --watch\" $ npm run build:aaa -- --watch & npm run build:bbb -- --watch When we use a pattern, arguments are forwarded to every matched script. Argument placeholders We can use placeholders to give the arguments preceded by -- to scripts. $ npm-run-all build \"start-server -- --port {1}\" -- 8080 This is useful to pass through arguments from npm run command. { \"scripts\": { \"start\": \"npm-run-all build \\\"start-server -- --port {1}\\\" --\" } } $ npm run start 8080 > example@0.0.0 start /path/to/package.json > npm-run-all build \"start-server -- --port {1}\" -- \"8080\" There are the following placeholders: {1}, {2}, ... -- An argument. {1} is the 1st argument. {2} is the 2nd. {@} -- All arguments. {*} -- All arguments as combined. Those are similar to Shell Parameters. But please note arguments are enclosed by double quotes automatically (similar to npm). Known Limitations If --print-label option is given, some tools in scripts might stop coloring their output. Because some coloring library (e.g. chalk) will stop coloring if process.stdout is not a TTY. npm-run-all changes the process.stdout of child processes to a pipe in order to add labels to the head of each line if --print-label option is given. For example, eslint stops coloring under npm-run-all --print-label. But eslint has --color option to force coloring, we can use it. For anything chalk based you can set the environment variable FORCE_COLOR=1 to produce colored output anyway."
  },
  "node_modules/npm-run-all/docs/run-p.html": {
    "href": "node_modules/npm-run-all/docs/run-p.html",
    "title": "run-p command | accouter",
    "keywords": "index npm-run-all run-s run-p Node API run-p command A CLI command to run given npm-scripts in parallel. This command is the shorthand of npm-run-all -p. Usage: $ run-p [--help | -h | --version | -v] $ run-p [OPTIONS] <tasks> Run given npm-scripts in parallel. <tasks> : A list of npm-scripts' names and Glob-like patterns. Options: --aggregate-output - - - Avoid interleaving output by delaying printing of each command's output until it has finished. -c, --continue-on-error - Set the flag to continue executing other tasks even if a task threw an error. 'run-p' itself will exit with non-zero code if one or more tasks threw error(s). --max-parallel <number> - Set the maximum number of parallelism. Default is unlimited. --npm-path <string> - - - Set the path to npm. Default is the value of environment variable npm_execpath. If the variable is not defined, then it's \"npm.\" In this case, the \"npm\" command must be found in environment variable PATH. -l, --print-label - - - - Set the flag to print the task name as a prefix on each line of output. Tools in tasks may stop coloring their output if this option was given. -n, --print-name - - - - Set the flag to print the task name before running each task. -r, --race - - - - - - - Set the flag to kill all tasks when a task finished with zero. -s, --silent - - - - - - Set 'silent' to the log level of npm. Shorthand aliases can be combined. For example, '-clns' equals to '-c -l -n -s'. Examples: $ run-p watch:** $ run-p --print-label \"build:** -- --watch\" $ run-p -l \"build:** -- --watch\" $ run-p start-server start-browser start-electron npm-scripts It's \"scripts\" field of package.json. For example: { \"scripts\": { \"clean\": \"rimraf dist\", \"lint\": \"eslint src\", \"build\": \"babel src -o lib\" } } We can run a script with npm run command. On the other hand, this run-p command runs multiple scripts in parallel. The following 2 commands are similar. The run-p command is shorter and available on Windows. $ run-p lint build $ npm run lint & npm run build Note1: If a script exited with a non-zero code, the other scripts and those descendant processes are killed with SIGTERM (On Windows, with taskkill.exe /F /T). If --continue-on-error option is given, this behavior will be disabled. Note2: & operator does not work on Windows' cmd.exe. But run-p works fine there. Glob-like pattern matching for script names We can use glob-like patterns to specify npm-scripts. The difference is one -- the separator is : instead of /. $ run-p watch:* In this case, runs sub scripts of watch. For example: watch:html, watch:js. But, doesn't run sub-sub scripts. For example: watch:js:index. $ run-p watch:** If we use a globstar **, runs both sub scripts and sub-sub scripts. run-p reads the actual npm-script list from package.json in the current directory, then filters the scripts by glob-like patterns, then runs those. Run with arguments We can enclose a script name or a pattern in quotes to use arguments. The following 2 commands are similar. $ run-p \"build:* -- --watch\" $ npm run build:aaa -- --watch & npm run build:bbb -- --watch When we use a pattern, arguments are forwarded to every matched script. Argument placeholders We can use placeholders to give the arguments preceded by -- to scripts. $ run-p \"start-server -- --port {1}\" -- 8080 This is useful to pass through arguments from npm run command. { \"scripts\": { \"start\": \"run-p \\\"start-server -- --port {1}\\\" --\" } } $ npm run start 8080 > example@0.0.0 start /path/to/package.json > run-p \"start-server -- --port {1}\" -- \"8080\" There are the following placeholders: {1}, {2}, ... -- An argument. {1} is the 1st argument. {2} is the 2nd. {@} -- All arguments. {*} -- All arguments as combined. Those are similar to Shell Parameters. But please note arguments are enclosed by double quotes automatically (similar to npm). Known Limitations If --print-label option is given, some tools in scripts might stop coloring their output. Because some coloring library (e.g. chalk) will stop coloring if process.stdout is not a TTY. run-p changes the process.stdout of child processes to a pipe in order to add labels to the head of each line if --print-label option is given. For example, eslint stops coloring under run-p --print-label. But eslint has --color option to force coloring, we can use it."
  },
  "node_modules/npm-run-all/docs/run-s.html": {
    "href": "node_modules/npm-run-all/docs/run-s.html",
    "title": "run-s command | accouter",
    "keywords": "index npm-run-all run-s run-p Node API run-s command A CLI command to run given npm-scripts sequentially. This command is the shorthand of npm-run-all -s. Usage: $ run-s [--help | -h | --version | -v] $ run-s [OPTIONS] <tasks> Run given npm-scripts sequentially. <tasks> : A list of npm-scripts' names and Glob-like patterns. Options: -c, --continue-on-error - Set the flag to continue executing subsequent tasks even if a task threw an error. 'run-s' itself will exit with non-zero code if one or more tasks threw error(s). --npm-path <string> - - - Set the path to npm. Default is the value of environment variable npm_execpath. If the variable is not defined, then it's \"npm.\" In this case, the \"npm\" command must be found in environment variable PATH. -l, --print-label - - - - Set the flag to print the task name as a prefix on each line of output. Tools in tasks may stop coloring their output if this option was given. -n, --print-name - - - - Set the flag to print the task name before running each task. -s, --silent - - - - - - Set 'silent' to the log level of npm. Shorthand aliases can be combined. For example, '-clns' equals to '-c -l -n -s'. Examples: $ run-s build:** $ run-s lint clean build:** $ run-s --silent --print-name lint clean build:** $ run-s -sn lint clean build:** npm-scripts It's \"scripts\" field of package.json. For example: { \"scripts\": { \"clean\": \"rimraf dist\", \"lint\": \"eslint src\", \"build\": \"babel src -o lib\" } } We can run a script with npm run command. On the other hand, this run-s command runs multiple scripts sequentially. The following 2 commands are the same. The run-s command is shorter. $ run-s clean lint build $ npm run clean && npm run lint && npm run build Note: If a script exited with a non-zero code, the following scripts are not run. Glob-like pattern matching for script names We can use glob-like patterns to specify npm-scripts. The difference is one -- the separator is : instead of /. $ run-s build:* In this case, runs sub scripts of build. For example: build:html, build:js. But, doesn't run sub-sub scripts. For example: build:js:index. $ run-s build:** If we use a globstar **, runs both sub scripts and sub-sub scripts. run-s reads the actual npm-script list from package.json in the current directory, then filters the scripts by glob-like patterns, then runs those. Run with arguments We can enclose a script name or a pattern in quotes to use arguments. The following 2 commands are the same. $ run-s start:server \"delay 3000\" start:client $ npm run start:server && npm run delay 3000 && npm run start:client When we use a pattern, arguments are forwarded to every matched script. Argument placeholders We can use placeholders to give the arguments preceded by -- to scripts. $ run-s build \"start-server -- --port {1}\" -- 8080 This is useful to pass through arguments from npm run command. { \"scripts\": { \"start\": \"run-s build \\\"start-server -- --port {1}\\\" --\" } } $ npm run start 8080 > example@0.0.0 start /path/to/package.json > run-s build \"start-server -- --port {1}\" -- \"8080\" There are the following placeholders: {1}, {2}, ... -- An argument. {1} is the 1st argument. {2} is the 2nd. {@} -- All arguments. {*} -- All arguments as combined. Those are similar to Shell Parameters. But please note arguments are enclosed by double quotes automatically (similar to npm). Known Limitations If --print-label option is given, some tools in scripts might stop coloring their output. Because some coloring library (e.g. chalk) will stop coloring if process.stdout is not a TTY. run-s changes the process.stdout of child processes to a pipe in order to add labels to the head of each line if --print-label option is given. For example, eslint stops coloring under run-s --print-label. But eslint has --color option to force coloring, we can use it."
  },
  "node_modules/npm-run-all/node_modules/ansi-styles/readme.html": {
    "href": "node_modules/npm-run-all/node_modules/ansi-styles/readme.html",
    "title": "ansi-styles | accouter",
    "keywords": "ansi-styles ANSI escape codes for styling strings in the terminal You probably want the higher-level chalk module for styling your strings. Install $ npm install ansi-styles Usage const style = require('ansi-styles'); console.log(`${style.green.open}Hello world!${style.green.close}`); // Color conversion between 16/256/truecolor // NOTE: If conversion goes to 16 colors or 256 colors, the original color // may be degraded to fit that color palette. This means terminals // that do not support 16 million colors will best-match the // original color. console.log(style.bgColor.ansi.hsl(120, 80, 72) + 'Hello world!' + style.bgColor.close); console.log(style.color.ansi256.rgb(199, 20, 250) + 'Hello world!' + style.color.close); console.log(style.color.ansi16m.hex('#ABCDEF') + 'Hello world!' + style.color.close); API Each style has an open and close property. Styles Modifiers reset bold dim italic (Not widely supported) underline inverse hidden strikethrough (Not widely supported) Colors black red green yellow blue magenta cyan white gray (\"bright black\") redBright greenBright yellowBright blueBright magentaBright cyanBright whiteBright Background colors bgBlack bgRed bgGreen bgYellow bgBlue bgMagenta bgCyan bgWhite bgBlackBright bgRedBright bgGreenBright bgYellowBright bgBlueBright bgMagentaBright bgCyanBright bgWhiteBright Advanced usage By default, you get a map of styles, but the styles are also available as groups. They are non-enumerable so they don't show up unless you access them explicitly. This makes it easier to expose only a subset in a higher-level module. style.modifier style.color style.bgColor Example console.log(style.color.green.open); Raw escape codes (i.e. without the CSI escape prefix \\u001B[ and render mode postfix m) are available under style.codes, which returns a Map with the open codes as keys and close codes as values. Example console.log(style.codes.get(36)); //=> 39 256 / 16 million (TrueColor) support ansi-styles uses the color-convert package to allow for converting between various colors and ANSI escapes, with support for 256 and 16 million colors. To use these, call the associated conversion function with the intended output, for example: style.color.ansi.rgb(100, 200, 15); // RGB to 16 color ansi foreground code style.bgColor.ansi.rgb(100, 200, 15); // RGB to 16 color ansi background code style.color.ansi256.hsl(120, 100, 60); // HSL to 256 color ansi foreground code style.bgColor.ansi256.hsl(120, 100, 60); // HSL to 256 color ansi foreground code style.color.ansi16m.hex('#C0FFEE'); // Hex (RGB) to 16 million color foreground code style.bgColor.ansi16m.hex('#C0FFEE'); // Hex (RGB) to 16 million color background code Related ansi-escapes - ANSI escape codes for manipulating the terminal Maintainers Sindre Sorhus Josh Junon License MIT"
  },
  "node_modules/npm-run-all/node_modules/brace-expansion/README.html": {
    "href": "node_modules/npm-run-all/node_modules/brace-expansion/README.html",
    "title": "brace-expansion | accouter",
    "keywords": "brace-expansion Brace expansion, as known from sh/bash, in JavaScript. Example var expand = require('brace-expansion'); expand('file-{a,b,c}.jpg') // => ['file-a.jpg', 'file-b.jpg', 'file-c.jpg'] expand('-v{,,}') // => ['-v', '-v', '-v'] expand('file{0..2}.jpg') // => ['file0.jpg', 'file1.jpg', 'file2.jpg'] expand('file-{a..c}.jpg') // => ['file-a.jpg', 'file-b.jpg', 'file-c.jpg'] expand('file{2..0}.jpg') // => ['file2.jpg', 'file1.jpg', 'file0.jpg'] expand('file{0..4..2}.jpg') // => ['file0.jpg', 'file2.jpg', 'file4.jpg'] expand('file-{a..e..2}.jpg') // => ['file-a.jpg', 'file-c.jpg', 'file-e.jpg'] expand('file{00..10..5}.jpg') // => ['file00.jpg', 'file05.jpg', 'file10.jpg'] expand('{{A..C},{a..c}}') // => ['A', 'B', 'C', 'a', 'b', 'c'] expand('ppp{,config,oe{,conf}}') // => ['ppp', 'pppconfig', 'pppoe', 'pppoeconf'] API var expand = require('brace-expansion'); var expanded = expand(str) Return an array of all possible and valid expansions of str. If none are found, [str] is returned. Valid expansions are: /^(.*,)+(.+)?$/ // {a,b,...} A comma separated list of options, like {a,b} or {a,{b,c}} or {,a,}. /^-?\\d+\\.\\.-?\\d+(\\.\\.-?\\d+)?$/ // {x..y[..incr]} A numeric sequence from x to y inclusive, with optional increment. If x or y start with a leading 0, all the numbers will be padded to have equal length. Negative numbers and backwards iteration work too. /^-?\\d+\\.\\.-?\\d+(\\.\\.-?\\d+)?$/ // {x..y[..incr]} An alphabetic sequence from x to y inclusive, with optional increment. x and y must be exactly one character, and if given, incr must be a number. For compatibility reasons, the string ${ is not eligible for brace expansion. Installation With npm do: npm install brace-expansion Contributors Julian Gruber Isaac Z. Schlueter Sponsors This module is proudly supported by my Sponsors! Do you want to support modules like this to improve their quality, stability and weigh in on new features? Then please consider donating to my Patreon. Not sure how much of my modules you're using? Try feross/thanks! License (MIT) Copyright (c) 2013 Julian Gruber <julian@juliangruber.com&gt; Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/npm-run-all/node_modules/chalk/readme.html": {
    "href": "node_modules/npm-run-all/node_modules/chalk/readme.html",
    "title": "| accouter",
    "keywords": "Terminal string styling done right See what's new in Chalk 2 Highlights Expressive API Highly performant Ability to nest styles 256/Truecolor color support Auto-detects color support Doesn't extend String.prototype Clean and focused Actively maintained Used by ~23,000 packages as of December 31, 2017 Install $ npm install chalk Usage const chalk = require('chalk'); console.log(chalk.blue('Hello world!')); Chalk comes with an easy to use composable API where you just chain and nest the styles you want. const chalk = require('chalk'); const log = console.log; // Combine styled and normal strings log(chalk.blue('Hello') + ' World' + chalk.red('!')); // Compose multiple styles using the chainable API log(chalk.blue.bgRed.bold('Hello world!')); // Pass in multiple arguments log(chalk.blue('Hello', 'World!', 'Foo', 'bar', 'biz', 'baz')); // Nest styles log(chalk.red('Hello', chalk.underline.bgBlue('world') + '!')); // Nest styles of the same type even (color, underline, background) log(chalk.green( 'I am a green line ' + chalk.blue.underline.bold('with a blue substring') + ' that becomes green again!' )); // ES2015 template literal log(` CPU: ${chalk.red('90%')} RAM: ${chalk.green('40%')} DISK: ${chalk.yellow('70%')} `); // ES2015 tagged template literal log(chalk` CPU: {red ${cpu.totalPercent}%} RAM: {green ${ram.used / ram.total * 100}%} DISK: {rgb(255,131,0) ${disk.used / disk.total * 100}%} `); // Use RGB colors in terminal emulators that support it. log(chalk.keyword('orange')('Yay for orange colored text!')); log(chalk.rgb(123, 45, 67).underline('Underlined reddish color')); log(chalk.hex('#DEADED').bold('Bold gray!')); Easily define your own themes: const chalk = require('chalk'); const error = chalk.bold.red; const warning = chalk.keyword('orange'); console.log(error('Error!')); console.log(warning('Warning!')); Take advantage of console.log string substitution: const name = 'Sindre'; console.log(chalk.green('Hello %s'), name); //=> 'Hello Sindre' API chalk.<style>[.<style>...](string, [string...]) Example: chalk.red.bold.underline('Hello', 'world'); Chain styles and call the last one as a method with a string argument. Order doesn't matter, and later styles take precedent in case of a conflict. This simply means that chalk.red.yellow.green is equivalent to chalk.green. Multiple arguments will be separated by space. chalk.enabled Color support is automatically detected, as is the level (see chalk.level). However, if you'd like to simply enable/disable Chalk, you can do so via the .enabled property. Chalk is enabled by default unless explicitly disabled via the constructor or chalk.level is 0. If you need to change this in a reusable module, create a new instance: const ctx = new chalk.constructor({enabled: false}); chalk.level Color support is automatically detected, but you can override it by setting the level property. You should however only do this in your own code as it applies globally to all Chalk consumers. If you need to change this in a reusable module, create a new instance: const ctx = new chalk.constructor({level: 0}); Levels are as follows: All colors disabled Basic color support (16 colors) 256 color support Truecolor support (16 million colors) chalk.supportsColor Detect whether the terminal supports color. Used internally and handled for you, but exposed for convenience. Can be overridden by the user with the flags --color and --no-color. For situations where using --color is not possible, add the environment variable FORCE_COLOR=1 to forcefully enable color or FORCE_COLOR=0 to forcefully disable. The use of FORCE_COLOR overrides all other color support checks. Explicit 256/Truecolor mode can be enabled using the --color=256 and --color=16m flags, respectively. Styles Modifiers reset bold dim italic (Not widely supported) underline inverse hidden strikethrough (Not widely supported) visible (Text is emitted only if enabled) Colors black red green yellow blue (On Windows the bright version is used since normal blue is illegible) magenta cyan white gray (\"bright black\") redBright greenBright yellowBright blueBright magentaBright cyanBright whiteBright Background colors bgBlack bgRed bgGreen bgYellow bgBlue bgMagenta bgCyan bgWhite bgBlackBright bgRedBright bgGreenBright bgYellowBright bgBlueBright bgMagentaBright bgCyanBright bgWhiteBright Tagged template literal Chalk can be used as a tagged template literal. const chalk = require('chalk'); const miles = 18; const calculateFeet = miles => miles * 5280; console.log(chalk` There are {bold 5280 feet} in a mile. In {bold ${miles} miles}, there are {green.bold ${calculateFeet(miles)} feet}. `); Blocks are delimited by an opening curly brace ({), a style, some content, and a closing curly brace (}). Template styles are chained exactly like normal Chalk styles. The following two statements are equivalent: console.log(chalk.bold.rgb(10, 100, 200)('Hello!')); console.log(chalk`{bold.rgb(10,100,200) Hello!}`); Note that function styles (rgb(), hsl(), keyword(), etc.) may not contain spaces between parameters. All interpolated values (chalk`${foo}`) are converted to strings via the .toString() method. All curly braces ({ and }) in interpolated value strings are escaped. 256 and Truecolor color support Chalk supports 256 colors and Truecolor (16 million colors) on supported terminal apps. Colors are downsampled from 16 million RGB values to an ANSI color format that is supported by the terminal emulator (or by specifying {level: n} as a Chalk option). For example, Chalk configured to run at level 1 (basic color support) will downsample an RGB value of #FF0000 (red) to 31 (ANSI escape for red). Examples: chalk.hex('#DEADED').underline('Hello, world!') chalk.keyword('orange')('Some orange text') chalk.rgb(15, 100, 204).inverse('Hello!') Background versions of these models are prefixed with bg and the first level of the module capitalized (e.g. keyword for foreground colors and bgKeyword for background colors). chalk.bgHex('#DEADED').underline('Hello, world!') chalk.bgKeyword('orange')('Some orange text') chalk.bgRgb(15, 100, 204).inverse('Hello!') The following color models can be used: rgb - Example: chalk.rgb(255, 136, 0).bold('Orange!') hex - Example: chalk.hex('#FF8800').bold('Orange!') keyword (CSS keywords) - Example: chalk.keyword('orange').bold('Orange!') hsl - Example: chalk.hsl(32, 100, 50).bold('Orange!') hsv - Example: chalk.hsv(32, 100, 100).bold('Orange!') hwb - Example: chalk.hwb(32, 0, 50).bold('Orange!') ansi16 ansi256 Windows If you're on Windows, do yourself a favor and use cmder instead of cmd.exe. Origin story colors.js used to be the most popular string styling module, but it has serious deficiencies like extending String.prototype which causes all kinds of problems and the package is unmaintained. Although there are other packages, they either do too much or not enough. Chalk is a clean and focused alternative. Related chalk-cli - CLI for this module ansi-styles - ANSI escape codes for styling strings in the terminal supports-color - Detect whether a terminal supports color strip-ansi - Strip ANSI escape codes strip-ansi-stream - Strip ANSI escape codes from a stream has-ansi - Check if a string has ANSI escape codes ansi-regex - Regular expression for matching ANSI escape codes wrap-ansi - Wordwrap a string with ANSI escape codes slice-ansi - Slice a string with ANSI escape codes color-convert - Converts colors between different models chalk-animation - Animate strings in the terminal gradient-string - Apply color gradients to strings chalk-pipe - Create chalk style schemes with simpler style strings terminal-link - Create clickable links in the terminal Maintainers Sindre Sorhus Josh Junon License MIT"
  },
  "node_modules/npm-run-all/node_modules/color-convert/CHANGELOG.html": {
    "href": "node_modules/npm-run-all/node_modules/color-convert/CHANGELOG.html",
    "title": "1.0.0 - 2016-01-07 | accouter",
    "keywords": "1.0.0 - 2016-01-07 Removed: unused speed test Added: Automatic routing between previously unsupported conversions (#27) Removed: xxx2xxx() and xxx2xxxRaw() functions (#27) Removed: convert() class (#27) Changed: all functions to lookup dictionary (#27) Changed: ansi to ansi256 (#27) Fixed: argument grouping for functions requiring only one argument (#27) 0.6.0 - 2015-07-23 Added: methods to handle ANSI 16/256 colors: rgb2ansi16 rgb2ansi hsl2ansi16 hsl2ansi hsv2ansi16 hsv2ansi hwb2ansi16 hwb2ansi cmyk2ansi16 cmyk2ansi keyword2ansi16 keyword2ansi ansi162rgb ansi162hsl ansi162hsv ansi162hwb ansi162cmyk ansi162keyword ansi2rgb ansi2hsl ansi2hsv ansi2hwb ansi2cmyk ansi2keyword (#18) 0.5.3 - 2015-06-02 Fixed: hsl2hsv does not return NaN anymore when using [0,0,0] (#15) Check out commit logs for older releases"
  },
  "node_modules/npm-run-all/node_modules/color-convert/README.html": {
    "href": "node_modules/npm-run-all/node_modules/color-convert/README.html",
    "title": "color-convert | accouter",
    "keywords": "color-convert Color-convert is a color conversion library for JavaScript and node. It converts all ways between rgb, hsl, hsv, hwb, cmyk, ansi, ansi16, hex strings, and CSS keywords (will round to closest): var convert = require('color-convert'); convert.rgb.hsl(140, 200, 100); // [96, 48, 59] convert.keyword.rgb('blue'); // [0, 0, 255] var rgbChannels = convert.rgb.channels; // 3 var cmykChannels = convert.cmyk.channels; // 4 var ansiChannels = convert.ansi16.channels; // 1 Install $ npm install color-convert API Simply get the property of the from and to conversion that you're looking for. All functions have a rounded and unrounded variant. By default, return values are rounded. To get the unrounded (raw) results, simply tack on .raw to the function. All 'from' functions have a hidden property called .channels that indicates the number of channels the function expects (not including alpha). var convert = require('color-convert'); // Hex to LAB convert.hex.lab('DEADBF'); // [ 76, 21, -2 ] convert.hex.lab.raw('DEADBF'); // [ 75.56213190997677, 20.653827952644754, -2.290532499330533 ] // RGB to CMYK convert.rgb.cmyk(167, 255, 4); // [ 35, 0, 98, 0 ] convert.rgb.cmyk.raw(167, 255, 4); // [ 34.509803921568626, 0, 98.43137254901961, 0 ] Arrays All functions that accept multiple arguments also support passing an array. Note that this does not apply to functions that convert from a color that only requires one value (e.g. keyword, ansi256, hex, etc.) var convert = require('color-convert'); convert.rgb.hex(123, 45, 67); // '7B2D43' convert.rgb.hex([123, 45, 67]); // '7B2D43' Routing Conversions that don't have an explicitly defined conversion (in conversions.js), but can be converted by means of sub-conversions (e.g. XYZ -> RGB -> CMYK), are automatically routed together. This allows just about any color model supported by color-convert to be converted to any other model, so long as a sub-conversion path exists. This is also true for conversions requiring more than one step in between (e.g. LCH -> LAB -> XYZ -> RGB -> Hex). Keep in mind that extensive conversions may result in a loss of precision, and exist only to be complete. For a list of \"direct\" (single-step) conversions, see conversions.js. Contribute If there is a new model you would like to support, or want to add a direct conversion between two existing models, please send us a pull request. License Copyright © 2011-2016, Heather Arthur and Josh Junon. Licensed under the MIT License."
  },
  "node_modules/npm-run-all/node_modules/color-name/README.html": {
    "href": "node_modules/npm-run-all/node_modules/color-name/README.html",
    "title": "| accouter",
    "keywords": "A JSON with color names and its values. Based on http://dev.w3.org/csswg/css-color/#named-colors. var colors = require('color-name'); colors.red //[255,0,0]"
  },
  "node_modules/npm-run-all/node_modules/escape-string-regexp/readme.html": {
    "href": "node_modules/npm-run-all/node_modules/escape-string-regexp/readme.html",
    "title": "escape-string-regexp | accouter",
    "keywords": "escape-string-regexp Escape RegExp special characters Install $ npm install --save escape-string-regexp Usage const escapeStringRegexp = require('escape-string-regexp'); const escapedString = escapeStringRegexp('how much $ for a unicorn?'); //=> 'how much \\$ for a unicorn\\?' new RegExp(escapedString); License MIT © Sindre Sorhus"
  },
  "node_modules/npm-run-all/node_modules/has-flag/readme.html": {
    "href": "node_modules/npm-run-all/node_modules/has-flag/readme.html",
    "title": "has-flag | accouter",
    "keywords": "has-flag Check if argv has a specific flag Correctly stops looking after an -- argument terminator. Install $ npm install has-flag Usage // foo.js const hasFlag = require('has-flag'); hasFlag('unicorn'); //=> true hasFlag('--unicorn'); //=> true hasFlag('f'); //=> true hasFlag('-f'); //=> true hasFlag('foo=bar'); //=> true hasFlag('foo'); //=> false hasFlag('rainbow'); //=> false $ node foo.js -f --unicorn --foo=bar -- --rainbow API hasFlag(flag, [argv]) Returns a boolean for whether the flag exists. flag Type: string CLI flag to look for. The -- prefix is optional. argv Type: string[] Default: process.argv CLI arguments. License MIT © Sindre Sorhus"
  },
  "node_modules/npm-run-all/node_modules/minimatch/README.html": {
    "href": "node_modules/npm-run-all/node_modules/minimatch/README.html",
    "title": "minimatch | accouter",
    "keywords": "minimatch A minimal matching utility. This is the matching library used internally by npm. It works by converting glob expressions into JavaScript RegExp objects. Usage var minimatch = require(\"minimatch\") minimatch(\"bar.foo\", \"*.foo\") // true! minimatch(\"bar.foo\", \"*.bar\") // false! minimatch(\"bar.foo\", \"*.+(bar|foo)\", { debug: true }) // true, and noisy! Features Supports these glob features: Brace Expansion Extended glob matching \"Globstar\" ** matching See: man sh man bash man 3 fnmatch man 5 gitignore Minimatch Class Create a minimatch object by instantiating the minimatch.Minimatch class. var Minimatch = require(\"minimatch\").Minimatch var mm = new Minimatch(pattern, options) Properties pattern The original pattern the minimatch object represents. options The options supplied to the constructor. set A 2-dimensional array of regexp or string expressions. Each row in the array corresponds to a brace-expanded pattern. Each item in the row corresponds to a single path-part. For example, the pattern {a,b/c}/d would expand to a set of patterns like: [ [ a, d ] , [ b, c, d ] ] If a portion of the pattern doesn't have any \"magic\" in it (that is, it's something like \"foo\" rather than fo*o?), then it will be left as a string rather than converted to a regular expression. regexp Created by the makeRe method. A single regular expression expressing the entire pattern. This is useful in cases where you wish to use the pattern somewhat like fnmatch(3) with FNM_PATH enabled. negate True if the pattern is negated. comment True if the pattern is a comment. empty True if the pattern is \"\". Methods makeRe Generate the regexp member if necessary, and return it. Will return false if the pattern is invalid. match(fname) Return true if the filename matches the pattern, or false otherwise. matchOne(fileArray, patternArray, partial) Take a /-split filename, and match it against a single row in the regExpSet. This method is mainly for internal use, but is exposed so that it can be used by a glob-walker that needs to avoid excessive filesystem calls. All other methods are internal, and will be called as necessary. minimatch(path, pattern, options) Main export. Tests a path against the pattern using the options. var isJS = minimatch(file, \"*.js\", { matchBase: true }) minimatch.filter(pattern, options) Returns a function that tests its supplied argument, suitable for use with Array.filter. Example: var javascripts = fileList.filter(minimatch.filter(\"*.js\", {matchBase: true})) minimatch.match(list, pattern, options) Match against the list of files, in the style of fnmatch or glob. If nothing is matched, and options.nonull is set, then return a list containing the pattern itself. var javascripts = minimatch.match(fileList, \"*.js\", {matchBase: true})) minimatch.makeRe(pattern, options) Make a regular expression object from the pattern. Options All options are false by default. debug Dump a ton of stuff to stderr. nobrace Do not expand {a,b} and {1..3} brace sets. noglobstar Disable ** matching against multiple folder names. dot Allow patterns to match filenames starting with a period, even if the pattern does not explicitly have a period in that spot. Note that by default, a/**/b will not match a/.d/b, unless dot is set. noext Disable \"extglob\" style patterns like +(a|b). nocase Perform a case-insensitive match. nonull When a match is not found by minimatch.match, return a list containing the pattern itself if this option is set. When not set, an empty list is returned if there are no matches. matchBase If set, then patterns without slashes will be matched against the basename of the path if it contains slashes. For example, a?b would match the path /xyz/123/acb, but not /xyz/acb/123. nocomment Suppress the behavior of treating # at the start of a pattern as a comment. nonegate Suppress the behavior of treating a leading ! character as negation. flipNegate Returns from negate expressions the same as if they were not negated. (Ie, true on a hit, false on a miss.) partial Compare a partial path to a pattern. As long as the parts of the path that are present are not contradicted by the pattern, it will be treated as a match. This is useful in applications where you're walking through a folder structure, and don't yet have the full path, but want to ensure that you do not walk down paths that can never be a match. For example, minimatch('/a/b', '/a/*/c/d', { partial: true }) // true, might be /a/b/c/d minimatch('/a/b', '/**/d', { partial: true }) // true, might be /a/b/.../d minimatch('/x/y/z', '/a/**/z', { partial: true }) // false, because x !== a allowWindowsEscape Windows path separator \\ is by default converted to /, which prohibits the usage of \\ as a escape character. This flag skips that behavior and allows using the escape character. Comparisons to other fnmatch/glob implementations While strict compliance with the existing standards is a worthwhile goal, some discrepancies exist between minimatch and other implementations, and are intentional. If the pattern starts with a ! character, then it is negated. Set the nonegate flag to suppress this behavior, and treat leading ! characters normally. This is perhaps relevant if you wish to start the pattern with a negative extglob pattern like !(a|B). Multiple ! characters at the start of a pattern will negate the pattern multiple times. If a pattern starts with #, then it is treated as a comment, and will not match anything. Use \\# to match a literal # at the start of a line, or set the nocomment flag to suppress this behavior. The double-star character ** is supported by default, unless the noglobstar flag is set. This is supported in the manner of bsdglob and bash 4.1, where ** only has special significance if it is the only thing in a path part. That is, a/**/b will match a/x/y/b, but a/**b will not. If an escaped pattern has no matches, and the nonull flag is set, then minimatch.match returns the pattern as-provided, rather than interpreting the character escapes. For example, minimatch.match([], \"\\\\*a\\\\?\") will return \"\\\\*a\\\\?\" rather than \"*a?\". This is akin to setting the nullglob option in bash, except that it does not resolve escaped pattern characters. If brace expansion is not disabled, then it is performed before any other interpretation of the glob pattern. Thus, a pattern like +(a|{b),c)}, which would not be valid in bash or zsh, is expanded first into the set of +(a|b) and +(a|c), and those patterns are checked for validity. Since those two are valid, matching proceeds."
  },
  "node_modules/npm-run-all/node_modules/supports-color/readme.html": {
    "href": "node_modules/npm-run-all/node_modules/supports-color/readme.html",
    "title": "supports-color | accouter",
    "keywords": "supports-color Detect whether a terminal supports color Install $ npm install supports-color Usage const supportsColor = require('supports-color'); if (supportsColor.stdout) { console.log('Terminal stdout supports color'); } if (supportsColor.stdout.has256) { console.log('Terminal stdout supports 256 colors'); } if (supportsColor.stderr.has16m) { console.log('Terminal stderr supports 16 million colors (truecolor)'); } API Returns an Object with a stdout and stderr property for testing either streams. Each property is an Object, or false if color is not supported. The stdout/stderr objects specifies a level of support for color through a .level property and a corresponding flag: .level = 1 and .hasBasic = true: Basic color support (16 colors) .level = 2 and .has256 = true: 256 color support .level = 3 and .has16m = true: Truecolor support (16 million colors) Info It obeys the --color and --no-color CLI flags. Can be overridden by the user with the flags --color and --no-color. For situations where using --color is not possible, add the environment variable FORCE_COLOR=1 to forcefully enable color or FORCE_COLOR=0 to forcefully disable. The use of FORCE_COLOR overrides all other color support checks. Explicit 256/Truecolor mode can be enabled using the --color=256 and --color=16m flags, respectively. Related supports-color-cli - CLI for this module chalk - Terminal string styling done right Maintainers Sindre Sorhus Josh Junon License MIT"
  },
  "node_modules/nth-check/README.html": {
    "href": "node_modules/nth-check/README.html",
    "title": "nth-check | accouter",
    "keywords": "nth-check Parses and compiles CSS nth-checks to highly optimized functions. About This module can be used to parse & compile nth-checks, as they are found in CSS 3's nth-child() and nth-last-of-type(). It can be used to check if a given index matches a given nth-rule, or to generate a sequence of indices matching a given nth-rule. nth-check focusses on speed, providing optimized functions for different kinds of nth-child formulas, while still following the spec. API import nthCheck, { parse, compile } from \"nth-check\"; nthCheck(formula) Parses and compiles a formula to a highly optimized function. Combination of parse and compile. If the formula doesn't match any elements, it returns boolbase's falseFunc. Otherwise, a function accepting an index is returned, which returns whether or not the passed index matches the formula. Note: The nth-rule starts counting at 1, the returned function at 0. Example: const check = nthCheck(\"2n+3\"); check(0); // `false` check(1); // `false` check(2); // `true` check(3); // `false` check(4); // `true` check(5); // `false` check(6); // `true` parse(formula) Parses the expression, throws an Error if it fails. Otherwise, returns an array containing the integer step size and the integer offset of the nth rule. Example: parse(\"2n+3\"); // [2, 3] compile([a, b]) Takes an array with two elements (as returned by .parse) and returns a highly optimized function. Example: const check = compile([2, 3]); check(0); // `false` check(1); // `false` check(2); // `true` check(3); // `false` check(4); // `true` check(5); // `false` check(6); // `true` generate([a, b]) Returns a function that produces a monotonously increasing sequence of indices. If the sequence has an end, the returned function will return null after the last index in the sequence. Example: An always increasing sequence const gen = nthCheck.generate([2, 3]); gen(); // `1` gen(); // `3` gen(); // `5` gen(); // `8` gen(); // `11` Example: With an end value const gen = nthCheck.generate([-2, 5]); gen(); // 0 gen(); // 2 gen(); // 4 gen(); // null sequence(formula) Parses and compiles a formula to a generator that produces a sequence of indices. Combination of parse and generate. Example: An always increasing sequence const gen = nthCheck.sequence(\"2n+3\"); gen(); // `1` gen(); // `3` gen(); // `5` gen(); // `8` gen(); // `11` Example: With an end value const gen = nthCheck.sequence(\"-2n+5\"); gen(); // 0 gen(); // 2 gen(); // 4 gen(); // null License: BSD-2-Clause Security contact information To report a security vulnerability, please use the Tidelift security contact. Tidelift will coordinate the fix and disclosure. nth-check for enterprise Available as part of the Tidelift Subscription The maintainers of nth-check and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more."
  },
  "node_modules/object-assign/readme.html": {
    "href": "node_modules/object-assign/readme.html",
    "title": "object-assign | accouter",
    "keywords": "object-assign ES2015 Object.assign() ponyfill Use the built-in Node.js 4 and up, as well as every evergreen browser (Chrome, Edge, Firefox, Opera, Safari), support Object.assign() 🎉. If you target only those environments, then by all means, use Object.assign() instead of this package. Install $ npm install --save object-assign Usage const objectAssign = require('object-assign'); objectAssign({foo: 0}, {bar: 1}); //=> {foo: 0, bar: 1} // multiple sources objectAssign({foo: 0}, {bar: 1}, {baz: 2}); //=> {foo: 0, bar: 1, baz: 2} // overwrites equal keys objectAssign({foo: 0}, {foo: 1}, {foo: 2}); //=> {foo: 2} // ignores null and undefined sources objectAssign({foo: 0}, null, {bar: 1}, undefined); //=> {foo: 0, bar: 1} API objectAssign(target, [source, ...]) Assigns enumerable own properties of source objects to the target object and returns the target object. Additional source objects will overwrite previous ones. Resources ES2015 spec - Object.assign Related deep-assign - Recursive Object.assign() License MIT © Sindre Sorhus"
  },
  "node_modules/object-inspect/CHANGELOG.html": {
    "href": "node_modules/object-inspect/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.13.1 - 2023-10-19 Commits [Fix] in IE 8, global can !== window despite them being prototypes of each other 30d0859 v1.13.0 - 2023-10-14 Commits [New] add special handling for the global object 431bab2 [Dev Deps] update @ljharb/eslint-config, aud, tape fd4f619 [Dev Deps] update mock-property, tape b453f6c [Dev Deps] update error-cause e8ffc57 [Dev Deps] update tape 054b8b9 [Dev Deps] temporarily remove aud due to breaking change in transitive deps 2476845 [Dev Deps] pin glob, since v10.3.8+ requires a broken jackspeak 383fa5e [Dev Deps] pin jackspeak since 2.1.2+ depends on npm aliases, which kill the install process in npm < 6 68c244c v1.12.3 - 2023-01-12 Commits [Fix] in eg FF 24, collections lack forEach 75fc226 [actions] update rebase action to use reusable workflow 250a277 [Dev Deps] update aud, es-value-fixtures, tape 66a19b3 [Dev Deps] update @ljharb/eslint-config, aud, error-cause c43d332 [Tests] add @pkgjs/support to postlint e2618d2 v1.12.2 - 2022-05-26 Commits [Fix] use util.inspect for a custom inspection symbol method e243bf2 [meta] add support info ca20ba3 [Fix] ignore cause in node v16.9 and v16.10 where it has a bug 86aa553 v1.12.1 - 2022-05-21 Commits [Tests] use mock-property 4ec8893 [meta] use npmignore to autogenerate an npmignore file 07f868c [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape b05244b [Dev Deps] update @ljharb/eslint-config, error-cause, es-value-fixtures, functions-have-names, tape d037398 [Fix] properly handle callable regexes in older engines 848fe48 v1.12.0 - 2021-12-18 Commits [New] add numericSeparator boolean option 2d2d537 [Robustness] cache more prototype methods 191533d [New] ensure an Error’s cause is displayed 53bc2ce [Dev Deps] update eslint, @ljharb/eslint-config bc164b6 [Robustness] cache RegExp.prototype.test a314ab8 [meta] fix auto-changelog settings 5ed0983 v1.11.1 - 2021-12-05 Commits [meta] add auto-changelog 7dbdd22 [actions] reuse common workflows c8823bc [Dev Deps] update eslint, @ljharb/eslint-config, safe-publish-latest, tape 7532b12 [Refactor] use has-tostringtag to behave correctly in the presence of symbol shams 94abb5d [actions] update codecov uploader 5ed5102 [Dev Deps] update eslint, tape 37b2ad2 [meta] add sideEffects flag d341f90 v1.11.0 - 2021-07-12 Commits [New] customInspect: add symbol option, to mimic modern util.inspect behavior e973a6e [Dev Deps] update eslint 05f1cb3 v1.10.3 - 2021-05-07 Commits [Fix] handle core-js Symbol shams 4acfc2c [readme] update badges 95c323a [Dev Deps] update eslint, @ljharb/eslint-config, aud cb38f48 v1.10.2 - 2021-04-17 Commits [Fix] use a robust check for a boxed Symbol 87f12d6 v1.10.1 - 2021-04-17 Commits [Fix] use a robust check for a boxed bigint d5ca829 v1.10.0 - 2021-04-17 Commits [Tests] increase coverage d8abb8a [actions] use node/install instead of node/run; use codecov action 4bfec2e [New] respect Symbol.toStringTag on objects 799b58f [Fix] do not allow Symbol.toStringTag to masquerade as builtins d6c5b37 [New] add WeakRef support b6d898e [meta] do not publish github action workflow files 918cdfc [meta] create FUNDING.yml 0bb5fc5 [Dev Deps] update eslint, @ljharb/eslint-config, aud, tape 22c8dc0 [meta] use prepublishOnly script for npm 7+ e52ee09 [Dev Deps] update eslint 7c4e6fd v1.9.0 - 2020-11-30 Commits [Tests] migrate tests to Github Actions d262251 [New] add enumerable own Symbols to plain object output ee60c03 [Tests] add passing tests 01ac3e4 [actions] add \"Require Allow Edits\" action c2d7746 [Dev Deps] update eslint, @ljharb/eslint-config, aud, core-js 70058de [Fix] hex characters in strings should be uppercased, to match node assert 6ab8faa [Tests] run nyc on all tests 4c47372 [Tests] node 0.8 has an unpredictable property order; fix groups test by removing property f192069 [New] add enumerable properties to Function inspect result, per node’s assert fd38e1b [Tests] fix tests for node < 10, due to regex match groups 2ac6462 [Dev Deps] update eslint, @ljharb/eslint-config 44b59e2 [Robustness] cache Symbol.prototype.toString f3c2074 [Dev Deps] update eslint 9411294 [meta] require-allow-edits no longer requires an explicit github token 36c0220 [actions] update rebase checkout action to v2 55a39a6 [actions] switch Automatic Rebase workflow to pull_request_target event f59fd3c [Dev Deps] update eslint a492bec v1.8.0 - 2020-06-18 Fixed [New] add indent option #27 Commits [Tests] add codecov 4324cbb [New] add maxStringLength option b3995cb [New] add customInspect option, to disable custom inspect methods 28b9179 [Tests] add Date and RegExp tests 3b28eca [actions] add automatic rebasing / merge commit blocking 0d9c6c0 [Dev Deps] update eslint, @ljharb/eslint-config, core-js, tape; add aud 7c204f2 [readme] fix repo URLs, remove testling 34ca9a0 [Fix] when truncating a deep array, note it as [Array] instead of just [Object] f74c82d [Dev Deps] update eslint, @ljharb/eslint-config, tape 1a8a5ea [Fix] do not be fooled by a function’s own toString method 7cb5c65 [patch] indicate explicitly that anon functions are anonymous, to match node 81ebdd4 [Dev Deps] loosen the core-js dep e7472e8 [Dev Deps] update tape 699827e [meta] add safe-publish-latest c5d2868 [Dev Deps] update @ljharb/eslint-config 9199501 v1.7.0 - 2019-11-10 Commits [Tests] use shared travis-ci configs 19899ed [Tests] add linting a00f057 [Tests] lint last file 2698047 [Tests] up to node v12.7, v11.15, v10.16, v8.16, v6.17 589e87a [New] add support for WeakMap and WeakSet 3ddb3e4 [meta] clean up license so github can detect it properly 27527bb [Tests] cover util.inspect.custom 36d47b9 [Dev Deps] update eslint, @ljharb/eslint-config, core-js, tape b614eaa [Tests] fix coverage thresholds 7b7b176 [Tests] bigint tests now can run on unflagged node 063af31 [Refactor] add early bailout to isMap and isSet checks fc51047 [meta] add funding field 7f9953a [Tests] Fix invalid strict-mode syntax with hexadecimal a8b5425 [Dev Deps] update @ljharb/eslint-config 98df157 add copyright to LICENSE bb69fd0 [Tests] use npx aud in posttest 4838353 [Tests] move 0.6 to allowed failures, because it won‘t build on travis 1bff32a v1.6.0 - 2018-05-02 Commits [New] add support for boxed BigInt primitives 356c66a [Tests] up to node v10.0, v9.11, v8.11, v6.14, v4.9 c77b65b [New] Add support for upcoming BigInt 1ac548e [Tests] run bigint tests in CI with --harmony-bigint flag d31b738 [Dev Deps] update core-js, tape ff9eff6 [Docs] fix example to use safer-buffer 48cae12 v1.5.0 - 2017-12-25 Commits [New] add quoteStyle option f5a72d2 [Tests] add more test coverage 30ebe4e [Tests] require 0.6 to pass 99a008c v1.4.1 - 2017-12-19 Commits [Tests] up to node v9.3, v8.9, v6.12 6674476 [Fix] inspect(Object(-0)) should be “Object(-0)”, not “Object(0)” d0a031f v1.4.0 - 2017-10-24 Commits [Tests] add npm run coverage 3b48fb2 [Tests] remove commented-out osx builds 71e24db [New] add support for util.inspect.custom, in node only. 20cca77 [Tests] up to node v8.6; use nvm install-latest-npm to ensure new npm doesn’t break old node 252952d [Tests] up to node v8.8 4aa868d [Dev Deps] update core-js, tape 59483d1 v1.3.0 - 2017-07-31 Fixed [Fix] Map/Set: work around core-js bug < v2.5.0 #9 Commits [New] add support for arrays with additional object keys 0d19937 [Tests] up to node v8.2, v7.10, v6.11; fix new npm breaking on older nodes e24784a Only apps should have lockfiles c6faebc [Dev Deps] update tape 7345a0a v1.2.2 - 2017-03-24 Commits [Tests] up to node v7.7, v6.10, v4.8; improve test matrix a2ddc15 [Tests] up to node v7.0, v6.9, v5.12, v4.6, io.js v3.3; improve test matrix a48949f [Performance] check for primitive types as early as possible. 3b8092a [Refactor] remove unneeded elses. 7255034 [Refactor] avoid recreating lowbyte function every time. 81edd34 [Fix] differentiate -0 from 0 521d345 [Refactor] move object key gathering into separate function aca6265 [Refactor] consolidate wrapping logic for boxed primitives into a function. 4e440cd [Robustness] use typeof instead of comparing to literal undefined 5ca6f60 [Refactor] consolidate Map/Set notations. 4e576e5 [Tests] ensure that this function remains anonymous, despite ES6 name inference. 7540ae5 [Refactor] explicitly coerce Error objects to strings. 7f4ca84 [Refactor] split up var declarations for debuggability 6f2c11e [Robustness] cache Object.prototype.toString df44a20 [Dev Deps] update tape 3ec714e [Dev Deps] update tape beb72d9 v1.2.1 - 2016-04-09 Fixed [Fix] fix Boolean false object inspection. #7 v1.2.0 - 2016-04-09 Fixed [New] add support for inspecting String/Number/Boolean objects. #6 Commits [Dev Deps] update tape 742caa2 v1.1.0 - 2015-12-14 Merged [New] add ES6 Map/Set support. #4 Fixed [New] add ES6 Map/Set support. #3 Commits Update travis.yml to test on bunches of iojs and node versions. 4c1fd65 [Dev Deps] update tape 88a907e 1.0.2 - 2015-08-07 Commits [Fix] Cache Object.prototype.hasOwnProperty in case it's deleted later. 1d0075d [Dev Deps] Update tape ca8d5d7 gitignore node_modules since this is a reusable modules. ed41407 1.0.1 - 2015-07-19 Commits Make inspect work with symbol primitives and objects, including in node 0.11 and 0.12. ddf1b94 bump tape 103d674 use newer travis config d497276 1.0.0 - 2014-08-05 Commits error inspect works properly 260a22d seen coverage 57269e8 htmlelement instance coverage 397ffe1 more element coverage 6905cc2 failing test for type errors 385b615 fn name coverage edc906d server-side element test 362d1d3 custom inspect fn e89b0f6 fixed browser test b530882 depth test, matches node 1cfd9e0 exercise hasOwnProperty path 8d753fb more cases covered for errors c5c46a5 \\W obj key test case b0eceee coverage for explicit depth param e12b91c 0.4.0 - 2014-03-21 Commits passing lowbyte interpolation test b847511 lowbyte test 4a2b0e1 0.3.1 - 2014-03-04 Commits sort keys a07b19c 0.3.0 - 2014-03-04 Commits [] and {} instead of [ ] and { } 654c44b 0.2.0 - 2014-03-04 Commits failing holes test 99cdfad regex already work e324033 failing undef/null test 1f88a00 holes in the all example 7d345f3 check for .inspect(), fixes Buffer use-case c3f7546 fixes for holes ce25f73 weird null behavior 405c1ea tape is actually a devDependency, upgrade 703b0ce put date in the example a342219 passing the null test 4ab737e 0.1.3 - 2013-07-26 Commits special isElement() check 882768a oh right old IEs don't have indexOf either 36d1275 0.1.1 - 2013-07-26 Commits tests! 4422fd9 fix for ie<9, doesn't have hasOwnProperty 6b7d611 fix for all IEs: no f.name 4e0c2f6 badges 5ed0d88 0.1.0 - 2013-07-26 Commits [Function] for functions ad5c485 0.0.0 - 2013-07-26 Commits working browser example 34be6b6 package.json etc cad51f2 docs complete b80cce2 circular example 4b4a7b9 string rep 7afb479"
  },
  "node_modules/object-keys/CHANGELOG.html": {
    "href": "node_modules/object-keys/CHANGELOG.html",
    "title": "1.1.1 / 2019-04-06 | accouter",
    "keywords": "1.1.1 / 2019-04-06 [Fix] exclude deprecated Firefox keys (#53) 1.1.0 / 2019-02-10 [New] [Refactor] move full implementation to implementation entry point [Refactor] only evaluate the implementation if Object.keys is not present [Tests] up to node v11.8, v10.15, v8.15, v6.16 [Tests] remove jscs [Tests] switch to npm audit from nsp 1.0.12 / 2018-06-18 [Fix] avoid accessing window.applicationCache, to avoid issues with latest Chrome on HTTP (#46) 1.0.11 / 2016-07-05 [Fix] exclude keys regarding the style (eg. pageYOffset) on window to avoid reflow (#32) 1.0.10 / 2016-07-04 [Fix] exclude height and width keys on window to avoid reflow (#31) [Fix] In IE 6, window.external makes Object.keys throw [Tests] up to node v6.2, v5.10, v4.4 [Tests] use pretest/posttest for linting/security [Dev Deps] update tape, jscs, nsp, eslint, @ljharb/eslint-config [Dev Deps] remove unused eccheck script + dep 1.0.9 / 2015-10-19 [Fix] Blacklist 'frame' property on window (#16, #17) [Dev Deps] update jscs, eslint, @ljharb/eslint-config 1.0.8 / 2015-10-14 [Fix] wrap automation equality bug checking in try/catch, per es5-shim#327 [Fix] Blacklist 'window.frameElement' per es5-shim#322 [Docs] Switch from vb.teelaun.ch to versionbadg.es for the npm version badge SVG [Tests] up to io.js v3.3, node v4.2 [Dev Deps] update eslint, tape, @ljharb/eslint-config, jscs 1.0.7 / 2015-07-18 [Fix] A proper fix for 176f03335e90d5c8d0d8125a99f27819c9b9cdad / https://github.com/es-shims/es5-shim/issues/275 that doesn't break dontEnum/constructor fixes in IE 8. [Fix] Remove deprecation message in Chrome by touching deprecated window properties (#15) [Tests] Improve test output for automation equality bugfix [Tests] Test on io.js v2.4 1.0.6 / 2015-07-09 [Fix] Use an object lookup rather than ES5's indexOf (#14) [Tests] ES3 browsers don't have Array.isArray [Tests] Fix no-shadow rule, as well as an IE 8 bug caused by engine NFE shadowing bugs. 1.0.5 / 2015-07-03 [Fix] Fix a flabbergasting IE 8 bug where localStorage.constructor.prototype === localStorage throws [Tests] Test up to io.js v2.3 [Dev Deps] Update nsp, eslint 1.0.4 / 2015-05-23 Fix a Safari 5.0 bug with Object.keys not working with arguments Test on latest node and io.js Update jscs, tape, eslint, nsp, is, editorconfig-tools, covert 1.0.3 / 2015-01-06 Revert \"Make object-keys more robust against later environment tampering\" to maintain ES3 compliance 1.0.2 / 2014-12-28 Update lots of dev dependencies Tweaks to README Make object-keys more robust against later environment tampering 1.0.1 / 2014-09-03 Update URLs and badges in README 1.0.0 / 2014-08-26 v1.0.0 0.6.1 / 2014-08-25 v0.6.1 Updating dependencies (tape, covert, is) Update badges in readme Use separate var statements 0.6.0 / 2014-04-23 v0.6.0 Updating dependencies (tape, covert) Make sure boxed primitives, and arguments objects, work properly in ES3 browsers Improve test matrix: test all node versions, but only latest two stables are a failure Remove internal foreach shim. 0.5.1 / 2014-03-09 0.5.1 Updating dependencies (tape, covert, is) Removing forEach from the module (but keeping it in tests) 0.5.0 / 2014-01-30 0.5.0 Explicitly returning the shim, instead of returning native Object.keys when present Adding a changelog. Cleaning up IIFE wrapping Testing on node 0.4 through 0.11 0.4.0 / 2013-08-14 v0.4.0 In Chrome 4-10 and Safari 4, typeof (new RegExp) === 'function' If it's a string, make sure to use charAt instead of brackets. Only use Function#call if necessary. Making sure the context tests actually run. Better function detection Adding the android browser Fixing testling files Updating tape Removing the \"is\" dependency. Making an isArguments shim. Adding a local forEach shim and tests. Updating paths. Moving the shim test. v0.3.0 0.3.0 / 2013-05-18 README tweak. Fixing constructor enum issue. Fixes #5. Adding a test for #5 Updating readme. Updating dependencies. Giving credit to lodash. Make sure that a prototype's constructor property is not enumerable. Fixes #3. Adding additional tests to handle arguments objects, and to skip \"prototype\" in functions. Fixes #2. Fixing a typo on this test for #3. Adding node 0.10 to travis. Adding an IE < 9 test per #3 Adding an iOS 5 mobile Safari test per #2 Moving \"indexof\" and \"is\" to be dev dependencies. Making sure the shim works with functions. Flattening the tests. 0.2.0 / 2013-05-10 v0.2.0 Object.keys should work with arrays. 0.1.8 / 2013-05-10 v0.1.8 Upgrading dependencies. Using a simpler check. Fixing a bug in hasDontEnumBug browsers. Using the newest tape! Fixing this error test. \"undefined\" is probably a reserved word in ES3. Better test message. 0.1.7 / 2013-04-17 Upgrading \"is\" once more. The key \"null\" is breaking some browsers. 0.1.6 / 2013-04-17 v0.1.6 Upgrading \"is\" 0.1.5 / 2013-04-14 Bumping version. Adding more testling browsers. Updating \"is\" 0.1.4 / 2013-04-08 Using \"is\" instead of \"is-extended\". 0.1.3 / 2013-04-07 Using \"foreach\" instead of my own shim. Removing \"tap\"; I'll just wait for \"tape\" to fix its node 0.10 bug. 0.1.2 / 2013-04-03 Adding dependency status; moving links to an index at the bottom. Upgrading is-extended; version 0.1.2 Adding an npm version badge. 0.1.1 / 2013-04-01 Adding Travis CI. Bumping the version. Adding indexOf since IE sucks. Adding a forEach shim since older browsers don't have Array#forEach. Upgrading tape - 0.3.2 uses Array#map Using explicit end instead of plan. Can't test with Array.isArray in older browsers. Using is-extended. Fixing testling files. JSHint/JSLint-ing. Removing an unused object. Using strict mode. 0.1.0 / 2013-03-30 Changing the exports should have meant a higher version bump. Oops, fixing the repo URL. Adding more tests. 0.0.2 Merge branch 'export_one_thing'; closes #1 Move shim export to a separate file."
  },
  "node_modules/object-keys/README.html": {
    "href": "node_modules/object-keys/README.html",
    "title": "| accouter",
    "keywords": "#object-keys An Object.keys shim. Invoke its \"shim\" method to shim Object.keys if it is unavailable. Most common usage: var keys = Object.keys || require('object-keys'); Example var keys = require('object-keys'); var assert = require('assert'); var obj = { a: true, b: true, c: true }; assert.deepEqual(keys(obj), ['a', 'b', 'c']); var keys = require('object-keys'); var assert = require('assert'); /* when Object.keys is not present */ delete Object.keys; var shimmedKeys = keys.shim(); assert.equal(shimmedKeys, keys); assert.deepEqual(Object.keys(obj), keys(obj)); var keys = require('object-keys'); var assert = require('assert'); /* when Object.keys is present */ var shimmedKeys = keys.shim(); assert.equal(shimmedKeys, Object.keys); assert.deepEqual(Object.keys(obj), keys(obj)); Source Implementation taken directly from es5-shim, with modifications, including from lodash. Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/object.assign/CHANGELOG.html": {
    "href": "node_modules/object.assign/CHANGELOG.html",
    "title": "4.1.5 / 2023-11-30 | accouter",
    "keywords": "4.1.5 / 2023-11-30 [meta] republish without testing HTML file (#85) [Deps] update call-bind, define-properties [Dev Deps] use hasown instead of has [Dev Deps] update @es-shims/api, @ljharb/eslint-config, aud, npmignore, mock-property, tape [actions] update rebase action 4.1.4 / 2022-08-16 [meta] fix npmignore integration (#83) 4.1.3 / 2022-08-05 [Refactor] make steps closer to actual spec [Refactor] simplify object coercible check [readme] remove defunct badges, add coverage and actions badges [eslint] ignore coverage output [meta] use npmignore to autogenerate an npmignore file [meta] remove audit-level [Deps] update call-bind, define-properties, has-symbols [Dev Deps] update eslint, @ljharb/eslint-config, @es-shims/api, aud, functions-have-names, safe-publish-latest, ses, tape [actions] use node/install instead of node/run; use codecov action [actions] reuse common workflows [actions] update codecov uploader [Tests] add implementation tests [Tests] use mock-property [Tests] disable posttest pending aud handling file: deps [Tests] migrate remaining tests to Github Actions (#81) [Tests] gitignore coverage output [Tests] test node v1-v9 on Github Actions instead of travis; resume testing all minors (#80) 4.1.2 / 2020-10-30 [Refactor] use extracted call-bind instead of full es-abstract [Dev Deps] update eslint, ses, browserify [Tests] run tests in SES [Tests] ses-compat: show error stacks 4.1.1 / 2020-09-11 [Fix] avoid mutating Object.assign in modern engines [Refactor] use callBind from es-abstract instead of function-bind [Deps] update has-symbols, object-keys, define-properties [meta] add funding field, FUNDING.yml [Dev Deps] update eslint, @ljharb/eslint-config, @es-shims/api, browserify, covert, for-each, is, tape, functions-have-names; add aud, safe-publish-latest; remove jscs [actions] add Require Allow Edits workflow [actions] add automatic rebasing / merge commit blocking [Tests] ses-compat - add test to ensure package initializes correctly after ses lockdown (#77) [Tests] Add passing test for a source of window.location (#68) [Tests] use shared travis-ci config [Tests] use npx aud instead of npm audit with hoops or nsp [Tests] use functions-have-names 4.1.0 / 2017-12-21 [New] add auto entry point (#52) [Refactor] Use has-symbols module [Deps] update function-bind, object-keys [Dev Deps] update @es-shims/api, browserify, nsp, eslint, @ljharb/eslint-config, is [Tests] up to node v9.3, v8.9, v6.12; use nvm install-latest-npm; pin included builds to LTS 4.0.4 / 2016-07-04 [Fix] Cache original getOwnPropertySymbols, and use that when Object.getOwnPropertySymbols is unavailable [Deps] update object-keys [Dev Deps] update eslint, get-own-property-symbols, core-js, jscs, nsp, browserify, @ljharb/eslint-config, tape, @es-shims/api [Tests] up to node v6.2, v5.10, v4.4 [Tests] run sham tests on node 0.10 [Tests] use pretest/posttest for linting/security 4.0.3 / 2015-10-21 [Fix] Support core-js's Symbol sham (#17) [Fix] Ensure that properties removed or made non-enumerable during enumeration are not assigned (#16) [Fix] Avoid looking up keys and values more than once [Tests] Avoid using reduce so npm run test:shams:corejs passes in node v0.8 (core-js#122) [Tests] Refactor to use my conventional structure that separates shimmed, implementation, and common tests [Tests] Create npm run test:shams and better organize tests for symbol shams [Tests] Remove nsp in favor of requiresafe 4.0.2 / 2015-10-20 [Fix] Ensure correct property enumeration order, particularly in v8 (#15) [Deps] update object-keys, define-properties [Dev Deps] update browserify, is, tape, jscs, eslint, @ljharb/eslint-config [Tests] up to io.js v3.3, node v4.2 4.0.1 / 2015-08-16 [Docs] Add Symbol note to readme 4.0.0 / 2015-08-15 [Breaking] Implement the es-shim API. [Robustness] Make implementation robust against later modification of environment methods. [Refactor] Move implementation to implementation.js [Docs] Switch from vb.teelaun.ch to versionbadg.es for the npm version badge SVG [Deps] update object-keys, define-properties [Dev Deps] update browserify, tape, eslint, jscs, browserify [Tests] Add npm run tests-only [Tests] use my personal shared eslint config. [Tests] up to io.js v3.0 3.0.1 / 2015-06-28 Cache Object and Array#push to make the shim more robust. [Fix] Remove use of Array#filter, which isn't in ES3. [Deps] Update object-keys, define-properties [Dev Deps] Update get-own-property-symbols, browserify, eslint, nsp [Tests] Test up to io.js v2.3 [Tests] Adding Object.assign tests for non-object targets, per https://github.com/paulmillr/es6-shim/issues/348 3.0.0 / 2015-05-20 Attempt to feature-detect Symbols, even if typeof Symbol() !== 'symbol' (#12) Make a separate hasSymbols internal module Update browserify, eslint 2.0.3 / 2015-06-28 Cache Object and Array#push to make the shim more robust. [Fix] Remove use of Array#filter, which isn't in ES3 [Deps] Update object-keys, define-properties [Dev Deps] Update browserify, nsp, eslint [Tests] Test up to io.js v2.3 2.0.2 / 2015-05-20 Make sure .shim is non-enumerable. Refactor .shim implementation to use define-properties predicates, rather than deleteing the original. Update docs to match spec/implementation. (#11) Add npm run eslint Test up to io.js v2.0 Update jscs, browserify, covert 2.0.1 / 2015-04-12 Make sure non-enumerable Symbols are excluded. 2.0.0 / 2015-04-12 Make sure the shim function overwrites a broken implementation with pending exceptions. Ensure shim is not enumerable using define-properties Ensure Object.assign includes symbols. All grade A-supported node/iojs versions now ship with an npm that understands ^. Run travis-ci tests on iojs and node v0.12; speed up builds; allow 0.8 failures. Add npm run security via nsp Update browserify, jscs, tape, object-keys, is 1.1.1 / 2014-12-14 Actually include the browser build in npm 1.1.0 / 2014-12-14 Add npm run build, and build an automatic-shimming browser distribution as part of the npm publish process. Update is, jscs 1.0.3 / 2014-11-29 Revert \"optimize --production installs\" 1.0.2 / 2014-11-27 Update jscs, is, object-keys, tape Add badges to README Name URLs in README Lock covert to v1.0.0 Optimize --production installs 1.0.1 / 2014-08-26 Update is, covert 1.0.0 / 2014-08-07 Update object-keys, tape 0.5.0 / 2014-07-31 Object.assign no longer throws on null or undefined sources, per https://bugs.ecmascript.org/show_bug.cgi?id=3096 0.4.3 / 2014-07-30 Don’t modify vars in the function signature, since it deoptimizes v8 0.4.2 / 2014-07-30 Fixing the version number: v0.4.2 0.4.1 / 2014-07-19 Revert \"Use the native Object.keys if it’s available.\" 0.4.0 / 2014-07-19 Use the native Object.keys if it’s available. Fixes #2. Adding failing tests for #2. Fix indentation. Adding npm run lint Update tape, covert README: Use SVG badge for Travis #1 from mathiasbynens/patch-1 0.3.1 / 2014-04-10 Object.assign does partially modify objects if it throws, per https://twitter.com/awbjs/status/454320863093862400 0.3.0 / 2014-04-10 Update with newest ES6 behavior - Object.assign now takes a variable number of source objects. Update tape Make sure old and unstable nodes don’t fail Travis 0.2.1 / 2014-03-16 Let object-keys handle the fallback Update dependency badges Adding bower.json 0.2.0 / 2014-03-16 Use a for loop, because ES3 browsers don’t have \"reduce\" 0.1.1 / 2014-03-14 Updating readme 0.1.0 / 2014-03-14 Initial release."
  },
  "node_modules/object.assign/README.html": {
    "href": "node_modules/object.assign/README.html",
    "title": "object.assign | accouter",
    "keywords": "object.assign An Object.assign shim. Invoke its \"shim\" method to shim Object.assign if it is unavailable. This package implements the es-shim API interface. It works in an ES3-supported environment and complies with the spec. In an ES6 environment, it will also work properly with Symbols. Takes a minimum of 2 arguments: target and source. Takes a variable sized list of source arguments - at least 1, as many as you want. Throws a TypeError if the target argument is null or undefined. Most common usage: var assign = require('object.assign').getPolyfill(); // returns native method if compliant /* or */ var assign = require('object.assign/polyfill')(); // returns native method if compliant Example var assert = require('assert'); // Multiple sources! var target = { a: true }; var source1 = { b: true }; var source2 = { c: true }; var sourceN = { n: true }; var expected = { a: true, b: true, c: true, n: true }; assign(target, source1, source2, sourceN); assert.deepEqual(target, expected); // AWESOME! var target = { a: true, b: true, c: true }; var source1 = { c: false, d: false }; var sourceN = { e: false }; var assigned = assign(target, source1, sourceN); assert.equal(target, assigned); // returns the target object assert.deepEqual(assigned, { a: true, b: true, c: false, d: false, e: false }); /* when Object.assign is not present */ delete Object.assign; var shimmedAssign = require('object.assign').shim(); /* or */ var shimmedAssign = require('object.assign/shim')(); assert.equal(shimmedAssign, assign); var target = { a: true, b: true, c: true }; var source = { c: false, d: false, e: false }; var assigned = assign(target, source); assert.deepEqual(Object.assign(target, source), assign(target, source)); /* when Object.assign is present */ var shimmedAssign = require('object.assign').shim(); assert.equal(shimmedAssign, Object.assign); var target = { a: true, b: true, c: true }; var source = { c: false, d: false, e: false }; assert.deepEqual(Object.assign(target, source), assign(target, source)); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/on-finished/HISTORY.html": {
    "href": "node_modules/on-finished/HISTORY.html",
    "title": "2.3.0 / 2015-05-26 | accouter",
    "keywords": "2.3.0 / 2015-05-26 Add defined behavior for HTTP CONNECT requests Add defined behavior for HTTP Upgrade requests deps: ee-first@1.1.1 2.2.1 / 2015-04-22 Fix isFinished(req) when data buffered 2.2.0 / 2014-12-22 Add message object to callback arguments 2.1.1 / 2014-10-22 Fix handling of pipelined requests 2.1.0 / 2014-08-16 Check if socket is detached Return undefined for isFinished if state unknown 2.0.0 / 2014-08-16 Add isFinished function Move to jshttp organization Remove support for plain socket argument Rename to on-finished Support both req and res as arguments deps: ee-first@1.0.5 1.2.2 / 2014-06-10 Reduce listeners added to emitters avoids \"event emitter leak\" warnings when used multiple times on same request 1.2.1 / 2014-06-08 Fix returned value when already finished 1.2.0 / 2014-06-05 Call callback when called on already-finished socket 1.1.4 / 2014-05-27 Support node.js 0.8 1.1.3 / 2014-04-30 Make sure errors passed as instanceof Error 1.1.2 / 2014-04-18 Default the socket to passed-in object 1.1.1 / 2014-01-16 Rename module to finished 1.1.0 / 2013-12-25 Call callback when called on already-errored socket 1.0.1 / 2013-12-20 Actually pass the error to the callback 1.0.0 / 2013-12-20 Initial release"
  },
  "node_modules/on-finished/README.html": {
    "href": "node_modules/on-finished/README.html",
    "title": "on-finished | accouter",
    "keywords": "on-finished Execute a callback when a HTTP request closes, finishes, or errors. Install $ npm install on-finished API var onFinished = require('on-finished') onFinished(res, listener) Attach a listener to listen for the response to finish. The listener will be invoked only once when the response finished. If the response finished to an error, the first argument will contain the error. If the response has already finished, the listener will be invoked. Listening to the end of a response would be used to close things associated with the response, like open files. Listener is invoked as listener(err, res). onFinished(res, function (err, res) { // clean up open fds, etc. // err contains the error is request error'd }) onFinished(req, listener) Attach a listener to listen for the request to finish. The listener will be invoked only once when the request finished. If the request finished to an error, the first argument will contain the error. If the request has already finished, the listener will be invoked. Listening to the end of a request would be used to know when to continue after reading the data. Listener is invoked as listener(err, req). var data = '' req.setEncoding('utf8') res.on('data', function (str) { data += str }) onFinished(req, function (err, req) { // data is read unless there is err }) onFinished.isFinished(res) Determine if res is already finished. This would be useful to check and not even start certain operations if the response has already finished. onFinished.isFinished(req) Determine if req is already finished. This would be useful to check and not even start certain operations if the request has already finished. Special Node.js requests HTTP CONNECT method The meaning of the CONNECT method from RFC 7231, section 4.3.6: The CONNECT method requests that the recipient establish a tunnel to the destination origin server identified by the request-target and, if successful, thereafter restrict its behavior to blind forwarding of packets, in both directions, until the tunnel is closed. Tunnels are commonly used to create an end-to-end virtual connection, through one or more proxies, which can then be secured using TLS (Transport Layer Security, [RFC5246]). In Node.js, these request objects come from the 'connect' event on the HTTP server. When this module is used on a HTTP CONNECT request, the request is considered \"finished\" immediately, due to limitations in the Node.js interface. This means if the CONNECT request contains a request entity, the request will be considered \"finished\" even before it has been read. There is no such thing as a response object to a CONNECT request in Node.js, so there is no support for for one. HTTP Upgrade request The meaning of the Upgrade header from RFC 7230, section 6.1: The \"Upgrade\" header field is intended to provide a simple mechanism for transitioning from HTTP/1.1 to some other protocol on the same connection. In Node.js, these request objects come from the 'upgrade' event on the HTTP server. When this module is used on a HTTP request with an Upgrade header, the request is considered \"finished\" immediately, due to limitations in the Node.js interface. This means if the Upgrade request contains a request entity, the request will be considered \"finished\" even before it has been read. There is no such thing as a response object to a Upgrade request in Node.js, so there is no support for for one. Example The following code ensures that file descriptors are always closed once the response finishes. var destroy = require('destroy') var http = require('http') var onFinished = require('on-finished') http.createServer(function onRequest(req, res) { var stream = fs.createReadStream('package.json') stream.pipe(res) onFinished(res, function (err) { destroy(stream) }) }) License MIT"
  },
  "node_modules/once/README.html": {
    "href": "node_modules/once/README.html",
    "title": "once | accouter",
    "keywords": "once Only call a function once. usage var once = require('once') function load (file, cb) { cb = once(cb) loader.load('file') loader.once('load', cb) loader.once('error', cb) } Or add to the Function.prototype in a responsible way: // only has to be done once require('once').proto() function load (file, cb) { cb = cb.once() loader.load('file') loader.once('load', cb) loader.once('error', cb) } Ironically, the prototype feature makes this module twice as complicated as necessary. To check whether you function has been called, use fn.called. Once the function is called for the first time the return value of the original function is saved in fn.value and subsequent calls will continue to return this value. var once = require('once') function load (cb) { cb = once(cb) var stream = createStream() stream.once('data', cb) stream.once('end', function () { if (!cb.called) cb(new Error('not found')) }) } once.strict(func) Throw an error if the function is called twice. Some functions are expected to be called only once. Using once for them would potentially hide logical errors. In the example below, the greet function has to call the callback only once: function greet (name, cb) { // return is missing from the if statement // when no name is passed, the callback is called twice if (!name) cb('Hello anonymous') cb('Hello ' + name) } function log (msg) { console.log(msg) } // this will print 'Hello anonymous' but the logical error will be missed greet(null, once(msg)) // once.strict will print 'Hello anonymous' and throw an error when the callback will be called the second time greet(null, once.strict(msg))"
  },
  "node_modules/opn/readme.html": {
    "href": "node_modules/opn/readme.html",
    "title": "opn | accouter",
    "keywords": "opn A better node-open. Opens stuff like websites, files, executables. Cross-platform. Why? Actively maintained Supports app arguments Safer as it uses spawn instead of exec Fixes most of the open node-open issues Includes the latest xdg-open script for Linux Install $ npm install opn Usage const opn = require('opn'); // Opens the image in the default image viewer opn('unicorn.png').then(() => { // image viewer closed }); // Opens the url in the default browser opn('http://sindresorhus.com'); // Specify the app to open in opn('http://sindresorhus.com', {app: 'firefox'}); // Specify app arguments opn('http://sindresorhus.com', {app: ['google chrome', '--incognito']}); API Uses the command open on macOS, start on Windows and xdg-open on other platforms. opn(target, [options]) Returns a promise for the spawned child process. You would normally not need to use this for anything, but it can be useful if you'd like to attach custom event listeners or perform other operations directly on the spawned process. target Type: string The thing you want to open. Can be a URL, file, or executable. Opens in the default app for the file type. For example, URLs opens in your default browser. options Type: Object wait Type: boolean Default: true Wait for the opened app to exit before fulfilling the promise. If false it's fulfilled immediately when opening the app. On Windows you have to explicitly specify an app for it to be able to wait. app Type: string Array Specify the app to open the target with, or an array with the app and app arguments. The app name is platform dependent. Don't hard code it in reusable modules. For example, Chrome is google chrome on macOS, google-chrome on Linux and chrome on Windows. Related opn-cli - CLI for this module License MIT © Sindre Sorhus"
  },
  "node_modules/p-event/readme.html": {
    "href": "node_modules/p-event/readme.html",
    "title": "p-event | accouter",
    "keywords": "p-event Promisify an event by waiting for it to be emitted Useful when you need only one event emission and want to use it with promises or await it in an async function. It works with any event API in Node.js and the browser (using a bundler). If you want multiple individual events as they are emitted, you can use the pEventIterator() method. Observables can be useful too. Install npm install p-event Usage In Node.js: import {pEvent} from 'p-event'; import emitter from './some-event-emitter'; try { const result = await pEvent(emitter, 'finish'); // `emitter` emitted a `finish` event console.log(result); } catch (error) { // `emitter` emitted an `error` event console.error(error); } In the browser: import {pEvent} from 'p-event'; await pEvent(document, 'DOMContentLoaded'); console.log('😎'); Async iteration: import {pEventIterator} from 'p-event'; import emitter from './some-event-emitter'; const asyncIterator = pEventIterator(emitter, 'data', { resolutionEvents: ['finish'] }); for await (const event of asyncIterator) { console.log(event); } API pEvent(emitter, event, options?) pEvent(emitter, event, filter) Returns a Promise that is fulfilled when emitter emits an event matching event, or rejects if emitter emits any of the events defined in the rejectionEvents option. Note: event is a string for a single event type, for example, 'data'. To listen on multiple events, pass an array of strings, such as ['started', 'stopped']. The returned promise has a .cancel() method, which when called, removes the event listeners and causes the promise to never be settled. emitter Type: object Event emitter object. Should have either a .on()/.addListener()/.addEventListener() and .off()/.removeListener()/.removeEventListener() method, like the Node.js EventEmitter and DOM events. event Type: string | string[] Name of the event or events to listen to. If the same event is defined both here and in rejectionEvents, this one takes priority. options Type: object rejectionEvents Type: string[] Default: ['error'] Events that will reject the promise. multiArgs Type: boolean Default: false By default, the promisified function will only return the first argument from the event callback, which works fine for most APIs. This option can be useful for APIs that return multiple arguments in the callback. Turning this on will make it return an array of all arguments from the callback, instead of just the first argument. This also applies to rejections. Example: import {pEvent} from 'p-event'; import emitter from './some-event-emitter'; const [foo, bar] = await pEvent(emitter, 'finish', {multiArgs: true}); timeout Type: number Default: Infinity Time in milliseconds before timing out. filter Type: Function A filter function for accepting an event. import {pEvent} from 'p-event'; import emitter from './some-event-emitter'; const result = await pEvent(emitter, '🦄', value => value > 3); // Do something with first 🦄 event with a value greater than 3 pEventMultiple(emitter, event, options) Wait for multiple event emissions. Returns an array. This method has the same arguments and options as pEvent() with the addition of the following options: options Type: object count Required Type: number The number of times the event needs to be emitted before the promise resolves. resolveImmediately Type: boolean Default: false Whether to resolve the promise immediately. Emitting one of the rejectionEvents won't throw an error. Note: The returned array will be mutated when an event is emitted. Example: import {pEventMultiple} from 'p-event'; const emitter = new EventEmitter(); const promise = pEventMultiple(emitter, 'hello', { resolveImmediately: true, count: Infinity }); const result = await promise; console.log(result); //=> [] emitter.emit('hello', 'Jack'); console.log(result); //=> ['Jack'] emitter.emit('hello', 'Mark'); console.log(result); //=> ['Jack', 'Mark'] // Stops listening emitter.emit('error', new Error('😿')); emitter.emit('hello', 'John'); console.log(result); //=> ['Jack', 'Mark'] pEventIterator(emitter, event, options?) pEventIterator(emitter, event, filter) Returns an async iterator that lets you asynchronously iterate over events of event emitted from emitter. The iterator ends when emitter emits an event matching any of the events defined in resolutionEvents, or rejects if emitter emits any of the events defined in the rejectionEvents option. This method has the same arguments and options as pEvent() with the addition of the following options: options Type: object limit Type: number (non-negative integer) Default: Infinity The maximum number of events for the iterator before it ends. When the limit is reached, the iterator will be marked as done. This option is useful to paginate events, for example, fetching 10 events per page. resolutionEvents Type: string[] Default: [] Events that will end the iterator. TimeoutError Exposed for instance checking and sub-classing. Example: import {pEvent} from 'p-event'; try { await pEvent(emitter, 'finish'); } catch (error) { if (error instanceof pEvent.TimeoutError) { // Do something specific for timeout errors } } Before and after import fs from 'node:fs'; function getOpenReadStream(file, callback) { const stream = fs.createReadStream(file); stream.on('open', () => { callback(null, stream); }); stream.on('error', error => { callback(error); }); } getOpenReadStream('unicorn.txt', (error, stream) => { if (error) { console.error(error); return; } console.log('File descriptor:', stream.fd); stream.pipe(process.stdout); }); import fs from 'node:fs'; import {pEvent} from 'p-event'; async function getOpenReadStream(file) { const stream = fs.createReadStream(file); await pEvent(stream, 'open'); return stream; } (async () => { const stream = await getOpenReadStream('unicorn.txt'); console.log('File descriptor:', stream.fd); stream.pipe(process.stdout); })() .catch(console.error); Tip Dealing with calls that resolve with an error code Some functions might use a single event for success and for certain errors. Promises make it easy to have combined error handler for both error events and successes containing values which represent errors. import {pEvent} from 'p-event'; import emitter from './some-event-emitter'; try { const result = await pEvent(emitter, 'finish'); if (result === 'unwanted result') { throw new Error('Emitter finished with an error'); } // `emitter` emitted a `finish` event with an acceptable value console.log(result); } catch (error) { // `emitter` emitted an `error` event or // emitted a `finish` with 'unwanted result' console.error(error); } Related pify - Promisify a callback-style function p-map - Map over promises concurrently More…"
  },
  "node_modules/p-filter/node_modules/p-map/readme.html": {
    "href": "node_modules/p-filter/node_modules/p-map/readme.html",
    "title": "p-map | accouter",
    "keywords": "p-map Map over promises concurrently Useful when you need to run promise-returning & async functions multiple times with different inputs concurrently. This is different from Promise.all() in that you can control the concurrency and also decide whether or not to stop iterating when there's an error. Install $ npm install p-map Usage import pMap from 'p-map'; import got from 'got'; const sites = [ getWebsiteFromUsername('sindresorhus'), //=> Promise 'https://avajs.dev', 'https://github.com' ]; const mapper = async site => { const {requestUrl} = await got.head(site); return requestUrl; }; const result = await pMap(sites, mapper, {concurrency: 2}); console.log(result); //=> ['https://sindresorhus.com/', 'https://avajs.dev/', 'https://github.com/'] API pMap(input, mapper, options?) Returns a Promise that is fulfilled when all promises in input and ones returned from mapper are fulfilled, or rejects if any of the promises reject. The fulfilled value is an Array of the fulfilled values returned from mapper in input order. input Type: AsyncIterable<Promise<unknown> | unknown> | Iterable<Promise<unknown> | unknown> Synchronous or asynchronous iterable that is iterated over concurrently, calling the mapper function for each element. Each iterated item is await'd before the mapper is invoked so the iterable may return a Promise that resolves to an item. Asynchronous iterables (different from synchronous iterables that return Promise that resolves to an item) can be used when the next item may not be ready without waiting for an asynchronous process to complete and/or the end of the iterable may be reached after the asynchronous process completes. For example, reading from a remote queue when the queue has reached empty, or reading lines from a stream. mapper(element, index) Type: Function Expected to return a Promise or value. options Type: object concurrency Type: number (Integer) Default: Infinity Minimum: 1 Number of concurrently pending promises returned by mapper. stopOnError Type: boolean Default: true When true, the first mapper rejection will be rejected back to the consumer. When false, instead of stopping when a promise rejects, it will wait for all the promises to settle and then reject with an aggregated error containing all the errors from the rejected promises. Caveat: When true, any already-started async mappers will continue to run until they resolve or reject. In the case of infinite concurrency with sync iterables, all mappers are invoked on startup and will continue after the first rejection. Issue #51 can be implemented for abort control. signal Type: AbortSignal You can abort the promises using AbortController. Requires Node.js 16 or later. import pMap from 'p-map'; import delay from 'delay'; const abortController = new AbortController(); setTimeout(() => { abortController.abort(); }, 500); const mapper = async value => value; await pMap([delay(1000), delay(1000)], mapper, {signal: abortController.signal}); // Throws AbortError (DOMException) after 500 ms. pMapSkip Return this value from a mapper function to skip including the value in the returned array. import pMap, {pMapSkip} from 'p-map'; import got from 'got'; const sites = [ getWebsiteFromUsername('sindresorhus'), //=> Promise 'https://avajs.dev', 'https://example.invalid', 'https://github.com' ]; const mapper = async site => { try { const {requestUrl} = await got.head(site); return requestUrl; } catch { return pMapSkip; } }; const result = await pMap(sites, mapper, {concurrency: 2}); console.log(result); //=> ['https://sindresorhus.com/', 'https://avajs.dev/', 'https://github.com/'] p-map for enterprise Available as part of the Tidelift Subscription. The maintainers of p-map and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more. Related p-all - Run promise-returning & async functions concurrently with optional limited concurrency p-filter - Filter promises concurrently p-times - Run promise-returning & async functions a specific number of times concurrently p-props - Like Promise.all() but for Map and Object p-map-series - Map over promises serially p-queue - Promise queue with concurrency control More…"
  },
  "node_modules/p-filter/readme.html": {
    "href": "node_modules/p-filter/readme.html",
    "title": "p-filter | accouter",
    "keywords": "p-filter Filter promises concurrently Useful when you need to run promise-returning & async functions multiple times with different inputs concurrently and get a filtered down result. Install $ npm install p-filter Usage import pFilter from 'p-filter'; import getWeather from 'get-weather'; // Not a real module const places = [ getCapital('Norway').then(info => info.name), 'Bangkok, Thailand', 'Berlin, Germany', 'Tokyo, Japan', ]; const filterer = async place => { const weather = await getWeather(place); return weather.temperature > 30; }; const result = await pFilter(places, filterer); console.log(result); //=> ['Bangkok, Thailand'] API pFilter(input, filterer, options?) Returns a Promise that is fulfilled when all promises in input and ones returned from filterer are fulfilled, or rejects if any of the promises reject. The fulfilled value is an Array of the fulfilled values returned from filterer in input order. input Type: Iterable<Promise|any> Iterated over concurrently in the filterer function. filterer(element, index) Type: Function The filterer function that decides whether an element should be included into result. Expected to return boolean | Promise<boolean>. options Type: object concurrency Type: number Default: Infinity Minimum: 1 The number of concurrently pending promises returned by filterer. Related p-locate - Get the first fulfilled promise that satisfies the provided testing function p-map - Map over promises concurrently p-times - Run promise-returning & async functions a specific number of times concurrently More…"
  },
  "node_modules/p-limit/readme.html": {
    "href": "node_modules/p-limit/readme.html",
    "title": "p-limit | accouter",
    "keywords": "p-limit Run multiple promise-returning & async functions with limited concurrency Install $ npm install p-limit Usage const pLimit = require('p-limit'); const limit = pLimit(1); const input = [ limit(() => fetchSomething('foo')), limit(() => fetchSomething('bar')), limit(() => doSomething()) ]; (async () => { // Only one promise is run at once const result = await Promise.all(input); console.log(result); })(); API pLimit(concurrency) Returns a limit function. concurrency Type: number Minimum: 1 Default: Infinity Concurrency limit. limit(fn, ...args) Returns the promise returned by calling fn(...args). fn Type: Function Promise-returning/async function. args Any arguments to pass through to fn. Support for passing arguments on to the fn is provided in order to be able to avoid creating unnecessary closures. You probably don't need this optimization unless you're pushing a lot of functions. limit.activeCount The number of promises that are currently running. limit.pendingCount The number of promises that are waiting to run (i.e. their internal fn was not called yet). limit.clearQueue() Discard pending promises that are waiting to run. This might be useful if you want to teardown the queue at the end of your program's lifecycle or discard any function calls referencing an intermediary state of your app. Note: This does not cancel promises that are already running. FAQ How is this different from the p-queue package? This package is only about limiting the number of concurrent executions, while p-queue is a fully featured queue implementation with lots of different options, introspection, and ability to pause the queue. Related p-queue - Promise queue with concurrency control p-throttle - Throttle promise-returning & async functions p-debounce - Debounce promise-returning & async functions p-all - Run promise-returning & async functions concurrently with optional limited concurrency More… Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "node_modules/p-locate/readme.html": {
    "href": "node_modules/p-locate/readme.html",
    "title": "p-locate | accouter",
    "keywords": "p-locate Get the first fulfilled promise that satisfies the provided testing function Think of it like an async version of Array#find. Install $ npm install p-locate Usage Here we find the first file that exists on disk, in array order. const pathExists = require('path-exists'); const pLocate = require('p-locate'); const files = [ 'unicorn.png', 'rainbow.png', // Only this one actually exists on disk 'pony.png' ]; (async () => { const foundPath = await pLocate(files, file => pathExists(file)); console.log(foundPath); //=> 'rainbow' })(); The above is just an example. Use locate-path if you need this. API pLocate(input, tester, options?) Returns a Promise that is fulfilled when tester resolves to true or the iterable is done, or rejects if any of the promises reject. The fulfilled value is the current iterable value or undefined if tester never resolved to true. input Type: Iterable<Promise | unknown> An iterable of promises/values to test. tester(element) Type: Function This function will receive resolved values from input and is expected to return a Promise<boolean> or boolean. options Type: object concurrency Type: number Default: Infinity Minimum: 1 Number of concurrently pending promises returned by tester. preserveOrder Type: boolean Default: true Preserve input order when searching. Disable this to improve performance if you don't care about the order. Related p-map - Map over promises concurrently p-filter - Filter promises concurrently p-any - Wait for any promise to be fulfilled More… Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "node_modules/p-map/readme.html": {
    "href": "node_modules/p-map/readme.html",
    "title": "p-map | accouter",
    "keywords": "p-map Map over promises concurrently Useful when you need to run promise-returning & async functions multiple times with different inputs concurrently. This is different from Promise.all() in that you can control the concurrency and also decide whether or not to stop iterating when there's an error. Install npm install p-map Usage import pMap from 'p-map'; import got from 'got'; const sites = [ getWebsiteFromUsername('sindresorhus'), //=> Promise 'https://avajs.dev', 'https://github.com' ]; const mapper = async site => { const {requestUrl} = await got.head(site); return requestUrl; }; const result = await pMap(sites, mapper, {concurrency: 2}); console.log(result); //=> ['https://sindresorhus.com/', 'https://avajs.dev/', 'https://github.com/'] API pMap(input, mapper, options?) Returns a Promise that is fulfilled when all promises in input and ones returned from mapper are fulfilled, or rejects if any of the promises reject. The fulfilled value is an Array of the fulfilled values returned from mapper in input order. input Type: AsyncIterable<Promise<unknown> | unknown> | Iterable<Promise<unknown> | unknown> Synchronous or asynchronous iterable that is iterated over concurrently, calling the mapper function for each element. Each iterated item is await'd before the mapper is invoked so the iterable may return a Promise that resolves to an item. Asynchronous iterables (different from synchronous iterables that return Promise that resolves to an item) can be used when the next item may not be ready without waiting for an asynchronous process to complete and/or the end of the iterable may be reached after the asynchronous process completes. For example, reading from a remote queue when the queue has reached empty, or reading lines from a stream. mapper(element, index) Type: Function Expected to return a Promise or value. options Type: object concurrency Type: number (Integer) Default: Infinity Minimum: 1 Number of concurrently pending promises returned by mapper. stopOnError Type: boolean Default: true When true, the first mapper rejection will be rejected back to the consumer. When false, instead of stopping when a promise rejects, it will wait for all the promises to settle and then reject with an AggregateError containing all the errors from the rejected promises. Caveat: When true, any already-started async mappers will continue to run until they resolve or reject. In the case of infinite concurrency with sync iterables, all mappers are invoked on startup and will continue after the first rejection. Issue #51 can be implemented for abort control. signal Type: AbortSignal You can abort the promises using AbortController. import pMap from 'p-map'; import delay from 'delay'; const abortController = new AbortController(); setTimeout(() => { abortController.abort(); }, 500); const mapper = async value => value; await pMap([delay(1000), delay(1000)], mapper, {signal: abortController.signal}); // Throws AbortError (DOMException) after 500 ms. pMapSkip Return this value from a mapper function to skip including the value in the returned array. import pMap, {pMapSkip} from 'p-map'; import got from 'got'; const sites = [ getWebsiteFromUsername('sindresorhus'), //=> Promise 'https://avajs.dev', 'https://example.invalid', 'https://github.com' ]; const mapper = async site => { try { const {requestUrl} = await got.head(site); return requestUrl; } catch { return pMapSkip; } }; const result = await pMap(sites, mapper, {concurrency: 2}); console.log(result); //=> ['https://sindresorhus.com/', 'https://avajs.dev/', 'https://github.com/'] Related p-all - Run promise-returning & async functions concurrently with optional limited concurrency p-filter - Filter promises concurrently p-times - Run promise-returning & async functions a specific number of times concurrently p-props - Like Promise.all() but for Map and Object p-map-series - Map over promises serially More…"
  },
  "node_modules/p-timeout/readme.html": {
    "href": "node_modules/p-timeout/readme.html",
    "title": "p-timeout | accouter",
    "keywords": "p-timeout Timeout a promise after a specified amount of time Install $ npm install p-timeout Usage import {setTimeout} from 'timers/promises'; import pTimeout from 'p-timeout'; const delayedPromise = setTimeout(200); await pTimeout(delayedPromise, 50); //=> [TimeoutError: Promise timed out after 50 milliseconds] API pTimeout(input, milliseconds, message?, options?) pTimeout(input, milliseconds, fallback?, options?) Returns a decorated input that times out after milliseconds time. It has a .clear() method that clears the timeout. If you pass in a cancelable promise, specifically a promise with a .cancel() method, that method will be called when the pTimeout promise times out. input Type: Promise Promise to decorate. milliseconds Type: number Milliseconds before timing out. Passing Infinity will cause it to never time out. message Type: string | Error Default: 'Promise timed out after 50 milliseconds' Specify a custom error message or error. If you do a custom error, it's recommended to sub-class pTimeout.TimeoutError. fallback Type: Function Do something other than rejecting with an error on timeout. You could for example retry: import {setTimeout} from 'timers/promises'; import pTimeout from 'p-timeout'; const delayedPromise = () => setTimeout(200); await pTimeout(delayedPromise(), 50, () => { return pTimeout(delayedPromise(), 300); }); options Type: object customTimers Type: object with function properties setTimeout and clearTimeout Custom implementations for the setTimeout and clearTimeout functions. Useful for testing purposes, in particular to work around sinon.useFakeTimers(). Example: import {setTimeout} from 'timers/promises'; import pTimeout from 'p-timeout'; const originalSetTimeout = setTimeout; const originalClearTimeout = clearTimeout; sinon.useFakeTimers(); // Use `pTimeout` without being affected by `sinon.useFakeTimers()`: await pTimeout(doSomething(), 2000, undefined, { customTimers: { setTimeout: originalSetTimeout, clearTimeout: originalClearTimeout } }); signal Type: AbortSignal You can abort the promise using AbortController. Requires Node.js 16 or later. import pTimeout from 'p-timeout'; import delay from 'delay'; const delayedPromise = delay(3000); const abortController = new AbortController(); setTimeout(() => { abortController.abort(); }, 100); await pTimeout(delayedPromise, 2000, undefined, { signal: abortController.signal }); TimeoutError Exposed for instance checking and sub-classing. Related delay - Delay a promise a specified amount of time p-min-delay - Delay a promise a minimum amount of time p-retry - Retry a promise-returning function More…"
  },
  "node_modules/parse-json/readme.html": {
    "href": "node_modules/parse-json/readme.html",
    "title": "parse-json | accouter",
    "keywords": "parse-json Parse JSON with more helpful errors Install $ npm install parse-json Usage const parseJson = require('parse-json'); const json = '{\\n\\t\"foo\": true,\\n}'; JSON.parse(json); /* undefined:3 } ^ SyntaxError: Unexpected token } */ parseJson(json); /* JSONError: Trailing comma in object at 3:1 } ^ */ parseJson(json, 'foo.json'); /* JSONError: Trailing comma in object in foo.json:3:1 } ^ */ // You can also add the filename at a later point try { parseJson(json); } catch (err) { err.fileName = 'foo.json'; throw err; } /* JSONError: Trailing comma in object in foo.json:3:1 } ^ */ API parseJson(input, [reviver], [filename]) input Type: string reviver Type: Function Prescribes how the value originally produced by parsing is transformed, before being returned. See JSON.parse docs for more. filename Type: string Filename displayed in the error message. License MIT © Sindre Sorhus"
  },
  "node_modules/parseurl/HISTORY.html": {
    "href": "node_modules/parseurl/HISTORY.html",
    "title": "1.3.3 / 2019-04-15 | accouter",
    "keywords": "1.3.3 / 2019-04-15 Fix Node.js 0.8 return value inconsistencies 1.3.2 / 2017-09-09 perf: reduce overhead for full URLs perf: unroll the \"fast-path\" RegExp 1.3.1 / 2016-01-17 perf: enable strict mode 1.3.0 / 2014-08-09 Add parseurl.original for parsing req.originalUrl with fallback Return undefined if req.url is undefined 1.2.0 / 2014-07-21 Cache URLs based on original value Remove no-longer-needed URL mis-parse work-around Simplify the \"fast-path\" RegExp 1.1.3 / 2014-07-08 Fix typo 1.1.2 / 2014-07-08 Seriously fix Node.js 0.8 compatibility 1.1.1 / 2014-07-08 Fix Node.js 0.8 compatibility 1.1.0 / 2014-07-08 Incorporate URL href-only parse fast-path 1.0.1 / 2014-03-08 Add missing require 1.0.0 / 2014-03-08 Genesis from connect"
  },
  "node_modules/parseurl/README.html": {
    "href": "node_modules/parseurl/README.html",
    "title": "parseurl | accouter",
    "keywords": "parseurl Parse a URL with memoization. Install This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install parseurl API var parseurl = require('parseurl') parseurl(req) Parse the URL of the given request object (looks at the req.url property) and return the result. The result is the same as url.parse in Node.js core. Calling this function multiple times on the same req where req.url does not change will return a cached parsed object, rather than parsing again. parseurl.original(req) Parse the original URL of the given request object and return the result. This works by trying to parse req.originalUrl if it is a string, otherwise parses req.url. The result is the same as url.parse in Node.js core. Calling this function multiple times on the same req where req.originalUrl does not change will return a cached parsed object, rather than parsing again. Benchmark $ npm run-script bench > parseurl@1.3.3 bench nodejs-parseurl > node benchmark/index.js http_parser@2.8.0 node@10.6.0 v8@6.7.288.46-node.13 uv@1.21.0 zlib@1.2.11 ares@1.14.0 modules@64 nghttp2@1.32.0 napi@3 openssl@1.1.0h icu@61.1 unicode@10.0 cldr@33.0 tz@2018c > node benchmark/fullurl.js Parsing URL \"http://localhost:8888/foo/bar?user=tj&pet=fluffy\" 4 tests completed. fasturl x 2,207,842 ops/sec ±3.76% (184 runs sampled) nativeurl - legacy x 507,180 ops/sec ±0.82% (191 runs sampled) nativeurl - whatwg x 290,044 ops/sec ±1.96% (189 runs sampled) parseurl x 488,907 ops/sec ±2.13% (192 runs sampled) > node benchmark/pathquery.js Parsing URL \"/foo/bar?user=tj&pet=fluffy\" 4 tests completed. fasturl x 3,812,564 ops/sec ±3.15% (188 runs sampled) nativeurl - legacy x 2,651,631 ops/sec ±1.68% (189 runs sampled) nativeurl - whatwg x 161,837 ops/sec ±2.26% (189 runs sampled) parseurl x 4,166,338 ops/sec ±2.23% (184 runs sampled) > node benchmark/samerequest.js Parsing URL \"/foo/bar?user=tj&pet=fluffy\" on same request object 4 tests completed. fasturl x 3,821,651 ops/sec ±2.42% (185 runs sampled) nativeurl - legacy x 2,651,162 ops/sec ±1.90% (187 runs sampled) nativeurl - whatwg x 175,166 ops/sec ±1.44% (188 runs sampled) parseurl x 14,912,606 ops/sec ±3.59% (183 runs sampled) > node benchmark/simplepath.js Parsing URL \"/foo/bar\" 4 tests completed. fasturl x 12,421,765 ops/sec ±2.04% (191 runs sampled) nativeurl - legacy x 7,546,036 ops/sec ±1.41% (188 runs sampled) nativeurl - whatwg x 198,843 ops/sec ±1.83% (189 runs sampled) parseurl x 24,244,006 ops/sec ±0.51% (194 runs sampled) > node benchmark/slash.js Parsing URL \"/\" 4 tests completed. fasturl x 17,159,456 ops/sec ±3.25% (188 runs sampled) nativeurl - legacy x 11,635,097 ops/sec ±3.79% (184 runs sampled) nativeurl - whatwg x 240,693 ops/sec ±0.83% (189 runs sampled) parseurl x 42,279,067 ops/sec ±0.55% (190 runs sampled) License MIT"
  },
  "node_modules/path-exists/readme.html": {
    "href": "node_modules/path-exists/readme.html",
    "title": "path-exists | accouter",
    "keywords": "path-exists Check if a path exists NOTE: fs.existsSync has been un-deprecated in Node.js since 6.8.0. If you only need to check synchronously, this module is not needed. While fs.exists() is being deprecated, there's still a genuine use-case of being able to check if a path exists for other purposes than doing IO with it. Never use this before handling a file though: In particular, checking if a file exists before opening it is an anti-pattern that leaves you vulnerable to race conditions: another process may remove the file between the calls to fs.exists() and fs.open(). Just open the file and handle the error when it's not there. Install $ npm install path-exists Usage // foo.js const pathExists = require('path-exists'); (async () => { console.log(await pathExists('foo.js')); //=> true })(); API pathExists(path) Returns a Promise<boolean> of whether the path exists. pathExists.sync(path) Returns a boolean of whether the path exists. Related path-exists-cli - CLI for this module License MIT © Sindre Sorhus"
  },
  "node_modules/path-key/readme.html": {
    "href": "node_modules/path-key/readme.html",
    "title": "path-key | accouter",
    "keywords": "path-key Get the PATH environment variable key cross-platform It's usually PATH, but on Windows it can be any casing like Path... Install $ npm install --save path-key Usage const pathKey = require('path-key'); const key = pathKey(); //=> 'PATH' const PATH = process.env[key]; //=> '/usr/local/bin:/usr/bin:/bin' API pathKey([options]) options env Type: Object Default: process.env Use a custom environment variables object. platform Type: string Default: process.platform Get the PATH key for a specific platform. License MIT © Sindre Sorhus"
  },
  "node_modules/path-parse/README.html": {
    "href": "node_modules/path-parse/README.html",
    "title": "path-parse | accouter",
    "keywords": "path-parse Node.js path.parse(pathString) ponyfill. Install $ npm install --save path-parse Usage var pathParse = require('path-parse'); pathParse('/home/user/dir/file.txt'); //=> { // root : \"/\", // dir : \"/home/user/dir\", // base : \"file.txt\", // ext : \".txt\", // name : \"file\" // } API See path.parse(pathString) docs. pathParse(path) pathParse.posix(path) The Posix specific version. pathParse.win32(path) The Windows specific version. License MIT © Javier Blanco"
  },
  "node_modules/path-scurry/LICENSE.html": {
    "href": "node_modules/path-scurry/LICENSE.html",
    "title": "Blue Oak Model License | accouter",
    "keywords": "Blue Oak Model License Version 1.0.0 Purpose This license gives everyone as much permission to work with this software as possible, while protecting contributors from liability. Acceptance In order to receive this license, you must agree to its rules. The rules of this license are both obligations under that agreement and conditions to your license. You must not do anything with this software that triggers a rule that you cannot or will not follow. Copyright Each contributor licenses you to do everything with this software that would otherwise infringe that contributor's copyright in it. Notices You must ensure that everyone who gets a copy of any part of this software from you, with or without changes, also gets the text of this license or a link to https://blueoakcouncil.org/license/1.0.0. Excuse If anyone notifies you in writing that you have not complied with Notices, you can keep your license by taking all practical steps to comply within 30 days after the notice. If you do not do so, your license ends immediately. Patent Each contributor licenses you to do everything with this software that would otherwise infringe any patent claims they can license or become able to license. Reliability No contributor can revoke this license. No Liability As far as the law allows, this software comes as is, without any warranty or condition, and no contributor will be liable to anyone for any damages related to this software or this license, under any kind of legal claim."
  },
  "node_modules/path-scurry/README.html": {
    "href": "node_modules/path-scurry/README.html",
    "title": "path-scurry | accouter",
    "keywords": "path-scurry Extremely high performant utility for building tools that read the file system, minimizing filesystem and path string munging operations to the greatest degree possible. Ugh, yet another file traversal thing on npm? Yes. None of the existing ones gave me exactly what I wanted. Well what is it you wanted? While working on glob, I found that I needed a module to very efficiently manage the traversal over a folder tree, such that: No readdir() or stat() would ever be called on the same file or directory more than one time. No readdir() calls would be made if we can be reasonably sure that the path is not a directory. (Ie, a previous readdir() or stat() covered the path, and ent.isDirectory() is false.) path.resolve(), dirname(), basename(), and other string-parsing/munging operations are be minimized. This means it has to track \"provisional\" child nodes that may not exist (and if we find that they don't exist, store that information as well, so we don't have to ever check again). The API is not limited to use as a stream/iterator/etc. There are many cases where an API like node's fs is preferrable. It's more important to prevent excess syscalls than to be up to date, but it should be smart enough to know what it doesn't know, and go get it seamlessly when requested. Do not blow up the JS heap allocation if operating on a directory with a huge number of entries. Handle all the weird aspects of Windows paths, like UNC paths and drive letters and wrongway slashes, so that the consumer can return canonical platform-specific paths without having to parse or join or do any error-prone string munging. PERFORMANCE JavaScript people throw around the word \"blazing\" a lot. I hope that this module doesn't blaze anyone. But it does go very fast, in the cases it's optimized for, if used properly. PathScurry provides ample opportunities to get extremely good performance, as well as several options to trade performance for convenience. Benchmarks can be run by executing npm run bench. As is always the case, doing more means going slower, doing less means going faster, and there are trade offs between speed and memory usage. PathScurry makes heavy use of LRUCache to efficiently cache whatever it can, and Path objects remain in the graph for the lifetime of the walker, so repeated calls with a single PathScurry object will be extremely fast. However, adding items to a cold cache means \"doing more\", so in those cases, we pay a price. Nothing is free, but every effort has been made to reduce costs wherever possible. Also, note that a \"cache as long as possible\" approach means that changes to the filesystem may not be reflected in the results of repeated PathScurry operations. For resolving string paths, PathScurry ranges from 5-50 times faster than path.resolve on repeated resolutions, but around 100 to 1000 times slower on the first resolution. If your program is spending a lot of time resolving the same paths repeatedly (like, thousands or millions of times), then this can be beneficial. But both implementations are pretty fast, and speeding up an infrequent operation from 4µs to 400ns is not going to move the needle on your app's performance. For walking file system directory trees, a lot depends on how often a given PathScurry object will be used, and also on the walk method used. With default settings on a folder tree of 100,000 items, consisting of around a 10-to-1 ratio of normal files to directories, PathScurry performs comparably to @nodelib/fs.walk, which is the fastest and most reliable file system walker I could find. As far as I can tell, it's almost impossible to go much faster in a Node.js program, just based on how fast you can push syscalls out to the fs thread pool. On my machine, that is about 1000-1200 completed walks per second for async or stream walks, and around 500-600 walks per second synchronously. In the warm cache state, PathScurry's performance increases around 4x for async for await iteration, 10-15x faster for streams and synchronous for of iteration, and anywhere from 30x to 80x faster for the rest. # walk 100,000 fs entries, 10/1 file/dir ratio # operations / ms New PathScurry object | Reuse PathScurry object stream: 1112.589 | 13974.917 sync stream: 492.718 | 15028.343 async walk: 1095.648 | 32706.395 sync walk: 527.632 | 46129.772 async iter: 1288.821 | 5045.510 sync iter: 498.496 | 17920.746 A hand-rolled walk calling entry.readdir() and recursing through the entries can benefit even more from caching, with greater flexibility and without the overhead of streams or generators. The cold cache state is still limited by the costs of file system operations, but with a warm cache, the only bottleneck is CPU speed and VM optimizations. Of course, in that case, some care must be taken to ensure that you don't lose performance as a result of silly mistakes, like calling readdir() on entries that you know are not directories. # manual recursive iteration functions cold cache | warm cache async: 1164.901 | 17923.320 cb: 1101.127 | 40999.344 zalgo: 1082.240 | 66689.936 sync: 526.935 | 87097.591 In this case, the speed improves by around 10-20x in the async case, 40x in the case of using entry.readdirCB with protections against synchronous callbacks, and 50-100x with callback deferrals disabled, and several hundred times faster for synchronous iteration. If you can think of a case that is not covered in these benchmarks, or an implementation that performs significantly better than PathScurry, please let me know. USAGE // hybrid module, load with either method import { PathScurry, Path } from 'path-scurry' // or: const { PathScurry, Path } = require('path-scurry') // very simple example, say we want to find and // delete all the .DS_Store files in a given path // note that the API is very similar to just a // naive walk with fs.readdir() import { unlink } from 'fs/promises' // easy way, iterate over the directory and do the thing const pw = new PathScurry(process.cwd()) for await (const entry of pw) { if (entry.isFile() && entry.name === '.DS_Store') { unlink(entry.fullpath()) } } // here it is as a manual recursive method const walk = async (entry: Path) => { const promises: Promise<any> = [] // readdir doesn't throw on non-directories, it just doesn't // return any entries, to save stack trace costs. // Items are returned in arbitrary unsorted order for (const child of await pw.readdir(entry)) { // each child is a Path object if (child.name === '.DS_Store' && child.isFile()) { // could also do pw.resolve(entry, child.name), // just like fs.readdir walking, but .fullpath is // a *slightly* more efficient shorthand. promises.push(unlink(child.fullpath())) } else if (child.isDirectory()) { promises.push(walk(child)) } } return Promise.all(promises) } walk(pw.cwd).then(() => { console.log('all .DS_Store files removed') }) const pw2 = new PathScurry('/a/b/c') // pw2.cwd is the Path for /a/b/c const relativeDir = pw2.cwd.resolve('../x') // Path entry for '/a/b/x' const relative2 = pw2.cwd.resolve('/a/b/d/../x') // same path, same entry assert.equal(relativeDir, relative2) API Full TypeDoc API There are platform-specific classes exported, but for the most part, the default PathScurry and Path exports are what you most likely need, unless you are testing behavior for other platforms. Intended public API is documented here, but the full documentation does include internal types, which should not be accessed directly. Interface PathScurryOpts The type of the options argument passed to the PathScurry constructor. nocase: Boolean indicating that file names should be compared case-insensitively. Defaults to true on darwin and win32 implementations, false elsewhere. Warning Performing case-insensitive matching on a case-sensitive filesystem will result in occasionally very bizarre behavior. Performing case-sensitive matching on a case-insensitive filesystem may negatively impact performance. childrenCacheSize: Number of child entries to cache, in order to speed up resolve() and readdir() calls. Defaults to 16 * 1024 (ie, 16384). Setting it to a higher value will run the risk of JS heap allocation errors on large directory trees. Setting it to 256 or smaller will significantly reduce the construction time and data consumption overhead, but with the downside of operations being slower on large directory trees. Setting it to 0 will mean that effectively no operations are cached, and this module will be roughly the same speed as fs for file system operations, and much slower than path.resolve() for repeated path resolution. fs An object that will be used to override the default fs methods. Any methods that are not overridden will use Node's built-in implementations. lstatSync readdir (callback withFileTypes Dirent variant, used for readdirCB and most walks) readdirSync readlinkSync realpathSync promises: Object containing the following async methods: lstat readdir (Dirent variant only) readlink realpath Interface WalkOptions The options object that may be passed to all walk methods. withFileTypes: Boolean, default true. Indicates that Path objects should be returned. Set to false to get string paths instead. follow: Boolean, default false. Attempt to read directory entries from symbolic links. Otherwise, only actual directories are traversed. Regardless of this setting, a given target path will only ever be walked once, meaning that a symbolic link to a previously traversed directory will never be followed. Setting this imposes a slight performance penalty, because readlink must be called on all symbolic links encountered, in order to avoid infinite cycles. filter: Function (entry: Path) => boolean. If provided, will prevent the inclusion of any entry for which it returns a falsey value. This will not prevent directories from being traversed if they do not pass the filter, though it will prevent the directories themselves from being included in the results. By default, if no filter is provided, then all entries are included in the results. walkFilter: Function (entry: Path) => boolean. If provided, will prevent the traversal of any directory (or in the case of follow:true symbolic links to directories) for which the function returns false. This will not prevent the directories themselves from being included in the result set. Use filter for that. Note that TypeScript return types will only be inferred properly from static analysis if the withFileTypes option is omitted, or a constant true or false value. Class PathScurry The main interface. Defaults to an appropriate class based on the current platform. Use PathScurryWin32, PathScurryDarwin, or PathScurryPosix if implementation-specific behavior is desired. All walk methods may be called with a WalkOptions argument to walk over the object's current working directory with the supplied options. async pw.walk(entry?: string | Path | WalkOptions, opts?: WalkOptions) Walk the directory tree according to the options provided, resolving to an array of all entries found. pw.walkSync(entry?: string | Path | WalkOptions, opts?: WalkOptions) Walk the directory tree according to the options provided, returning an array of all entries found. pw.iterate(entry?: string | Path | WalkOptions, opts?: WalkOptions) Iterate over the directory asynchronously, for use with for await of. This is also the default async iterator method. pw.iterateSync(entry?: string | Path | WalkOptions, opts?: WalkOptions) Iterate over the directory synchronously, for use with for of. This is also the default sync iterator method. pw.stream(entry?: string | Path | WalkOptions, opts?: WalkOptions) Return a Minipass stream that emits each entry or path string in the walk. Results are made available asynchronously. pw.streamSync(entry?: string | Path | WalkOptions, opts?: WalkOptions) Return a Minipass stream that emits each entry or path string in the walk. Results are made available synchronously, meaning that the walk will complete in a single tick if the stream is fully consumed. pw.cwd Path object representing the current working directory for the PathScurry. pw.chdir(path: string) Set the new effective current working directory for the scurry object, so that path.relative() and path.relativePosix() return values relative to the new cwd path. pw.depth(path?: Path | string): number Return the depth of the specified path (or the PathScurry cwd) within the directory tree. Root entries have a depth of 0. pw.resolve(...paths: string[]) Caching path.resolve(). Significantly faster than path.resolve() if called repeatedly with the same paths. Significantly slower otherwise, as it builds out the cached Path entries. To get a Path object resolved from the PathScurry, use pw.cwd.resolve(path). Note that Path.resolve only takes a single string argument, not multiple. pw.resolvePosix(...paths: string[]) Caching path.resolve(), but always using posix style paths. This is identical to pw.resolve(...paths) on posix systems (ie, everywhere except Windows). On Windows, it returns the full absolute UNC path using / separators. Ie, instead of 'C:\\\\foo\\\\bar, it would return //?/C:/foo/bar. pw.relative(path: string | Path): string Return the relative path from the PathWalker cwd to the supplied path string or entry. If the nearest common ancestor is the root, then an absolute path is returned. pw.relativePosix(path: string | Path): string Return the relative path from the PathWalker cwd to the supplied path string or entry, using / path separators. If the nearest common ancestor is the root, then an absolute path is returned. On posix platforms (ie, all platforms except Windows), this is identical to pw.relative(path). On Windows systems, it returns the resulting string as a /-delimited path. If an absolute path is returned (because the target does not share a common ancestor with pw.cwd), then a full absolute UNC path will be returned. Ie, instead of 'C:\\\\foo\\\\bar, it would return //?/C:/foo/bar. pw.basename(path: string | Path): string Return the basename of the provided string or Path. pw.dirname(path: string | Path): string Return the parent directory of the supplied string or Path. async pw.readdir(dir = pw.cwd, opts = { withFileTypes: true }) Read the directory and resolve to an array of strings if withFileTypes is explicitly set to false or Path objects otherwise. Can be called as pw.readdir({ withFileTypes: boolean }) as well. Returns [] if no entries are found, or if any error occurs. Note that TypeScript return types will only be inferred properly from static analysis if the withFileTypes option is omitted, or a constant true or false value. pw.readdirSync(dir = pw.cwd, opts = { withFileTypes: true }) Synchronous pw.readdir() async pw.readlink(link = pw.cwd, opts = { withFileTypes: false }) Call fs.readlink on the supplied string or Path object, and return the result. Can be called as pw.readlink({ withFileTypes: boolean }) as well. Returns undefined if any error occurs (for example, if the argument is not a symbolic link), or a Path object if withFileTypes is explicitly set to true, or a string otherwise. Note that TypeScript return types will only be inferred properly from static analysis if the withFileTypes option is omitted, or a constant true or false value. pw.readlinkSync(link = pw.cwd, opts = { withFileTypes: false }) Synchronous pw.readlink() async pw.lstat(entry = pw.cwd) Call fs.lstat on the supplied string or Path object, and fill in as much information as possible, returning the updated Path object. Returns undefined if the entry does not exist, or if any error is encountered. Note that some Stats data (such as ino, dev, and mode) will not be supplied. For those things, you'll need to call fs.lstat yourself. pw.lstatSync(entry = pw.cwd) Synchronous pw.lstat() pw.realpath(entry = pw.cwd, opts = { withFileTypes: false }) Call fs.realpath on the supplied string or Path object, and return the realpath if available. Returns undefined if any error occurs. May be called as pw.realpath({ withFileTypes: boolean }) to run on pw.cwd. pw.realpathSync(entry = pw.cwd, opts = { withFileTypes: false }) Synchronous pw.realpath() Class Path implements fs.Dirent Object representing a given path on the filesystem, which may or may not exist. Note that the actual class in use will be either PathWin32 or PathPosix, depending on the implementation of PathScurry in use. They differ in the separators used to split and join path strings, and the handling of root paths. In PathPosix implementations, paths are split and joined using the '/' character, and '/' is the only root path ever in use. In PathWin32 implementations, paths are split using either '/' or '\\\\' and joined using '\\\\', and multiple roots may be in use based on the drives and UNC paths encountered. UNC paths such as //?/C:/ that identify a drive letter, will be treated as an alias for the same root entry as their associated drive letter (in this case 'C:\\\\'). path.name Name of this file system entry. Important: always test the path name against any test string using the isNamed method, and not by directly comparing this string. Otherwise, unicode path strings that the system sees as identical will not be properly treated as the same path, leading to incorrect behavior and possible security issues. path.isNamed(name: string): boolean Return true if the path is a match for the given path name. This handles case sensitivity and unicode normalization. Note: even on case-sensitive systems, it is not safe to test the equality of the .name property to determine whether a given pathname matches, due to unicode normalization mismatches. Always use this method instead of testing the path.name property directly. path.isCWD Set to true if this Path object is the current working directory of the PathScurry collection that contains it. path.getType() Returns the type of the Path object, 'File', 'Directory', etc. path.isType(t: type) Returns true if is{t}() returns true. For example, path.isType('Directory') is equivalent to path.isDirectory(). path.depth() Return the depth of the Path entry within the directory tree. Root paths have a depth of 0. path.fullpath() The fully resolved path to the entry. path.fullpathPosix() The fully resolved path to the entry, using / separators. On posix systems, this is identical to path.fullpath(). On windows, this will return a fully resolved absolute UNC path using / separators. Eg, instead of 'C:\\\\foo\\\\bar', it will return '//?/C:/foo/bar'. path.isFile(), path.isDirectory(), etc. Same as the identical fs.Dirent.isX() methods. path.isUnknown() Returns true if the path's type is unknown. Always returns true when the path is known to not exist. path.resolve(p: string) Return a Path object associated with the provided path string as resolved from the current Path object. path.relative(): string Return the relative path from the PathWalker cwd to the supplied path string or entry. If the nearest common ancestor is the root, then an absolute path is returned. path.relativePosix(): string Return the relative path from the PathWalker cwd to the supplied path string or entry, using / path separators. If the nearest common ancestor is the root, then an absolute path is returned. On posix platforms (ie, all platforms except Windows), this is identical to pw.relative(path). On Windows systems, it returns the resulting string as a /-delimited path. If an absolute path is returned (because the target does not share a common ancestor with pw.cwd), then a full absolute UNC path will be returned. Ie, instead of 'C:\\\\foo\\\\bar, it would return //?/C:/foo/bar. async path.readdir() Return an array of Path objects found by reading the associated path entry. If path is not a directory, or if any error occurs, returns [], and marks all children as provisional and non-existent. path.readdirSync() Synchronous path.readdir() async path.readlink() Return the Path object referenced by the path as a symbolic link. If the path is not a symbolic link, or any error occurs, returns undefined. path.readlinkSync() Synchronous path.readlink() async path.lstat() Call lstat on the path object, and fill it in with details determined. If path does not exist, or any other error occurs, returns undefined, and marks the path as \"unknown\" type. path.lstatSync() Synchronous path.lstat() async path.realpath() Call realpath on the path, and return a Path object corresponding to the result, or undefined if any error occurs. path.realpathSync() Synchornous path.realpath()"
  },
  "node_modules/path-type/readme.html": {
    "href": "node_modules/path-type/readme.html",
    "title": "path-type | accouter",
    "keywords": "path-type Check if a path is a file, directory, or symlink Install $ npm install path-type Usage const {isFile} = require('path-type'); (async () => { console.log(await isFile('package.json')); //=> true })(); API isFile(path) Check whether the passed path is a file. Returns a Promise<boolean>. path Type: string The path to check. isDirectory(path) Check whether the passed path is a directory. Returns a Promise<boolean>. isSymlink(path) Check whether the passed path is a symlink. Returns a Promise<boolean>. isFileSync(path) Synchronously check whether the passed path is a file. Returns a boolean. isDirectorySync(path) Synchronously check whether the passed path is a directory. Returns a boolean. isSymlinkSync(path) Synchronously check whether the passed path is a symlink. Returns a boolean. License MIT © Sindre Sorhus"
  },
  "node_modules/picocolors/README.html": {
    "href": "node_modules/picocolors/README.html",
    "title": "picocolors | accouter",
    "keywords": "picocolors The tiniest and the fastest library for terminal output formatting with ANSI colors. import pc from \"picocolors\" console.log( pc.green(`How are ${pc.italic(`you`)} doing?`) ) No dependencies. 14 times smaller and 2 times faster than chalk. Used by popular tools like PostCSS, SVGO, Stylelint, and Browserslist. Node.js v6+ & browsers support. Support for both CJS and ESM projects. TypeScript type declarations included. NO_COLOR friendly. Docs Read full docs on GitHub."
  },
  "node_modules/picomatch/CHANGELOG.html": {
    "href": "node_modules/picomatch/CHANGELOG.html",
    "title": "Release history | accouter",
    "keywords": "Release history All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. Guiding Principles Changelogs are for humans, not machines. There should be an entry for every single version. The same types of changes should be grouped. Versions and sections should be linkable. The latest version comes first. The release date of each versions is displayed. Mention whether you follow Semantic Versioning. Types of changes Changelog entries are classified using the following labels (from keep-a-changelog): Added for new features. Changed for changes in existing functionality. Deprecated for soon-to-be removed features. Removed for now removed features. Fixed for any bug fixes. Security in case of vulnerabilities. 2.3.1 (2022-01-02) Fixed Fixes bug when a pattern containing an expression after the closing parenthesis (/!(*.d).{ts,tsx}) was incorrectly converted to regexp (9f241ef). Changed Some documentation improvements (f81d236, 421e0e7). 2.3.0 (2021-05-21) Fixed Fixes bug where file names with two dots were not being matched consistently with negation extglobs containing a star (56083ef) 2.2.3 (2021-04-10) Fixed Do not skip pattern seperator for square brackets (fb08a30). Set negatedExtGlob also if it does not span the whole pattern (032e3f5). 2.2.2 (2020-03-21) Fixed Correctly handle parts of the pattern after parentheses in the scan method (e15b920). 2.2.1 (2020-01-04) Fixes #49, so that braces with no sets or ranges are now propertly treated as literals. 2.2.0 (2020-01-04) Disable fastpaths mode for the parse method (5b8d33f) Add tokens, slashes, and parts to the object returned by picomatch.scan(). 2.1.0 (2019-10-31) add benchmarks for scan (4793b92) Add eslint object-curly-spacing rule (707c650) Add prefer-const eslint rule (5c7501c) Add support for nonegate in scan API (275c9b9) Change lets to consts. Move root import up. (4840625) closes https://github.com/micromatch/picomatch/issues/21 (766bcb0) Fix \"Extglobs\" table in readme (eb19da8) fixes https://github.com/micromatch/picomatch/issues/20 (9caca07) fixes https://github.com/micromatch/picomatch/issues/26 (fa58f45) Lint test (d433a34) lint unit tests (0159b55) Make scan work with noext (6c02e03) minor linting (c2a2b87) minor parser improvements (197671d) remove eslint since it... (07876fa) remove funding file (8ebe96d) Remove unused funks (cbc6d54) Run eslint during pretest, fix existing eslint findings (0682367) support noparen in scan (3d37569) update changelog (7b34e77) update travis (777f038) Use eslint-disable-next-line instead of eslint-disable (4e7c1fd) 2.0.7 (2019-05-14) 2.0.7 (9eb9a71) supports lookbehinds (1f63f7e) update .verb.md file with typo change (2741279) fix: typo in README (0753e44) 2.0.4 (2019-04-10) Fixed Readme link fixed by @danez. options.capture now works as expected when fastpaths are enabled. See https://github.com/micromatch/picomatch/pull/12/commits/26aefd71f1cfaf95c37f1c1fcab68a693b037304. Thanks to @DrPizza. 2.0.0 (2019-04-10) Added Adds support for options.onIgnore. See the readme for details Adds support for options.onResult. See the readme for details Breaking changes The unixify option was renamed to windows caching and all related options and methods have been removed 1.0.0 (2018-11-05) adds .onMatch option improvements to .scan method numerous improvements and optimizations for matching and parsing better windows path handling 0.1.0 - 2017-04-13 First release."
  },
  "node_modules/picomatch/README.html": {
    "href": "node_modules/picomatch/README.html",
    "title": "Picomatch | accouter",
    "keywords": "Picomatch Blazing fast and accurate glob matcher written in JavaScript. No dependencies and full support for standard and extended Bash glob features, including braces, extglobs, POSIX brackets, and regular expressions. Why picomatch? Lightweight - No dependencies Minimal - Tiny API surface. Main export is a function that takes a glob pattern and returns a matcher function. Fast - Loads in about 2ms (that's several times faster than a single frame of a HD movie at 60fps) Performant - Use the returned matcher function to speed up repeat matching (like when watching files) Accurate matching - Using wildcards (* and ?), globstars (**) for nested directories, advanced globbing with extglobs, braces, and POSIX brackets, and support for escaping special characters with \\ or quotes. Well tested - Thousands of unit tests See the library comparison to other libraries. Table of Contents Click to expand Install Usage API picomatch .test .matchBase .isMatch .parse .scan .compileRe .makeRe .toRegex Options Picomatch options Scan Options Options Examples Globbing features Basic globbing Advanced globbing Braces Matching special characters as literals Library Comparisons Benchmarks Philosophies About Author License (TOC generated by verb using markdown-toc) Install Install with npm: npm install --save picomatch Usage The main export is a function that takes a glob pattern and an options object and returns a function for matching strings. const pm = require('picomatch'); const isMatch = pm('*.js'); console.log(isMatch('abcd')); //=> false console.log(isMatch('a.js')); //=> true console.log(isMatch('a.md')); //=> false console.log(isMatch('a/b.js')); //=> false API picomatch Creates a matcher function from one or more glob patterns. The returned function takes a string to match as its first argument, and returns true if the string is a match. The returned matcher function also takes a boolean as the second argument that, when true, returns an object with additional information. Params globs {String|Array}: One or more glob patterns. options {Object=} returns {Function=}: Returns a matcher function. Example const picomatch = require('picomatch'); // picomatch(glob[, options]); const isMatch = picomatch('*.!(*a)'); console.log(isMatch('a.a')); //=> false console.log(isMatch('a.b')); //=> true .test Test input with the given regex. This is used by the main picomatch() function to test the input string. Params input {String}: String to test. regex {RegExp} returns {Object}: Returns an object with matching info. Example const picomatch = require('picomatch'); // picomatch.test(input, regex[, options]); console.log(picomatch.test('foo/bar', /^(?:([^/]*?)\\/([^/]*?))$/)); // { isMatch: true, match: [ 'foo/', 'foo', 'bar' ], output: 'foo/bar' } .matchBase Match the basename of a filepath. Params input {String}: String to test. glob {RegExp|String}: Glob pattern or regex created by .makeRe. returns {Boolean} Example const picomatch = require('picomatch'); // picomatch.matchBase(input, glob[, options]); console.log(picomatch.matchBase('foo/bar.js', '*.js'); // true .isMatch Returns true if any of the given glob patterns match the specified string. Params {String|Array}: str The string to test. {String|Array}: patterns One or more glob patterns to use for matching. {Object}: See available options. returns {Boolean}: Returns true if any patterns match str Example const picomatch = require('picomatch'); // picomatch.isMatch(string, patterns[, options]); console.log(picomatch.isMatch('a.a', ['b.*', '*.a'])); //=> true console.log(picomatch.isMatch('a.a', 'b.*')); //=> false .parse Parse a glob pattern to create the source string for a regular expression. Params pattern {String} options {Object} returns {Object}: Returns an object with useful properties and output to be used as a regex source string. Example const picomatch = require('picomatch'); const result = picomatch.parse(pattern[, options]); .scan Scan a glob pattern to separate the pattern into segments. Params input {String}: Glob pattern to scan. options {Object} returns {Object}: Returns an object with Example const picomatch = require('picomatch'); // picomatch.scan(input[, options]); const result = picomatch.scan('!./foo/*.js'); console.log(result); { prefix: '!./', input: '!./foo/*.js', start: 3, base: 'foo', glob: '*.js', isBrace: false, isBracket: false, isGlob: true, isExtglob: false, isGlobstar: false, negated: true } .compileRe Compile a regular expression from the state object returned by the parse() method. Params state {Object} options {Object} returnOutput {Boolean}: Intended for implementors, this argument allows you to return the raw output from the parser. returnState {Boolean}: Adds the state to a state property on the returned regex. Useful for implementors and debugging. returns {RegExp} .makeRe Create a regular expression from a parsed glob pattern. Params state {String}: The object returned from the .parse method. options {Object} returnOutput {Boolean}: Implementors may use this argument to return the compiled output, instead of a regular expression. This is not exposed on the options to prevent end-users from mutating the result. returnState {Boolean}: Implementors may use this argument to return the state from the parsed glob with the returned regular expression. returns {RegExp}: Returns a regex created from the given pattern. Example const picomatch = require('picomatch'); const state = picomatch.parse('*.js'); // picomatch.compileRe(state[, options]); console.log(picomatch.compileRe(state)); //=> /^(?:(?!\\.)(?=.)[^/]*?\\.js)$/ .toRegex Create a regular expression from the given regex source string. Params source {String}: Regular expression source string. options {Object} returns {RegExp} Example const picomatch = require('picomatch'); // picomatch.toRegex(source[, options]); const { output } = picomatch.parse('*.js'); console.log(picomatch.toRegex(output)); //=> /^(?:(?!\\.)(?=.)[^/]*?\\.js)$/ Options Picomatch options The following options may be used with the main picomatch() function or any of the methods on the picomatch API. Option Type Default value Description basename boolean false If set, then patterns without slashes will be matched against the basename of the path if it contains slashes. For example, a?b would match the path /xyz/123/acb, but not /xyz/acb/123. bash boolean false Follow bash matching rules more strictly - disallows backslashes as escape characters, and treats single stars as globstars (**). capture boolean undefined Return regex matches in supporting methods. contains boolean undefined Allows glob to match any part of the given string(s). cwd string process.cwd() Current working directory. Used by picomatch.split() debug boolean undefined Debug regular expressions when an error is thrown. dot boolean false Enable dotfile matching. By default, dotfiles are ignored unless a . is explicitly defined in the pattern, or options.dot is true expandRange function undefined Custom function for expanding ranges in brace patterns, such as {a..z}. The function receives the range values as two arguments, and it must return a string to be used in the generated regex. It's recommended that returned strings be wrapped in parentheses. failglob boolean false Throws an error if no matches are found. Based on the bash option of the same name. fastpaths boolean true To speed up processing, full parsing is skipped for a handful common glob patterns. Disable this behavior by setting this option to false. flags string undefined Regex flags to use in the generated regex. If defined, the nocase option will be overridden. format function undefined Custom function for formatting the returned string. This is useful for removing leading slashes, converting Windows paths to Posix paths, etc. ignore array\\|string undefined One or more glob patterns for excluding strings that should not be matched from the result. keepQuotes boolean false Retain quotes in the generated regex, since quotes may also be used as an alternative to backslashes. literalBrackets boolean undefined When true, brackets in the glob pattern will be escaped so that only literal brackets will be matched. matchBase boolean false Alias for basename maxLength boolean 65536 Limit the max length of the input string. An error is thrown if the input string is longer than this value. nobrace boolean false Disable brace matching, so that {a,b} and {1..3} would be treated as literal characters. nobracket boolean undefined Disable matching with regex brackets. nocase boolean false Make matching case-insensitive. Equivalent to the regex i flag. Note that this option is overridden by the flags option. nodupes boolean true Deprecated, use nounique instead. This option will be removed in a future major release. By default duplicates are removed. Disable uniquification by setting this option to false. noext boolean false Alias for noextglob noextglob boolean false Disable support for matching with extglobs (like +(a\\|b)) noglobstar boolean false Disable support for matching nested directories with globstars (**) nonegate boolean false Disable support for negating with leading ! noquantifiers boolean false Disable support for regex quantifiers (like a{1,2}) and treat them as brace patterns to be expanded. onIgnore function undefined Function to be called on ignored items. onMatch function undefined Function to be called on matched items. onResult function undefined Function to be called on all items, regardless of whether or not they are matched or ignored. posix boolean false Support POSIX character classes (\"posix brackets\"). posixSlashes boolean undefined Convert all slashes in file paths to forward slashes. This does not convert slashes in the glob pattern itself prepend boolean undefined String to prepend to the generated regex used for matching. regex boolean false Use regular expression rules for + (instead of matching literal +), and for stars that follow closing parentheses or brackets (as in )* and ]*). strictBrackets boolean undefined Throw an error if brackets, braces, or parens are imbalanced. strictSlashes boolean undefined When true, picomatch won't match trailing slashes with single stars. unescape boolean undefined Remove backslashes preceding escaped characters in the glob pattern. By default, backslashes are retained. unixify boolean undefined Alias for posixSlashes, for backwards compatibility. picomatch has automatic detection for regex positive and negative lookbehinds. If the pattern contains a negative lookbehind, you must be using Node.js >= 8.10 or else picomatch will throw an error. Scan Options In addition to the main picomatch options, the following options may also be used with the .scan method. Option Type Default value Description tokens boolean false When true, the returned object will include an array of tokens (objects), representing each path \"segment\" in the scanned glob pattern parts boolean false When true, the returned object will include an array of strings representing each path \"segment\" in the scanned glob pattern. This is automatically enabled when options.tokens is true Example const picomatch = require('picomatch'); const result = picomatch.scan('!./foo/*.js', { tokens: true }); console.log(result); // { // prefix: '!./', // input: '!./foo/*.js', // start: 3, // base: 'foo', // glob: '*.js', // isBrace: false, // isBracket: false, // isGlob: true, // isExtglob: false, // isGlobstar: false, // negated: true, // maxDepth: 2, // tokens: [ // { value: '!./', depth: 0, isGlob: false, negated: true, isPrefix: true }, // { value: 'foo', depth: 1, isGlob: false }, // { value: '*.js', depth: 1, isGlob: true } // ], // slashes: [ 2, 6 ], // parts: [ 'foo', '*.js' ] // } Options Examples options.expandRange Type: function Default: undefined Custom function for expanding ranges in brace patterns. The fill-range library is ideal for this purpose, or you can use custom code to do whatever you need. Example The following example shows how to create a glob that matches a folder const fill = require('fill-range'); const regex = pm.makeRe('foo/{01..25}/bar', { expandRange(a, b) { return `(${fill(a, b, { toRegex: true })})`; } }); console.log(regex); //=> /^(?:foo\\/((?:0[1-9]|1[0-9]|2[0-5]))\\/bar)$/ console.log(regex.test('foo/00/bar')) // false console.log(regex.test('foo/01/bar')) // true console.log(regex.test('foo/10/bar')) // true console.log(regex.test('foo/22/bar')) // true console.log(regex.test('foo/25/bar')) // true console.log(regex.test('foo/26/bar')) // false options.format Type: function Default: undefined Custom function for formatting strings before they're matched. Example // strip leading './' from strings const format = str => str.replace(/^\\.\\//, ''); const isMatch = picomatch('foo/*.js', { format }); console.log(isMatch('./foo/bar.js')); //=> true options.onMatch const onMatch = ({ glob, regex, input, output }) => { console.log({ glob, regex, input, output }); }; const isMatch = picomatch('*', { onMatch }); isMatch('foo'); isMatch('bar'); isMatch('baz'); options.onIgnore const onIgnore = ({ glob, regex, input, output }) => { console.log({ glob, regex, input, output }); }; const isMatch = picomatch('*', { onIgnore, ignore: 'f*' }); isMatch('foo'); isMatch('bar'); isMatch('baz'); options.onResult const onResult = ({ glob, regex, input, output }) => { console.log({ glob, regex, input, output }); }; const isMatch = picomatch('*', { onResult, ignore: 'f*' }); isMatch('foo'); isMatch('bar'); isMatch('baz'); Globbing features Basic globbing (Wildcard matching) Advanced globbing (extglobs, posix brackets, brace matching) Basic globbing Character Description * Matches any character zero or more times, excluding path separators. Does not match path separators or hidden files or directories (\"dotfiles\"), unless explicitly enabled by setting the dot option to true. ** Matches any character zero or more times, including path separators. Note that ** will only match path separators (/, and \\\\ on Windows) when they are the only characters in a path segment. Thus, foo**/bar is equivalent to foo*/bar, and foo/a**b/bar is equivalent to foo/a*b/bar, and more than two consecutive stars in a glob path segment are regarded as a single star. Thus, foo/***/bar is equivalent to foo/*/bar. ? Matches any character excluding path separators one time. Does not match path separators or leading dots. [abc] Matches any characters inside the brackets. For example, [abc] would match the characters a, b or c, and nothing else. Matching behavior vs. Bash Picomatch's matching features and expected results in unit tests are based on Bash's unit tests and the Bash 4.3 specification, with the following exceptions: Bash will match foo/bar/baz with *. Picomatch only matches nested directories with **. Bash greedily matches with negated extglobs. For example, Bash 4.3 says that !(foo)* should match foo and foobar, since the trailing * bracktracks to match the preceding pattern. This is very memory-inefficient, and IMHO, also incorrect. Picomatch would return false for both foo and foobar. Advanced globbing extglobs POSIX brackets Braces Extglobs Pattern Description @(pattern) Match only one consecutive occurrence of pattern *(pattern) Match zero or more consecutive occurrences of pattern +(pattern) Match one or more consecutive occurrences of pattern ?(pattern) Match zero or one consecutive occurrences of pattern !(pattern) Match anything but pattern Examples const pm = require('picomatch'); // *(pattern) matches ZERO or more of \"pattern\" console.log(pm.isMatch('a', 'a*(z)')); // true console.log(pm.isMatch('az', 'a*(z)')); // true console.log(pm.isMatch('azzz', 'a*(z)')); // true // +(pattern) matches ONE or more of \"pattern\" console.log(pm.isMatch('a', 'a*(z)')); // true console.log(pm.isMatch('az', 'a*(z)')); // true console.log(pm.isMatch('azzz', 'a*(z)')); // true // supports multiple extglobs console.log(pm.isMatch('foo.bar', '!(foo).!(bar)')); // false // supports nested extglobs console.log(pm.isMatch('foo.bar', '!(!(foo)).!(!(bar))')); // true POSIX brackets POSIX classes are disabled by default. Enable this feature by setting the posix option to true. Enable POSIX bracket support console.log(pm.makeRe('[[:word:]]+', { posix: true })); //=> /^(?:(?=.)[A-Za-z0-9_]+\\/?)$/ Supported POSIX classes The following named POSIX bracket expressions are supported: [:alnum:] - Alphanumeric characters, equ [a-zA-Z0-9] [:alpha:] - Alphabetical characters, equivalent to [a-zA-Z]. [:ascii:] - ASCII characters, equivalent to [\\\\x00-\\\\x7F]. [:blank:] - Space and tab characters, equivalent to [ \\\\t]. [:cntrl:] - Control characters, equivalent to [\\\\x00-\\\\x1F\\\\x7F]. [:digit:] - Numerical digits, equivalent to [0-9]. [:graph:] - Graph characters, equivalent to [\\\\x21-\\\\x7E]. [:lower:] - Lowercase letters, equivalent to [a-z]. [:print:] - Print characters, equivalent to [\\\\x20-\\\\x7E ]. [:punct:] - Punctuation and symbols, equivalent to [\\\\-!\"#$%&\\'()\\\\*+,./:;<=>?@[\\\\]^_{|}~]`. [:space:] - Extended space characters, equivalent to [ \\\\t\\\\r\\\\n\\\\v\\\\f]. [:upper:] - Uppercase letters, equivalent to [A-Z]. [:word:] - Word characters (letters, numbers and underscores), equivalent to [A-Za-z0-9_]. [:xdigit:] - Hexadecimal digits, equivalent to [A-Fa-f0-9]. See the Bash Reference Manual for more information. Braces Picomatch does not do brace expansion. For brace expansion and advanced matching with braces, use micromatch instead. Picomatch has very basic support for braces. Matching special characters as literals If you wish to match the following special characters in a filepath, and you want to use these characters in your glob pattern, they must be escaped with backslashes or quotes: Special Characters Some characters that are used for matching in regular expressions are also regarded as valid file path characters on some platforms. To match any of the following characters as literals: `$^*+?()[] Examples: console.log(pm.makeRe('foo/bar \\\\(1\\\\)')); console.log(pm.makeRe('foo/bar \\\\(1\\\\)')); Library Comparisons The following table shows which features are supported by minimatch, micromatch, picomatch, nanomatch, extglob, braces, and expand-brackets. Feature minimatch micromatch picomatch nanomatch extglob braces expand-brackets Wildcard matching (*?+) ✔ ✔ ✔ ✔ - - - Advancing globbing ✔ ✔ ✔ - - - - Brace matching ✔ ✔ ✔ - - ✔ - Brace expansion ✔ ✔ - - - ✔ - Extglobs partial ✔ ✔ - ✔ - - Posix brackets - ✔ ✔ - - - ✔ Regular expression syntax - ✔ ✔ ✔ ✔ - ✔ File system operations - - - - - - - Benchmarks Performance comparison of picomatch and minimatch. # .makeRe star picomatch x 1,993,050 ops/sec ±0.51% (91 runs sampled) minimatch x 627,206 ops/sec ±1.96% (87 runs sampled)) # .makeRe star; dot=true picomatch x 1,436,640 ops/sec ±0.62% (91 runs sampled) minimatch x 525,876 ops/sec ±0.60% (88 runs sampled) # .makeRe globstar picomatch x 1,592,742 ops/sec ±0.42% (90 runs sampled) minimatch x 962,043 ops/sec ±1.76% (91 runs sampled)d) # .makeRe globstars picomatch x 1,615,199 ops/sec ±0.35% (94 runs sampled) minimatch x 477,179 ops/sec ±1.33% (91 runs sampled) # .makeRe with leading star picomatch x 1,220,856 ops/sec ±0.40% (92 runs sampled) minimatch x 453,564 ops/sec ±1.43% (94 runs sampled) # .makeRe - basic braces picomatch x 392,067 ops/sec ±0.70% (90 runs sampled) minimatch x 99,532 ops/sec ±2.03% (87 runs sampled)) Philosophies The goal of this library is to be blazing fast, without compromising on accuracy. Accuracy The number one of goal of this library is accuracy. However, it's not unusual for different glob implementations to have different rules for matching behavior, even with simple wildcard matching. It gets increasingly more complicated when combinations of different features are combined, like when extglobs are combined with globstars, braces, slashes, and so on: !(**/{a,b,*/c}). Thus, given that there is no canonical glob specification to use as a single source of truth when differences of opinion arise regarding behavior, sometimes we have to implement our best judgement and rely on feedback from users to make improvements. Performance Although this library performs well in benchmarks, and in most cases it's faster than other popular libraries we benchmarked against, we will always choose accuracy over performance. It's not helpful to anyone if our library is faster at returning the wrong answer. About Contributing Pull requests and stars are always welcome. For bugs and feature requests, please create an issue. Please read the contributing guide for advice on opening issues, pull requests, and coding standards. Running Tests Running and reviewing unit tests is a great way to get familiarized with a library and its API. You can install dependencies and run tests with the following command: npm install && npm test Building docs (This project's readme.md is generated by verb, please don't edit the readme directly. Any changes to the readme must be made in the .verb.md readme template.) To generate the readme, run the following command: npm install -g verbose/verb#dev verb-generate-readme && verb Author Jon Schlinkert GitHub Profile Twitter Profile LinkedIn Profile License Copyright © 2017-present, Jon Schlinkert. Released under the MIT License."
  },
  "node_modules/pidtree/readme.html": {
    "href": "node_modules/pidtree/readme.html",
    "title": "pidtree | accouter",
    "keywords": "pidtree 🚸 Cross platform children list of a PID. Coded with ❤️ by Simone Primarosa. Synopsis This package is really similar to ps-tree but is faster, safer and provides sub-children results. Furthermore ps-tree is unmaintained. Uuh, and a fancy CLI is also available! Usage var pidtree = require('pidtree') // Get childs of current process pidtree(process.pid, function (err, pids) { console.log(pids) // => [] }) // Include the given pid in the result array pidtree(process.pid, {root: true}, function (err, pids) { console.log(pids) // => [727] }) // Get all the processes of the System (-1 is a special value of this package) pidtree(-1, function (err, pids) { console.log(pids) // => [530, 42, ..., 41241] }) // Include PPID in the results pidtree(1, {advanced: true}, function (err, pids) { console.log(pids) // => [{ppid: 1, pid: 530}, {ppid: 1, pid: 42}, ..., {ppid: 1, pid: 41241}] }) // If no callback is given it returns a promise instead const pids = await pidtree(1) console.log(pids) // => [141, 42, ..., 15242] Compatibility Linux FreeBSD NetBSD SunOS macOS Win AIX ✅ ❓ ❓ ❓ ✅ ✅ ❓ ✅ = Working ❓ = Not tested but should work Please if your platform is not supported file an issue. CLI Show a tree of the processes inside your system inside your terminal. npx pidtree $PPID Just replace $PPID with one of the pids inside your system. Or don't pass anything if you want all the pids inside your system. npx pidtree To display the output as a list, similar to the one produced from pgrep -P $PID, pass the --list flag. npx pidtree --list API pidtree(pid, [options], [callback]) ⇒ [Promise.<Array.<Object>>] Get the list of children pids of the given pid. Kind: global function Returns: Promise.<Array.<Object>> - Only when the callback is not provided. Access: public Param Type Default Description pid Number | String A pid. If -1 will return all the pids. [options] Object Optional options object. [options.root] Boolean false Include the provided pid in the list. Ignored if -1 is passed as pid. [callback] function Called when the list is ready. If not provided a promise is returned instead. Related pidusage - Cross-platform process cpu % and memory usage of a PID Authors Simone Primarosa - simonepri See also the list of contributors who participated in this project. License This project is licensed under the MIT License - see the license file for details."
  },
  "node_modules/pify/readme.html": {
    "href": "node_modules/pify/readme.html",
    "title": "pify | accouter",
    "keywords": "pify Promisify a callback-style function Install $ npm install --save pify Usage const fs = require('fs'); const pify = require('pify'); // promisify a single function pify(fs.readFile)('package.json', 'utf8').then(data => { console.log(JSON.parse(data).name); //=> 'pify' }); // or promisify all methods in a module pify(fs).readFile('package.json', 'utf8').then(data => { console.log(JSON.parse(data).name); //=> 'pify' }); API pify(input, [promiseModule], [options]) Returns a promise wrapped version of the supplied function or module. input Type: function, object Callback-style function or module whose methods you want to promisify. promiseModule Type: function Custom promise module to use instead of the native one. Check out pinkie-promise if you need a tiny promise polyfill. options multiArgs Type: boolean Default: false By default, the promisified function will only return the second argument from the callback, which works fine for most APIs. This option can be useful for modules like request that return multiple arguments. Turning this on will make it return an array of all arguments from the callback, excluding the error argument, instead of just the second argument. const request = require('request'); const pify = require('pify'); pify(request, {multiArgs: true})('https://sindresorhus.com').then(result => { const [httpResponse, body] = result; }); include Type: array of (string|regex) Methods in a module to promisify. Remaining methods will be left untouched. exclude Type: array of (string|regex) Default: [/.+Sync$/] Methods in a module not to promisify. Methods with names ending with 'Sync' are excluded by default. excludeMain Type: boolean Default: false By default, if given module is a function itself, this function will be promisified. Turn this option on if you want to promisify only methods of the module. const pify = require('pify'); function fn() { return true; } fn.method = (data, callback) => { setImmediate(() => { callback(data, null); }); }; // promisify methods but not fn() const promiseFn = pify(fn, {excludeMain: true}); if (promiseFn()) { promiseFn.method('hi').then(data => { console.log(data); }); } License MIT © Sindre Sorhus"
  },
  "node_modules/portscanner/CHANGELOG.html": {
    "href": "node_modules/portscanner/CHANGELOG.html",
    "title": "2.1.0 | accouter",
    "keywords": "2.1.0 New [ed4682bd3c] - Accept ports as strings (laggingreflex) 2.0.0 Breaking Changes Ports must be numbers. Some of the new changes are based on the assumption that ports must be numbers. New [84db394996] - promise support (laggingreflex) [3b90e2ca74] - Improve arguments parsing (laggingreflex) [eb345da68c] - Make host parameter optional (Maciej Dudzinski) [2ed556b159] [99483dc28e] #26 - Add support for checking array of ports instead of range (Maciej Dudzinski) Fixes [da8ff250bd] #23 - handle ports range provided in reverse order (laggingreflex) [4c7a88436f] - Update async module for use this module in strict mode (Luca Pau) [04fea5dd4d] - Preserve error message from socket's error event (Jan Melcher) Misc [0beeca8cbd] - Implement JavaScript Standard Style Guide (laggingreflex) [da1ce58319] - more tests for different argument signatures (laggingreflex) [9fdbdc38d7] - Add basic unit tests with Ava runner (Maciej Dudzinski) 1.2.0 Some recent changes in 1.1.0 [3b90e2ca74] [eb345da68c] were based on the assumption that the ports would always be of the type numbers. This broke portscanner in some cases #49 #50. All changes were reverted back to 1.0.0 and only some very critical fixes [4c7a88436f] [04fea5dd4d] were applied to this version. Fixes [4c7a88436f] - Update async module for use this module in strict mode (Luca Pau) [04fea5dd4d] - Preserve error message from socket's error event (Jan Melcher) Misc [69c648c740] - tests - ports as strings (laggingreflex) [9fdbdc38d7] - Add basic unit tests with Ava runner (Maciej Dudzinski) 1.1.1 Reverted to 1.0.0 1.1.0 Some breaking changes were introduced in this version which have since been reverted in 1.1.1. Please update to either 1.1.1 or 2.0.0. 1.0.0 [2463e64a0a] - 1.0.0 (Sean Massa) [21aa98b632] - update readme (Sean Massa) [5fe4ab4a69] - Merge pull request #21 from jdwilliams15/master (Sean Massa) [725afef7b4] - fix indent (jdwilliams15) [053b56e455] - fixed indentation (jdwilliams15) [b1dd496633] - Changed socket error handler to handle 'ECONNREFUSED'. In event of ECONNREFUSED the port is available (jdwilliams15) [512cfdbf78] - 0.2.3 (Sean Massa) [5526b8b4eb] - Merge pull request #19 from thomseddon/fix-end (Sean Massa) [a854ec6bd6] - Use socket.destroy() not socket.end() on successful connection (Thom Seddon) [c747ffa9de] - 0.2.2 (Sean Massa) [4a1f8f811b] - Merge pull request #16 from baalexander/fix-port-finding (Sean Massa) [ff51ebe871] - fix port reporting (Sean Massa) [e9070e85ca] - 0.2.1 (Sean Massa) [809b7760ad] - 0.2.0 (Sean Massa) [87f35e5b87] - Merge pull request #14 from baalexander/localhost-127.0.0.1 (Sean Massa) [0b72b83cab] - switch out localhost for 127.0.0.1 (Sean Massa) [4407d6f701] - Merge pull request #13 from skilesare/master (Sean Massa) [3ed682ad7a] - Update portscanner.js (skilesare) [c1544a1bb3] - Update portscanner.js (skilesare) [d3b029c384] - Adds @EndangeredMassa as a package maintainer. (Brandon Alexander) [8f5559b1fe] - Merge pull request #7 from EndangeredMassa/smassa/timeout (Brandon Alexander) [16d0db3944] - added options param to checkPortStatus; supports host and timeout (Sean Massa) [b8acb18a08] - exposed errors for checkPortStatus (Sean Massa) [381769162d] - Updates version to 0.1.3. (Brandon Alexander) [38cb922d1c] - Uses callback in listen() instead of a timeout. (Brandon Alexander) [aefd8ccad1] - Merge pull request #4 from DennisKehrig/master (Brandon Alexander) [5b58f03421] - Call socket.destroy() on timeout (Dennis Kehrig) [45028c6e3e] - Updates version to 0.1.2. (Brandon Alexander) [a60a248a2a] - Fixes multiple callbacks when checking port status. (Brandon Alexander) [19a8c1df2c] - Updates to v0.1.1. (Brandon Alexander) [c81ae8d6e4] - Checks range of ports one at a time. (Brandon Alexander) [fe9726773d] - Only returns status of a port after connection closed. (Brandon Alexander) [af6c474f38] - Ignores example and test directories in NPM. (Brandon Alexander) [78be727cb4] - Initial release to NPM. (Brandon Alexander) [cc71a028cb] - Renames port finding functions for clarity. (Brandon Alexander) [bb0356a82e] - Quits scanning ports when a matching port has been found. (Brandon Alexander) [24224b8148] - Destroys the socket on error instead of end. (Brandon Alexander) [e2c4448293] - Updates README since not yet ready for NPM. (Brandon Alexander) [5cca315f8b] - Packages up port scanner for NPM. (Brandon Alexander) [8c1f11e76c] - Adds JSDocs and updates example code. (Brandon Alexander) [4b432ba950] - Set max port range to 65535. (Brandon Alexander) [3a78761e4f] - Adds README and MIT license. (Brandon Alexander) [e232efc85f] - Checks a range of ports for first open or closed port. (Brandon Alexander) [8568c23e7c] - Initial commit checks status of a specified port. (Brandon Alexander)"
  },
  "node_modules/portscanner/README.html": {
    "href": "node_modules/portscanner/README.html",
    "title": "portscanner | accouter",
    "keywords": "portscanner The portscanner module is an asynchronous JavaScript port scanner for Node.js. Portscanner can check a port, or range of ports, for 'open' or 'closed' statuses. Looking for maintainer! Install npm install portscanner Usage A brief example: var portscanner = require('portscanner') // Checks the status of a single port portscanner.checkPortStatus(3000, '127.0.0.1', function(error, status) { // Status is 'open' if currently in use or 'closed' if available console.log(status) }) // Find the first available port. Asynchronously checks, so first port // determined as available is returned. portscanner.findAPortNotInUse(3000, 3010, '127.0.0.1', function(error, port) { console.log('AVAILABLE PORT AT: ' + port) }) // Find the first port in use or blocked. Asynchronously checks, so first port // to respond is returned. portscanner.findAPortInUse(3000, 3010, '127.0.0.1', function(error, port) { console.log('PORT IN USE AT: ' + port) }) // You can also pass array of ports to check portscanner.findAPortInUse([3000, 3005, 3006], '127.0.0.1', function(error, port) { console.log('PORT IN USE AT: ' + port) }) // And skip host param. Default is '127.0.0.1' portscanner.findAPortNotInUse(3000, 4000, function(error, port) { console.log('PORT IN USE AT: ' + port) }) // And use promises portscanner.findAPortNotInUse(3000, 4000).then(function(port) { console.log('PORT IN USE AT: ' + port) }) The example directory contains a more detailed example. Test npm test Future Please create issues or pull requests for port scanning related features you'd like to see included. License (MIT) MIT"
  },
  "node_modules/possible-typed-array-names/CHANGELOG.html": {
    "href": "node_modules/possible-typed-array-names/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.0 - 2024-02-19 Commits Initial implementation, tests, readme, types c279f55 Initial commit 0f22bf2 npm init 25d6cff Only apps should have lockfiles a1bd592"
  },
  "node_modules/possible-typed-array-names/README.html": {
    "href": "node_modules/possible-typed-array-names/README.html",
    "title": "possible-typed-array-names | accouter",
    "keywords": "possible-typed-array-names A simple list of possible Typed Array names. Example const assert = require('assert'); const names = require('possible-typed-array-names'); assert(Array.isArray(names)); assert(names.every(name => ( typeof name === 'string' && typeof globalThis[name] === 'function' && globalThis[name].name === name ))); Tests Simply clone the repo, npm install, and run npm test Security Please email @ljharb or see https://tidelift.com/security if you have a potential security vulnerability to report."
  },
  "node_modules/postcss-calc/README.html": {
    "href": "node_modules/postcss-calc/README.html",
    "title": "PostCSS Calc | accouter",
    "keywords": "PostCSS Calc PostCSS Calc lets you reduce calc() references whenever it's possible. When multiple units are mixed together in the same expression, the calc() statement is left as is, to fallback to the W3C calc() implementation. Installation npm install postcss-calc Usage // dependencies var fs = require(\"fs\") var postcss = require(\"postcss\") var calc = require(\"postcss-calc\") // css to be processed var css = fs.readFileSync(\"input.css\", \"utf8\") // process css var output = postcss() .use(calc()) .process(css) .css Using this input.css: h1 { font-size: calc(16px * 2); height: calc(100px - 2em); width: calc(2*var(--base-width)); margin-bottom: calc(16px * 1.5); } you will get: h1 { font-size: 32px; height: calc(100px - 2em); width: calc(2*var(--base-width)); margin-bottom: 24px } Checkout tests for more examples. Options precision (default: 5) Allow you to define the precision for decimal numbers. var out = postcss() .use(calc({precision: 10})) .process(css) .css preserve (default: false) Allow you to preserve calc() usage in output so browsers will handle decimal precision themselves. var out = postcss() .use(calc({preserve: true})) .process(css) .css warnWhenCannotResolve (default: false) Adds warnings when calc() are not reduced to a single value. var out = postcss() .use(calc({warnWhenCannotResolve: true})) .process(css) .css mediaQueries (default: false) Allows calc() usage as part of media query declarations. var out = postcss() .use(calc({mediaQueries: true})) .process(css) .css selectors (default: false) Allows calc() usage as part of selectors. var out = postcss() .use(calc({selectors: true})) .process(css) .css Example: div[data-size=\"calc(3*3)\"] { width: 100px; } Related PostCSS plugins To replace the value of CSS custom properties at build time, try PostCSS Custom Properties. Contributing Work on a branch, install dev-dependencies, respect coding style & run tests before submitting a bug fix or a feature. git clone git@github.com:postcss/postcss-calc.git git checkout -b patch-1 npm install npm test Changelog License"
  },
  "node_modules/postcss-cli/README.html": {
    "href": "node_modules/postcss-cli/README.html",
    "title": "PostCSS CLI | accouter",
    "keywords": "PostCSS CLI Install npm i -D postcss postcss-cli Usage Usage: postcss [input.css] [OPTIONS] [-o|--output output.css] [--watch|-w] postcss <input.css>... [OPTIONS] --dir <output-directory> [--watch|-w] postcss <input-directory> [OPTIONS] --dir <output-directory> [--watch|-w] postcss <input-glob-pattern> [OPTIONS] --dir <output-directory> [--watch|-w] postcss <input.css>... [OPTIONS] --replace Basic options: -o, --output Output file [string] -d, --dir Output directory [string] -r, --replace Replace (overwrite) the input file [boolean] -m, --map Create an external sourcemap --no-map Disable the default inline sourcemaps -w, --watch Watch files for changes and recompile as needed [boolean] --verbose Be verbose [boolean] --env A shortcut for setting NODE_ENV [string] Options for use without a config file: -u, --use List of postcss plugins to use [array] --parser Custom postcss parser [string] --stringifier Custom postcss stringifier [string] --syntax Custom postcss syntax [string] Options for use with --dir: --ext Override the output file extension; for use with --dir [string] --base Mirror the directory structure relative to this path in the output directory, for use with --dir [string] Advanced options: --include-dotfiles Enable glob to match files/dirs that begin with \".\" [boolean] --poll Use polling for file watching. Can optionally pass polling interval; default 100 ms --config Set a custom directory to look for a config file [string] Options: --version Show version number [boolean] -h, --help Show help [boolean] Examples: postcss input.css -o output.css Basic usage postcss src/**/*.css --base src --dir build Glob Pattern & output cat input.css | postcss -u autoprefixer > output.css Piping input & output If no input files are passed, it reads from stdin. If neither -o, --dir, or --replace is passed, it writes to stdout. If there are multiple input files, the --dir or --replace option must be passed. Input files may contain globs (e.g. src/**/*.css). If you pass an input directory, it will process all files in the directory and any subdirectories, respecting the glob pattern. ℹ️ More details on custom parsers, stringifiers and syntaxes, can be found here. Config If you need to pass options to your plugins, or have a long plugin chain, you'll want to use a configuration file. postcss.config.js module.exports = { parser: 'sugarss', plugins: [ require('postcss-import')({ ...options }), require('postcss-url')({ url: 'copy', useHash: true }), ], } Note that you can not set the from or to options for postcss in the config file. They are set automatically based on the CLI arguments. Context For more advanced usage, it's recommended to use a function in postcss.config.js; this gives you access to the CLI context to dynamically apply options and plugins per file Name Type Default Description env {String} 'development' process.env.NODE_ENV file {Object} dirname, basename, extname File options {Object} map, parser, syntax, stringifier PostCSS Options postcss.config.js module.exports = (ctx) => ({ map: ctx.options.map, parser: ctx.file.extname === '.sss' ? 'sugarss' : false, plugins: { 'postcss-import': { root: ctx.file.dirname }, cssnano: ctx.env === 'production' ? {} : false, }, }) ⚠️ If you want to set options via CLI, it's mandatory to reference ctx.options in postcss.config.js postcss input.sss -p sugarss -o output.css -m postcss.config.js module.exports = (ctx) => ({ map: ctx.options.map, parser: ctx.options.parser, plugins: { 'postcss-import': { root: ctx.file.dirname }, cssnano: ctx.env === 'production' ? {} : false, }, })"
  },
  "node_modules/postcss-cli/node_modules/fs-extra/README.html": {
    "href": "node_modules/postcss-cli/node_modules/fs-extra/README.html",
    "title": "Node.js: fs-extra | accouter",
    "keywords": "Node.js: fs-extra fs-extra adds file system methods that aren't included in the native fs module and adds promise support to the fs methods. It also uses graceful-fs to prevent EMFILE errors. It should be a drop in replacement for fs. Why? I got tired of including mkdirp, rimraf, and ncp in most of my projects. Installation npm install fs-extra Usage CommonJS fs-extra is a drop in replacement for native fs. All methods in fs are attached to fs-extra. All fs methods return promises if the callback isn't passed. You don't ever need to include the original fs module again: const fs = require('fs') // this is no longer necessary you can now do this: const fs = require('fs-extra') or if you prefer to make it clear that you're using fs-extra and not fs, you may want to name your fs variable fse like so: const fse = require('fs-extra') you can also keep both, but it's redundant: const fs = require('fs') const fse = require('fs-extra') ESM There is also an fs-extra/esm import, that supports both default and named exports. However, note that fs methods are not included in fs-extra/esm; you still need to import fs and/or fs/promises seperately: import { readFileSync } from 'fs' import { readFile } from 'fs/promises' import { outputFile, outputFileSync } from 'fs-extra/esm' Default exports are supported: import fs from 'fs' import fse from 'fs-extra/esm' // fse.readFileSync is not a function; must use fs.readFileSync but you probably want to just use regular fs-extra instead of fs-extra/esm for default exports: import fs from 'fs-extra' // both fs and fs-extra methods are defined Sync vs Async vs Async/Await Most methods are async by default. All async methods will return a promise if the callback isn't passed. Sync methods on the other hand will throw if an error occurs. Also Async/Await will throw an error if one occurs. Example: const fs = require('fs-extra') // Async with promises: fs.copy('/tmp/myfile', '/tmp/mynewfile') .then(() => console.log('success!')) .catch(err => console.error(err)) // Async with callbacks: fs.copy('/tmp/myfile', '/tmp/mynewfile', err => { if (err) return console.error(err) console.log('success!') }) // Sync: try { fs.copySync('/tmp/myfile', '/tmp/mynewfile') console.log('success!') } catch (err) { console.error(err) } // Async/Await: async function copyFiles () { try { await fs.copy('/tmp/myfile', '/tmp/mynewfile') console.log('success!') } catch (err) { console.error(err) } } copyFiles() Methods Async copy emptyDir ensureFile ensureDir ensureLink ensureSymlink mkdirp mkdirs move outputFile outputJson pathExists readJson remove writeJson Sync copySync emptyDirSync ensureFileSync ensureDirSync ensureLinkSync ensureSymlinkSync mkdirpSync mkdirsSync moveSync outputFileSync outputJsonSync pathExistsSync readJsonSync removeSync writeJsonSync NOTE: You can still use the native Node.js methods. They are promisified and copied over to fs-extra. See notes on fs.read(), fs.write(), & fs.writev() What happened to walk() and walkSync()? They were removed from fs-extra in v2.0.0. If you need the functionality, walk and walkSync are available as separate packages, klaw and klaw-sync. Third Party CLI fse-cli allows you to run fs-extra from a console or from npm scripts. TypeScript If you like TypeScript, you can use fs-extra with it: https://github.com/DefinitelyTyped/DefinitelyTyped/tree/master/types/fs-extra File / Directory Watching If you want to watch for changes to files or directories, then you should use chokidar. Obtain Filesystem (Devices, Partitions) Information fs-filesystem allows you to read the state of the filesystem of the host on which it is run. It returns information about both the devices and the partitions (volumes) of the system. Misc. fs-extra-debug - Send your fs-extra calls to debug. mfs - Monitor your fs-extra calls. Hacking on fs-extra Wanna hack on fs-extra? Great! Your help is needed! fs-extra is one of the most depended upon Node.js packages. This project uses JavaScript Standard Style - if the name or style choices bother you, you're gonna have to get over it :) If standard is good enough for npm, it's good enough for fs-extra. What's needed? First, take a look at existing issues. Those are probably going to be where the priority lies. More tests for edge cases. Specifically on different platforms. There can never be enough tests. Improve test coverage. Note: If you make any big changes, you should definitely file an issue for discussion first. Running the Test Suite fs-extra contains hundreds of tests. npm run lint: runs the linter (standard) npm run unit: runs the unit tests npm run unit-esm: runs tests for fs-extra/esm exports npm test: runs the linter and all tests When running unit tests, set the environment variable CROSS_DEVICE_PATH to the absolute path of an empty directory on another device (like a thumb drive) to enable cross-device move tests. Windows If you run the tests on the Windows and receive a lot of symbolic link EPERM permission errors, it's because on Windows you need elevated privilege to create symbolic links. You can add this to your Windows's account by following the instructions here: http://superuser.com/questions/104845/permission-to-make-symbolic-links-in-windows-7 However, I didn't have much luck doing this. Since I develop on Mac OS X, I use VMWare Fusion for Windows testing. I create a shared folder that I map to a drive on Windows. I open the Node.js command prompt and run as Administrator. I then map the network drive running the following command: net use z: \"\\\\vmware-host\\Shared Folders\" I can then navigate to my fs-extra directory and run the tests. Naming I put a lot of thought into the naming of these functions. Inspired by @coolaj86's request. So he deserves much of the credit for raising the issue. See discussion(s) here: https://github.com/jprichardson/node-fs-extra/issues/2 https://github.com/flatiron/utile/issues/11 https://github.com/ryanmcgrath/wrench-js/issues/29 https://github.com/substack/node-mkdirp/issues/17 First, I believe that in as many cases as possible, the Node.js naming schemes should be chosen. However, there are problems with the Node.js own naming schemes. For example, fs.readFile() and fs.readdir(): the F is capitalized in File and the d is not capitalized in dir. Perhaps a bit pedantic, but they should still be consistent. Also, Node.js has chosen a lot of POSIX naming schemes, which I believe is great. See: fs.mkdir(), fs.rmdir(), fs.chown(), etc. We have a dilemma though. How do you consistently name methods that perform the following POSIX commands: cp, cp -r, mkdir -p, and rm -rf? My perspective: when in doubt, err on the side of simplicity. A directory is just a hierarchical grouping of directories and files. Consider that for a moment. So when you want to copy it or remove it, in most cases you'll want to copy or remove all of its contents. When you want to create a directory, if the directory that it's suppose to be contained in does not exist, then in most cases you'll want to create that too. So, if you want to remove a file or a directory regardless of whether it has contents, just call fs.remove(path). If you want to copy a file or a directory whether it has contents, just call fs.copy(source, destination). If you want to create a directory regardless of whether its parent directories exist, just call fs.mkdirs(path) or fs.mkdirp(path). Credit fs-extra wouldn't be possible without using the modules from the following authors: Isaac Shlueter Charlie McConnel James Halliday Andrew Kelley License Licensed under MIT Copyright (c) 2011-2017 JP Richardson"
  },
  "node_modules/postcss-cli/node_modules/globby/readme.html": {
    "href": "node_modules/postcss-cli/node_modules/globby/readme.html",
    "title": "globby | accouter",
    "keywords": "globby User-friendly glob matching Based on fast-glob but adds a bunch of useful features. Features Promise API Multiple patterns Negated patterns: ['foo*', '!foobar'] Expands directories: foo → foo/**/* Supports .gitignore and similar ignore config files Supports URL as cwd Install npm install globby Usage ├── unicorn ├── cake └── rainbow import {globby} from 'globby'; const paths = await globby(['*', '!cake']); console.log(paths); //=> ['unicorn', 'rainbow'] API Note that glob patterns can only contain forward-slashes, not backward-slashes, so if you want to construct a glob pattern from path components, you need to use path.posix.join() instead of path.join(). globby(patterns, options?) Returns a Promise<string[]> of matching paths. patterns Type: string | string[] See supported minimatch patterns. options Type: object See the fast-glob options in addition to the ones below. expandDirectories Type: boolean | string[] | object Default: true If set to true, globby will automatically glob directories for you. If you define an Array it will only glob files that matches the patterns inside the Array. You can also define an object with files and extensions like below: import {globby} from 'globby'; const paths = await globby('images', { expandDirectories: { files: ['cat', 'unicorn', '*.jpg'], extensions: ['png'] } }); console.log(paths); //=> ['cat.png', 'unicorn.png', 'cow.jpg', 'rainbow.jpg'] Note that if you set this option to false, you won't get back matched directories unless you set onlyFiles: false. gitignore Type: boolean Default: false Respect ignore patterns in .gitignore files that apply to the globbed files. ignoreFiles Type: string | string[] Default: undefined Glob patterns to look for ignore files, which are then used to ignore globbed files. This is a more generic form of the gitignore option, allowing you to find ignore files with a compatible syntax. For instance, this works with Babel's .babelignore, Prettier's .prettierignore, or ESLint's .eslintignore files. globbySync(patterns, options?) Returns string[] of matching paths. globbyStream(patterns, options?) Returns a stream.Readable of matching paths. For example, loop over glob matches in a for await...of loop like this: import {globbyStream} from 'globby'; for await (const path of globbyStream('*.tmp')) { console.log(path); } convertPathToPattern(path) Convert a path to a pattern. Learn more. generateGlobTasks(patterns, options?) Returns an Promise<object[]> in the format {patterns: string[], options: Object}, which can be passed as arguments to fast-glob. This is useful for other globbing-related packages. Note that you should avoid running the same tasks multiple times as they contain a file system cache. Instead, run this method each time to ensure file system changes are taken into consideration. generateGlobTasksSync(patterns, options?) Returns an object[] in the format {patterns: string[], options: Object}, which can be passed as arguments to fast-glob. This is useful for other globbing-related packages. Takes the same arguments as generateGlobTasks. isDynamicPattern(patterns, options?) Returns a boolean of whether there are any special glob characters in the patterns. Note that the options affect the results. This function is backed by fast-glob. isGitIgnored(options?) Returns a Promise<(path: URL | string) => boolean> indicating whether a given path is ignored via a .gitignore file. Takes cwd?: URL | string as options. import {isGitIgnored} from 'globby'; const isIgnored = await isGitIgnored(); console.log(isIgnored('some/file')); isGitIgnoredSync(options?) Returns a (path: URL | string) => boolean indicating whether a given path is ignored via a .gitignore file. Takes cwd?: URL | string as options. Globbing patterns Just a quick overview. * matches any number of characters, but not / ? matches a single character, but not / ** matches any number of characters, including /, as long as it's the only thing in a path part {} allows for a comma-separated list of \"or\" expressions ! at the beginning of a pattern will negate the match Various patterns and expected matches. Related multimatch - Match against a list instead of the filesystem matcher - Simple wildcard matching del - Delete files and directories make-dir - Make a directory and its parents if needed"
  },
  "node_modules/postcss-cli/node_modules/jsonfile/CHANGELOG.html": {
    "href": "node_modules/postcss-cli/node_modules/jsonfile/CHANGELOG.html",
    "title": "| accouter",
    "keywords": "6.1.0 / 2020-10-31 Add finalEOL option to disable writing final EOL (#115, #137) Update dependency (#138) 6.0.1 / 2020-03-07 Update dependency (#130) Fix code style (#129) 6.0.0 / 2020-02-24 BREAKING: Drop support for Node 6 & 8 (#128) BREAKING: Do not allow passing null as options to readFile() or writeFile() (#128) Refactor internals (#128) 5.0.0 / 2018-09-08 BREAKING: Drop Node 4 support BREAKING: If no callback is passed to an asynchronous method, a promise is now returned (#109) Cleanup docs 4.0.0 / 2017-07-12 BREAKING: Remove global spaces option. BREAKING: Drop support for Node 0.10, 0.12, and io.js. Remove undocumented passParsingErrors option. Added EOL override option to writeFile when using spaces. #89 3.0.1 / 2017-07-05 Fixed bug in writeFile when there was a serialization error & no callback was passed. In previous versions, an empty file would be written; now no file is written. 3.0.0 / 2017-04-25 Changed behavior of throws option for readFileSync; now does not throw filesystem errors when throws is false 2.4.0 / 2016-09-15 Changed added optional support for graceful-fs [#62] 2.3.1 / 2016-05-13 fix to support BOM. #45 2.3.0 / 2016-04-16 add throws to readFile(). See #39 add support for any arbitrary fs module. Useful with mock-fs 2.2.3 / 2015-10-14 include file name in parse error. See: https://github.com/jprichardson/node-jsonfile/pull/34 2.2.2 / 2015-09-16 split out tests into separate files fixed throws when set to true in readFileSync(). See: https://github.com/jprichardson/node-jsonfile/pull/33 2.2.1 / 2015-06-25 fixed regression when passing in string as encoding for options in writeFile() and writeFileSync(). See: https://github.com/jprichardson/node-jsonfile/issues/28 2.2.0 / 2015-06-25 added options.spaces to writeFile() and writeFileSync() 2.1.2 / 2015-06-22 fixed if passed readFileSync(file, 'utf8'). See: https://github.com/jprichardson/node-jsonfile/issues/25 2.1.1 / 2015-06-19 fixed regressions if null is passed for options. See: https://github.com/jprichardson/node-jsonfile/issues/24 2.1.0 / 2015-06-19 cleanup: JavaScript Standard Style, rename files, dropped terst for assert methods now support JSON revivers/replacers 2.0.1 / 2015-05-24 update license attribute https://github.com/jprichardson/node-jsonfile/pull/21 2.0.0 / 2014-07-28 added \\n to end of file on write. #14 added options.throws to readFileSync() dropped support for Node v0.8 1.2.0 / 2014-06-29 removed semicolons bugfix: passed options to fs.readFile and fs.readFileSync. This technically changes behavior, but changes it according to docs. #12 1.1.1 / 2013-11-11 fixed catching of callback bug (ffissore / #5) 1.1.0 / 2013-10-11 added options param to methods, (seanodell / #4) 1.0.1 / 2013-09-05 removed homepage field from package.json to remove NPM warning 1.0.0 / 2013-06-28 added .npmignore, #1 changed spacing default from 4 to 2 to follow Node conventions 0.0.1 / 2012-09-10 Initial release."
  },
  "node_modules/postcss-cli/node_modules/jsonfile/README.html": {
    "href": "node_modules/postcss-cli/node_modules/jsonfile/README.html",
    "title": "Node.js - jsonfile | accouter",
    "keywords": "Node.js - jsonfile Easily read/write JSON files in Node.js. Note: this module cannot be used in the browser. Why? Writing JSON.stringify() and then fs.writeFile() and JSON.parse() with fs.readFile() enclosed in try/catch blocks became annoying. Installation npm install --save jsonfile API readFile(filename, [options], callback) readFileSync(filename, [options]) writeFile(filename, obj, [options], callback) writeFileSync(filename, obj, [options]) readFile(filename, [options], callback) options (object, default undefined): Pass in any fs.readFile options or set reviver for a JSON reviver. throws (boolean, default: true). If JSON.parse throws an error, pass this error to the callback. If false, returns null for the object. const jsonfile = require('jsonfile') const file = '/tmp/data.json' jsonfile.readFile(file, function (err, obj) { if (err) console.error(err) console.dir(obj) }) You can also use this method with promises. The readFile method will return a promise if you do not pass a callback function. const jsonfile = require('jsonfile') const file = '/tmp/data.json' jsonfile.readFile(file) .then(obj => console.dir(obj)) .catch(error => console.error(error)) readFileSync(filename, [options]) options (object, default undefined): Pass in any fs.readFileSync options or set reviver for a JSON reviver. throws (boolean, default: true). If an error is encountered reading or parsing the file, throw the error. If false, returns null for the object. const jsonfile = require('jsonfile') const file = '/tmp/data.json' console.dir(jsonfile.readFileSync(file)) writeFile(filename, obj, [options], callback) options: Pass in any fs.writeFile options or set replacer for a JSON replacer. Can also pass in spaces, or override EOL string or set finalEOL flag as false to not save the file with EOL at the end. const jsonfile = require('jsonfile') const file = '/tmp/data.json' const obj = { name: 'JP' } jsonfile.writeFile(file, obj, function (err) { if (err) console.error(err) }) Or use with promises as follows: const jsonfile = require('jsonfile') const file = '/tmp/data.json' const obj = { name: 'JP' } jsonfile.writeFile(file, obj) .then(res => { console.log('Write complete') }) .catch(error => console.error(error)) formatting with spaces: const jsonfile = require('jsonfile') const file = '/tmp/data.json' const obj = { name: 'JP' } jsonfile.writeFile(file, obj, { spaces: 2 }, function (err) { if (err) console.error(err) }) overriding EOL: const jsonfile = require('jsonfile') const file = '/tmp/data.json' const obj = { name: 'JP' } jsonfile.writeFile(file, obj, { spaces: 2, EOL: '\\r\\n' }, function (err) { if (err) console.error(err) }) disabling the EOL at the end of file: const jsonfile = require('jsonfile') const file = '/tmp/data.json' const obj = { name: 'JP' } jsonfile.writeFile(file, obj, { spaces: 2, finalEOL: false }, function (err) { if (err) console.log(err) }) appending to an existing JSON file: You can use fs.writeFile option { flag: 'a' } to achieve this. const jsonfile = require('jsonfile') const file = '/tmp/mayAlreadyExistedData.json' const obj = { name: 'JP' } jsonfile.writeFile(file, obj, { flag: 'a' }, function (err) { if (err) console.error(err) }) writeFileSync(filename, obj, [options]) options: Pass in any fs.writeFileSync options or set replacer for a JSON replacer. Can also pass in spaces, or override EOL string or set finalEOL flag as false to not save the file with EOL at the end. const jsonfile = require('jsonfile') const file = '/tmp/data.json' const obj = { name: 'JP' } jsonfile.writeFileSync(file, obj) formatting with spaces: const jsonfile = require('jsonfile') const file = '/tmp/data.json' const obj = { name: 'JP' } jsonfile.writeFileSync(file, obj, { spaces: 2 }) overriding EOL: const jsonfile = require('jsonfile') const file = '/tmp/data.json' const obj = { name: 'JP' } jsonfile.writeFileSync(file, obj, { spaces: 2, EOL: '\\r\\n' }) disabling the EOL at the end of file: const jsonfile = require('jsonfile') const file = '/tmp/data.json' const obj = { name: 'JP' } jsonfile.writeFileSync(file, obj, { spaces: 2, finalEOL: false }) appending to an existing JSON file: You can use fs.writeFileSync option { flag: 'a' } to achieve this. const jsonfile = require('jsonfile') const file = '/tmp/mayAlreadyExistedData.json' const obj = { name: 'JP' } jsonfile.writeFileSync(file, obj, { flag: 'a' }) License (MIT License) Copyright 2012-2016, JP Richardson jprichardson@gmail.com"
  },
  "node_modules/postcss-cli/node_modules/path-type/readme.html": {
    "href": "node_modules/postcss-cli/node_modules/path-type/readme.html",
    "title": "path-type | accouter",
    "keywords": "path-type Check if a path is a file, directory, or symlink Install $ npm install path-type Usage import {isFile} from 'path-type'; console.log(await isFile('package.json')); //=> true API isFile(path) Check whether the passed path is a file. Returns a Promise<boolean>. path Type: string The path to check. isDirectory(path) Check whether the passed path is a directory. Returns a Promise<boolean>. isSymlink(path) Check whether the passed path is a symlink. Returns a Promise<boolean>. isFileSync(path) Synchronously check whether the passed path is a file. Returns a boolean. isDirectorySync(path) Synchronously check whether the passed path is a directory. Returns a boolean. isSymlinkSync(path) Synchronously check whether the passed path is a symlink. Returns a boolean. Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "node_modules/postcss-cli/node_modules/slash/readme.html": {
    "href": "node_modules/postcss-cli/node_modules/slash/readme.html",
    "title": "slash | accouter",
    "keywords": "slash Convert Windows backslash paths to slash paths: foo\\\\bar ➔ foo/bar Forward-slash paths can be used in Windows as long as they're not extended-length paths. This was created since the path methods in Node.js outputs \\\\ paths on Windows. Install npm install slash Usage import path from 'node:path'; import slash from 'slash'; const string = path.join('foo', 'bar'); // Unix => foo/bar // Windows => foo\\\\bar slash(string); // Unix => foo/bar // Windows => foo/bar API slash(path) Type: string Accepts a Windows backslash path and returns a path with forward slashes."
  },
  "node_modules/postcss-cli/node_modules/universalify/README.html": {
    "href": "node_modules/postcss-cli/node_modules/universalify/README.html",
    "title": "universalify | accouter",
    "keywords": "universalify Make a callback- or promise-based function support both promises and callbacks. Uses the native promise implementation. Installation npm install universalify API universalify.fromCallback(fn) Takes a callback-based function to universalify, and returns the universalified function. Function must take a callback as the last parameter that will be called with the signature (error, result). universalify does not support calling the callback with three or more arguments, and does not ensure that the callback is only called once. function callbackFn (n, cb) { setTimeout(() => cb(null, n), 15) } const fn = universalify.fromCallback(callbackFn) // Works with Promises: fn('Hello World!') .then(result => console.log(result)) // -> Hello World! .catch(error => console.error(error)) // Works with Callbacks: fn('Hi!', (error, result) => { if (error) return console.error(error) console.log(result) // -> Hi! }) universalify.fromPromise(fn) Takes a promise-based function to universalify, and returns the universalified function. Function must return a valid JS promise. universalify does not ensure that a valid promise is returned. function promiseFn (n) { return new Promise(resolve => { setTimeout(() => resolve(n), 15) }) } const fn = universalify.fromPromise(promiseFn) // Works with Promises: fn('Hello World!') .then(result => console.log(result)) // -> Hello World! .catch(error => console.error(error)) // Works with Callbacks: fn('Hi!', (error, result) => { if (error) return console.error(error) console.log(result) // -> Hi! }) License MIT"
  },
  "node_modules/postcss-colormin/README.html": {
    "href": "node_modules/postcss-colormin/README.html",
    "title": "postcss-colormin | accouter",
    "keywords": "postcss-colormin Minify colors in your CSS files with PostCSS. Install With npm do: npm install postcss-colormin --save Example var postcss = require('postcss') var colormin = require('postcss-colormin'); var css = 'h1 {color: rgba(255, 0, 0, 1)}'; console.log(postcss(colormin()).process(css).css); // => 'h1 {color:red}' For more examples see the tests. Usage See the PostCSS documentation for examples for your environment. Contributors See CONTRIBUTORS.md. License MIT © Ben Briggs"
  },
  "node_modules/postcss-convert-values/README.html": {
    "href": "node_modules/postcss-convert-values/README.html",
    "title": "postcss-convert-values | accouter",
    "keywords": "postcss-convert-values Convert values with PostCSS (e.g. ms -> s) Install With npm do: npm install postcss-convert-values --save Example This plugin reduces CSS size by converting values to use different units where possible; for example, 500ms can be represented as .5s. You can read more about these units in this article. Input h1 { font-size: 16px; width: 0em } Output h1 { font-size: 1pc; width: 0 } Note that this plugin only covers conversions for duration and absolute length values. For color conversions, use [postcss-colormin][colormin]. API convertValues([options]) options length Type: boolean Default: true Pass false to disable conversion from px to other absolute length units, such as pc & pt & vice versa. time Type: boolean Default: true Pass false to disable conversion from ms to s & vice versa. angle Type: boolean Default: true Pass false to disable conversion from deg to turn & vice versa. precision Type: boolean|number Default: false Specify any numeric value here to round px values to that many decimal places; for example, using {precision: 2} will round 6.66667px to 6.67px, and {precision: 0} will round it to 7px. Passing false (the default) will leave these values as is. It is recommended for most use cases to set this option to 2. Usage See the PostCSS documentation for examples for your environment. Contributors See CONTRIBUTORS.md. License MIT © Ben Briggs"
  },
  "node_modules/postcss-discard-comments/README.html": {
    "href": "node_modules/postcss-discard-comments/README.html",
    "title": "postcss-discard-comments | accouter",
    "keywords": "postcss-discard-comments Discard comments in your CSS files with PostCSS. Install With npm do: npm install postcss-discard-comments --save Example Input h1/* heading */{ margin: 0 auto } Output h1 { margin: 0 auto } This module discards comments from your CSS files; by default, it will remove all regular comments (/* comment */) and preserve comments marked as important (/*! important */). Note that this module does not handle source map comments because they are not available to it; PostCSS handles this internally, so if they are removed then you will have to configure source maps in PostCSS. API comments([options]) options remove(function) Type: function Return: boolean Variable: comment contains a comment without /**/ For each comment, return true to remove, or false to keep the comment. function(comment) {} var css = '/* headings *//*@ h1 */h1{margin:0 auto}/*@ h2 */h2{color:red}'; console.log(postcss(comments({ remove: function(comment) { return comment[0] == \"@\"; } })).process(css).css); //=> /* headings */h1{margin:0 auto}h2{color:red} NOTE: If you use the remove function other options will not be available. removeAll Type: boolean Default: false Remove all comments marked as important. var css = '/*! heading */h1{margin:0 auto}/*! heading 2 */h2{color:red}'; console.log(postcss(comments({removeAll: true})).process(css).css); //=> h1{margin:0 auto}h2{color:red} removeAllButFirst Type: boolean Default: false Remove all comments marked as important, but the first one. var css = '/*! heading */h1{margin:0 auto}/*! heading 2 */h2{color:red}'; console.log(postcss(comments({removeAllButFirst: true})).process(css).css); //=> /*! heading */h1{margin:0 auto}h2{color:red} Usage See the PostCSS documentation for examples for your environment. Contributors See CONTRIBUTORS.md. License MIT © Ben Briggs"
  },
  "node_modules/postcss-discard-duplicates/README.html": {
    "href": "node_modules/postcss-discard-duplicates/README.html",
    "title": "postcss-discard-duplicates | accouter",
    "keywords": "postcss-discard-duplicates Discard duplicate rules in your CSS files with PostCSS. Install With npm do: npm install postcss-discard-duplicates --save Example This module will remove all duplicate rules from your stylesheets. It works on at rules, normal rules and declarations. Note that this module does not have any responsibility for normalising declarations, selectors or whitespace, so that it considers these two rules to be different: h1, h2 { color: blue; } h2, h1 { color: blue; } It has to assume that your rules have already been transformed by another processor, otherwise it would be responsible for too many things. Input h1 { margin: 0 auto; margin: 0 auto } h1 { margin: 0 auto } Output h1 { margin: 0 auto } Usage See the PostCSS documentation for examples for your environment. Contributors See CONTRIBUTORS.md. License MIT © Ben Briggs"
  },
  "node_modules/postcss-discard-empty/README.html": {
    "href": "node_modules/postcss-discard-empty/README.html",
    "title": "postcss-discard-empty | accouter",
    "keywords": "postcss-discard-empty Discard empty rules and values with PostCSS. Install With npm do: npm install postcss-discard-empty --save Example For more examples see the tests. Input @font-face; h1 {} {color:blue} h2 {color:} h3 {color:red} Output h3 {color:red} Usage See the PostCSS documentation for examples for your environment. Contributors See CONTRIBUTORS.md. License MIT © Ben Briggs"
  },
  "node_modules/postcss-discard-overridden/README.html": {
    "href": "node_modules/postcss-discard-overridden/README.html",
    "title": "PostCSS Discard Overridden | accouter",
    "keywords": "PostCSS Discard Overridden PostCSS plugin to discard overridden @keyframes or @counter-style. @keyframes or @counter-style will be overridden by those who share the same identifiers and appear later in stylesheets. So we can discard all of them except the last one. When defined inside a @media or @supports rule, @keyframes and @counter-style rules only override global rules in some of the client browsers so they need handled separately. This plugin has taken care of this and transforms the PostCss AST safely. @-webkit-keyframes fade-in { 0% { opacity: 0; } 100% { opacity: 0.8; } } @keyframes fade-in { 0% { opacity: 0; } 100% { opacity: 0.8; } } @media (max-width: 500px) { @-webkit-keyframes fade-in { 0% { opacity: 0; } 100% { opacity: 1; } } @keyframes fade-in { 0% { opacity: 0; } 100% { opacity: 1; } } @-webkit-keyframes fade-in { 0% { opacity: 0; } 100% { opacity: 0.8; } } @keyframes fade-in { 0% { opacity: 0; } 100% { opacity: 0.8; } } @supports (display: flex) { @-webkit-keyframes fade-in { 0% { opacity: 0; } 100% { opacity: 1; } } @keyframes fade-in { 0% { opacity: 0; } 100% { opacity: 1; } } } } @-webkit-keyframes fade-in { 0% { opacity: 0; } 100% { opacity: 1; } } @keyframes fade-in { 0% { opacity: 0; } 100% { opacity: 1; } } @media (max-width: 500px) { @-webkit-keyframes fade-in { 0% { opacity: 0; } 100% { opacity: 0.8; } } @keyframes fade-in { 0% { opacity: 0; } 100% { opacity: 0.8; } } @supports (display: flex) { @-webkit-keyframes fade-in { 0% { opacity: 0; } 100% { opacity: 1; } } @keyframes fade-in { 0% { opacity: 0; } 100% { opacity: 1; } } } } @-webkit-keyframes fade-in { 0% { opacity: 0; } 100% { opacity: 1; } } @keyframes fade-in { 0% { opacity: 0; } 100% { opacity: 1; } } Usage See the PostCSS documentation for examples for your environment. Contributors See CONTRIBUTORS.md."
  },
  "node_modules/postcss-load-config/README.html": {
    "href": "node_modules/postcss-load-config/README.html",
    "title": "Load Config | accouter",
    "keywords": "Load Config Install npm i -D postcss-load-config Usage npm i -S|-D postcss-plugin Install all required PostCSS plugins and save them to your package.json dependencies/devDependencies Then create a PostCSS config file by choosing one of the following formats package.json Create a postcss section in your project's package.json Project (Root) |– client |– public | |- package.json { \"postcss\": { \"parser\": \"sugarss\", \"map\": false, \"plugins\": { \"postcss-plugin\": {} } } } .postcssrc Create a .postcssrc file in JSON or YAML format ℹ️ It's recommended to use an extension (e.g .postcssrc.json or .postcssrc.yml) instead of .postcssrc Project (Root) |– client |– public | |- (.postcssrc|.postcssrc.json|.postcssrc.yml) |- package.json .postcssrc.json { \"parser\": \"sugarss\", \"map\": false, \"plugins\": { \"postcss-plugin\": {} } } .postcssrc.yml parser: sugarss map: false plugins: postcss-plugin: {} .postcssrc.js or postcss.config.js You may need some logic within your config. In this case create JS/TS file named: .postcssrc.js .postcssrc.mjs .postcssrc.cjs .postcssrc.ts .postcssrc.mts .postcssrc.cts postcss.config.js postcss.config.mjs postcss.config.cjs postcss.config.ts postcss.config.mts postcss.config.cts Note For TypeScript configs, you must have tsx or jiti installed as a peer dependency. Project (Root) |– client |– public |- (.postcssrc|postcss.config).(js|mjs|cjs|ts|mts|cts) |- package.json You can export the config as an {Object} .postcssrc.js module.exports = { parser: 'sugarss', map: false, plugins: { 'postcss-plugin': {} } } Or export a {Function} that returns the config (more about the ctx param below) .postcssrc.js module.exports = (ctx) => ({ parser: ctx.parser ? 'sugarss' : false, map: ctx.env === 'development' ? ctx.map : false, plugins: { 'postcss-plugin': ctx.options.plugin } }) Plugins can be loaded either using an {Object} or an {Array} {Object} .postcssrc.js module.exports = ({ env }) => ({ ...options, plugins: { 'postcss-plugin': env === 'production' ? {} : false } }) ℹ️ When using an {Object}, the key can be a Node.js module name, a path to a JavaScript file that is relative to the directory of the PostCSS config file, or an absolute path to a JavaScript file. {Array} .postcssrc.js module.exports = ({ env }) => ({ ...options, plugins: [ env === 'production' ? require('postcss-plugin')() : false ] }) ⚠️ When using an {Array}, make sure to require() each plugin Options Name Type Default Description to {String} undefined Destination File Path map {String\\|Object} false Enable/Disable Source Maps from {String} undefined Source File Path parser {String\\|Function} false Custom PostCSS Parser syntax {String\\|Function} false Custom PostCSS Syntax stringifier {String\\|Function} false Custom PostCSS Stringifier parser .postcssrc.js module.exports = { parser: 'sugarss' } syntax .postcssrc.js module.exports = { syntax: 'postcss-scss' } stringifier .postcssrc.js module.exports = { stringifier: 'midas' } map .postcssrc.js module.exports = { map: 'inline' } ⚠️ In most cases options.from && options.to are set by the third-party which integrates this package (CLI, gulp, webpack). It's unlikely one needs to set/use options.from && options.to within a config file. Unless you're a third-party plugin author using this module and its Node API directly dont't set options.from && options.to yourself to module.exports = { to: 'path/to/dest.css' } from module.exports = { from: 'path/to/src.css' } Plugins {} || null The plugin will be loaded with defaults 'postcss-plugin': {} || null .postcssrc.js module.exports = { plugins: { 'postcss-plugin': {} || null } } ⚠️ {} must be an empty {Object} literal {Object} The plugin will be loaded with given options 'postcss-plugin': { option: '', option: '' } .postcssrc.js module.exports = { plugins: { 'postcss-plugin': { option: '', option: '' } } } false The plugin will not be loaded 'postcss-plugin': false .postcssrc.js module.exports = { plugins: { 'postcss-plugin': false } } Ordering Plugin execution order is determined by declaration in the plugins section (top-down) { plugins: { 'postcss-plugin': {}, // [0] 'postcss-plugin': {}, // [1] 'postcss-plugin': {} // [2] } } Context When using a {Function} (postcss.config.js or .postcssrc.js), it's possible to pass context to postcss-load-config, which will be evaluated while loading your config. By default ctx.env (process.env.NODE_ENV) and ctx.cwd (process.cwd()) are available on the ctx {Object} ℹ️ Most third-party integrations add additional properties to the ctx (e.g postcss-loader). Check the specific module's README for more information about what is available on the respective ctx Examples postcss.config.js module.exports = (ctx) => ({ parser: ctx.parser ? 'sugarss' : false, map: ctx.env === 'development' ? ctx.map : false, plugins: { 'postcss-import': {}, 'postcss-nested': {}, cssnano: ctx.env === 'production' ? {} : false } }) \"scripts\": { \"build\": \"NODE_ENV=production node postcss\", \"start\": \"NODE_ENV=development node postcss\" } const { readFileSync } = require('fs') const postcss = require('postcss') const postcssrc = require('postcss-load-config') const css = readFileSync('index.css', 'utf8') const ctx = { parser: true, map: 'inline' } postcssrc(ctx).then(({ plugins, options }) => { postcss(plugins) .process(css, options) .then((result) => console.log(result.css)) }) \"scripts\": { \"build\": \"NODE_ENV=production gulp\", \"start\": \"NODE_ENV=development gulp\" } const { task, src, dest, series, watch } = require('gulp') const postcss = require('gulp-postcssrc') const css = () => { src('src/*.css') .pipe(postcss()) .pipe(dest('dest')) }) task('watch', () => { watch(['src/*.css', 'postcss.config.js'], css) }) task('default', series(css, 'watch')) \"scripts\": { \"build\": \"NODE_ENV=production webpack\", \"start\": \"NODE_ENV=development webpack-dev-server\" } webpack.config.js module.exports = (env) => ({ module: { rules: [ { test: /\\.css$/, use: [ 'style-loader', 'css-loader', 'postcss-loader' ] } ] } }) Maintainers Michael Ciniawsky Mateusz Derks Contributors Ryan Dunckel Patrick Gilday Dalton Santos François Wouts Security Contact To report a security vulnerability, please use the Tidelift security contact. Tidelift will coordinate the fix and disclosure."
  },
  "node_modules/postcss-merge-longhand/README.html": {
    "href": "node_modules/postcss-merge-longhand/README.html",
    "title": "postcss-merge-longhand | accouter",
    "keywords": "postcss-merge-longhand Merge longhand properties into shorthand with PostCSS. Install With npm do: npm install postcss-merge-longhand --save Example Merge longhand properties into shorthand; works with margin, padding & border. For more examples see the tests. Input h1 { margin-top: 10px; margin-right: 20px; margin-bottom: 10px; margin-left: 20px; } Output h1 { margin: 10px 20px; } Usage See the PostCSS documentation for examples for your environment. Contributors See CONTRIBUTORS.md. License MIT © Ben Briggs"
  },
  "node_modules/postcss-merge-rules/README.html": {
    "href": "node_modules/postcss-merge-rules/README.html",
    "title": "postcss-merge-rules | accouter",
    "keywords": "postcss-merge-rules Merge CSS rules with PostCSS. Install With npm do: npm install postcss-merge-rules --save Examples This module will attempt to merge adjacent CSS rules: By declarations Input a { color: blue; font-weight: bold } p { color: blue; font-weight: bold } Output a,p { color: blue; font-weight: bold } By selectors Input a { color: blue } a { font-weight: bold } Output a { color: blue; font-weight: bold } By partial declarations Input a { font-weight: bold } p { color: blue; font-weight: bold } Output a,p { font-weight: bold } p { color: blue } Usage See the PostCSS documentation for examples for your environment. Contributors See CONTRIBUTORS.md. License MIT © Ben Briggs"
  },
  "node_modules/postcss-minify-font-values/README.html": {
    "href": "node_modules/postcss-minify-font-values/README.html",
    "title": "postcss-minify-font-values | accouter",
    "keywords": "postcss-minify-font-values Minify font declarations with PostCSS. This module will try to minimise the font-family, font-weight and font shorthand properties; it can unquote font families where necessary, detect & remove duplicates, and cut short a declaration after it finds a keyword. For more examples, see the tests. h1 { font:bold 2.2rem/.9 \"Open Sans Condensed\", sans-serif; } p { font-family: \"Helvetica Neue\", Arial, sans-serif, Helvetica; font-weight: normal; } h1 { font:700 2.2rem/.9 Open Sans Condensed,sans-serif } p { font-family: Helvetica Neue,Arial,sans-serif; font-weight: 400; } API minifyFontValues([options]) options removeAfterKeyword Type: boolean Default: false Pass true to remove font families after the module encounters a font keyword, for example sans-serif. removeDuplicates Type: boolean Default: true Pass false to disable the module from removing duplicated font families. removeQuotes Type: boolean | (prop: string) => '' | 'font' | 'font-family' | 'font-weight' Default: true Pass false to disable the module from removing quotes from font families. Note that oftentimes, this is a safe optimisation & is done safely. For more details, see Mathias Bynens' article. Pass a function to determine whether a css variable is one of font, font-family, and font-weight to determine whether the variable needs to remove quotes. Usage postcss([ require('postcss-minify-font-values') ]) See PostCSS docs for examples for your environment. Contributors See CONTRIBUTORS.md. License MIT © Bogdan Chadkin"
  },
  "node_modules/postcss-minify-gradients/README.html": {
    "href": "node_modules/postcss-minify-gradients/README.html",
    "title": "postcss-minify-gradients | accouter",
    "keywords": "postcss-minify-gradients Minify gradient parameters with PostCSS. Install With npm do: npm install postcss-minify-gradients Example Where possible, this module will minify gradient parameters. It can convert linear gradient directional syntax to angles, remove the unnecessary 0% and 100% start and end values, and minimise color stops that use the same length values (the browser will adjust the value automatically). Input h1 { background: linear-gradient(to bottom, #ffe500 0%, #ffe500 50%, #121 50%, #121 100%) } Output h1 { background: linear-gradient(180deg, #ffe500, #ffe500 50%, #121 0, #121) } Usage See the PostCSS documentation for examples for your environment. Contributors See CONTRIBUTORS.md. License MIT © Ben Briggs"
  },
  "node_modules/postcss-minify-params/README.html": {
    "href": "node_modules/postcss-minify-params/README.html",
    "title": "postcss-minify-params | accouter",
    "keywords": "postcss-minify-params Minify at-rule params with PostCSS. @media only screen and ( min-width: 400px, min-height: 500px ) { h2{ color:blue } } @media only screen and (min-width:400px,min-height:500px) { h2{ color:blue } } Usage postcss([ require('postcss-minify-params') ]) See PostCSS docs for examples for your environment. Contributors See CONTRIBUTORS.md. License MIT © Bogdan Chadkin"
  },
  "node_modules/postcss-minify-selectors/README.html": {
    "href": "node_modules/postcss-minify-selectors/README.html",
    "title": "postcss-minify-selectors | accouter",
    "keywords": "postcss-minify-selectors Minify selectors with PostCSS. Install With npm do: npm install postcss-minify-selectors --save Example Input h1 + p, h2, h3, h2{color:blue} Output h1+p,h2,h3{color:blue} For more examples see the tests. Usage See the PostCSS documentation for examples for your environment. Contributors See CONTRIBUTORS.md. License MIT © Ben Briggs"
  },
  "node_modules/postcss-normalize-charset/README.html": {
    "href": "node_modules/postcss-normalize-charset/README.html",
    "title": "postcss-normalize-charset | accouter",
    "keywords": "postcss-normalize-charset Add necessary or remove extra charset with PostCSS a{ content: \"©\"; } @charset \"utf-8\"; a{ content: \"©\"; } API normalizeCharset([options]) options add Type: boolean Default: true Pass false to stop the module from adding a @charset declaration if it was missing from the file (and the file contained non-ascii characters). Usage See the PostCSS documentation for examples for your environment. Contributors See CONTRIBUTORS.md. License MIT © Bogdan Chadkin"
  },
  "node_modules/postcss-normalize-display-values/README.html": {
    "href": "node_modules/postcss-normalize-display-values/README.html",
    "title": "postcss-normalize-display-values | accouter",
    "keywords": "postcss-normalize-display-values Normalize display property values with PostCSS. Install With npm do: npm install postcss-normalize-display-values --save Example Input div { display: inline flow-root } Output div { display: inline-block } Usage See the PostCSS documentation for examples for your environment. Contributors See CONTRIBUTORS.md. License MIT © Ben Briggs"
  },
  "node_modules/postcss-normalize-positions/README.html": {
    "href": "node_modules/postcss-normalize-positions/README.html",
    "title": "postcss-normalize-positions | accouter",
    "keywords": "postcss-normalize-positions Normalize positions with PostCSS. Install With npm do: npm install postcss-normalize-positions --save Example Input div { background-position: bottom left; } Output div { background-position:0 100%; } Usage See the PostCSS documentation for examples for your environment. Contributors See CONTRIBUTORS.md. License MIT © Ben Briggs"
  },
  "node_modules/postcss-normalize-repeat-style/README.html": {
    "href": "node_modules/postcss-normalize-repeat-style/README.html",
    "title": "postcss-normalize-repeat-style | accouter",
    "keywords": "postcss-normalize-repeat-style Normalize repeat styles with PostCSS. Install With npm do: npm install postcss-normalize-repeat-style --save Example Input h1 { background: url(image.jpg) repeat no-repeat } Output h1 { background: url(image.jpg) repeat-x } Usage See the PostCSS documentation for examples for your environment. Contributors See CONTRIBUTORS.md. License MIT © Ben Briggs"
  },
  "node_modules/postcss-normalize-string/README.html": {
    "href": "node_modules/postcss-normalize-string/README.html",
    "title": "postcss-normalize-string | accouter",
    "keywords": "postcss-normalize-string Normalize strings with PostCSS. Install With npm do: npm install postcss-normalize-string --save Example Input p:after{ content: '\\\\'string\\\\' is intact' } Output p:after{ content:\"'string' is intact\" } Usage See the PostCSS documentation for examples for your environment. API normalize([options]) options preferredQuote Type: string Default: double Sets what type of quote to prefer. Possible values are single and double. var css = 'p:after{content:\"\"}'; console.log(postcss(normalize({preferredQuote: 'single'})).process(css).css); //=> p:after{content:''} Contributors See CONTRIBUTORS.md. License MIT © Ben Briggs"
  },
  "node_modules/postcss-normalize-timing-functions/README.html": {
    "href": "node_modules/postcss-normalize-timing-functions/README.html",
    "title": "postcss-normalize-timing-functions | accouter",
    "keywords": "postcss-normalize-timing-functions Normalize timing functions with PostCSS. Install With npm do: npm install postcss-normalize-timing-functions --save Example Input div { animate: fade 3s cubic-bezier(0.42, 0, 1, 1) } Output div { animate: fade 3s ease-in } Usage See the PostCSS documentation for examples for your environment. Contributors See CONTRIBUTORS.md. License MIT © Ben Briggs"
  },
  "node_modules/postcss-normalize-unicode/README.html": {
    "href": "node_modules/postcss-normalize-unicode/README.html",
    "title": "postcss-normalize-unicode | accouter",
    "keywords": "postcss-normalize-unicode Normalize unicode with PostCSS. Install With npm do: npm install postcss-normalize-unicode --save Example Input @font-face{ font-family: test; unicode-range: u+2b00-2bff } Output @font-face{ font-family: test; unicode-range: u+2b?? } Usage See the PostCSS documentation for examples for your environment. Contributors See CONTRIBUTORS.md. License MIT © Ben Briggs"
  },
  "node_modules/postcss-normalize-url/README.html": {
    "href": "node_modules/postcss-normalize-url/README.html",
    "title": "postcss-normalize-url | accouter",
    "keywords": "postcss-normalize-url Normalize URLs with PostCSS. Install With npm do: npm install postcss-normalize-url --save Example Input h1 { background: url(\"http://site.com:80/image.jpg\") } Output h1 { background: url(http://site.com/image.jpg) } Note that this module will also try to normalize relative URLs, and is capable of stripping unnecessary quotes. For more examples, see the tests. Usage See the PostCSS documentation for examples for your environment. Contributors See CONTRIBUTORS.md. License MIT © Ben Briggs"
  },
  "node_modules/postcss-normalize-whitespace/README.html": {
    "href": "node_modules/postcss-normalize-whitespace/README.html",
    "title": "postcss-normalize-whitespace | accouter",
    "keywords": "postcss-normalize-whitespace Normalize whitespace with PostCSS. Install With npm do: npm install postcss-normalize-whitespace --save Example Input h1{ width: calc(10px - ( 100px / var(--test) )) } Output h1{ width: calc(10px - 100px / var(--test)) } Usage See the PostCSS documentation for examples for your environment. Contributors See CONTRIBUTORS.md. License MIT © Ben Briggs"
  },
  "node_modules/postcss-ordered-values/README.html": {
    "href": "node_modules/postcss-ordered-values/README.html",
    "title": "postcss-ordered-values | accouter",
    "keywords": "postcss-ordered-values Ensure values are ordered consistently in your CSS. Install With npm do: npm install postcss-ordered-values --save Example Some CSS properties accept their values in an arbitrary order; for this reason, it is entirely possible that different developers will write their values in different orders. This module normalizes the order, making it easier for other modules to understand which declarations are duplicates. Input h1 { border: solid 1px red; border: red solid .5em; border: rgba(0, 30, 105, 0.8) solid 1px; border: 1px solid red; } Output h1 { border: 1px solid red; border: .5em solid red; border: 1px solid rgba(0, 30, 105, 0.8); border: 1px solid red; } Support List For more examples, see the tests. animation, -webkit-animation border(border-left|right|top|bottom) box-shadow outline flex-flow transition, -webkit-transition Usage See the PostCSS documentation for examples for your environment. Contributors See CONTRIBUTORS.md. License MIT © Ben Briggs"
  },
  "node_modules/postcss-reduce-initial/README.html": {
    "href": "node_modules/postcss-reduce-initial/README.html",
    "title": "postcss-reduce-initial | accouter",
    "keywords": "postcss-reduce-initial Reduce initial definitions to the actual initial value, where possible. Install With npm do: npm install postcss-reduce-initial --save Examples See the data for more conversions. This data is courtesy of Mozilla. Convert initial values When the initial keyword is longer than the property value, it will be converted: Input h1 { min-width: initial; } Output h1 { min-width: auto; } Convert values back to initial When the initial value is smaller than the property value, it will be converted: Input h1 { transform-box: border-box; } Output h1 { transform-box: initial; } This conversion is only applied when you supply a browsers list that all support the initial keyword; it's worth noting that Internet Explorer has no support. API reduceInitial([options]) options ignore Type: Array<String> Default: undefined It contains the Array of properties that will be ignored while reducing its value to initial. Example : { ignore : [\"min-height\"] } Usage See the PostCSS documentation for examples for your environment. Contributors See CONTRIBUTORS.md. License This program uses a list of CSS properties derived from data maintained my the MDN team at Mozilla and licensed under the CC0 1.0 Universal Public Domain Dedication. MIT © Ben Briggs"
  },
  "node_modules/postcss-reduce-transforms/README.html": {
    "href": "node_modules/postcss-reduce-transforms/README.html",
    "title": "postcss-reduce-transforms | accouter",
    "keywords": "postcss-reduce-transforms Reduce transform functions with PostCSS. Install With npm do: npm install postcss-reduce-transforms --save Example This module will reduce transform functions where possible. For more examples, see the tests. Input h1 { transform: rotate3d(0, 0, 1, 20deg); } Output h1 { transform: rotate(20deg); } Usage See the PostCSS documentation for examples for your environment. Contributors See CONTRIBUTORS.md. License MIT © Ben Briggs"
  },
  "node_modules/postcss-reporter/README.html": {
    "href": "node_modules/postcss-reporter/README.html",
    "title": "postcss-reporter | accouter",
    "keywords": "postcss-reporter A PostCSS plugin to console.log() the messages (warnings, etc.) registered by other PostCSS plugins. SEEKING A NEW MAINTAINER! Interested in contributing to the ecosystem of PostCSS and Stylelint? Please open an issue if you'd like to take over maintenance of this package. Docs Read full docs here."
  },
  "node_modules/postcss-selector-parser/API.html": {
    "href": "node_modules/postcss-selector-parser/API.html",
    "title": "API Documentation | accouter",
    "keywords": "API Documentation Please use only this documented API when working with the parser. Methods not documented here are subject to change at any point. parser function This is the module's main entry point. const parser = require('postcss-selector-parser'); parser([transform], [options]) Creates a new processor instance const processor = parser(); Or, with optional transform function const transform = selectors => { selectors.walkUniversals(selector => { selector.remove(); }); }; const processor = parser(transform) // Example const result = processor.processSync('*.class'); // => .class See processor documentation Arguments: transform (function): Provide a function to work with the parsed AST. options (object): Provide default options for all calls on the returned Processor. parser.attribute([props]) Creates a new attribute selector. parser.attribute({attribute: 'href'}); // => [href] Arguments: props (object): The new node's properties. parser.className([props]) Creates a new class selector. parser.className({value: 'button'}); // => .button Arguments: props (object): The new node's properties. parser.combinator([props]) Creates a new selector combinator. parser.combinator({value: '+'}); // => + Arguments: props (object): The new node's properties. Notes: Descendant Combinators The value of descendant combinators created by the parser always just a single space (\" \"). For descendant selectors with no comments, additional space is now stored in node.spaces.before. Depending on the location of comments, additional spaces may be stored in node.raws.spaces.before, node.raws.spaces.after, or node.raws.value. Named Combinators Although, nonstandard and unlikely to ever become a standard, named combinators like /deep/ and /for/ are parsed as combinators. The node.value is name after being unescaped and normalized as lowercase. The original value for the combinator name is stored in node.raws.value. parser.comment([props]) Creates a new comment. parser.comment({value: '/* Affirmative, Dave. I read you. */'}); // => /* Affirmative, Dave. I read you. */ Arguments: props (object): The new node's properties. parser.id([props]) Creates a new id selector. parser.id({value: 'search'}); // => #search Arguments: props (object): The new node's properties. parser.nesting([props]) Creates a new nesting selector. parser.nesting(); // => & Arguments: props (object): The new node's properties. parser.pseudo([props]) Creates a new pseudo selector. parser.pseudo({value: '::before'}); // => ::before Arguments: props (object): The new node's properties. parser.root([props]) Creates a new root node. parser.root(); // => (empty) Arguments: props (object): The new node's properties. parser.selector([props]) Creates a new selector node. parser.selector(); // => (empty) Arguments: props (object): The new node's properties. parser.string([props]) Creates a new string node. parser.string(); // => (empty) Arguments: props (object): The new node's properties. parser.tag([props]) Creates a new tag selector. parser.tag({value: 'button'}); // => button Arguments: props (object): The new node's properties. parser.universal([props]) Creates a new universal selector. parser.universal(); // => * Arguments: props (object): The new node's properties. Node types node.type A string representation of the selector type. It can be one of the following; attribute, class, combinator, comment, id, nesting, pseudo, root, selector, string, tag, or universal. Note that for convenience, these constants are exposed on the main parser as uppercased keys. So for example you can get id by querying parser.ID. parser.attribute({attribute: 'href'}).type; // => 'attribute' node.parent Returns the parent node. root.nodes[0].parent === root; node.toString(), String(node), or '' + node Returns a string representation of the node. const id = parser.id({value: 'search'}); console.log(String(id)); // => #search node.next() & node.prev() Returns the next/previous child of the parent node. const next = id.next(); if (next && next.type !== 'combinator') { throw new Error('Qualified IDs are not allowed!'); } node.replaceWith(node) Replace a node with another. const attr = selectors.first.first; const className = parser.className({value: 'test'}); attr.replaceWith(className); Arguments: node: The node to substitute the original with. node.remove() Removes the node from its parent node. if (node.type === 'id') { node.remove(); } node.clone([opts]) Returns a copy of a node, detached from any parent containers that the original might have had. const cloned = node.clone(); node.isAtPosition(line, column) Return a boolean indicating whether this node includes the character at the position of the given line and column. Returns undefined if the nodes lack sufficient source metadata to determine the position. Arguments: line: 1-index based line number relative to the start of the selector. column: 1-index based column number relative to the start of the selector. node.spaces Extra whitespaces around the node will be moved into node.spaces.before and node.spaces.after. So for example, these spaces will be moved as they have no semantic meaning: h1 , h2 {} For descendent selectors, the value is always a single space. h1 h2 {} Additional whitespace is found in either the node.spaces.before and node.spaces.after depending on the presence of comments or other whitespace characters. If the actual whitespace does not start or end with a single space, the node's raw value is set to the actual space(s) found in the source. node.source An object describing the node's start/end, line/column source position. Within the following CSS, the .bar class node ... .foo, .bar {} ... will contain the following source object. source: { start: { line: 2, column: 3 }, end: { line: 2, column: 6 } } node.sourceIndex The zero-based index of the node within the original source string. Within the following CSS, the .baz class node will have a sourceIndex of 12. .foo, .bar, .baz {} Container types The root, selector, and pseudo nodes have some helper methods for working with their children. container.nodes An array of the container's children. // Input: h1 h2 selectors.at(0).nodes.length // => 3 selectors.at(0).nodes[0].value // => 'h1' selectors.at(0).nodes[1].value // => ' ' container.first & container.last The first/last child of the container. selector.first === selector.nodes[0]; selector.last === selector.nodes[selector.nodes.length - 1]; container.at(index) Returns the node at position index. selector.at(0) === selector.first; selector.at(0) === selector.nodes[0]; Arguments: index: The index of the node to return. container.atPosition(line, column) Returns the node at the source position line and column. // Input: :not(.foo),\\n#foo > :matches(ol, ul) selector.atPosition(1, 1); // => :not(.foo) selector.atPosition(2, 1); // => \\n#foo Arguments: line: The line number of the node to return. column: The column number of the node to return. container.index(node) Return the index of the node within its container. selector.index(selector.nodes[2]) // => 2 Arguments: node: A node within the current container. container.length Proxy to the length of the container's nodes. container.length === container.nodes.length container Array iterators The container class provides proxies to certain Array methods; these are: container.map === container.nodes.map container.reduce === container.nodes.reduce container.every === container.nodes.every container.some === container.nodes.some container.filter === container.nodes.filter container.sort === container.nodes.sort Note that these methods only work on a container's immediate children; recursive iteration is provided by container.walk. container.each(callback) Iterate the container's immediate children, calling callback for each child. You may return false within the callback to break the iteration. let className; selectors.each((selector, index) => { if (selector.type === 'class') { className = selector.value; return false; } }); Note that unlike Array#forEach(), this iterator is safe to use whilst adding or removing nodes from the container. Arguments: callback (function): A function to call for each node, which receives node and index arguments. container.walk(callback) Like container#each, but will also iterate child nodes as long as they are container types. selectors.walk((selector, index) => { // all nodes }); Arguments: callback (function): A function to call for each node, which receives node and index arguments. This iterator is safe to use whilst mutating container.nodes, like container#each. container.walk proxies The container class provides proxy methods for iterating over types of nodes, so that it is easier to write modules that target specific selectors. Those methods are: container.walkAttributes container.walkClasses container.walkCombinators container.walkComments container.walkIds container.walkNesting container.walkPseudos container.walkTags container.walkUniversals container.split(callback) This method allows you to split a group of nodes by returning true from a callback. It returns an array of arrays, where each inner array corresponds to the groups that you created via the callback. // (input) => h1 h2>>h3 const list = selectors.first.split(selector => { return selector.type === 'combinator'; }); // (node values) => [['h1', ' '], ['h2', '>>'], ['h3']] Arguments: callback (function): A function to call for each node, which receives node as an argument. container.prepend(node) & container.append(node) Add a node to the start/end of the container. Note that doing so will set the parent property of the node to this container. const id = parser.id({value: 'search'}); selector.append(id); Arguments: node: The node to add. container.insertBefore(old, new) & container.insertAfter(old, new) Add a node before or after an existing node in a container: selectors.walk(selector => { if (selector.type !== 'class') { const className = parser.className({value: 'theme-name'}); selector.parent.insertAfter(selector, className); } }); Arguments: old: The existing node in the container. new: The new node to add before/after the existing node. container.removeChild(node) Remove the node from the container. Note that you can also use node.remove() if you would like to remove just a single node. selector.length // => 2 selector.remove(id) selector.length // => 1; id.parent // undefined Arguments: node: The node to remove. container.removeAll() or container.empty() Remove all children from the container. selector.removeAll(); selector.length // => 0 Root nodes A root node represents a comma separated list of selectors. Indeed, all a root's toString() method does is join its selector children with a ','. Other than this, it has no special functionality and acts like a container. root.trailingComma This will be set to true if the input has a trailing comma, in order to support parsing of legacy CSS hacks. Selector nodes A selector node represents a single complex selector. For example, this selector string h1 h2 h3, [href] > p, is represented as two selector nodes. It has no special functionality of its own. Pseudo nodes A pseudo selector extends a container node; if it has any parameters of its own (such as h1:not(h2, h3)), they will be its children. Note that the pseudo value will always contain the colons preceding the pseudo identifier. This is so that both :before and ::before are properly represented in the AST. Attribute nodes attribute.quoted Returns true if the attribute's value is wrapped in quotation marks, false if it is not. Remains undefined if there is no attribute value. [href=foo] /* false */ [href='foo'] /* true */ [href=\"foo\"] /* true */ [href] /* undefined */ attribute.qualifiedAttribute Returns the attribute name qualified with the namespace if one is given. attribute.offsetOf(part) Returns the offset of the attribute part specified relative to the start of the node of the output string. This is useful in raising error messages about a specific part of the attribute, especially in combination with attribute.sourceIndex. Returns -1 if the name is invalid or the value doesn't exist in this attribute. The legal values for part are: \"ns\" - alias for \"namespace\" \"namespace\" - the namespace if it exists. \"attribute\" - the attribute name \"attributeNS\" - the start of the attribute or its namespace \"operator\" - the match operator of the attribute \"value\" - The value (string or identifier) \"insensitive\" - the case insensitivity flag attribute.raws.unquoted Returns the unquoted content of the attribute's value. Remains undefined if there is no attribute value. [href=foo] /* foo */ [href='foo'] /* foo */ [href=\"foo\"] /* foo */ [href] /* undefined */ attribute.spaces Like node.spaces with the before and after values containing the spaces around the element, the parts of the attribute can also have spaces before and after them. The for each of attribute, operator, value and insensitive there is corresponding property of the same nam in node.spaces that has an optional before or after string containing only whitespace. Note that corresponding values in attributes.raws.spaces contain values including any comments. If set, these values will override the attribute.spaces value. Take care to remove them if changing attribute.spaces. attribute.raws The raws object stores comments and other information necessary to re-render the node exactly as it was in the source. If a comment is embedded within the identifiers for the namespace, attribute or value then a property is placed in the raws for that value containing the full source of the propery including comments. If a comment is embedded within the space between parts of the attribute then the raw for that space is set accordingly. Setting an attribute's property raws value to be deleted. For now, changing the spaces required also updating or removing any of the raws values that override them. Example: [ /*before*/ href /* after-attr */ = /* after-operator */ te/*inside-value*/st/* wow */ /*omg*/i/*bbq*/ /*whodoesthis*/] would parse as: { attribute: \"href\", operator: \"=\", value: \"test\", spaces: { before: '', after: '', attribute: { before: ' ', after: ' ' }, operator: { after: ' ' }, value: { after: ' ' }, insensitive: { after: ' ' } }, raws: { spaces: { attribute: { before: ' /*before*/ ', after: ' /* after-attr */ ' }, operator: { after: ' /* after-operator */ ' }, value: { after: '/* wow */ /*omg*/' }, insensitive: { after: '/*bbq*/ /*whodoesthis*/' } }, unquoted: 'test', value: 'te/*inside-value*/st' } } Processor ProcessorOptions lossless - When true, whitespace is preserved. Defaults to true. updateSelector - When true, if any processor methods are passed a postcss Rule node instead of a string, then that Rule's selector is updated with the results of the processing. Defaults to true. process|processSync(selectors, [options]) Processes the selectors, returning a string from the result of processing. Note: when the updateSelector option is set, the rule's selector will be updated with the resulting string. Example: const parser = require(\"postcss-selector-parser\"); const processor = parser(); let result = processor.processSync(' .class'); console.log(result); // => .class // Asynchronous operation let promise = processor.process(' .class').then(result => { console.log(result) // => .class }); // To have the parser normalize whitespace values, utilize the options result = processor.processSync(' .class ', {lossless: false}); console.log(result); // => .class // For better syntax errors, pass a PostCSS Rule node. const postcss = require('postcss'); rule = postcss.rule({selector: ' #foo > a, .class '}); processor.process(rule, {lossless: false, updateSelector: true}).then(result => { console.log(result); // => #foo>a,.class console.log(\"rule:\", rule.selector); // => rule: #foo>a,.class }) Arguments: selectors (string|postcss.Rule): Either a selector string or a PostCSS Rule node. [options] (object): Process options ast|astSync(selectors, [options]) Like process() and processSync() but after processing the selectors these methods return the Root node of the result instead of a string. Note: when the updateSelector option is set, the rule's selector will be updated with the resulting string. transform|transformSync(selectors, [options]) Like process() and processSync() but after processing the selectors these methods return the value returned by the processor callback. Note: when the updateSelector option is set, the rule's selector will be updated with the resulting string. Error Handling Within Selector Processors The root node passed to the selector processor callback has a method error(message, options) that returns an error object. This method should always be used to raise errors relating to the syntax of selectors. The options to this method are passed to postcss's error constructor (documentation). Async Error Example let processor = (root) => { return new Promise((resolve, reject) => { root.walkClasses((classNode) => { if (/^(.*)[-_]/.test(classNode.value)) { let msg = \"classes may not have underscores or dashes in them\"; reject(root.error(msg, { index: classNode.sourceIndex + RegExp.$1.length + 1, word: classNode.value })); } }); resolve(); }); }; const postcss = require(\"postcss\"); const parser = require(\"postcss-selector-parser\"); const selectorProcessor = parser(processor); const plugin = postcss.plugin('classValidator', (options) => { return (root) => { let promises = []; root.walkRules(rule => { promises.push(selectorProcessor.process(rule)); }); return Promise.all(promises); }; }); postcss(plugin()).process(` .foo-bar { color: red; } `.trim(), {from: 'test.css'}).catch((e) => console.error(e.toString())); // CssSyntaxError: classValidator: ./test.css:1:5: classes may not have underscores or dashes in them // // > 1 | .foo-bar { // | ^ // 2 | color: red; // 3 | } Synchronous Error Example let processor = (root) => { root.walkClasses((classNode) => { if (/.*[-_]/.test(classNode.value)) { let msg = \"classes may not have underscores or dashes in them\"; throw root.error(msg, { index: classNode.sourceIndex, word: classNode.value }); } }); }; const postcss = require(\"postcss\"); const parser = require(\"postcss-selector-parser\"); const selectorProcessor = parser(processor); const plugin = postcss.plugin('classValidator', (options) => { return (root) => { root.walkRules(rule => { selectorProcessor.processSync(rule); }); }; }); postcss(plugin()).process(` .foo-bar { color: red; } `.trim(), {from: 'test.css'}).catch((e) => console.error(e.toString())); // CssSyntaxError: classValidator: ./test.css:1:5: classes may not have underscores or dashes in them // // > 1 | .foo-bar { // | ^ // 2 | color: red; // 3 | }"
  },
  "node_modules/postcss-selector-parser/CHANGELOG.html": {
    "href": "node_modules/postcss-selector-parser/CHANGELOG.html",
    "title": "6.1.0 | accouter",
    "keywords": "6.1.0 Feature: add sourceIndex to Selector nodes (#290) 6.0.16 Fixed: add missing index argument to each/walk callback types (#289) 6.0.15 Fixed: Node#prev and Node#next type for the first/last node 6.0.14 Fixed: type definitions 6.0.13 Fixed: throw on unexpected pipe symbols 6.0.12 Fixed: clone arguments should be optional 6.0.11 Fixed: parse attribute case insensitivity flag 6.0.10 Fixed: isPseudoElement() supports :first-letter and :first-line 6.0.9 Fixed: Combinator.raws property type 6.0.8 Fixed: reduced size 6.0.7 Fixed: parse animation percents 6.0.6 Fixed: parse quoted attributes containing a newline correctly 6.0.5 Perf: rework unesc for a 63+% performance boost 6.0.4 Fixed: ts errors 6.0.3 Fixed: replace node built-in \"util\" module with \"util-deprecate\" Fixed: handle uppercase pseudo elements Fixed: do not create invalid combinator before comment 6.0.2 Fixed an issue with parsing and stringifying an empty attribute value 6.0.1 Fixed an issue with unicode surrogate pair parsing 6.0.0 Updated: cssesc to 3.0.0 (major) Fixed: Issues with escaped id and class selectors 5.0.0 Allow escaped dot within class name. Update PostCSS to 7.0.7 (patch) 5.0.0-rc.4 Fixed an issue where comments immediately after an insensitive (in attribute) were not parsed correctly. Updated cssesc to 2.0.0 (major). Removed outdated integration tests. Added tests for custom selectors, tags with attributes, the universal selector with pseudos, and tokens after combinators. 5.0.0-rc.1 To ease adoption of the v5.0 release, we have relaxed the node version check performed by npm at installation time to allow for node 4, which remains officially unsupported, but likely to continue working for the time being. 5.0.0-rc.0 This release has BREAKING CHANGES that were required to fix regressions in 4.0.0 and to make the Combinator Node API consistent for all combinator types. Please read carefully. Summary of Changes The way a descendent combinator that isn't a single space character (E.g. .a .b) is stored in the AST has changed. Named Combinators (E.g. .a /for/ .b) are now properly parsed as a combinator. It is now possible to look up a node based on the source location of a character in that node and to query nodes if they contain some character. Several bug fixes that caused the parser to hang and run out of memory when a / was encountered have been fixed. The minimum supported version of Node is now v6.0.0. Changes to the Descendent Combinator In prior releases, the value of a descendant combinator with multiple spaces included all the spaces. .a .b: Extra spaces are now stored as space before. Old & Busted: combinator.value === \" \" New hotness: combinator.value === \" \" && combinator.spaces.before === \" \" .a /*comment*/.b: A comment at the end of the combinator causes extra space to become after space. Old & Busted: combinator.value === \" \" combinator.raws.value === \" /*comment/\" New hotness: combinator.value === \" \" combinator.spaces.after === \" \" combinator.raws.spaces.after === \" /*comment*/\" .a<newline>.b: whitespace that doesn't start or end with a single space character is stored as a raw value. Old & Busted: combinator.value === \"\\n\" combinator.raws.value === undefined New hotness: combinator.value === \" \" combinator.raws.value === \"\\n\" Support for \"Named Combinators\" Although, nonstandard and unlikely to ever become a standard, combinators like /deep/ and /for/ are now properly supported. Because they've been taken off the standardization track, there is no spec-official name for combinators of the form /<ident>/. However, I talked to Tab Atkins and we agreed to call them \"named combinators\" so now they are called that. Before this release such named combinators were parsed without intention and generated three nodes of type \"tag\" where the first and last nodes had a value of \"/\". .a /for/ .b is parsed as a combinator. Old & Busted: root.nodes[0].nodes[1].type === \"tag\" root.nodes[0].nodes[1].value === \"/\" New hotness: root.nodes[0].nodes[1].type === \"combinator\" root.nodes[0].nodes[1].value === \"/for/\" .a /F\\6fR/ .b escapes are handled and uppercase is normalized. Old & Busted: root.nodes[0].nodes[2].type === \"tag\" root.nodes[0].nodes[2].value === \"F\\\\6fR\" New hotness: root.nodes[0].nodes[1].type === \"combinator\" root.nodes[0].nodes[1].value === \"/for/\" root.nodes[0].nodes[1].raws.value === \"/F\\\\6fR/\" Source position checks and lookups A new API was added to look up a node based on the source location. const selectorParser = require(\"postcss-selector-parser\"); // You can find the most specific node for any given character let combinator = selectorParser.astSync(\".a > .b\").atPosition(1,4); combinator.toString() === \" > \"; // You can check if a node includes a specific character // Whitespace surrounding the node that is owned by that node // is included in the check. [2,3,4,5,6].map(column => combinator.isAtPosition(1, column)); // => [false, true, true, true, false] 4.0.0 This release has BREAKING CHANGES that were required to fix bugs regarding values with escape sequences. Please read carefully. Identifiers with escapes - CSS escape sequences are now hidden from the public API by default. The normal value of a node like a class name or ID, or an aspect of a node such as attribute selector's value, is unescaped. Escapes representing Non-ascii characters are unescaped into unicode characters. For example: bu\\tton, .\\31 00, #i\\2764\\FE0Fu, [attr=\"value is \\\"quoted\\\"\"] will parse respectively to the values button, 100, i❤️u, value is \"quoted\". The original escape sequences for these values can be found in the corresponding property name in node.raws. Where possible, deprecation warnings were added, but the nature of escape handling makes it impossible to detect what is escaped or not. Our expectation is that most users are neither expecting nor handling escape sequences in their use of this library, and so for them, this is a bug fix. Users who are taking care to handle escapes correctly can now update their code to remove the escape handling and let us do it for them. Mutating values with escapes - When you make an update to a node property that has escape handling The value is assumed to be unescaped, and any special characters are escaped automatically and the corresponding raws value is immediately updated. This can result in changes to the original escape format. Where the exact value of the escape sequence is important there are methods that allow both values to be set in conjunction. There are a number of new convenience methods for manipulating values that involve escapes, especially for attributes values where the quote mark is involved. See https://github.com/postcss/postcss-selector-parser/pull/133 for an extensive write-up on these changes. Upgrade/API Example In 3.x there was no unescape handling and internal consistency of several properties was the caller's job to maintain. It was very easy for the developer to create a CSS file that did not parse correctly when some types of values were in use. const selectorParser = require(\"postcss-selector-parser\"); let attr = selectorParser.attribute({attribute: \"id\", operator: \"=\", value: \"a-value\"}); attr.value; // => \"a-value\" attr.toString(); // => [id=a-value] // Add quotes to an attribute's value. // All these values have to be set by the caller to be consistent: // no internal consistency is maintained. attr.raws.unquoted = attr.value attr.value = \"'\" + attr.value + \"'\"; attr.value; // => \"'a-value'\" attr.quoted = true; attr.toString(); // => \"[id='a-value']\" In 4.0 there is a convenient API for setting and mutating values that may need escaping. Especially for attributes. const selectorParser = require(\"postcss-selector-parser\"); // The constructor requires you specify the exact escape sequence let className = selectorParser.className({value: \"illegal class name\", raws: {value: \"illegal\\\\ class\\\\ name\"}}); className.toString(); // => '.illegal\\\\ class\\\\ name' // So it's better to set the value as a property className = selectorParser.className(); // Most properties that deal with identifiers work like this className.value = \"escape for me\"; className.value; // => 'escape for me' className.toString(); // => '.escape\\\\ for\\\\ me' // emoji and all non-ascii are escaped to ensure it works in every css file. className.value = \"😱🦄😍\"; className.value; // => '😱🦄😍' className.toString(); // => '.\\\\1F631\\\\1F984\\\\1F60D' // you can control the escape sequence if you want, or do bad bad things className.setPropertyAndEscape('value', 'xxxx', 'yyyy'); className.value; // => \"xxxx\" className.toString(); // => \".yyyy\" // Pass a value directly through to the css output without escaping it. className.setPropertyWithoutEscape('value', '$REPLACE_ME$'); className.value; // => \"$REPLACE_ME$\" className.toString(); // => \".$REPLACE_ME$\" // The biggest changes are to the Attribute class // passing quoteMark explicitly is required to avoid a deprecation warning. let attr = selectorParser.attribute({attribute: \"id\", operator: \"=\", value: \"a-value\", quoteMark: null}); attr.toString(); // => \"[id=a-value]\" // Get the value with quotes on it and any necessary escapes. // This is the same as reading attr.value in 3.x. attr.getQuotedValue(); // => \"a-value\"; attr.quoteMark; // => null // Add quotes to an attribute's value. attr.quoteMark = \"'\"; // This is all that's required. attr.toString(); // => \"[id='a-value']\" attr.quoted; // => true // The value is still the same, only the quotes have changed. attr.value; // => a-value attr.getQuotedValue(); // => \"'a-value'\"; // deprecated assignment, no warning because there's no escapes attr.value = \"new-value\"; // no quote mark is needed so it is removed attr.getQuotedValue(); // => \"new-value\"; // deprecated assignment, attr.value = \"\\\"a 'single quoted' value\\\"\"; // > (node:27859) DeprecationWarning: Assigning an attribute a value containing characters that might need to be escaped is deprecated. Call attribute.setValue() instead. attr.getQuotedValue(); // => '\"a \\'single quoted\\' value\"'; // quote mark inferred from first and last characters. attr.quoteMark; // => '\"' // setValue takes options to make manipulating the value simple. attr.setValue('foo', {smart: true}); // foo doesn't require any escapes or quotes. attr.toString(); // => '[id=foo]' attr.quoteMark; // => null // An explicit quote mark can be specified attr.setValue('foo', {quoteMark: '\"'}); attr.toString(); // => '[id=\"foo\"]' // preserves quote mark by default attr.setValue('bar'); attr.toString(); // => '[id=\"bar\"]' attr.quoteMark = null; attr.toString(); // => '[id=bar]' // with no arguments, it preserves quote mark even when it's not a great idea attr.setValue('a value \\n that should be quoted'); attr.toString(); // => '[id=a\\\\ value\\\\ \\\\A\\\\ that\\\\ should\\\\ be\\\\ quoted]' // smart preservation with a specified default attr.setValue('a value \\n that should be quoted', {smart: true, preferCurrentQuoteMark: true, quoteMark: \"'\"}); // => \"[id='a value \\\\A that should be quoted']\" attr.quoteMark = '\"'; // => '[id=\"a value \\\\A that should be quoted\"]' // this keeps double quotes because it wants to quote the value and the existing value has double quotes. attr.setValue('this should be quoted', {smart: true, preferCurrentQuoteMark: true, quoteMark: \"'\"}); // => '[id=\"this should be quoted\"]' // picks single quotes because the value has double quotes attr.setValue('a \"double quoted\" value', {smart: true, preferCurrentQuoteMark: true, quoteMark: \"'\"}); // => \"[id='a \"double quoted\" value']\" // setPropertyAndEscape lets you do anything you want. Even things that are a bad idea and illegal. attr.setPropertyAndEscape('value', 'xxxx', 'the password is 42'); attr.value; // => \"xxxx\" attr.toString(); // => \"[id=the password is 42]\" // Pass a value directly through to the css output without escaping it. attr.setPropertyWithoutEscape('value', '$REPLACEMENT$'); attr.value; // => \"$REPLACEMENT$\" attr.toString(); // => \"[id=$REPLACEMENT$]\" 3.1.2 Fix: Removed dot-prop dependency since it's no longer written in es5. 3.1.1 Fix: typescript definitions weren't in the published package. 3.1.0 Fixed numerous bugs in attribute nodes relating to the handling of comments and whitespace. There's significant changes to attrNode.spaces and attrNode.raws since the 3.0.0 release. Added Attribute#offsetOf(part) to get the offset location of attribute parts like \"operator\" and \"value\". This is most often added to Attribute#sourceIndex for error reporting. 3.0.0 Breaking changes Some tweaks to the tokenizer/attribute selector parsing mean that whitespace locations might be slightly different to the 2.x code. Better attribute selector parsing with more validation; postcss-selector-parser no longer uses regular expressions to parse attribute selectors. Added an async API (thanks to @jacobp100); the default process API is now async, and the sync API is now accessed through processSync instead. process() and processSync() now return a string instead of the Processor instance. Tweaks handling of Less interpolation (thanks to @jwilsson). Removes support for Node 0.12. Other changes ast() and astSync() methods have been added to the Processor. These return the Root node of the selectors after processing them. transform() and transformSync() methods have been added to the Processor. These return the value returned by the processor callback after processing the selectors. Set the parent when inserting a node (thanks to @chriseppstein). Correctly adjust indices when using insertBefore/insertAfter (thanks to @tivac). Fixes handling of namespaces with qualified tag selectors. process, ast and transform (and their sync variants) now accept a postcss rule node. When provided, better errors are generated and selector processing is automatically set back to the rule selector (unless the updateSelector option is set to false.) Now more memory efficient when tokenizing selectors. Upgrade hints The pattern of: rule.selector = processor.process(rule.selector).result.toString(); is now: processor.processSync(rule) 2.2.3 Resolves an issue where the parser would not reduce multiple spaces between an ampersand and another simple selector in lossy mode (thanks to @adam-26). 2.2.2 No longer hangs on an unescaped semicolon; instead the parser will throw an exception for these cases. 2.2.1 Allows a consumer to specify whitespace tokens when creating a new Node (thanks to @Semigradsky). 2.2.0 Added a new option to normalize whitespace when parsing the selector string (thanks to @adam-26). 2.1.1 Better unquoted value handling within attribute selectors (thanks to @evilebottnawi). 2.1.0 Added: Use string constants for all node types & expose them on the main parser instance (thanks to @Aweary). # 2.0.0 This release contains the following breaking changes: Renamed all eachInside iterators to walk. For example, eachTag is now walkTags, and eachInside is now walk. Renamed Node#removeSelf() to Node#remove(). Renamed Container#remove() to Container#removeChild(). Renamed Node#raw to Node#raws (thanks to @davidtheclark). Now parses & as the nesting selector, rather than a tag selector. Fixes misinterpretation of Sass interpolation (e.g. #{foo}) as an id selector (thanks to @davidtheclark). and; Fixes parsing of attribute selectors with equals signs in them (e.g. [data-attr=\"foo=bar\"]) (thanks to @montmanu). Adds quoted and raw.unquoted properties to attribute nodes (thanks to @davidtheclark). 1.3.3 Fixes an infinite loop on ) and ] tokens when they had no opening pairs. Now postcss-selector-parser will throw when it encounters these lone tokens. # 1.3.2 Now uses plain integers rather than str.charCodeAt(0) for compiled builds. 1.3.1 Update flatten to v1.x (thanks to @shinnn). 1.3.0 Adds a new node type, String, to fix a crash on selectors such as foo:bar(\"test\"). 1.2.1 Fixes a crash when the parser encountered a trailing combinator. 1.2.0 A more descriptive error is thrown when the parser expects to find a pseudo-class/pseudo-element (thanks to @ashelley). Adds support for line/column locations for selector nodes, as well as a Node#sourceIndex method (thanks to @davidtheclark). 1.1.4 Fixes a crash when a selector started with a > combinator. The module will now no longer throw if a selector has a leading/trailing combinator node. 1.1.3 Fixes a crash on @ tokens. 1.1.2 Fixes an infinite loop caused by using parentheses in a non-pseudo element context. 1.1.1 Fixes a crash when a backslash ended a selector string. 1.1.0 Adds support for replacing multiple nodes at once with replaceWith (thanks to @jonathantneal). Parser no longer throws on sequential IDs and trailing commas, to support parsing of selector hacks. 1.0.1 Fixes using insertAfter and insertBefore during iteration. 1.0.0 Adds clone and replaceWith methods to nodes. Adds insertBefore and insertAfter to containers. Stabilises API. 0.0.5 Fixes crash on extra whitespace inside a pseudo selector's parentheses. Adds sort function to the container class. Enables the parser to pass its input through without transforming. Iteration-safe each and eachInside. 0.0.4 Tidy up redundant duplication. Fixes a bug where the parser would loop infinitely on universal selectors inside pseudo selectors. Adds length getter and eachInside, map, reduce to the container class. When a selector has been removed from the tree, the root node will no longer cast it to a string. Adds node type iterators to the container class (e.g. eachComment). Adds filter function to the container class. Adds split function to the container class. Create new node types by doing parser.id(opts) etc. Adds support for pseudo classes anywhere in the selector. 0.0.3 Adds next and prev to the node class. Adds first and last getters to the container class. Adds every and some iterators to the container class. Add empty alias for removeAll. Combinators are now types of node. Fixes the at method so that it is not an alias for index. Tidy up creation of new nodes in the parser. Refactors how namespaces are handled for consistency & less redundant code. Refactors AST to use nodes exclusively, and eliminates excessive nesting. Fixes nested pseudo parsing. Fixes whitespace parsing. 0.0.2 Adds support for namespace selectors. Adds support for selectors joined by escaped spaces - such as .\\31\\ 0. 0.0.1 Initial release."
  },
  "node_modules/postcss-selector-parser/README.html": {
    "href": "node_modules/postcss-selector-parser/README.html",
    "title": "postcss-selector-parser | accouter",
    "keywords": "postcss-selector-parser Selector parser with built in methods for working with selector strings. Install With npm do: npm install postcss-selector-parser Quick Start const parser = require('postcss-selector-parser'); const transform = selectors => { selectors.walk(selector => { // do something with the selector console.log(String(selector)) }); }; const transformed = parser(transform).processSync('h1, h2, h3'); To normalize selector whitespace: const parser = require('postcss-selector-parser'); const normalized = parser().processSync('h1, h2, h3', {lossless: false}); // -> h1,h2,h3 Async support is provided through parser.process and will resolve a Promise with the resulting selector string. API Please see API.md. Credits Huge thanks to Andrey Sitnik (@ai) for work on PostCSS which helped accelerate this module's development. License MIT"
  },
  "node_modules/postcss-svgo/README.html": {
    "href": "node_modules/postcss-svgo/README.html",
    "title": "postcss-svgo | accouter",
    "keywords": "postcss-svgo Optimise inline SVG with PostCSS. Install With npm do: npm install postcss-svgo --save Example Input h1 { background: url('data:image/svg+xml;charset=utf-8,<?xml version=\"1.0\" encoding=\"utf-8\"?><!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"><svg version=\"1.1\" id=\"Layer_1\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:space=\"preserve\"><circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"yellow\" /></svg>'); } h2 { background: url('data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz48IURPQ1RZUEUgc3ZnIFBVQkxJQyAiLS8vVzNDLy9EVEQgU1ZHIDEuMS8vRU4iICJodHRwOi8vd3d3LnczLm9yZy9HcmFwaGljcy9TVkcvMS4xL0RURC9zdmcxMS5kdGQiPjxzdmcgdmVyc2lvbj0iMS4xIiBpZD0iTGF5ZXJfMSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayIgeG1sOnNwYWNlPSJwcmVzZXJ2ZSI+PGNpcmNsZSBjeD0iNTAiIGN5PSI1MCIgcj0iNDAiIGZpbGw9InllbGxvdyIgLz48IS0tdGVzdCBjb21tZW50LS0+PC9zdmc+'); } Output h1 { background: url('data:image/svg+xml;charset=utf-8,<svg xmlns=\"http://www.w3.org/2000/svg\"><circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"%23ff0\"/></svg>'); } h2 { background: url('data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciPjxjaXJjbGUgY3g9IjUwIiBjeT0iNTAiIHI9IjQwIiBmaWxsPSIjZmYwIi8+PC9zdmc+'); } API svgo([options]) options encode Type: boolean Default: undefined If true, it will encode URL-unsafe characters such as <, > and &; false will decode these characters, and undefined will neither encode nor decode the original input. Note that regardless of this setting, # will always be URL-encoded. plugins Optionally, you can customise the output by specifying the plugins option. You will need to provide the config in comma separated objects, like the example below. Note that you can either disable the plugin by setting it to false, or pass different options to change the default behaviour. const postcss = require('postcss'); const svgo = require('postcss-svgo'); const opts = { plugins: [{ name: 'preset-default', params: { overrides: { removeViewBox: false, removeComments: false, cleanupNumericValues: { floatPrecision: 2 } } } }] }; postcss([ svgo(opts) ]).process(css).then((result) => { console.log(result.css) }); You can view the full list of plugins here. Usage See the PostCSS documentation for examples for your environment. Contributors See CONTRIBUTORS.md. License MIT © Ben Briggs"
  },
  "node_modules/postcss-unique-selectors/README.html": {
    "href": "node_modules/postcss-unique-selectors/README.html",
    "title": "postcss-unique-selectors | accouter",
    "keywords": "postcss-unique-selectors Ensure CSS selectors are unique. Install With npm do: npm install postcss-unique-selectors --save Example Selectors are sorted naturally, and deduplicated: Input h1,h3,h2,h1 { color: red } Output h1,h2,h3 { color: red } Usage See the PostCSS documentation for examples for your environment. Contributors See CONTRIBUTORS.md. License MIT © Ben Briggs"
  },
  "node_modules/postcss-value-parser/README.html": {
    "href": "node_modules/postcss-value-parser/README.html",
    "title": "postcss-value-parser | accouter",
    "keywords": "postcss-value-parser Transforms CSS declaration values and at-rule parameters into a tree of nodes, and provides a simple traversal API. Usage var valueParser = require('postcss-value-parser'); var cssBackgroundValue = 'url(foo.png) no-repeat 40px 73%'; var parsedValue = valueParser(cssBackgroundValue); // parsedValue exposes an API described below, // e.g. parsedValue.walk(..), parsedValue.toString(), etc. For example, parsing the value rgba(233, 45, 66, .5) will return the following: { nodes: [ { type: 'function', value: 'rgba', before: '', after: '', nodes: [ { type: 'word', value: '233' }, { type: 'div', value: ',', before: '', after: ' ' }, { type: 'word', value: '45' }, { type: 'div', value: ',', before: '', after: ' ' }, { type: 'word', value: '66' }, { type: 'div', value: ',', before: ' ', after: '' }, { type: 'word', value: '.5' } ] } ] } If you wanted to convert each rgba() value in sourceCSS to a hex value, you could do so like this: var valueParser = require('postcss-value-parser'); var parsed = valueParser(sourceCSS); // walk() will visit all the of the nodes in the tree, // invoking the callback for each. parsed.walk(function (node) { // Since we only want to transform rgba() values, // we can ignore anything else. if (node.type !== 'function' && node.value !== 'rgba') return; // We can make an array of the rgba() arguments to feed to a // convertToHex() function var color = node.nodes.filter(function (node) { return node.type === 'word'; }).map(function (node) { return Number(node.value); }); // [233, 45, 66, .5] // Now we will transform the existing rgba() function node // into a word node with the hex value node.type = 'word'; node.value = convertToHex(color); }) parsed.toString(); // #E92D42 Nodes Each node is an object with these common properties: type: The type of node (word, string, div, space, comment, or function). Each type is documented below. value: Each node has a value property; but what exactly value means is specific to the node type. Details are documented for each type below. sourceIndex: The starting index of the node within the original source string. For example, given the source string 10px 20px, the word node whose value is 20px will have a sourceIndex of 5. word The catch-all node type that includes keywords (e.g. no-repeat), quantities (e.g. 20px, 75%, 1.5), and hex colors (e.g. #e6e6e6). Node-specific properties: value: The \"word\" itself. string A quoted string value, e.g. \"something\" in content: \"something\";. Node-specific properties: value: The text content of the string. quote: The quotation mark surrounding the string, either \" or '. unclosed: true if the string was not closed properly. e.g. \"unclosed string . div A divider, for example , in animation-duration: 1s, 2s, 3s / in border-radius: 10px / 23px : in (min-width: 700px) Node-specific properties: value: The divider character. Either ,, /, or : (see examples above). before: Whitespace before the divider. after: Whitespace after the divider. space Whitespace used as a separator, e.g. occurring twice in border: 1px solid black;. Node-specific properties: value: The whitespace itself. comment A CSS comment starts with /* and ends with */ Node-specific properties: value: The comment value without /* and */ unclosed: true if the comment was not closed properly. e.g. /* comment without an end . function A CSS function, e.g. rgb(0,0,0) or url(foo.bar). Function nodes have nodes nested within them: the function arguments. Additional properties: value: The name of the function, e.g. rgb in rgb(0,0,0). before: Whitespace after the opening parenthesis and before the first argument, e.g. in rgb( 0,0,0). after: Whitespace before the closing parenthesis and after the last argument, e.g. in rgb(0,0,0 ). nodes: More nodes representing the arguments to the function. unclosed: true if the parentheses was not closed properly. e.g. ( unclosed-function . Media features surrounded by parentheses are considered functions with an empty value. For example, (min-width: 700px) parses to these nodes: [ { type: 'function', value: '', before: '', after: '', nodes: [ { type: 'word', value: 'min-width' }, { type: 'div', value: ':', before: '', after: ' ' }, { type: 'word', value: '700px' } ] } ] url() functions can be parsed a little bit differently depending on whether the first character in the argument is a quotation mark. url( /gfx/img/bg.jpg ) parses to: { type: 'function', sourceIndex: 0, value: 'url', before: ' ', after: ' ', nodes: [ { type: 'word', sourceIndex: 5, value: '/gfx/img/bg.jpg' } ] } url( \"/gfx/img/bg.jpg\" ), on the other hand, parses to: { type: 'function', sourceIndex: 0, value: 'url', before: ' ', after: ' ', nodes: [ type: 'string', sourceIndex: 5, quote: '\"', value: '/gfx/img/bg.jpg' }, ] } unicode-range The unicode-range CSS descriptor sets the specific range of characters to be used from a font defined by @font-face and made available for use on the current page (unicode-range: U+0025-00FF). Node-specific properties: value: The \"unicode-range\" itself. API var valueParser = require('postcss-value-parser'); valueParser.unit(quantity) Parses quantity, distinguishing the number from the unit. Returns an object like the following: // Given 2rem { number: '2', unit: 'rem' } If the quantity argument cannot be parsed as a number, returns false. This function does not parse complete values: you cannot pass it 1px solid black and expect px as the unit. Instead, you should pass it single quantities only. Parse 1px solid black, then pass it the stringified 1px node (a word node) to parse the number and unit. valueParser.stringify(nodes[, custom]) Stringifies a node or array of nodes. The custom function is called for each node; return a string to override the default behaviour. valueParser.walk(nodes, callback[, bubble]) Walks each provided node, recursively walking all descendent nodes within functions. Returning false in the callback will prevent traversal of descendent nodes (within functions). You can use this feature to for shallow iteration, walking over only the immediate children. Note: This only applies if bubble is false (which is the default). By default, the tree is walked from the outermost node inwards. To reverse the direction, pass true for the bubble argument. The callback is invoked with three arguments: callback(node, index, nodes). node: The current node. index: The index of the current node. nodes: The complete nodes array passed to walk(). Returns the valueParser instance. var parsed = valueParser(value) Returns the parsed node tree. parsed.nodes The array of nodes. parsed.toString() Stringifies the node tree. parsed.walk(callback[, bubble]) Walks each node inside parsed.nodes. See the documentation for valueParser.walk() above. License MIT © Bogdan Chadkin"
  },
  "node_modules/postcss/README.html": {
    "href": "node_modules/postcss/README.html",
    "title": "PostCSS | accouter",
    "keywords": "PostCSS PostCSS is a tool for transforming styles with JS plugins. These plugins can lint your CSS, support variables and mixins, transpile future CSS syntax, inline images, and more. PostCSS is used by industry leaders including Wikipedia, Twitter, Alibaba, and JetBrains. The Autoprefixer and Stylelint PostCSS plugins is one of the most popular CSS tools. Made in Evil Martians, product consulting for developer tools. Docs Read full docs here."
  },
  "node_modules/prettier/README.html": {
    "href": "node_modules/prettier/README.html",
    "title": "| accouter",
    "keywords": "Opinionated Code Formatter JavaScript · TypeScript · Flow · JSX · JSON CSS · SCSS · Less HTML · Vue · Angular GraphQL · Markdown · YAML Your favorite language? Intro Prettier is an opinionated code formatter. It enforces a consistent style by parsing your code and re-printing it with its own rules that take the maximum line length into account, wrapping code when necessary. Input foo(reallyLongArg(), omgSoManyParameters(), IShouldRefactorThis(), isThereSeriouslyAnotherOne()); Output foo( reallyLongArg(), omgSoManyParameters(), IShouldRefactorThis(), isThereSeriouslyAnotherOne(), ); Prettier can be run in your editor on-save, in a pre-commit hook, or in CI environments to ensure your codebase has a consistent style without devs ever having to post a nit-picky comment on a code review ever again! Documentation Install · Options · CLI · API Playground Badge Show the world you're using Prettier → [![code style: prettier](https://img.shields.io/badge/code_style-prettier-ff69b4.svg?style=flat-square)](https://github.com/prettier/prettier) Contributing See CONTRIBUTING.md."
  },
  "node_modules/pretty-format/README.html": {
    "href": "node_modules/pretty-format/README.html",
    "title": "pretty-format | accouter",
    "keywords": "pretty-format Stringify any JavaScript value. Serialize built-in JavaScript types. Serialize application-specific data types with built-in or user-defined plugins. Installation $ yarn add pretty-format Usage const {format: prettyFormat} = require('pretty-format'); // CommonJS import {format as prettyFormat} from 'pretty-format'; // ES2015 modules const val = {object: {}}; val.circularReference = val; val[Symbol('foo')] = 'foo'; val.map = new Map([['prop', 'value']]); val.array = [-0, Infinity, NaN]; console.log(prettyFormat(val)); /* Object { \"array\": Array [ -0, Infinity, NaN, ], \"circularReference\": [Circular], \"map\": Map { \"prop\" => \"value\", }, \"object\": Object {}, Symbol(foo): \"foo\", } */ Usage with options function onClick() {} console.log(prettyFormat(onClick)); /* [Function onClick] */ const options = { printFunctionName: false, }; console.log(prettyFormat(onClick, options)); /* [Function] */ key type default description callToJSON boolean true call toJSON method (if it exists) on objects compareKeys function\\|null undefined compare function used when sorting object keys, null can be used to skip over sorting escapeRegex boolean false escape special characters in regular expressions escapeString boolean true escape special characters in strings highlight boolean false highlight syntax with colors in terminal (some plugins) indent number 2 spaces in each level of indentation maxDepth number Infinity levels to print in arrays, objects, elements, and so on maxWidth number Infinity number of elements to print in arrays, sets, and so on min boolean false minimize added space: no indentation nor line breaks plugins array [] plugins to serialize application-specific data types printBasicPrototype boolean false print the prototype for plain objects and arrays printFunctionName boolean true include or omit the name of a function theme object colors to highlight syntax in terminal Property values of theme are from ansi-styles colors const DEFAULT_THEME = { comment: 'gray', content: 'reset', prop: 'yellow', tag: 'cyan', value: 'green', }; Usage with plugins The pretty-format package provides some built-in plugins, including: ReactElement for elements from react ReactTestComponent for test objects from react-test-renderer // CommonJS const React = require('react'); const renderer = require('react-test-renderer'); const {format: prettyFormat, plugins} = require('pretty-format'); const {ReactElement, ReactTestComponent} = plugins; // ES2015 modules and destructuring assignment import React from 'react'; import renderer from 'react-test-renderer'; import {plugins, format as prettyFormat} from 'pretty-format'; const {ReactElement, ReactTestComponent} = plugins; const onClick = () => {}; const element = React.createElement('button', {onClick}, 'Hello World'); const formatted1 = prettyFormat(element, { plugins: [ReactElement], printFunctionName: false, }); const formatted2 = prettyFormat(renderer.create(element).toJSON(), { plugins: [ReactTestComponent], printFunctionName: false, }); /* <button onClick=[Function] > Hello World </button> */ Usage in Jest For snapshot tests, Jest uses pretty-format with options that include some of its built-in plugins. For this purpose, plugins are also known as snapshot serializers. To serialize application-specific data types, you can add modules to devDependencies of a project, and then: In an individual test file, you can add a module as follows. It precedes any modules from Jest configuration. import serializer from 'my-serializer-module'; expect.addSnapshotSerializer(serializer); // tests which have `expect(value).toMatchSnapshot()` assertions For all test files, you can specify modules in Jest configuration. They precede built-in plugins for React, HTML, and Immutable.js data types. For example, in a package.json file: { \"jest\": { \"snapshotSerializers\": [\"my-serializer-module\"] } } Writing plugins A plugin is a JavaScript object. If options has a plugins array: for the first plugin whose test(val) method returns a truthy value, then prettyFormat(val, options) returns the result from either: serialize(val, …) method of the improved interface (available in version 21 or later) print(val, …) method of the original interface (if plugin does not have serialize method) test Write test so it can receive val argument of any type. To serialize objects which have certain properties, then a guarded expression like val != null && … or more concise val && … prevents the following errors: TypeError: Cannot read property 'whatever' of null TypeError: Cannot read property 'whatever' of undefined For example, test method of built-in ReactElement plugin: const elementSymbol = Symbol.for('react.element'); const test = val => val && val.$$typeof === elementSymbol; Pay attention to efficiency in test because pretty-format calls it often. serialize The improved interface is available in version 21 or later. Write serialize to return a string, given the arguments: val which “passed the test” unchanging config object: derived from options current indentation string: concatenate to indent from config current depth number: compare to maxDepth from config current refs array: find circular references in objects printer callback function: serialize children config key type description callToJSON boolean call toJSON method (if it exists) on objects compareKeys function\\|null compare function used when sorting object keys, null can be used to skip over sorting colors Object escape codes for colors to highlight syntax escapeRegex boolean escape special characters in regular expressions escapeString boolean escape special characters in strings indent string spaces in each level of indentation maxDepth number levels to print in arrays, objects, elements, and so on min boolean minimize added space: no indentation nor line breaks plugins array plugins to serialize application-specific data types printFunctionName boolean include or omit the name of a function spacingInner string spacing to separate items in a list spacingOuter string spacing to enclose a list of items Each property of colors in config corresponds to a property of theme in options: the key is the same (for example, tag) the value in colors is a object with open and close properties whose values are escape codes from ansi-styles for the color value in theme (for example, 'cyan') Some properties in config are derived from min in options: spacingInner and spacingOuter are newline if min is false spacingInner is space and spacingOuter is empty string if min is true Example of serialize and test This plugin is a pattern you can apply to serialize composite data types. Side note: pretty-format does not need a plugin to serialize arrays. // We reused more code when we factored out a function for child items // that is independent of depth, name, and enclosing punctuation (see below). const SEPARATOR = ','; function serializeItems(items, config, indentation, depth, refs, printer) { if (items.length === 0) { return ''; } const indentationItems = indentation + config.indent; return ( config.spacingOuter + items .map( item => indentationItems + printer(item, config, indentationItems, depth, refs), // callback ) .join(SEPARATOR + config.spacingInner) + (config.min ? '' : SEPARATOR) + // following the last item config.spacingOuter + indentation ); } const plugin = { test(val) { return Array.isArray(val); }, serialize(array, config, indentation, depth, refs, printer) { const name = array.constructor.name; return ++depth > config.maxDepth ? `[${name}]` : `${config.min ? '' : `${name} `}[${serializeItems( array, config, indentation, depth, refs, printer, )}]`; }, }; const val = { filter: 'completed', items: [ { text: 'Write test', completed: true, }, { text: 'Write serialize', completed: true, }, ], }; console.log( prettyFormat(val, { plugins: [plugin], }), ); /* Object { \"filter\": \"completed\", \"items\": Array [ Object { \"completed\": true, \"text\": \"Write test\", }, Object { \"completed\": true, \"text\": \"Write serialize\", }, ], } */ console.log( prettyFormat(val, { indent: 4, plugins: [plugin], }), ); /* Object { \"filter\": \"completed\", \"items\": Array [ Object { \"completed\": true, \"text\": \"Write test\", }, Object { \"completed\": true, \"text\": \"Write serialize\", }, ], } */ console.log( prettyFormat(val, { maxDepth: 1, plugins: [plugin], }), ); /* Object { \"filter\": \"completed\", \"items\": [Array], } */ console.log( prettyFormat(val, { min: true, plugins: [plugin], }), ); /* {\"filter\": \"completed\", \"items\": [{\"completed\": true, \"text\": \"Write test\"}, {\"completed\": true, \"text\": \"Write serialize\"}]} */ print The original interface is adequate for plugins: that do not depend on options other than highlight or min that do not depend on depth or refs in recursive traversal, and if values either do not require indentation, or do not occur as children of JavaScript data structures (for example, array) Write print to return a string, given the arguments: val which “passed the test” current printer(valChild) callback function: serialize children current indenter(lines) callback function: indent lines at the next level unchanging config object: derived from options unchanging colors object: derived from options The 3 properties of config are min in options and: spacing and edgeSpacing are newline if min is false spacing is space and edgeSpacing is empty string if min is true Each property of colors corresponds to a property of theme in options: the key is the same (for example, tag) the value in colors is a object with open and close properties whose values are escape codes from ansi-styles for the color value in theme (for example, 'cyan') Example of print and test This plugin prints functions with the number of named arguments excluding rest argument. const plugin = { print(val) { return `[Function ${val.name || 'anonymous'} ${val.length}]`; }, test(val) { return typeof val === 'function'; }, }; const val = { onClick(event) {}, render() {}, }; prettyFormat(val, { plugins: [plugin], }); /* Object { \"onClick\": [Function onClick 1], \"render\": [Function render 0], } */ prettyFormat(val); /* Object { \"onClick\": [Function onClick], \"render\": [Function render], } */ This plugin ignores the printFunctionName option. That limitation of the original print interface is a reason to use the improved serialize interface, described above. prettyFormat(val, { plugins: [pluginOld], printFunctionName: false, }); /* Object { \"onClick\": [Function onClick 1], \"render\": [Function render 0], } */ prettyFormat(val, { printFunctionName: false, }); /* Object { \"onClick\": [Function], \"render\": [Function], } */"
  },
  "node_modules/pretty-format/node_modules/ansi-styles/readme.html": {
    "href": "node_modules/pretty-format/node_modules/ansi-styles/readme.html",
    "title": "ansi-styles | accouter",
    "keywords": "ansi-styles ANSI escape codes for styling strings in the terminal You probably want the higher-level chalk module for styling your strings. Install $ npm install ansi-styles Usage const style = require('ansi-styles'); console.log(`${style.green.open}Hello world!${style.green.close}`); // Color conversion between 256/truecolor // NOTE: When converting from truecolor to 256 colors, the original color // may be degraded to fit the new color palette. This means terminals // that do not support 16 million colors will best-match the // original color. console.log(`${style.color.ansi256(style.rgbToAnsi256(199, 20, 250))}Hello World${style.color.close}`) console.log(`${style.color.ansi16m(...style.hexToRgb('#abcdef'))}Hello World${style.color.close}`) API Each style has an open and close property. Styles Modifiers reset bold dim italic (Not widely supported) underline overline Supported on VTE-based terminals, the GNOME terminal, mintty, and Git Bash. inverse hidden strikethrough (Not widely supported) Colors black red green yellow blue magenta cyan white blackBright (alias: gray, grey) redBright greenBright yellowBright blueBright magentaBright cyanBright whiteBright Background colors bgBlack bgRed bgGreen bgYellow bgBlue bgMagenta bgCyan bgWhite bgBlackBright (alias: bgGray, bgGrey) bgRedBright bgGreenBright bgYellowBright bgBlueBright bgMagentaBright bgCyanBright bgWhiteBright Advanced usage By default, you get a map of styles, but the styles are also available as groups. They are non-enumerable so they don't show up unless you access them explicitly. This makes it easier to expose only a subset in a higher-level module. style.modifier style.color style.bgColor Example console.log(style.color.green.open); Raw escape codes (i.e. without the CSI escape prefix \\u001B[ and render mode postfix m) are available under style.codes, which returns a Map with the open codes as keys and close codes as values. Example console.log(style.codes.get(36)); //=> 39 256 / 16 million (TrueColor) support ansi-styles allows converting between various color formats and ANSI escapes, with support for 256 and 16 million colors. The following color spaces from color-convert are supported: rgb hex ansi256 To use these, call the associated conversion function with the intended output, for example: style.color.ansi256(style.rgbToAnsi256(100, 200, 15)); // RGB to 256 color ansi foreground code style.bgColor.ansi256(style.hexToAnsi256('#C0FFEE')); // HEX to 256 color ansi foreground code style.color.ansi16m(100, 200, 15); // RGB to 16 million color foreground code style.bgColor.ansi16m(...style.hexToRgb('#C0FFEE')); // Hex (RGB) to 16 million color foreground code Related ansi-escapes - ANSI escape codes for manipulating the terminal Maintainers Sindre Sorhus Josh Junon For enterprise Available as part of the Tidelift Subscription. The maintainers of ansi-styles and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more."
  },
  "node_modules/pretty-hrtime/README.html": {
    "href": "node_modules/pretty-hrtime/README.html",
    "title": "pretty-hrtime | accouter",
    "keywords": "pretty-hrtime process.hrtime() to words Usage var prettyHrtime = require('pretty-hrtime'); var start = process.hrtime(); // do stuff var end = process.hrtime(start); var words = prettyHrtime(end); console.log(words); // '1.2 ms' words = prettyHrtime(end, {verbose:true}); console.log(words); // '1 millisecond 209 microseconds' words = prettyHrtime(end, {precise:true}); console.log(words); // '1.20958 ms' Note: process.hrtime() has been available since 0.7.6. See http://nodejs.org/changelog.html and https://github.com/joyent/node/commit/f06abd. LICENSE (MIT License) Copyright (c) 2013 Richardson & Sons, LLC Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/pstree.remy/README.html": {
    "href": "node_modules/pstree.remy/README.html",
    "title": "pstree.remy | accouter",
    "keywords": "pstree.remy Cross platform ps-tree (including unix flavours without ps) Installation npm install pstree.remy Usage const psTree = psTree require('pstree.remy'); psTree(PID, (err, pids) => { if (err) { console.error(err); } console.log(pids) }); console.log(psTree.hasPS ? \"This platform has the ps shell command\" : \"This platform does not have the ps shell command\");"
  },
  "node_modules/queue-microtask/README.html": {
    "href": "node_modules/queue-microtask/README.html",
    "title": "queue-microtask | accouter",
    "keywords": "queue-microtask fast, tiny queueMicrotask shim for modern engines Use queueMicrotask in all modern JS engines. No dependencies. Less than 10 lines. No shims or complicated fallbacks. Optimal performance in all modern environments Uses queueMicrotask in modern environments Fallback to Promise.resolve().then(fn) in Node.js 10 and earlier, and old browsers (same performance as queueMicrotask) install npm install queue-microtask usage const queueMicrotask = require('queue-microtask') queueMicrotask(() => { /* this will run soon */ }) What is queueMicrotask and why would one use it? The queueMicrotask function is a WHATWG standard. It queues a microtask to be executed prior to control returning to the event loop. A microtask is a short function which will run after the current task has completed its work and when there is no other code waiting to be run before control of the execution context is returned to the event loop. The code queueMicrotask(fn) is equivalent to the code Promise.resolve().then(fn). It is also very similar to process.nextTick(fn) in Node. Using microtasks lets code run without interfering with any other, potentially higher priority, code that is pending, but before the JS engine regains control over the execution context. See the spec or Node documentation for more information. Who is this package for? This package allows you to use queueMicrotask safely in all modern JS engines. Use it if you prioritize small JS bundle size over support for old browsers. If you just need to support Node 12 and later, use queueMicrotask directly. If you need to support all versions of Node, use this package. Why not use process.nextTick? In Node, queueMicrotask and process.nextTick are essentially equivalent, though there are subtle differences that don't matter in most situations. You can think of queueMicrotask as a standardized version of process.nextTick that works in the browser. No need to rely on your browser bundler to shim process for the browser environment. Why not use setTimeout(fn, 0)? This approach is the most compatible, but it has problems. Modern browsers throttle timers severely, so setTimeout(…, 0) usually takes at least 4ms to run. Furthermore, the throttling gets even worse if the page is backgrounded. If you have many setTimeout calls, then this can severely limit the performance of your program. Why not use a microtask library like immediate or asap? These packages are great! However, if you prioritize small JS bundle size over optimal performance in old browsers then you may want to consider this package. This package (queue-microtask) is four times smaller than immediate, twice as small as asap, and twice as small as using process.nextTick and letting the browser bundler shim it automatically. Note: This package throws an exception in JS environments which lack Promise support -- which are usually very old browsers and Node.js versions. Since the queueMicrotask API is supported in Node.js, Chrome, Firefox, Safari, Opera, and Edge, the vast majority of users will get optimal performance. Any JS environment with Promise, which is almost all of them, also get optimal performance. If you need support for JS environments which lack Promise support, use one of the alternative packages. What is a shim? In computer programming, a shim is a library that transparently intercepts API calls and changes the arguments passed, handles the operation itself or redirects the operation elsewhere. – Wikipedia This package could also be described as a \"ponyfill\". A ponyfill is almost the same as a polyfill, but not quite. Instead of patching functionality for older browsers, a ponyfill provides that functionality as a standalone module you can use. – PonyFoo API queueMicrotask(fn) The queueMicrotask() method queues a microtask. The fn argument is a function to be executed after all pending tasks have completed but before yielding control to the browser's event loop. license MIT. Copyright (c) Feross Aboukhadijeh."
  },
  "node_modules/randombytes/README.html": {
    "href": "node_modules/randombytes/README.html",
    "title": "randombytes | accouter",
    "keywords": "randombytes randombytes from node that works in the browser. In node you just get crypto.randomBytes, but in the browser it uses .crypto/msCrypto.getRandomValues var randomBytes = require('randombytes'); randomBytes(16);//get 16 random bytes randomBytes(16, function (err, resp) { // resp is 16 random bytes });"
  },
  "node_modules/range-parser/HISTORY.html": {
    "href": "node_modules/range-parser/HISTORY.html",
    "title": "1.2.1 / 2019-05-10 | accouter",
    "keywords": "1.2.1 / 2019-05-10 Improve error when str is not a string 1.2.0 / 2016-06-01 Add combine option to combine overlapping ranges 1.1.0 / 2016-05-13 Fix incorrectly returning -1 when there is at least one valid range perf: remove internal function 1.0.3 / 2015-10-29 perf: enable strict mode 1.0.2 / 2014-09-08 Support Node.js 0.6 1.0.1 / 2014-09-07 Move repository to jshttp 1.0.0 / 2013-12-11 Add repository to package.json Add MIT license 0.0.4 / 2012-06-17 Change ret -1 for unsatisfiable and -2 when invalid 0.0.3 / 2012-06-17 Fix last-byte-pos default to len - 1 0.0.2 / 2012-06-14 Add .type 0.0.1 / 2012-06-11 Initial release"
  },
  "node_modules/range-parser/README.html": {
    "href": "node_modules/range-parser/README.html",
    "title": "range-parser | accouter",
    "keywords": "range-parser Range header field parser. Installation This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install range-parser API var parseRange = require('range-parser') parseRange(size, header, options) Parse the given header string where size is the maximum size of the resource. An array of ranges will be returned or negative numbers indicating an error parsing. -2 signals a malformed header string -1 signals an unsatisfiable range // parse header from request var range = parseRange(size, req.headers.range) // the type of the range if (range.type === 'bytes') { // the ranges range.forEach(function (r) { // do something with r.start and r.end }) } Options These properties are accepted in the options object. combine Specifies if overlapping & adjacent ranges should be combined, defaults to false. When true, ranges will be combined and returned as if they were specified that way in the header. parseRange(100, 'bytes=50-55,0-10,5-10,56-60', { combine: true }) // => [ // { start: 0, end: 10 }, // { start: 50, end: 60 } // ] License MIT"
  },
  "node_modules/raw-body/HISTORY.html": {
    "href": "node_modules/raw-body/HISTORY.html",
    "title": "2.5.2 / 2023-02-21 | accouter",
    "keywords": "2.5.2 / 2023-02-21 Fix error message for non-stream argument 2.5.1 / 2022-02-28 Fix error on early async hooks implementations 2.5.0 / 2022-02-21 Prevent loss of async hooks context Prevent hanging when stream is not readable deps: http-errors@2.0.0 deps: depd@2.0.0 deps: statuses@2.0.1 2.4.3 / 2022-02-14 deps: bytes@3.1.2 2.4.2 / 2021-11-16 deps: bytes@3.1.1 deps: http-errors@1.8.1 deps: setprototypeof@1.2.0 deps: toidentifier@1.0.1 2.4.1 / 2019-06-25 deps: http-errors@1.7.3 deps: inherits@2.0.4 2.4.0 / 2019-04-17 deps: bytes@3.1.0 Add petabyte (pb) support deps: http-errors@1.7.2 Set constructor name when possible deps: setprototypeof@1.1.1 deps: statuses@'>= 1.5.0 < 2' deps: iconv-lite@0.4.24 Added encoding MIK 2.3.3 / 2018-05-08 deps: http-errors@1.6.3 deps: depd@~1.1.2 deps: setprototypeof@1.1.0 deps: statuses@'>= 1.3.1 < 2' deps: iconv-lite@0.4.23 Fix loading encoding with year appended Fix deprecation warnings on Node.js 10+ 2.3.2 / 2017-09-09 deps: iconv-lite@0.4.19 Fix ISO-8859-1 regression Update Windows-1255 2.3.1 / 2017-09-07 deps: bytes@3.0.0 deps: http-errors@1.6.2 deps: depd@1.1.1 perf: skip buffer decoding on overage chunk 2.3.0 / 2017-08-04 Add TypeScript definitions Use http-errors for standard emitted errors deps: bytes@2.5.0 deps: iconv-lite@0.4.18 Add support for React Native Add a warning if not loaded as utf-8 Fix CESU-8 decoding in Node.js 8 Improve speed of ISO-8859-1 encoding 2.2.0 / 2017-01-02 deps: iconv-lite@0.4.15 Added encoding MS-31J Added encoding MS-932 Added encoding MS-936 Added encoding MS-949 Added encoding MS-950 Fix GBK/GB18030 handling of Euro character 2.1.7 / 2016-06-19 deps: bytes@2.4.0 perf: remove double-cleanup on happy path 2.1.6 / 2016-03-07 deps: bytes@2.3.0 Drop partial bytes on all parsed units Fix parsing byte string that looks like hex 2.1.5 / 2015-11-30 deps: bytes@2.2.0 deps: iconv-lite@0.4.13 2.1.4 / 2015-09-27 Fix masking critical errors from iconv-lite deps: iconv-lite@0.4.12 Fix CESU-8 decoding in Node.js 4.x 2.1.3 / 2015-09-12 Fix sync callback when attaching data listener causes sync read Node.js 0.10 compatibility issue 2.1.2 / 2015-07-05 Fix error stack traces to skip makeError deps: iconv-lite@0.4.11 Add encoding CESU-8 2.1.1 / 2015-06-14 Use unpipe module for unpiping requests 2.1.0 / 2015-05-28 deps: iconv-lite@0.4.10 Improved UTF-16 endianness detection Leading BOM is now removed when decoding The encoding UTF-16 without BOM now defaults to UTF-16LE when detection fails 2.0.2 / 2015-05-21 deps: bytes@2.1.0 Slight optimizations 2.0.1 / 2015-05-10 Fix a false-positive when unpiping in Node.js 0.8 2.0.0 / 2015-05-08 Return a promise without callback instead of thunk deps: bytes@2.0.1 units no longer case sensitive when parsing 1.3.4 / 2015-04-15 Fix hanging callback if request aborts during read deps: iconv-lite@0.4.8 Add encoding alias UNICODE-1-1-UTF-7 1.3.3 / 2015-02-08 deps: iconv-lite@0.4.7 Gracefully support enumerables on Object.prototype 1.3.2 / 2015-01-20 deps: iconv-lite@0.4.6 Fix rare aliases of single-byte encodings 1.3.1 / 2014-11-21 deps: iconv-lite@0.4.5 Fix Windows-31J and X-SJIS encoding support 1.3.0 / 2014-07-20 Fully unpipe the stream on error Fixes Cannot switch to old mode now error on Node.js 0.10+ 1.2.3 / 2014-07-20 deps: iconv-lite@0.4.4 Added encoding UTF-7 1.2.2 / 2014-06-19 Send invalid encoding error to callback 1.2.1 / 2014-06-15 deps: iconv-lite@0.4.3 Added encodings UTF-16BE and UTF-16 with BOM 1.2.0 / 2014-06-13 Passing string as options interpreted as encoding Support all encodings from iconv-lite 1.1.7 / 2014-06-12 use string_decoder module from npm 1.1.6 / 2014-05-27 check encoding for old streams1 support node.js < 0.10.6 1.1.5 / 2014-05-14 bump bytes 1.1.4 / 2014-04-19 allow true as an option bump bytes 1.1.3 / 2014-03-02 fix case when length=null 1.1.2 / 2013-12-01 be less strict on state.encoding check 1.1.1 / 2013-11-27 add engines 1.1.0 / 2013-11-27 add err.statusCode and err.type allow for encoding option to be true pause the stream instead of dumping on error throw if the stream's encoding is set 1.0.1 / 2013-11-19 dont support streams1, throw if dev set encoding 1.0.0 / 2013-11-17 rename expected option to length 0.2.0 / 2013-11-15 republish 0.1.1 / 2013-11-15 use bytes 0.1.0 / 2013-11-11 generator support 0.0.3 / 2013-10-10 update repo 0.0.2 / 2013-09-14 dump stream on bad headers listen to events after defining received and buffers 0.0.1 / 2013-09-14 Initial release"
  },
  "node_modules/raw-body/README.html": {
    "href": "node_modules/raw-body/README.html",
    "title": "raw-body | accouter",
    "keywords": "raw-body Gets the entire buffer of a stream either as a Buffer or a string. Validates the stream's length against an expected length and maximum limit. Ideal for parsing request bodies. Install This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install raw-body TypeScript This module includes a TypeScript declaration file to enable auto complete in compatible editors and type information for TypeScript projects. This module depends on the Node.js types, so install @types/node: $ npm install @types/node API var getRawBody = require('raw-body') getRawBody(stream, [options], [callback]) Returns a promise if no callback specified and global Promise exists. Options: length - The length of the stream. If the contents of the stream do not add up to this length, an 400 error code is returned. limit - The byte limit of the body. This is the number of bytes or any string format supported by bytes, for example 1000, '500kb' or '3mb'. If the body ends up being larger than this limit, a 413 error code is returned. encoding - The encoding to use to decode the body into a string. By default, a Buffer instance will be returned when no encoding is specified. Most likely, you want utf-8, so setting encoding to true will decode as utf-8. You can use any type of encoding supported by iconv-lite. You can also pass a string in place of options to just specify the encoding. If an error occurs, the stream will be paused, everything unpiped, and you are responsible for correctly disposing the stream. For HTTP requests, you may need to finish consuming the stream if you want to keep the socket open for future requests. For streams that use file descriptors, you should stream.destroy() or stream.close() to prevent leaks. Errors This module creates errors depending on the error condition during reading. The error may be an error from the underlying Node.js implementation, but is otherwise an error created by this module, which has the following attributes: limit - the limit in bytes length and expected - the expected length of the stream received - the received bytes encoding - the invalid encoding status and statusCode - the corresponding status code for the error type - the error type Types The errors from this module have a type property which allows for the programmatic determination of the type of error returned. encoding.unsupported This error will occur when the encoding option is specified, but the value does not map to an encoding supported by the iconv-lite module. entity.too.large This error will occur when the limit option is specified, but the stream has an entity that is larger. request.aborted This error will occur when the request stream is aborted by the client before reading the body has finished. request.size.invalid This error will occur when the length option is specified, but the stream has emitted more bytes. stream.encoding.set This error will occur when the given stream has an encoding set on it, making it a decoded stream. The stream should not have an encoding set and is expected to emit Buffer objects. stream.not.readable This error will occur when the given stream is not readable. Examples Simple Express example var contentType = require('content-type') var express = require('express') var getRawBody = require('raw-body') var app = express() app.use(function (req, res, next) { getRawBody(req, { length: req.headers['content-length'], limit: '1mb', encoding: contentType.parse(req).parameters.charset }, function (err, string) { if (err) return next(err) req.text = string next() }) }) // now access req.text Simple Koa example var contentType = require('content-type') var getRawBody = require('raw-body') var koa = require('koa') var app = koa() app.use(function * (next) { this.text = yield getRawBody(this.req, { length: this.req.headers['content-length'], limit: '1mb', encoding: contentType.parse(this.req).parameters.charset }) yield next }) // now access this.text Using as a promise To use this library as a promise, simply omit the callback and a promise is returned, provided that a global Promise is defined. var getRawBody = require('raw-body') var http = require('http') var server = http.createServer(function (req, res) { getRawBody(req) .then(function (buf) { res.statusCode = 200 res.end(buf.length + ' bytes submitted') }) .catch(function (err) { res.statusCode = 500 res.end(err.message) }) }) server.listen(3000) Using with TypeScript import * as getRawBody from 'raw-body'; import * as http from 'http'; const server = http.createServer((req, res) => { getRawBody(req) .then((buf) => { res.statusCode = 200; res.end(buf.length + ' bytes submitted'); }) .catch((err) => { res.statusCode = err.statusCode; res.end(err.message); }); }); server.listen(3000); License MIT"
  },
  "node_modules/raw-body/SECURITY.html": {
    "href": "node_modules/raw-body/SECURITY.html",
    "title": "Security Policies and Procedures | accouter",
    "keywords": "Security Policies and Procedures Reporting a Bug The raw-body team and community take all security bugs seriously. Thank you for improving the security of Express. We appreciate your efforts and responsible disclosure and will make every effort to acknowledge your contributions. Report security bugs by emailing the current owners of raw-body. This information can be found in the npm registry using the command npm owner ls raw-body. If unsure or unable to get the information from the above, open an issue in the project issue tracker asking for the current contact information. To ensure the timely response to your report, please ensure that the entirety of the report is contained within the email body and not solely behind a web link or an attachment. At least one owner will acknowledge your email within 48 hours, and will send a more detailed response within 48 hours indicating the next steps in handling your report. After the initial reply to your report, the owners will endeavor to keep you informed of the progress towards a fix and full announcement, and may ask for additional information or guidance."
  },
  "node_modules/react-is/README.html": {
    "href": "node_modules/react-is/README.html",
    "title": "react-is | accouter",
    "keywords": "react-is This package allows you to test arbitrary values and see if they're a particular React element type. Installation # Yarn yarn add react-is # NPM npm install react-is Usage Determining if a Component is Valid import React from \"react\"; import * as ReactIs from \"react-is\"; class ClassComponent extends React.Component { render() { return React.createElement(\"div\"); } } const FunctionComponent = () => React.createElement(\"div\"); const ForwardRefComponent = React.forwardRef((props, ref) => React.createElement(Component, { forwardedRef: ref, ...props }) ); const Context = React.createContext(false); ReactIs.isValidElementType(\"div\"); // true ReactIs.isValidElementType(ClassComponent); // true ReactIs.isValidElementType(FunctionComponent); // true ReactIs.isValidElementType(ForwardRefComponent); // true ReactIs.isValidElementType(Context.Provider); // true ReactIs.isValidElementType(Context.Consumer); // true ReactIs.isValidElementType(React.createFactory(\"div\")); // true Determining an Element's Type Context import React from \"react\"; import * as ReactIs from 'react-is'; const ThemeContext = React.createContext(\"blue\"); ReactIs.isContextConsumer(<ThemeContext.Consumer />); // true ReactIs.isContextProvider(<ThemeContext.Provider />); // true ReactIs.typeOf(<ThemeContext.Provider />) === ReactIs.ContextProvider; // true ReactIs.typeOf(<ThemeContext.Consumer />) === ReactIs.ContextConsumer; // true Element import React from \"react\"; import * as ReactIs from 'react-is'; ReactIs.isElement(<div />); // true ReactIs.typeOf(<div />) === ReactIs.Element; // true Fragment import React from \"react\"; import * as ReactIs from 'react-is'; ReactIs.isFragment(<></>); // true ReactIs.typeOf(<></>) === ReactIs.Fragment; // true Portal import React from \"react\"; import ReactDOM from \"react-dom\"; import * as ReactIs from 'react-is'; const div = document.createElement(\"div\"); const portal = ReactDOM.createPortal(<div />, div); ReactIs.isPortal(portal); // true ReactIs.typeOf(portal) === ReactIs.Portal; // true StrictMode import React from \"react\"; import * as ReactIs from 'react-is'; ReactIs.isStrictMode(<React.StrictMode />); // true ReactIs.typeOf(<React.StrictMode />) === ReactIs.StrictMode; // true"
  },
  "node_modules/read-cache/README.html": {
    "href": "node_modules/read-cache/README.html",
    "title": "read-cache | accouter",
    "keywords": "read-cache Reads and caches the entire contents of a file until it is modified. Install $ npm i read-cache Usage // foo.js var readCache = require('read-cache'); readCache('foo.js').then(function (contents) { console.log(contents); }); API readCache(path[, encoding]) Returns a promise that resolves with the file's contents. readCache.sync(path[, encoding]) Returns the content of the file. readCache.get(path[, encoding]) Returns the content of cached file or null. readCache.clear() Clears the contents of the cache. License MIT © Bogdan Chadkin"
  },
  "node_modules/read-pkg/node_modules/path-type/readme.html": {
    "href": "node_modules/read-pkg/node_modules/path-type/readme.html",
    "title": "path-type | accouter",
    "keywords": "path-type Check if a path is a file, directory, or symlink Install $ npm install path-type Usage const pathType = require('path-type'); pathType.file('package.json').then(isFile => { console.log(isFile); //=> true }) API .file(path) .dir(path) .symlink(path) Returns a Promise for a boolean of whether the path is the checked type. .fileSync(path) .dirSync(path) .symlinkSync(path) Returns a boolean of whether the path is the checked type. License MIT © Sindre Sorhus"
  },
  "node_modules/read-pkg/node_modules/pify/readme.html": {
    "href": "node_modules/read-pkg/node_modules/pify/readme.html",
    "title": "pify | accouter",
    "keywords": "pify Promisify a callback-style function Install $ npm install --save pify Usage const fs = require('fs'); const pify = require('pify'); // Promisify a single function pify(fs.readFile)('package.json', 'utf8').then(data => { console.log(JSON.parse(data).name); //=> 'pify' }); // Promisify all methods in a module pify(fs).readFile('package.json', 'utf8').then(data => { console.log(JSON.parse(data).name); //=> 'pify' }); API pify(input, [options]) Returns a Promise wrapped version of the supplied function or module. input Type: Function Object Callback-style function or module whose methods you want to promisify. options multiArgs Type: boolean Default: false By default, the promisified function will only return the second argument from the callback, which works fine for most APIs. This option can be useful for modules like request that return multiple arguments. Turning this on will make it return an array of all arguments from the callback, excluding the error argument, instead of just the second argument. This also applies to rejections, where it returns an array of all the callback arguments, including the error. const request = require('request'); const pify = require('pify'); pify(request, {multiArgs: true})('https://sindresorhus.com').then(result => { const [httpResponse, body] = result; }); include Type: string[] RegExp[] Methods in a module to promisify. Remaining methods will be left untouched. exclude Type: string[] RegExp[] Default: [/.+(Sync|Stream)$/] Methods in a module not to promisify. Methods with names ending with 'Sync' are excluded by default. excludeMain Type: boolean Default: false If given module is a function itself, it will be promisified. Turn this option on if you want to promisify only methods of the module. const pify = require('pify'); function fn() { return true; } fn.method = (data, callback) => { setImmediate(() => { callback(null, data); }); }; // Promisify methods but not `fn()` const promiseFn = pify(fn, {excludeMain: true}); if (promiseFn()) { promiseFn.method('hi').then(data => { console.log(data); }); } errorFirst Type: boolean Default: true Whether the callback has an error as the first argument. You'll want to set this to false if you're dealing with an API that doesn't have an error as the first argument, like fs.exists(), some browser APIs, Chrome Extension APIs, etc. promiseModule Type: Function Custom promise module to use instead of the native one. Check out pinkie-promise if you need a tiny promise polyfill. Related p-event - Promisify an event by waiting for it to be emitted p-map - Map over promises concurrently More… License MIT © Sindre Sorhus"
  },
  "node_modules/read-pkg/readme.html": {
    "href": "node_modules/read-pkg/readme.html",
    "title": "read-pkg | accouter",
    "keywords": "read-pkg Read a package.json file Why Gracefully handles filesystem issues Strips UTF-8 BOM Throws more helpful JSON errors Normalizes the data Install $ npm install read-pkg Usage const readPkg = require('read-pkg'); readPkg().then(pkg => { console.log(pkg); //=> {name: 'read-pkg', ...} }); readPkg(__dirname).then(pkg => { console.log(pkg); //=> {name: 'read-pkg', ...} }); readPkg(path.join('unicorn', 'package.json')).then(pkg => { console.log(pkg); //=> {name: 'read-pkg', ...} }); API readPkg([path], [options]) Returns a Promise for the parsed JSON. readPkg.sync([path], [options]) Returns the parsed JSON. path Type: string Default: process.cwd() Path to a package.json file or its directory. options normalize Type: boolean Default: true Normalize the package data. Related read-pkg-up - Read the closest package.json file write-pkg - Write a package.json file load-json-file - Read and parse a JSON file License MIT © Sindre Sorhus"
  },
  "node_modules/readdirp/README.html": {
    "href": "node_modules/readdirp/README.html",
    "title": "readdirp | accouter",
    "keywords": "readdirp Recursive version of fs.readdir. Exposes a stream API and a promise API. npm install readdirp const readdirp = require('readdirp'); // Use streams to achieve small RAM & CPU footprint. // 1) Streams example with for-await. for await (const entry of readdirp('.')) { const {path} = entry; console.log(`${JSON.stringify({path})}`); } // 2) Streams example, non for-await. // Print out all JS files along with their size within the current folder & subfolders. readdirp('.', {fileFilter: '*.js', alwaysStat: true}) .on('data', (entry) => { const {path, stats: {size}} = entry; console.log(`${JSON.stringify({path, size})}`); }) // Optionally call stream.destroy() in `warn()` in order to abort and cause 'close' to be emitted .on('warn', error => console.error('non-fatal error', error)) .on('error', error => console.error('fatal error', error)) .on('end', () => console.log('done')); // 3) Promise example. More RAM and CPU than streams / for-await. const files = await readdirp.promise('.'); console.log(files.map(file => file.path)); // Other options. readdirp('test', { fileFilter: '*.js', directoryFilter: ['!.git', '!*modules'] // directoryFilter: (di) => di.basename.length === 9 type: 'files_directories', depth: 1 }); For more examples, check out examples directory. API const stream = readdirp(root[, options]) — Stream API Reads given root recursively and returns a stream of entry infos Optionally can be used like for await (const entry of stream) with node.js 10+ (asyncIterator). on('data', (entry) => {}) entry info for every file / dir. on('warn', (error) => {}) non-fatal Error that prevents a file / dir from being processed. Example: inaccessible to the user. on('error', (error) => {}) fatal Error which also ends the stream. Example: illegal options where passed. on('end') — we are done. Called when all entries were found and no more will be emitted. on('close') — stream is destroyed via stream.destroy(). Could be useful if you want to manually abort even on a non fatal error. At that point the stream is no longer readable and no more entries, warning or errors are emitted To learn more about streams, consult the very detailed nodejs streams documentation or the stream-handbook const entries = await readdirp.promise(root[, options]) — Promise API. Returns a list of entry infos. First argument is awalys root, path in which to start reading and recursing into subdirectories. options fileFilter: [\"*.js\"]: filter to include or exclude files. A Function, Glob string or Array of glob strings. Function: a function that takes an entry info as a parameter and returns true to include or false to exclude the entry Glob string: a string (e.g., *.js) which is matched using picomatch, so go there for more information. Globstars (**) are not supported since specifying a recursive pattern for an already recursive function doesn't make sense. Negated globs (as explained in the minimatch documentation) are allowed, e.g., !*.txt matches everything but text files. Array of glob strings: either need to be all inclusive or all exclusive (negated) patterns otherwise an error is thrown. ['*.json', '*.js'] includes all JavaScript and Json files. ['!.git', '!node_modules'] includes all directories except the '.git' and 'node_modules'. Directories that do not pass a filter will not be recursed into. directoryFilter: ['!.git']: filter to include/exclude directories found and to recurse into. Directories that do not pass a filter will not be recursed into. depth: 5: depth at which to stop recursing even if more subdirectories are found type: 'files': determines if data events on the stream should be emitted for 'files' (default), 'directories', 'files_directories', or 'all'. Setting to 'all' will also include entries for other types of file descriptors like character devices, unix sockets and named pipes. alwaysStat: false: always return stats property for every file. Default is false, readdirp will return Dirent entries. Setting it to true can double readdir execution time - use it only when you need file size, mtime etc. Cannot be enabled on node <10.10.0. lstat: false: include symlink entries in the stream along with files. When true, fs.lstat would be used instead of fs.stat EntryInfo Has the following properties: path: 'assets/javascripts/react.js': path to the file/directory (relative to given root) fullPath: '/Users/dev/projects/app/assets/javascripts/react.js': full path to the file/directory found basename: 'react.js': name of the file/directory dirent: fs.Dirent: built-in dir entry object - only with alwaysStat: false stats: fs.Stats: built in stat object - only with alwaysStat: true Changelog 3.5 (Oct 13, 2020) disallows recursive directory-based symlinks. Before, it could have entered infinite loop. 3.4 (Mar 19, 2020) adds support for directory-based symlinks. 3.3 (Dec 6, 2019) stabilizes RAM consumption and enables perf management with highWaterMark option. Fixes race conditions related to for-await looping. 3.2 (Oct 14, 2019) improves performance by 250% and makes streams implementation more idiomatic. 3.1 (Jul 7, 2019) brings bigint support to stat output on Windows. This is backwards-incompatible for some cases. Be careful. It you use it incorrectly, you'll see \"TypeError: Cannot mix BigInt and other types, use explicit conversions\". 3.0 brings huge performance improvements and stream backpressure support. Upgrading 2.x to 3.x: Signature changed from readdirp(options) to readdirp(root, options) Replaced callback API with promise API. Renamed entryType option to type Renamed entryType: 'both' to 'files_directories' EntryInfo Renamed stat to stats Emitted only when alwaysStat: true dirent is emitted instead of stats by default with alwaysStat: false Renamed name to basename Removed parentDir and fullParentDir properties Supported node.js versions: 3.x: node 8+ 2.x: node 0.6+ License Copyright (c) 2012-2019 Thorsten Lorenz, Paul Miller (https://paulmillr.com) MIT License, see LICENSE file."
  },
  "node_modules/regexp.prototype.flags/CHANGELOG.html": {
    "href": "node_modules/regexp.prototype.flags/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.5.2 - 2024-02-11 Commits [Tests] increase coverage c692c88 [Dev Deps] use hasown instead of has fb5b350 [Dev Deps] update aud, hasown, npmignore, tape fd0ddd9 [Deps] update call-bind, define-properties, set-function-name ca53f66 [Dev Deps] update object-inspect, tape 4491680 [Refactor] use es-errors 1d03d22 [Fix] properly check for a non-object receiver 024d442 [Deps] update call-bind f222ce0 v1.5.1 - 2023-09-12 Commits [Refactor] use set-function-name 1384147 [Dev Deps] update @es-shims/api, @ljharb/eslint-config, aud, available-regexp-flags, tape 07bf9a2 [Dev Deps] add missing npmignore dep 8ca9dfe v1.5.0 - 2023-04-18 Commits [meta] use npmignore to autogenerate an npmignore file f7438ad [New] add unicodeSets/v flag f922170 [Dev Deps] update @es-shims/api, @ljharb/eslint-config, aud, available-regexp-flags, object-inspect, tape 1203078 [actions] update rebase action to use reusable workflow c562ea2 [Dev Deps] update aud, object-inspect, tape f3ae811 [Deps] update define-properties, functions-have-names 2d0476e [Tests] use for-each instead of foreach d9f30da [Deps] update define-properties 81c1c20 v1.4.3 - 2022-04-14 Commits [Fix] when shimmed, name must be get flags fcefd00 v1.4.2 - 2022-04-12 Commits [Fix] ensure hasIndices is patched properly, and getter order is correct a1af45a [Dev Deps] update eslint, @ljharb/eslint-config, auto-changelog, tape 24f5a0c v1.4.1 - 2022-01-13 Commits [Fix] polyfill: do not throw in a descriptorless environment e2d24e7 v1.4.0 - 2022-01-13 Commits [Tests] use available-regexp-flags 95af246 [New] add hasIndices/d flag 89959ca v1.3.2 - 2022-01-13 Commits [actions] reuse common workflows 6665b5d [actions] use node/install instead of node/run; use codecov action babce94 [Dev Deps] update eslint, @ljharb/eslint-config, @es-shims/api, object-inspect, safe-publish-latest, tape 52132d9 [Dev Deps] update eslint, @ljharb/eslint-config, @es-shims/api, aud, auto-changelog, object-inspect, tape c16687c [actions] update codecov uploader 0a3c904 [Dev Deps] update eslint, @ljharb/eslint-config, aud, object-inspect, tape 3fce7f2 [Dev Deps] update eslint, @ljharb/eslint-config, aud, tape 75ca498 [actions] update workflows 300f321 [meta] better eccheck command 5f735ab [Dev Deps] update eslint, tape 3059637 [actions] update workflows [dbd8ab4`](https://github.com/es-shims/RegExp.prototype.flags/commit/dbd8ab49fa2196dd74791107825c43e4481cdfd2) [meta] use prepublishOnly script for npm 7+ 5cc8652 [Fix] use polyfill, not implementation, in main export 15ab4b8 [meta] remove audit-level config, which breaks npm 7 installs 1cb98ae v1.3.1 - 2021-01-15 Commits [Tests] run nyc on all tests; use tape runner; add full es-shims test suite 047a1e8 [Tests] migrate tests to Github Actions e4e391f [meta] use auto-changelog for changelog afbcd06 [actions] add Require Allow Edits workflow 0db5d50 [meta] do not publish github action workflow files 53f2902 [Dev Deps] update eslint, @ljharb/eslint-config, tape; add aud 05f2a85 [Dev Deps] update eslint, @ljharb/eslint-config, aud, tape 2a197b8 [Dev Deps] update eslint, @ljharb/eslint-config, tape; add safe-publish-latest e40bd37 [Refactor] use call-bind instead of es-abstract e6eac90 [Deps] update es-abstract f198075 [actions] switch Automatic Rebase workflow to pull_request_target event 2d21727 [Deps] update es-abstract 7e7ddc6 v1.3.0 - 2019-12-14 Commits [Tests] remove jscs 4a09ab4 [Tests] use shared travis-ci configs 8afa6a9 [Dev Deps] update eslint, @ljharb/eslint-config, covert, has, tape 13a9fc9 [Refactor] use callBind helper from es-abstract c3a3727 [actions] add automatic rebasing / merge commit blocking 51e3f93 [Tests] use npx aud instead of nsp or npm audit with hoops 7e1ee50 [meta] add funding field c99cbec [New] add auto entry point 1e53e85 [Tests] use eclint instead of editorconfig-tools 8600bfe [Deps] update define-properties ad221fa v1.2.0 - 2017-10-24 Commits [Tests] up to node v8.8, v7.10, v6.11, v4.8; improve matrix; use nvm install-latest-npm so new npm doesn’t break old node 5a9653d [Dev Deps] update tape, jscs, nsp, eslint, @ljharb/eslint-config; add has 556de86 [Dev Deps] update tape, jscs, nsp, eslint, @ljharb/eslint-config 726772c [New] add support for dotAll regex flag. fcbd64f [Dev Deps] update eslint, jscs, nsp, tape, @ljharb/eslint-config, @es-shims/api 0272934 [Dev Deps] update jscs, nsp, eslint e4cd264 [Dev Deps] update jscs, nsp, eslint, @es-shims/api baf5169 [Dev Deps] update tape, nsp, eslint, @ljharb/eslint-config 97cea15 [Dev Deps] update tape, discs, eslint, @ljharb/eslint-config b6872f4 [Dev Deps] update tape, jscs, nsp, eslint, @ljharb/eslint-config 14702cc [Dev Deps] update jscs, @es-shims/api cd060a6 [Tests] up to node v6.2, v5.11 14638bd [Tests] up to io.js v3.3, node v4.1 b0a5ffb [Tests] npm run silently 35804d4 [Tests] up to node v5.9, v4.4 e0fe80d [Tests] up to node v5.7, v4.3 9739c42 [Dev Deps] update jscs 4aa1699 [Dev Deps] update tape, jscs, nsp, @ljharb/eslint-config 8bc5e6b [Tests] fix npm upgrades on older nodes ae00bb9 Only apps should have lockfiles. 6d14965 [Tests] use pretest/posttest for better organization 0520cfd [Tests] up to node v5.5 810f62b [Tests] on node v5.3 f839662 [Dev Deps] update eslint, @ljharb/eslint-config 78ecaa5 [Tests] up to node v5.2 c04d762 [Tests] up to node v5.0 7c0d5b9 [Tests] on node v5.10 40ddafd [Deps] update define-properties 98ea89d v1.1.1 - 2015-08-16 Commits [Fix] cover the case where there is no descriptor on the prototype 67014c3 v1.1.0 - 2015-08-16 Commits Update jscs, eslint; use my personal shared eslint config. 37ca379 Update eslint, tape, editorconfig-tools, nsp cb92d6e Implement the es-shim API. 15eb821 Refactoring to reduce complexity. aeb4785 Move implementation to implementation.js a698925 Update eslint, jscs 277a4a1 Update nsp, eslint c9f3866 Update tape, eslint a08795b Make some things a bit more robust. 450abb4 Update eslint 25d898f Test on latest two io.js versions. 2e17ca3 All grade A-supported node/iojs versions now ship with an npm that understands ^. 4a2a548 Update eslint 64df4e0 Update eslint ac05ae5 Clean up supportsDescriptors check. e44d0de [Dev Deps] Update jscs 8741758 Update tape, jscs, nsp, eslint db1f658 Test on io.js v2.3 18c948f Run travis-ci tests on iojs and node v0.12; speed up builds; allow 0.8 failures. c37e79f Update tape, jscs, eslint 4b652bf [Dev Deps] Update tape, eslint 29d4ac0 Test up to io.js v2.1 9f9e342 Update covert, jscs c98f3b4 Update jscs 9e5e220 [Dev Deps] update tape cdd3af2 [Dev Deps] update tape d42d0bf Switch from vb.teelaun.ch to versionbadg.es for the npm version badge SVG. a5e7453 Update tape 2a675ec Test on io.js v2.5 448cbdb Test on io.js v2.4 948e511 Test on io.js v2.2 4793278 Update eslint 0f463da Update eslint 5a16967 Test on io.js v3.0 7ba8706 Test on iojs-v1.2 b521e09 v1.0.1 - 2014-12-13 Merged Match the spec properly: throw when not an object; make getter generic. #3 Fixed Match the spec properly #1 Commits Speed up the “is object” check in case of null or undefined 77137f9 v1.0.0 - 2014-12-10 Commits Adding dotfiles 313812e Tests 625a042 Add package.json 8b98257 Adding the README 884798b Implementation. 4186cc9 Adding LICENSE and CHANGELOG f87fa81 Fixing README URLs b821703 Clean up dependencies; update tape, jscs, nsp 0e13fc1 Initial commit. 8a9e35e"
  },
  "node_modules/regexp.prototype.flags/README.html": {
    "href": "node_modules/regexp.prototype.flags/README.html",
    "title": "| accouter",
    "keywords": "RegExp.prototype.flags An ES6 spec-compliant RegExp.prototype.flags shim. Invoke its \"shim\" method to shim RegExp.prototype.flags if it is unavailable. Note: RegExp#flags requires a true ES5 environment - specifically, one with ES5 getters. This package implements the es-shim API interface. It works in an ES5-supported environment and complies with the spec. Most common usage: var flags = require('regexp.prototype.flags'); assert(flags(/a/) === ''); assert(flags(new RegExp('a') === ''); assert(flags(/a/mig) === 'gim'); assert(flags(new RegExp('a', 'mig')) === 'gim'); if (!RegExp.prototype.flags) { flags.shim(); } assert(flags(/a/) === /a/.flags); assert(flags(new RegExp('a') === new RegExp('a').flags); assert(flags(/a/mig) === /a/mig.flags); assert(flags(new RegExp('a', 'mig')) === new RegExp('a', 'mig').flags); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/requires-port/README.html": {
    "href": "node_modules/requires-port/README.html",
    "title": "requires-port | accouter",
    "keywords": "requires-port The module name says it all, check if a protocol requires a given port. Installation This module is intended to be used with browserify or Node.js and is distributed in the public npm registry. To install it simply run the following command from your CLI: npm install --save requires-port Usage The module exports it self as function and requires 2 arguments: The port number, can be a string or number. Protocol, can be http, http: or even https://yomoma.com. We just split it at : and use the first result. We currently accept the following protocols: http https ws wss ftp gopher file It returns a boolean that indicates if protocol requires this port to be added to your URL. 'use strict'; var required = require('requires-port'); console.log(required('8080', 'http')) // true console.log(required('80', 'http')) // false License MIT"
  },
  "node_modules/resolve/SECURITY.html": {
    "href": "node_modules/resolve/SECURITY.html",
    "title": "Security | accouter",
    "keywords": "Security Please email @ljharb or see https://tidelift.com/security if you have a potential security vulnerability to report."
  },
  "node_modules/resp-modifier/README.html": {
    "href": "node_modules/resp-modifier/README.html",
    "title": "resp-modifier | accouter",
    "keywords": "resp-modifier All the good parts from connect-livereload without the livereload specific bits & with multiple replacements added. Contributing In lieu of a formal styleguide, take care to maintain the existing coding style. Add unit tests for any new or changed functionality. Lint and test your code using Gulp. Release History (Nothing yet) License Copyright (c) 2013 Shane Osbourne Licensed under the MIT license."
  },
  "node_modules/resp-modifier/node_modules/brace-expansion/README.html": {
    "href": "node_modules/resp-modifier/node_modules/brace-expansion/README.html",
    "title": "brace-expansion | accouter",
    "keywords": "brace-expansion Brace expansion, as known from sh/bash, in JavaScript. Example var expand = require('brace-expansion'); expand('file-{a,b,c}.jpg') // => ['file-a.jpg', 'file-b.jpg', 'file-c.jpg'] expand('-v{,,}') // => ['-v', '-v', '-v'] expand('file{0..2}.jpg') // => ['file0.jpg', 'file1.jpg', 'file2.jpg'] expand('file-{a..c}.jpg') // => ['file-a.jpg', 'file-b.jpg', 'file-c.jpg'] expand('file{2..0}.jpg') // => ['file2.jpg', 'file1.jpg', 'file0.jpg'] expand('file{0..4..2}.jpg') // => ['file0.jpg', 'file2.jpg', 'file4.jpg'] expand('file-{a..e..2}.jpg') // => ['file-a.jpg', 'file-c.jpg', 'file-e.jpg'] expand('file{00..10..5}.jpg') // => ['file00.jpg', 'file05.jpg', 'file10.jpg'] expand('{{A..C},{a..c}}') // => ['A', 'B', 'C', 'a', 'b', 'c'] expand('ppp{,config,oe{,conf}}') // => ['ppp', 'pppconfig', 'pppoe', 'pppoeconf'] API var expand = require('brace-expansion'); var expanded = expand(str) Return an array of all possible and valid expansions of str. If none are found, [str] is returned. Valid expansions are: /^(.*,)+(.+)?$/ // {a,b,...} A comma separated list of options, like {a,b} or {a,{b,c}} or {,a,}. /^-?\\d+\\.\\.-?\\d+(\\.\\.-?\\d+)?$/ // {x..y[..incr]} A numeric sequence from x to y inclusive, with optional increment. If x or y start with a leading 0, all the numbers will be padded to have equal length. Negative numbers and backwards iteration work too. /^-?\\d+\\.\\.-?\\d+(\\.\\.-?\\d+)?$/ // {x..y[..incr]} An alphabetic sequence from x to y inclusive, with optional increment. x and y must be exactly one character, and if given, incr must be a number. For compatibility reasons, the string ${ is not eligible for brace expansion. Installation With npm do: npm install brace-expansion Contributors Julian Gruber Isaac Z. Schlueter Sponsors This module is proudly supported by my Sponsors! Do you want to support modules like this to improve their quality, stability and weigh in on new features? Then please consider donating to my Patreon. Not sure how much of my modules you're using? Try feross/thanks! License (MIT) Copyright (c) 2013 Julian Gruber <julian@juliangruber.com&gt; Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/resp-modifier/node_modules/minimatch/README.html": {
    "href": "node_modules/resp-modifier/node_modules/minimatch/README.html",
    "title": "minimatch | accouter",
    "keywords": "minimatch A minimal matching utility. This is the matching library used internally by npm. It works by converting glob expressions into JavaScript RegExp objects. Usage var minimatch = require(\"minimatch\") minimatch(\"bar.foo\", \"*.foo\") // true! minimatch(\"bar.foo\", \"*.bar\") // false! minimatch(\"bar.foo\", \"*.+(bar|foo)\", { debug: true }) // true, and noisy! Features Supports these glob features: Brace Expansion Extended glob matching \"Globstar\" ** matching See: man sh man bash man 3 fnmatch man 5 gitignore Minimatch Class Create a minimatch object by instantiating the minimatch.Minimatch class. var Minimatch = require(\"minimatch\").Minimatch var mm = new Minimatch(pattern, options) Properties pattern The original pattern the minimatch object represents. options The options supplied to the constructor. set A 2-dimensional array of regexp or string expressions. Each row in the array corresponds to a brace-expanded pattern. Each item in the row corresponds to a single path-part. For example, the pattern {a,b/c}/d would expand to a set of patterns like: [ [ a, d ] , [ b, c, d ] ] If a portion of the pattern doesn't have any \"magic\" in it (that is, it's something like \"foo\" rather than fo*o?), then it will be left as a string rather than converted to a regular expression. regexp Created by the makeRe method. A single regular expression expressing the entire pattern. This is useful in cases where you wish to use the pattern somewhat like fnmatch(3) with FNM_PATH enabled. negate True if the pattern is negated. comment True if the pattern is a comment. empty True if the pattern is \"\". Methods makeRe Generate the regexp member if necessary, and return it. Will return false if the pattern is invalid. match(fname) Return true if the filename matches the pattern, or false otherwise. matchOne(fileArray, patternArray, partial) Take a /-split filename, and match it against a single row in the regExpSet. This method is mainly for internal use, but is exposed so that it can be used by a glob-walker that needs to avoid excessive filesystem calls. All other methods are internal, and will be called as necessary. minimatch(path, pattern, options) Main export. Tests a path against the pattern using the options. var isJS = minimatch(file, \"*.js\", { matchBase: true }) minimatch.filter(pattern, options) Returns a function that tests its supplied argument, suitable for use with Array.filter. Example: var javascripts = fileList.filter(minimatch.filter(\"*.js\", {matchBase: true})) minimatch.match(list, pattern, options) Match against the list of files, in the style of fnmatch or glob. If nothing is matched, and options.nonull is set, then return a list containing the pattern itself. var javascripts = minimatch.match(fileList, \"*.js\", {matchBase: true})) minimatch.makeRe(pattern, options) Make a regular expression object from the pattern. Options All options are false by default. debug Dump a ton of stuff to stderr. nobrace Do not expand {a,b} and {1..3} brace sets. noglobstar Disable ** matching against multiple folder names. dot Allow patterns to match filenames starting with a period, even if the pattern does not explicitly have a period in that spot. Note that by default, a/**/b will not match a/.d/b, unless dot is set. noext Disable \"extglob\" style patterns like +(a|b). nocase Perform a case-insensitive match. nonull When a match is not found by minimatch.match, return a list containing the pattern itself if this option is set. When not set, an empty list is returned if there are no matches. matchBase If set, then patterns without slashes will be matched against the basename of the path if it contains slashes. For example, a?b would match the path /xyz/123/acb, but not /xyz/acb/123. nocomment Suppress the behavior of treating # at the start of a pattern as a comment. nonegate Suppress the behavior of treating a leading ! character as negation. flipNegate Returns from negate expressions the same as if they were not negated. (Ie, true on a hit, false on a miss.) partial Compare a partial path to a pattern. As long as the parts of the path that are present are not contradicted by the pattern, it will be treated as a match. This is useful in applications where you're walking through a folder structure, and don't yet have the full path, but want to ensure that you do not walk down paths that can never be a match. For example, minimatch('/a/b', '/a/*/c/d', { partial: true }) // true, might be /a/b/c/d minimatch('/a/b', '/**/d', { partial: true }) // true, might be /a/b/.../d minimatch('/x/y/z', '/a/**/z', { partial: true }) // false, because x !== a allowWindowsEscape Windows path separator \\ is by default converted to /, which prohibits the usage of \\ as a escape character. This flag skips that behavior and allows using the escape character. Comparisons to other fnmatch/glob implementations While strict compliance with the existing standards is a worthwhile goal, some discrepancies exist between minimatch and other implementations, and are intentional. If the pattern starts with a ! character, then it is negated. Set the nonegate flag to suppress this behavior, and treat leading ! characters normally. This is perhaps relevant if you wish to start the pattern with a negative extglob pattern like !(a|B). Multiple ! characters at the start of a pattern will negate the pattern multiple times. If a pattern starts with #, then it is treated as a comment, and will not match anything. Use \\# to match a literal # at the start of a line, or set the nocomment flag to suppress this behavior. The double-star character ** is supported by default, unless the noglobstar flag is set. This is supported in the manner of bsdglob and bash 4.1, where ** only has special significance if it is the only thing in a path part. That is, a/**/b will match a/x/y/b, but a/**b will not. If an escaped pattern has no matches, and the nonull flag is set, then minimatch.match returns the pattern as-provided, rather than interpreting the character escapes. For example, minimatch.match([], \"\\\\*a\\\\?\") will return \"\\\\*a\\\\?\" rather than \"*a?\". This is akin to setting the nullglob option in bash, except that it does not resolve escaped pattern characters. If brace expansion is not disabled, then it is performed before any other interpretation of the glob pattern. Thus, a pattern like +(a|{b),c)}, which would not be valid in bash or zsh, is expanded first into the set of +(a|b) and +(a|c), and those patterns are checked for validity. Since those two are valid, matching proceeds."
  },
  "node_modules/reusify/README.html": {
    "href": "node_modules/reusify/README.html",
    "title": "reusify | accouter",
    "keywords": "reusify Reuse your objects and functions for maximum speed. This technique will make any function run ~10% faster. You call your functions a lot, and it adds up quickly in hot code paths. $ node benchmarks/createNoCodeFunction.js Total time 53133 Total iterations 100000000 Iteration/s 1882069.5236482036 $ node benchmarks/reuseNoCodeFunction.js Total time 50617 Total iterations 100000000 Iteration/s 1975620.838848608 The above benchmark uses fibonacci to simulate a real high-cpu load. The actual numbers might differ for your use case, but the difference should not. The benchmark was taken using Node v6.10.0. This library was extracted from fastparallel. Example var reusify = require('reusify') var fib = require('reusify/benchmarks/fib') var instance = reusify(MyObject) // get an object from the cache, // or creates a new one when cache is empty var obj = instance.get() // set the state obj.num = 100 obj.func() // reset the state. // if the state contains any external object // do not use delete operator (it is slow) // prefer set them to null obj.num = 0 // store an object in the cache instance.release(obj) function MyObject () { // you need to define this property // so V8 can compile MyObject into an // hidden class this.next = null this.num = 0 var that = this // this function is never reallocated, // so it can be optimized by V8 this.func = function () { if (null) { // do nothing } else { // calculates fibonacci fib(that.num) } } } The above example was intended for synchronous code, let's see async: var reusify = require('reusify') var instance = reusify(MyObject) for (var i = 0; i < 100; i++) { getData(i, console.log) } function getData (value, cb) { var obj = instance.get() obj.value = value obj.cb = cb obj.run() } function MyObject () { this.next = null this.value = null var that = this this.run = function () { asyncOperation(that.value, that.handle) } this.handle = function (err, result) { that.cb(err, result) that.value = null that.cb = null instance.release(that) } } Also note how in the above examples, the code, that consumes an istance of MyObject, reset the state to initial condition, just before storing it in the cache. That's needed so that every subsequent request for an instance from the cache, could get a clean instance. Why It is faster because V8 doesn't have to collect all the functions you create. On a short-lived benchmark, it is as fast as creating the nested function, but on a longer time frame it creates less pressure on the garbage collector. Other examples If you want to see some complex example, checkout middie and steed. Acknowledgements Thanks to Trevor Norris for getting me down the rabbit hole of performance, and thanks to Mathias Buss for suggesting me to share this trick. License MIT"
  },
  "node_modules/rimraf/README.html": {
    "href": "node_modules/rimraf/README.html",
    "title": "| accouter",
    "keywords": "The UNIX command rm -rf for node in a cross-platform implementation. Install with npm install rimraf. Major Changes v4 to v5 There is no default export anymore. Import the functions directly using, e.g., import { rimrafSync } from 'rimraf. v3 to v4 The function returns a Promise instead of taking a callback. Globbing requires the --glob CLI option or glob option property to be set. (Removed in 4.0 and 4.1, opt-in support added in 4.2.) Functions take arrays of paths, as well as a single path. Native implementation used by default when available, except on Windows, where this implementation is faster and more reliable. New implementation on Windows, falling back to \"move then remove\" strategy when exponential backoff for EBUSY fails to resolve the situation. Simplified implementation on Posix, since the Windows affordances are not necessary there. As of 4.3, return/resolve value is boolean instead of undefined API Hybrid module, load either with import or require(). // 'rimraf' export is the one you probably want, but other // strategies exported as well. import { rimraf, rimrafSync, native, nativeSync } from 'rimraf' // or const { rimraf, rimrafSync, native, nativeSync } = require('rimraf') All removal functions return a boolean indicating that all entries were successfully removed. The only case in which this will not return true is if something was omitted from the removal via a filter option. rimraf(f, [opts]) -> Promise This first parameter is a path or array of paths. The second argument is an options object. Options: preserveRoot: If set to boolean false, then allow the recursive removal of the root directory. Otherwise, this is not allowed. tmp: Windows only. Temp folder to use to place files and folders for the \"move then remove\" fallback. Must be on the same physical device as the path being deleted. Defaults to os.tmpdir() when that is on the same drive letter as the path being deleted, or ${drive}:\\temp if present, or ${drive}:\\ if not. maxRetries: Windows and Native only. Maximum number of retry attempts in case of EBUSY, EMFILE, and ENFILE errors. Default 10 for Windows implementation, 0 for Native implementation. backoff: Windows only. Rate of exponential backoff for async removal in case of EBUSY, EMFILE, and ENFILE errors. Should be a number greater than 1. Default 1.2 maxBackoff: Windows only. Maximum total backoff time in ms to attempt asynchronous retries in case of EBUSY, EMFILE, and ENFILE errors. Default 200. With the default 1.2 backoff rate, this results in 14 retries, with the final retry being delayed 33ms. retryDelay: Native only. Time to wait between retries, using linear backoff. Default 100. signal Pass in an AbortSignal to cancel the directory removal. This is useful when removing large folder structures, if you'd like to limit the amount of time spent. Using a signal option prevents the use of Node's built-in fs.rm because that implementation does not support abort signals. glob Boolean flag to treat path as glob pattern, or an object specifying glob options. filter Method that returns a boolean indicating whether that path should be deleted. With async rimraf methods, this may return a Promise that resolves to a boolean. (Since Promises are truthy, returning a Promise from a sync filter is the same as just not filtering anything.) The first argument to the filter is the path string. The second argument is either a Dirent or Stats object for that path. (The first path explored will be a Stats, the rest will be Dirent.) If a filter method is provided, it will only remove entries if the filter returns (or resolves to) a truthy value. Omitting a directory will still allow its children to be removed, unless they are also filtered out, but any parents of a filtered entry will not be removed, since the directory would not be empty in that case. Using a filter method prevents the use of Node's built-in fs.rm because that implementation does not support filtering. Any other options are provided to the native Node.js fs.rm implementation when that is used. This will attempt to choose the best implementation, based on Node.js version and process.platform. To force a specific implementation, use one of the other functions provided. rimraf.sync(f, [opts]) rimraf.rimrafSync(f, [opts]) Synchronous form of rimraf() Note that, unlike many file system operations, the synchronous form will typically be significantly slower than the async form, because recursive deletion is extremely parallelizable. rimraf.native(f, [opts]) Uses the built-in fs.rm implementation that Node.js provides. This is used by default on Node.js versions greater than or equal to 14.14.0. rimraf.native.sync(f, [opts]) rimraf.nativeSync(f, [opts]) Synchronous form of rimraf.native rimraf.manual(f, [opts]) Use the JavaScript implementation appropriate for your operating system. rimraf.manual.sync(f, [opts]) rimraf.manualSync(f, opts) Synchronous form of rimraf.manual() rimraf.windows(f, [opts]) JavaScript implementation of file removal appropriate for Windows platforms. Works around unlink and rmdir not being atomic operations, and EPERM when deleting files with certain permission modes. First deletes all non-directory files within the tree, and then removes all directories, which should ideally be empty by that time. When an ENOTEMPTY is raised in the second pass, falls back to the rimraf.moveRemove strategy as needed. rimraf.windows.sync(path, [opts]) rimraf.windowsSync(path, [opts]) Synchronous form of rimraf.windows() rimraf.moveRemove(path, [opts]) Moves all files and folders to the parent directory of path with a temporary filename prior to attempting to remove them. Note that, in cases where the operation fails, this may leave files lying around in the parent directory with names like .file-basename.txt.0.123412341. Until the Windows kernel provides a way to perform atomic unlink and rmdir operations, this is unfortunately unavoidable. To move files to a different temporary directory other than the parent, provide opts.tmp. Note that this must be on the same physical device as the folder being deleted, or else the operation will fail. This is the slowest strategy, but most reliable on Windows platforms. Used as a last-ditch fallback by rimraf.windows(). rimraf.moveRemove.sync(path, [opts]) rimraf.moveRemoveSync(path, [opts]) Synchronous form of rimraf.moveRemove() Command Line Interface rimraf version 4.3.0 Usage: rimraf <path> [<path> ...] Deletes all files and folders at \"path\", recursively. Options: -- Treat all subsequent arguments as paths -h --help Display this usage info --preserve-root Do not remove '/' recursively (default) --no-preserve-root Do not treat '/' specially -G --no-glob Treat arguments as literal paths, not globs (default) -g --glob Treat arguments as glob patterns -v --verbose Be verbose when deleting files, showing them as they are removed. Not compatible with --impl=native -V --no-verbose Be silent when deleting files, showing nothing as they are removed (default) -i --interactive Ask for confirmation before deleting anything Not compatible with --impl=native -I --no-interactive Do not ask for confirmation before deleting --impl=<type> Specify the implementation to use: rimraf: choose the best option (default) native: the built-in implementation in Node.js manual: the platform-specific JS implementation posix: the Posix JS implementation windows: the Windows JS implementation (falls back to move-remove on ENOTEMPTY) move-remove: a slow reliable Windows fallback Implementation-specific options: --tmp=<path> Temp file folder for 'move-remove' implementation --max-retries=<n> maxRetries for 'native' and 'windows' implementations --retry-delay=<n> retryDelay for 'native' implementation, default 100 --backoff=<n> Exponential backoff factor for retries (default: 1.2) mkdirp If you need to create a directory recursively, check out mkdirp."
  },
  "node_modules/rimraf/node_modules/glob/README.html": {
    "href": "node_modules/rimraf/node_modules/glob/README.html",
    "title": "Glob | accouter",
    "keywords": "Glob Match files using the patterns the shell uses. The most correct and second fastest glob implementation in JavaScript. (See Comparison to Other JavaScript Glob Implementations at the bottom of this readme.) Usage Install with npm npm i glob Note the npm package name is not node-glob that's a different thing that was abandoned years ago. Just glob. // load using import import { glob, globSync, globStream, globStreamSync, Glob } from 'glob' // or using commonjs, that's fine, too const { glob, globSync, globStream, globStreamSync, Glob, } = require('glob') // the main glob() and globSync() resolve/return array of filenames // all js files, but don't look in node_modules const jsfiles = await glob('**/*.js', { ignore: 'node_modules/**' }) // pass in a signal to cancel the glob walk const stopAfter100ms = await glob('**/*.css', { signal: AbortSignal.timeout(100), }) // multiple patterns supported as well const images = await glob(['css/*.{png,jpeg}', 'public/*.{png,jpeg}']) // but of course you can do that with the glob pattern also // the sync function is the same, just returns a string[] instead // of Promise<string[]> const imagesAlt = globSync('{css,public}/*.{png,jpeg}') // you can also stream them, this is a Minipass stream const filesStream = globStream(['**/*.dat', 'logs/**/*.log']) // construct a Glob object if you wanna do it that way, which // allows for much faster walks if you have to look in the same // folder multiple times. const g = new Glob('**/foo', {}) // glob objects are async iterators, can also do globIterate() or // g.iterate(), same deal for await (const file of g) { console.log('found a foo file:', file) } // pass a glob as the glob options to reuse its settings and caches const g2 = new Glob('**/bar', g) // sync iteration works as well for (const file of g2) { console.log('found a bar file:', file) } // you can also pass withFileTypes: true to get Path objects // these are like a Dirent, but with some more added powers // check out http://npm.im/path-scurry for more info on their API const g3 = new Glob('**/baz/**', { withFileTypes: true }) g3.stream().on('data', path => { console.log( 'got a path object', path.fullpath(), path.isDirectory(), path.readdirSync().map(e => e.name), ) }) // if you use stat:true and withFileTypes, you can sort results // by things like modified time, filter by permission mode, etc. // All Stats fields will be available in that case. Slightly // slower, though. // For example: const results = await glob('**', { stat: true, withFileTypes: true }) const timeSortedFiles = results .sort((a, b) => a.mtimeMs - b.mtimeMs) .map(path => path.fullpath()) const groupReadableFiles = results .filter(path => path.mode & 0o040) .map(path => path.fullpath()) // custom ignores can be done like this, for example by saying // you'll ignore all markdown files, and all folders named 'docs' const customIgnoreResults = await glob('**', { ignore: { ignored: p => /\\.md$/.test(p.name), childrenIgnored: p => p.isNamed('docs'), }, }) // another fun use case, only return files with the same name as // their parent folder, plus either `.ts` or `.js` const folderNamedModules = await glob('**/*.{ts,js}', { ignore: { ignored: p => { const pp = p.parent return !(p.isNamed(pp.name + '.ts') || p.isNamed(pp.name + '.js')) }, }, }) // find all files edited in the last hour, to do this, we ignore // all of them that are more than an hour old const newFiles = await glob('**', { // need stat so we have mtime stat: true, // only want the files, not the dirs nodir: true, ignore: { ignored: p => { return new Date() - p.mtime > 60 * 60 * 1000 }, // could add similar childrenIgnored here as well, but // directory mtime is inconsistent across platforms, so // probably better not to, unless you know the system // tracks this reliably. }, }) Note Glob patterns should always use / as a path separator, even on Windows systems, as \\ is used to escape glob characters. If you wish to use \\ as a path separator instead of using it as an escape character on Windows platforms, you may set windowsPathsNoEscape:true in the options. In this mode, special glob characters cannot be escaped, making it impossible to match a literal * ? and so on in filenames. Command Line Interface $ glob -h Usage: glob [options] [<pattern> [<pattern> ...]] Expand the positional glob expression arguments into any matching file system paths found. -c<command> --cmd=<command> Run the command provided, passing the glob expression matches as arguments. -A --all By default, the glob cli command will not expand any arguments that are an exact match to a file on disk. This prevents double-expanding, in case the shell expands an argument whose filename is a glob expression. For example, if 'app/*.ts' would match 'app/[id].ts', then on Windows powershell or cmd.exe, 'glob app/*.ts' will expand to 'app/[id].ts', as expected. However, in posix shells such as bash or zsh, the shell will first expand 'app/*.ts' to a list of filenames. Then glob will look for a file matching 'app/[id].ts' (ie, 'app/i.ts' or 'app/d.ts'), which is unexpected. Setting '--all' prevents this behavior, causing glob to treat ALL patterns as glob expressions to be expanded, even if they are an exact match to a file on disk. When setting this option, be sure to enquote arguments so that the shell will not expand them prior to passing them to the glob command process. -a --absolute Expand to absolute paths -d --dot-relative Prepend './' on relative matches -m --mark Append a / on any directories matched -x --posix Always resolve to posix style paths, using '/' as the directory separator, even on Windows. Drive letter absolute matches on Windows will be expanded to their full resolved UNC maths, eg instead of 'C:\\foo\\bar', it will expand to '//?/C:/foo/bar'. -f --follow Follow symlinked directories when expanding '**' -R --realpath Call 'fs.realpath' on all of the results. In the case of an entry that cannot be resolved, the entry is omitted. This incurs a slight performance penalty, of course, because of the added system calls. -s --stat Call 'fs.lstat' on all entries, whether required or not to determine if it's a valid match. -b --match-base Perform a basename-only match if the pattern does not contain any slash characters. That is, '*.js' would be treated as equivalent to '**/*.js', matching js files in all directories. --dot Allow patterns to match files/directories that start with '.', even if the pattern does not start with '.' --nobrace Do not expand {...} patterns --nocase Perform a case-insensitive match. This defaults to 'true' on macOS and Windows platforms, and false on all others. Note: 'nocase' should only be explicitly set when it is known that the filesystem's case sensitivity differs from the platform default. If set 'true' on case-insensitive file systems, then the walk may return more or less results than expected. --nodir Do not match directories, only files. Note: to *only* match directories, append a '/' at the end of the pattern. --noext Do not expand extglob patterns, such as '+(a|b)' --noglobstar Do not expand '**' against multiple path portions. Ie, treat it as a normal '*' instead. --windows-path-no-escape Use '\\' as a path separator *only*, and *never* as an escape character. If set, all '\\' characters are replaced with '/' in the pattern. -D<n> --max-depth=<n> Maximum depth to traverse from the current working directory -C<cwd> --cwd=<cwd> Current working directory to execute/match in -r<root> --root=<root> A string path resolved against the 'cwd', which is used as the starting point for absolute patterns that start with '/' (but not drive letters or UNC paths on Windows). Note that this *doesn't* necessarily limit the walk to the 'root' directory, and doesn't affect the cwd starting point for non-absolute patterns. A pattern containing '..' will still be able to traverse out of the root directory, if it is not an actual root directory on the filesystem, and any non-absolute patterns will still be matched in the 'cwd'. To start absolute and non-absolute patterns in the same path, you can use '--root=' to set it to the empty string. However, be aware that on Windows systems, a pattern like 'x:/*' or '//host/share/*' will *always* start in the 'x:/' or '//host/share/' directory, regardless of the --root setting. --platform=<platform> Defaults to the value of 'process.platform' if available, or 'linux' if not. Setting --platform=win32 on non-Windows systems may cause strange behavior! -i<ignore> --ignore=<ignore> Glob patterns to ignore Can be set multiple times -v --debug Output a huge amount of noisy debug information about patterns as they are parsed and used to match files. -h --help Show this usage information glob(pattern: string | string[], options?: GlobOptions) => Promise<string[] | Path[]> Perform an asynchronous glob search for the pattern(s) specified. Returns Path objects if the withFileTypes option is set to true. See below for full options field desciptions. globSync(pattern: string | string[], options?: GlobOptions) => string[] | Path[] Synchronous form of glob(). Alias: glob.sync() globIterate(pattern: string | string[], options?: GlobOptions) => AsyncGenerator<string> Return an async iterator for walking glob pattern matches. Alias: glob.iterate() globIterateSync(pattern: string | string[], options?: GlobOptions) => Generator<string> Return a sync iterator for walking glob pattern matches. Alias: glob.iterate.sync(), glob.sync.iterate() globStream(pattern: string | string[], options?: GlobOptions) => Minipass<string | Path> Return a stream that emits all the strings or Path objects and then emits end when completed. Alias: glob.stream() globStreamSync(pattern: string | string[], options?: GlobOptions) => Minipass<string | Path> Syncronous form of globStream(). Will read all the matches as fast as you consume them, even all in a single tick if you consume them immediately, but will still respond to backpressure if they're not consumed immediately. Alias: glob.stream.sync(), glob.sync.stream() hasMagic(pattern: string | string[], options?: GlobOptions) => boolean Returns true if the provided pattern contains any \"magic\" glob characters, given the options provided. Brace expansion is not considered \"magic\" unless the magicalBraces option is set, as brace expansion just turns one string into an array of strings. So a pattern like 'x{a,b}y' would return false, because 'xay' and 'xby' both do not contain any magic glob characters, and it's treated the same as if you had called it on ['xay', 'xby']. When magicalBraces:true is in the options, brace expansion is treated as a pattern having magic. escape(pattern: string, options?: GlobOptions) => string Escape all magic characters in a glob pattern, so that it will only ever match literal strings If the windowsPathsNoEscape option is used, then characters are escaped by wrapping in [], because a magic character wrapped in a character class can only be satisfied by that exact character. Slashes (and backslashes in windowsPathsNoEscape mode) cannot be escaped or unescaped. unescape(pattern: string, options?: GlobOptions) => string Un-escape a glob string that may contain some escaped characters. If the windowsPathsNoEscape option is used, then square-brace escapes are removed, but not backslash escapes. For example, it will turn the string '[*]' into *, but it will not turn '\\\\*' into '*', because \\ is a path separator in windowsPathsNoEscape mode. When windowsPathsNoEscape is not set, then both brace escapes and backslash escapes are removed. Slashes (and backslashes in windowsPathsNoEscape mode) cannot be escaped or unescaped. Class Glob An object that can perform glob pattern traversals. const g = new Glob(pattern: string | string[], options: GlobOptions) Options object is required. See full options descriptions below. Note that a previous Glob object can be passed as the GlobOptions to another Glob instantiation to re-use settings and caches with a new pattern. Traversal functions can be called multiple times to run the walk again. g.stream() Stream results asynchronously, g.streamSync() Stream results synchronously. g.iterate() Default async iteration function. Returns an AsyncGenerator that iterates over the results. g.iterateSync() Default sync iteration function. Returns a Generator that iterates over the results. g.walk() Returns a Promise that resolves to the results array. g.walkSync() Returns a results array. Properties All options are stored as properties on the Glob object. opts The options provided to the constructor. patterns An array of parsed immutable Pattern objects. Options Exported as GlobOptions TypeScript interface. A GlobOptions object may be provided to any of the exported methods, and must be provided to the Glob constructor. All options are optional, boolean, and false by default, unless otherwise noted. All resolved options are added to the Glob object as properties. If you are running many glob operations, you can pass a Glob object as the options argument to a subsequent operation to share the previously loaded cache. cwd String path or file:// string or URL object. The current working directory in which to search. Defaults to process.cwd(). See also: \"Windows, CWDs, Drive Letters, and UNC Paths\", below. This option may be either a string path or a file:// URL object or string. root A string path resolved against the cwd option, which is used as the starting point for absolute patterns that start with /, (but not drive letters or UNC paths on Windows). Note that this doesn't necessarily limit the walk to the root directory, and doesn't affect the cwd starting point for non-absolute patterns. A pattern containing .. will still be able to traverse out of the root directory, if it is not an actual root directory on the filesystem, and any non-absolute patterns will be matched in the cwd. For example, the pattern /../* with {root:'/some/path'} will return all files in /some, not all files in /some/path. The pattern * with {root:'/some/path'} will return all the entries in the cwd, not the entries in /some/path. To start absolute and non-absolute patterns in the same path, you can use {root:''}. However, be aware that on Windows systems, a pattern like x:/* or //host/share/* will always start in the x:/ or //host/share directory, regardless of the root setting. windowsPathsNoEscape Use \\\\ as a path separator only, and never as an escape character. If set, all \\\\ characters are replaced with / in the pattern. Note that this makes it impossible to match against paths containing literal glob pattern characters, but allows matching with patterns constructed using path.join() and path.resolve() on Windows platforms, mimicking the (buggy!) behavior of Glob v7 and before on Windows. Please use with caution, and be mindful of the caveat below about Windows paths. (For legacy reasons, this is also set if allowWindowsEscape is set to the exact value false.) dot Include .dot files in normal matches and globstar matches. Note that an explicit dot in a portion of the pattern will always match dot files. magicalBraces Treat brace expansion like {a,b} as a \"magic\" pattern. Has no effect if {@link nobrace} is set. Only has effect on the {@link hasMagic} function, no effect on glob pattern matching itself. dotRelative Prepend all relative path strings with ./ (or .\\ on Windows). Without this option, returned relative paths are \"bare\", so instead of returning './foo/bar', they are returned as 'foo/bar'. Relative patterns starting with '../' are not prepended with ./, even if this option is set. mark Add a / character to directory matches. Note that this requires additional stat calls. nobrace Do not expand {a,b} and {1..3} brace sets. noglobstar Do not match ** against multiple filenames. (Ie, treat it as a normal * instead.) noext Do not match \"extglob\" patterns such as +(a|b). nocase Perform a case-insensitive match. This defaults to true on macOS and Windows systems, and false on all others. Note nocase should only be explicitly set when it is known that the filesystem's case sensitivity differs from the platform default. If set true on case-sensitive file systems, or false on case-insensitive file systems, then the walk may return more or less results than expected. maxDepth Specify a number to limit the depth of the directory traversal to this many levels below the cwd. matchBase Perform a basename-only match if the pattern does not contain any slash characters. That is, *.js would be treated as equivalent to **/*.js, matching all js files in all directories. nodir Do not match directories, only files. (Note: to match only directories, put a / at the end of the pattern.) Note: when follow and nodir are both set, then symbolic links to directories are also omitted. stat Call lstat() on all entries, whether required or not to determine whether it's a valid match. When used with withFileTypes, this means that matches will include data such as modified time, permissions, and so on. Note that this will incur a performance cost due to the added system calls. ignore string or string[], or an object with ignore and ignoreChildren methods. If a string or string[] is provided, then this is treated as a glob pattern or array of glob patterns to exclude from matches. To ignore all children within a directory, as well as the entry itself, append '/**' to the ignore pattern. Note ignore patterns are always in dot:true mode, regardless of any other settings. If an object is provided that has ignored(path) and/or childrenIgnored(path) methods, then these methods will be called to determine whether any Path is a match or if its children should be traversed, respectively. follow Follow symlinked directories when expanding ** patterns. This can result in a lot of duplicate references in the presence of cyclic links, and make performance quite bad. By default, a ** in a pattern will follow 1 symbolic link if it is not the first item in the pattern, or none if it is the first item in the pattern, following the same behavior as Bash. Note: when follow and nodir are both set, then symbolic links to directories are also omitted. realpath Set to true to call fs.realpath on all of the results. In the case of an entry that cannot be resolved, the entry is omitted. This incurs a slight performance penalty, of course, because of the added system calls. absolute Set to true to always receive absolute paths for matched files. Set to false to always receive relative paths for matched files. By default, when this option is not set, absolute paths are returned for patterns that are absolute, and otherwise paths are returned that are relative to the cwd setting. This does not make an extra system call to get the realpath, it only does string path resolution. absolute may not be used along with withFileTypes. posix Set to true to use / as the path separator in returned results. On posix systems, this has no effect. On Windows systems, this will return / delimited path results, and absolute paths will be returned in their full resolved UNC path form, eg insted of 'C:\\\\foo\\\\bar', it will return //?/C:/foo/bar. platform Defaults to value of process.platform if available, or 'linux' if not. Setting platform:'win32' on non-Windows systems may cause strange behavior. withFileTypes Return PathScurry Path objects instead of strings. These are similar to a NodeJS Dirent object, but with additional methods and properties. withFileTypes may not be used along with absolute. signal An AbortSignal which will cancel the Glob walk when triggered. fs An override object to pass in custom filesystem methods. See PathScurry docs for what can be overridden. scurry A PathScurry object used to traverse the file system. If the nocase option is set explicitly, then any provided scurry object must match this setting. includeChildMatches boolean, default true. Do not match any children of any matches. For example, the pattern **\\/foo would match a/foo, but not a/foo/b/foo in this mode. This is especially useful for cases like \"find all node_modules folders, but not the ones in node_modules\". In order to support this, the Ignore implementation must support an add(pattern: string) method. If using the default Ignore class, then this is fine, but if this is set to false, and a custom Ignore is provided that does not have an add() method, then it will throw an error. Caveat It only ignores matches that would be a descendant of a previous match, and only if that descendant is matched after the ancestor is encountered. Since the file system walk happens in indeterminate order, it's possible that a match will already be added before its ancestor, if multiple or braced patterns are used. For example: const results = await glob( [ // likely to match first, since it's just a stat 'a/b/c/d/e/f', // this pattern is more complicated! It must to various readdir() // calls and test the results against a regular expression, and that // is certainly going to take a little bit longer. // // So, later on, it encounters a match at 'a/b/c/d/e', but it's too // late to ignore a/b/c/d/e/f, because it's already been emitted. 'a/[bdf]/?/[a-z]/*', ], { includeChildMatches: false }, ) It's best to only set this to false if you can be reasonably sure that no components of the pattern will potentially match one another's file system descendants, or if the occasional included child entry will not cause problems. Glob Primer Much more information about glob pattern expansion can be found by running man bash and searching for Pattern Matching. \"Globs\" are the patterns you type when you do stuff like ls *.js on the command line, or put build/* in a .gitignore file. Before parsing the path part patterns, braced sections are expanded into a set. Braced sections start with { and end with }, with 2 or more comma-delimited sections within. Braced sections may contain slash characters, so a{/b/c,bcd} would expand into a/b/c and abcd. The following characters have special magic meaning when used in a path portion. With the exception of **, none of these match path separators (ie, / on all platforms, and \\ on Windows). * Matches 0 or more characters in a single path portion. When alone in a path portion, it must match at least 1 character. If dot:true is not specified, then * will not match against a . character at the start of a path portion. ? Matches 1 character. If dot:true is not specified, then ? will not match against a . character at the start of a path portion. [...] Matches a range of characters, similar to a RegExp range. If the first character of the range is ! or ^ then it matches any character not in the range. If the first character is ], then it will be considered the same as \\], rather than the end of the character class. !(pattern|pattern|pattern) Matches anything that does not match any of the patterns provided. May not contain / characters. Similar to *, if alone in a path portion, then the path portion must have at least one character. ?(pattern|pattern|pattern) Matches zero or one occurrence of the patterns provided. May not contain / characters. +(pattern|pattern|pattern) Matches one or more occurrences of the patterns provided. May not contain / characters. *(a|b|c) Matches zero or more occurrences of the patterns provided. May not contain / characters. @(pattern|pat*|pat?erN) Matches exactly one of the patterns provided. May not contain / characters. ** If a \"globstar\" is alone in a path portion, then it matches zero or more directories and subdirectories searching for matches. It does not crawl symlinked directories, unless {follow:true} is passed in the options object. A pattern like a/b/** will only match a/b if it is a directory. Follows 1 symbolic link if not the first item in the pattern, or 0 if it is the first item, unless follow:true is set, in which case it follows all symbolic links. [:class:] patterns are supported by this implementation, but [=c=] and [.symbol.] style class patterns are not. Dots If a file or directory path portion has a . as the first character, then it will not match any glob pattern unless that pattern's corresponding path part also has a . as its first character. For example, the pattern a/.*/c would match the file at a/.b/c. However the pattern a/*/c would not, because * does not start with a dot character. You can make glob treat dots as normal characters by setting dot:true in the options. Basename Matching If you set matchBase:true in the options, and the pattern has no slashes in it, then it will seek for any file anywhere in the tree with a matching basename. For example, *.js would match test/simple/basic.js. Empty Sets If no matching files are found, then an empty array is returned. This differs from the shell, where the pattern itself is returned. For example: $ echo a*s*d*f a*s*d*f Comparisons to other fnmatch/glob implementations While strict compliance with the existing standards is a worthwhile goal, some discrepancies exist between node-glob and other implementations, and are intentional. The double-star character ** is supported by default, unless the noglobstar flag is set. This is supported in the manner of bsdglob and bash 5, where ** only has special significance if it is the only thing in a path part. That is, a/**/b will match a/x/y/b, but a/**b will not. Note that symlinked directories are not traversed as part of a **, though their contents may match against subsequent portions of the pattern. This prevents infinite loops and duplicates and the like. You can force glob to traverse symlinks with ** by setting {follow:true} in the options. There is no equivalent of the nonull option. A pattern that does not find any matches simply resolves to nothing. (An empty array, immediately ended stream, etc.) If brace expansion is not disabled, then it is performed before any other interpretation of the glob pattern. Thus, a pattern like +(a|{b),c)}, which would not be valid in bash or zsh, is expanded first into the set of +(a|b) and +(a|c), and those patterns are checked for validity. Since those two are valid, matching proceeds. The character class patterns [:class:] (posix standard named classes) style class patterns are supported and unicode-aware, but [=c=] (locale-specific character collation weight), and [.symbol.] (collating symbol), are not. Repeated Slashes Unlike Bash and zsh, repeated / are always coalesced into a single path separator. Comments and Negation Previously, this module let you mark a pattern as a \"comment\" if it started with a # character, or a \"negated\" pattern if it started with a ! character. These options were deprecated in version 5, and removed in version 6. To specify things that should not match, use the ignore option. Windows Please only use forward-slashes in glob expressions. Though windows uses either / or \\ as its path separator, only / characters are used by this glob implementation. You must use forward-slashes only in glob expressions. Back-slashes will always be interpreted as escape characters, not path separators. Results from absolute patterns such as /foo/* are mounted onto the root setting using path.join. On windows, this will by default result in /foo/* matching C:\\foo\\bar.txt. To automatically coerce all \\ characters to / in pattern strings, thus making it impossible to escape literal glob characters, you may set the windowsPathsNoEscape option to true. Windows, CWDs, Drive Letters, and UNC Paths On posix systems, when a pattern starts with /, any cwd option is ignored, and the traversal starts at /, plus any non-magic path portions specified in the pattern. On Windows systems, the behavior is similar, but the concept of an \"absolute path\" is somewhat more involved. UNC Paths A UNC path may be used as the start of a pattern on Windows platforms. For example, a pattern like: //?/x:/* will return all file entries in the root of the x: drive. A pattern like //ComputerName/Share/* will return all files in the associated share. UNC path roots are always compared case insensitively. Drive Letters A pattern starting with a drive letter, like c:/*, will search in that drive, regardless of any cwd option provided. If the pattern starts with /, and is not a UNC path, and there is an explicit cwd option set with a drive letter, then the drive letter in the cwd is used as the root of the directory traversal. For example, glob('/tmp', { cwd: 'c:/any/thing' }) will return ['c:/tmp'] as the result. If an explicit cwd option is not provided, and the pattern starts with /, then the traversal will run on the root of the drive provided as the cwd option. (That is, it is the result of path.resolve('/').) Race Conditions Glob searching, by its very nature, is susceptible to race conditions, since it relies on directory walking. As a result, it is possible that a file that exists when glob looks for it may have been deleted or modified by the time it returns the result. By design, this implementation caches all readdir calls that it makes, in order to cut down on system overhead. However, this also makes it even more susceptible to races, especially if the cache object is reused between glob calls. Users are thus advised not to use a glob result as a guarantee of filesystem state in the face of rapid changes. For the vast majority of operations, this is never a problem. See Also: man sh man bash Pattern Matching man 3 fnmatch man 5 gitignore minimatch documentation Glob Logo Glob's logo was created by Tanya Brassie. Logo files can be found here. The logo is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License. Contributing Any change to behavior (including bugfixes) must come with a test. Patches that fail tests or reduce performance will be rejected. # to run tests npm test # to re-generate test fixtures npm run test-regen # run the benchmarks npm run bench # to profile javascript npm run prof Comparison to Other JavaScript Glob Implementations tl;dr If you want glob matching that is as faithful as possible to Bash pattern expansion semantics, and as fast as possible within that constraint, use this module. If you are reasonably sure that the patterns you will encounter are relatively simple, and want the absolutely fastest glob matcher out there, use fast-glob. If you are reasonably sure that the patterns you will encounter are relatively simple, and want the convenience of automatically respecting .gitignore files, use globby. There are some other glob matcher libraries on npm, but these three are (in my opinion, as of 2023) the best. full explanation Every library reflects a set of opinions and priorities in the trade-offs it makes. Other than this library, I can personally recommend both globby and fast-glob, though they differ in their benefits and drawbacks. Both have very nice APIs and are reasonably fast. fast-glob is, as far as I am aware, the fastest glob implementation in JavaScript today. However, there are many cases where the choices that fast-glob makes in pursuit of speed mean that its results differ from the results returned by Bash and other sh-like shells, which may be surprising. In my testing, fast-glob is around 10-20% faster than this module when walking over 200k files nested 4 directories deep1. However, there are some inconsistencies with Bash matching behavior that this module does not suffer from: ** only matches files, not directories .. path portions are not handled unless they appear at the start of the pattern ./!(<pattern>) will not match any files that start with <pattern>, even if they do not match <pattern>. For example, !(9).txt will not match 9999.txt. Some brace patterns in the middle of a pattern will result in failing to find certain matches. Extglob patterns are allowed to contain / characters. Globby exhibits all of the same pattern semantics as fast-glob, (as it is a wrapper around fast-glob) and is slightly slower than node-glob (by about 10-20% in the benchmark test set, or in other words, anywhere from 20-50% slower than fast-glob). However, it adds some API conveniences that may be worth the costs. Support for .gitignore and other ignore files. Support for negated globs (ie, patterns starting with ! rather than using a separate ignore option). The priority of this module is \"correctness\" in the sense of performing a glob pattern expansion as faithfully as possible to the behavior of Bash and other sh-like shells, with as much speed as possible. Note that prior versions of node-glob are not on this list. Former versions of this module are far too slow for any cases where performance matters at all, and were designed with APIs that are extremely dated by current JavaScript standards. [1]: In the cases where this module returns results and fast-glob doesn't, it's even faster, of course. Benchmark Results First number is time, smaller is better. Second number is the count of results returned. --- pattern: '**' --- ~~ sync ~~ node fast-glob sync 0m0.598s 200364 node globby sync 0m0.765s 200364 node current globSync mjs 0m0.683s 222656 node current glob syncStream 0m0.649s 222656 ~~ async ~~ node fast-glob async 0m0.350s 200364 node globby async 0m0.509s 200364 node current glob async mjs 0m0.463s 222656 node current glob stream 0m0.411s 222656 --- pattern: '**/..' --- ~~ sync ~~ node fast-glob sync 0m0.486s 0 node globby sync 0m0.769s 200364 node current globSync mjs 0m0.564s 2242 node current glob syncStream 0m0.583s 2242 ~~ async ~~ node fast-glob async 0m0.283s 0 node globby async 0m0.512s 200364 node current glob async mjs 0m0.299s 2242 node current glob stream 0m0.312s 2242 --- pattern: './**/0/**/0/**/0/**/0/**/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.490s 10 node globby sync 0m0.517s 10 node current globSync mjs 0m0.540s 10 node current glob syncStream 0m0.550s 10 ~~ async ~~ node fast-glob async 0m0.290s 10 node globby async 0m0.296s 10 node current glob async mjs 0m0.278s 10 node current glob stream 0m0.302s 10 --- pattern: './**/[01]/**/[12]/**/[23]/**/[45]/**/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.500s 160 node globby sync 0m0.528s 160 node current globSync mjs 0m0.556s 160 node current glob syncStream 0m0.573s 160 ~~ async ~~ node fast-glob async 0m0.283s 160 node globby async 0m0.301s 160 node current glob async mjs 0m0.306s 160 node current glob stream 0m0.322s 160 --- pattern: './**/0/**/0/**/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.502s 5230 node globby sync 0m0.527s 5230 node current globSync mjs 0m0.544s 5230 node current glob syncStream 0m0.557s 5230 ~~ async ~~ node fast-glob async 0m0.285s 5230 node globby async 0m0.305s 5230 node current glob async mjs 0m0.304s 5230 node current glob stream 0m0.310s 5230 --- pattern: '**/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.580s 200023 node globby sync 0m0.771s 200023 node current globSync mjs 0m0.685s 200023 node current glob syncStream 0m0.649s 200023 ~~ async ~~ node fast-glob async 0m0.349s 200023 node globby async 0m0.509s 200023 node current glob async mjs 0m0.427s 200023 node current glob stream 0m0.388s 200023 --- pattern: '{**/*.txt,**/?/**/*.txt,**/?/**/?/**/*.txt,**/?/**/?/**/?/**/*.txt,**/?/**/?/**/?/**/?/**/*.txt}' --- ~~ sync ~~ node fast-glob sync 0m0.589s 200023 node globby sync 0m0.771s 200023 node current globSync mjs 0m0.716s 200023 node current glob syncStream 0m0.684s 200023 ~~ async ~~ node fast-glob async 0m0.351s 200023 node globby async 0m0.518s 200023 node current glob async mjs 0m0.462s 200023 node current glob stream 0m0.468s 200023 --- pattern: '**/5555/0000/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.496s 1000 node globby sync 0m0.519s 1000 node current globSync mjs 0m0.539s 1000 node current glob syncStream 0m0.567s 1000 ~~ async ~~ node fast-glob async 0m0.285s 1000 node globby async 0m0.299s 1000 node current glob async mjs 0m0.305s 1000 node current glob stream 0m0.301s 1000 --- pattern: './**/0/**/../[01]/**/0/../**/0/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.484s 0 node globby sync 0m0.507s 0 node current globSync mjs 0m0.577s 4880 node current glob syncStream 0m0.586s 4880 ~~ async ~~ node fast-glob async 0m0.280s 0 node globby async 0m0.298s 0 node current glob async mjs 0m0.327s 4880 node current glob stream 0m0.324s 4880 --- pattern: '**/????/????/????/????/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.547s 100000 node globby sync 0m0.673s 100000 node current globSync mjs 0m0.626s 100000 node current glob syncStream 0m0.618s 100000 ~~ async ~~ node fast-glob async 0m0.315s 100000 node globby async 0m0.414s 100000 node current glob async mjs 0m0.366s 100000 node current glob stream 0m0.345s 100000 --- pattern: './{**/?{/**/?{/**/?{/**/?,,,,},,,,},,,,},,,}/**/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.588s 100000 node globby sync 0m0.670s 100000 node current globSync mjs 0m0.717s 200023 node current glob syncStream 0m0.687s 200023 ~~ async ~~ node fast-glob async 0m0.343s 100000 node globby async 0m0.418s 100000 node current glob async mjs 0m0.519s 200023 node current glob stream 0m0.451s 200023 --- pattern: '**/!(0|9).txt' --- ~~ sync ~~ node fast-glob sync 0m0.573s 160023 node globby sync 0m0.731s 160023 node current globSync mjs 0m0.680s 180023 node current glob syncStream 0m0.659s 180023 ~~ async ~~ node fast-glob async 0m0.345s 160023 node globby async 0m0.476s 160023 node current glob async mjs 0m0.427s 180023 node current glob stream 0m0.388s 180023 --- pattern: './{*/**/../{*/**/../{*/**/../{*/**/../{*/**,,,,},,,,},,,,},,,,},,,,}/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.483s 0 node globby sync 0m0.512s 0 node current globSync mjs 0m0.811s 200023 node current glob syncStream 0m0.773s 200023 ~~ async ~~ node fast-glob async 0m0.280s 0 node globby async 0m0.299s 0 node current glob async mjs 0m0.617s 200023 node current glob stream 0m0.568s 200023 --- pattern: './*/**/../*/**/../*/**/../*/**/../*/**/../*/**/../*/**/../*/**/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.485s 0 node globby sync 0m0.507s 0 node current globSync mjs 0m0.759s 200023 node current glob syncStream 0m0.740s 200023 ~~ async ~~ node fast-glob async 0m0.281s 0 node globby async 0m0.297s 0 node current glob async mjs 0m0.544s 200023 node current glob stream 0m0.464s 200023 --- pattern: './*/**/../*/**/../*/**/../*/**/../*/**/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.486s 0 node globby sync 0m0.513s 0 node current globSync mjs 0m0.734s 200023 node current glob syncStream 0m0.696s 200023 ~~ async ~~ node fast-glob async 0m0.286s 0 node globby async 0m0.296s 0 node current glob async mjs 0m0.506s 200023 node current glob stream 0m0.483s 200023 --- pattern: './0/**/../1/**/../2/**/../3/**/../4/**/../5/**/../6/**/../7/**/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.060s 0 node globby sync 0m0.074s 0 node current globSync mjs 0m0.067s 0 node current glob syncStream 0m0.066s 0 ~~ async ~~ node fast-glob async 0m0.060s 0 node globby async 0m0.075s 0 node current glob async mjs 0m0.066s 0 node current glob stream 0m0.067s 0 --- pattern: './**/?/**/?/**/?/**/?/**/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.568s 100000 node globby sync 0m0.651s 100000 node current globSync mjs 0m0.619s 100000 node current glob syncStream 0m0.617s 100000 ~~ async ~~ node fast-glob async 0m0.332s 100000 node globby async 0m0.409s 100000 node current glob async mjs 0m0.372s 100000 node current glob stream 0m0.351s 100000 --- pattern: '**/*/**/*/**/*/**/*/**' --- ~~ sync ~~ node fast-glob sync 0m0.603s 200113 node globby sync 0m0.798s 200113 node current globSync mjs 0m0.730s 222137 node current glob syncStream 0m0.693s 222137 ~~ async ~~ node fast-glob async 0m0.356s 200113 node globby async 0m0.525s 200113 node current glob async mjs 0m0.508s 222137 node current glob stream 0m0.455s 222137 --- pattern: './**/*/**/*/**/*/**/*/**/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.622s 200000 node globby sync 0m0.792s 200000 node current globSync mjs 0m0.722s 200000 node current glob syncStream 0m0.695s 200000 ~~ async ~~ node fast-glob async 0m0.369s 200000 node globby async 0m0.527s 200000 node current glob async mjs 0m0.502s 200000 node current glob stream 0m0.481s 200000 --- pattern: '**/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.588s 200023 node globby sync 0m0.771s 200023 node current globSync mjs 0m0.684s 200023 node current glob syncStream 0m0.658s 200023 ~~ async ~~ node fast-glob async 0m0.352s 200023 node globby async 0m0.516s 200023 node current glob async mjs 0m0.432s 200023 node current glob stream 0m0.384s 200023 --- pattern: './**/**/**/**/**/**/**/**/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.589s 200023 node globby sync 0m0.766s 200023 node current globSync mjs 0m0.682s 200023 node current glob syncStream 0m0.652s 200023 ~~ async ~~ node fast-glob async 0m0.352s 200023 node globby async 0m0.523s 200023 node current glob async mjs 0m0.436s 200023 node current glob stream 0m0.380s 200023 --- pattern: '**/*/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.592s 200023 node globby sync 0m0.776s 200023 node current globSync mjs 0m0.691s 200023 node current glob syncStream 0m0.659s 200023 ~~ async ~~ node fast-glob async 0m0.357s 200023 node globby async 0m0.513s 200023 node current glob async mjs 0m0.471s 200023 node current glob stream 0m0.424s 200023 --- pattern: '**/*/**/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.585s 200023 node globby sync 0m0.766s 200023 node current globSync mjs 0m0.694s 200023 node current glob syncStream 0m0.664s 200023 ~~ async ~~ node fast-glob async 0m0.350s 200023 node globby async 0m0.514s 200023 node current glob async mjs 0m0.472s 200023 node current glob stream 0m0.424s 200023 --- pattern: '**/[0-9]/**/*.txt' --- ~~ sync ~~ node fast-glob sync 0m0.544s 100000 node globby sync 0m0.636s 100000 node current globSync mjs 0m0.626s 100000 node current glob syncStream 0m0.621s 100000 ~~ async ~~ node fast-glob async 0m0.322s 100000 node globby async 0m0.404s 100000 node current glob async mjs 0m0.360s 100000 node current glob stream 0m0.352s 100000"
  },
  "node_modules/rimraf/node_modules/minimatch/README.html": {
    "href": "node_modules/rimraf/node_modules/minimatch/README.html",
    "title": "minimatch | accouter",
    "keywords": "minimatch A minimal matching utility. This is the matching library used internally by npm. It works by converting glob expressions into JavaScript RegExp objects. Usage // hybrid module, load with require() or import import { minimatch } from 'minimatch' // or: const { minimatch } = require('minimatch') minimatch('bar.foo', '*.foo') // true! minimatch('bar.foo', '*.bar') // false! minimatch('bar.foo', '*.+(bar|foo)', { debug: true }) // true, and noisy! Features Supports these glob features: Brace Expansion Extended glob matching \"Globstar\" ** matching Posix character classes, like [[:alpha:]], supporting the full range of Unicode characters. For example, [[:alpha:]] will match against 'é', though [a-zA-Z] will not. Collating symbol and set matching is not supported, so [[=e=]] will not match 'é' and [[.ch.]] will not match 'ch' in locales where ch is considered a single character. See: man sh man bash Pattern Matching man 3 fnmatch man 5 gitignore Windows Please only use forward-slashes in glob expressions. Though windows uses either / or \\ as its path separator, only / characters are used by this glob implementation. You must use forward-slashes only in glob expressions. Back-slashes in patterns will always be interpreted as escape characters, not path separators. Note that \\ or / will be interpreted as path separators in paths on Windows, and will match against / in glob expressions. So just always use / in patterns. UNC Paths On Windows, UNC paths like //?/c:/... or //ComputerName/Share/... are handled specially. Patterns starting with a double-slash followed by some non-slash characters will preserve their double-slash. As a result, a pattern like //* will match //x, but not /x. Patterns staring with //?/<drive letter>: will not treat the ? as a wildcard character. Instead, it will be treated as a normal string. Patterns starting with //?/<drive letter>:/... will match file paths starting with <drive letter>:/..., and vice versa, as if the //?/ was not present. This behavior only is present when the drive letters are a case-insensitive match to one another. The remaining portions of the path/pattern are compared case sensitively, unless nocase:true is set. Note that specifying a UNC path using \\ characters as path separators is always allowed in the file path argument, but only allowed in the pattern argument when windowsPathsNoEscape: true is set in the options. Minimatch Class Create a minimatch object by instantiating the minimatch.Minimatch class. var Minimatch = require('minimatch').Minimatch var mm = new Minimatch(pattern, options) Properties pattern The original pattern the minimatch object represents. options The options supplied to the constructor. set A 2-dimensional array of regexp or string expressions. Each row in the array corresponds to a brace-expanded pattern. Each item in the row corresponds to a single path-part. For example, the pattern {a,b/c}/d would expand to a set of patterns like: [ [ a, d ] , [ b, c, d ] ] If a portion of the pattern doesn't have any \"magic\" in it (that is, it's something like \"foo\" rather than fo*o?), then it will be left as a string rather than converted to a regular expression. regexp Created by the makeRe method. A single regular expression expressing the entire pattern. This is useful in cases where you wish to use the pattern somewhat like fnmatch(3) with FNM_PATH enabled. negate True if the pattern is negated. comment True if the pattern is a comment. empty True if the pattern is \"\". Methods makeRe() Generate the regexp member if necessary, and return it. Will return false if the pattern is invalid. match(fname) Return true if the filename matches the pattern, or false otherwise. matchOne(fileArray, patternArray, partial) Take a /-split filename, and match it against a single row in the regExpSet. This method is mainly for internal use, but is exposed so that it can be used by a glob-walker that needs to avoid excessive filesystem calls. hasMagic() Returns true if the parsed pattern contains any magic characters. Returns false if all comparator parts are string literals. If the magicalBraces option is set on the constructor, then it will consider brace expansions which are not otherwise magical to be magic. If not set, then a pattern like a{b,c}d will return false, because neither abd nor acd contain any special glob characters. This does not mean that the pattern string can be used as a literal filename, as it may contain magic glob characters that are escaped. For example, the pattern \\\\* or [*] would not be considered to have magic, as the matching portion parses to the literal string '*' and would match a path named '*', not '\\\\*' or '[*]'. The minimatch.unescape() method may be used to remove escape characters. All other methods are internal, and will be called as necessary. minimatch(path, pattern, options) Main export. Tests a path against the pattern using the options. var isJS = minimatch(file, '*.js', { matchBase: true }) minimatch.filter(pattern, options) Returns a function that tests its supplied argument, suitable for use with Array.filter. Example: var javascripts = fileList.filter(minimatch.filter('*.js', { matchBase: true })) minimatch.escape(pattern, options = {}) Escape all magic characters in a glob pattern, so that it will only ever match literal strings If the windowsPathsNoEscape option is used, then characters are escaped by wrapping in [], because a magic character wrapped in a character class can only be satisfied by that exact character. Slashes (and backslashes in windowsPathsNoEscape mode) cannot be escaped or unescaped. minimatch.unescape(pattern, options = {}) Un-escape a glob string that may contain some escaped characters. If the windowsPathsNoEscape option is used, then square-brace escapes are removed, but not backslash escapes. For example, it will turn the string '[*]' into *, but it will not turn '\\\\*' into '*', because \\ is a path separator in windowsPathsNoEscape mode. When windowsPathsNoEscape is not set, then both brace escapes and backslash escapes are removed. Slashes (and backslashes in windowsPathsNoEscape mode) cannot be escaped or unescaped. minimatch.match(list, pattern, options) Match against the list of files, in the style of fnmatch or glob. If nothing is matched, and options.nonull is set, then return a list containing the pattern itself. var javascripts = minimatch.match(fileList, '*.js', { matchBase: true }) minimatch.makeRe(pattern, options) Make a regular expression object from the pattern. Options All options are false by default. debug Dump a ton of stuff to stderr. nobrace Do not expand {a,b} and {1..3} brace sets. noglobstar Disable ** matching against multiple folder names. dot Allow patterns to match filenames starting with a period, even if the pattern does not explicitly have a period in that spot. Note that by default, a/**/b will not match a/.d/b, unless dot is set. noext Disable \"extglob\" style patterns like +(a|b). nocase Perform a case-insensitive match. nocaseMagicOnly When used with {nocase: true}, create regular expressions that are case-insensitive, but leave string match portions untouched. Has no effect when used without {nocase: true} Useful when some other form of case-insensitive matching is used, or if the original string representation is useful in some other way. nonull When a match is not found by minimatch.match, return a list containing the pattern itself if this option is set. When not set, an empty list is returned if there are no matches. magicalBraces This only affects the results of the Minimatch.hasMagic method. If the pattern contains brace expansions, such as a{b,c}d, but no other magic characters, then the Minimatch.hasMagic() method will return false by default. When this option set, it will return true for brace expansion as well as other magic glob characters. matchBase If set, then patterns without slashes will be matched against the basename of the path if it contains slashes. For example, a?b would match the path /xyz/123/acb, but not /xyz/acb/123. nocomment Suppress the behavior of treating # at the start of a pattern as a comment. nonegate Suppress the behavior of treating a leading ! character as negation. flipNegate Returns from negate expressions the same as if they were not negated. (Ie, true on a hit, false on a miss.) partial Compare a partial path to a pattern. As long as the parts of the path that are present are not contradicted by the pattern, it will be treated as a match. This is useful in applications where you're walking through a folder structure, and don't yet have the full path, but want to ensure that you do not walk down paths that can never be a match. For example, minimatch('/a/b', '/a/*/c/d', { partial: true }) // true, might be /a/b/c/d minimatch('/a/b', '/**/d', { partial: true }) // true, might be /a/b/.../d minimatch('/x/y/z', '/a/**/z', { partial: true }) // false, because x !== a windowsPathsNoEscape Use \\\\ as a path separator only, and never as an escape character. If set, all \\\\ characters are replaced with / in the pattern. Note that this makes it impossible to match against paths containing literal glob pattern characters, but allows matching with patterns constructed using path.join() and path.resolve() on Windows platforms, mimicking the (buggy!) behavior of earlier versions on Windows. Please use with caution, and be mindful of the caveat about Windows paths. For legacy reasons, this is also set if options.allowWindowsEscape is set to the exact value false. windowsNoMagicRoot When a pattern starts with a UNC path or drive letter, and in nocase:true mode, do not convert the root portions of the pattern into a case-insensitive regular expression, and instead leave them as strings. This is the default when the platform is win32 and nocase:true is set. preserveMultipleSlashes By default, multiple / characters (other than the leading // in a UNC path, see \"UNC Paths\" above) are treated as a single /. That is, a pattern like a///b will match the file path a/b. Set preserveMultipleSlashes: true to suppress this behavior. optimizationLevel A number indicating the level of optimization that should be done to the pattern prior to parsing and using it for matches. Globstar parts ** are always converted to * when noglobstar is set, and multiple adjascent ** parts are converted into a single ** (ie, a/**/**/b will be treated as a/**/b, as this is equivalent in all cases). 0 - Make no further changes. In this mode, . and .. are maintained in the pattern, meaning that they must also appear in the same position in the test path string. Eg, a pattern like a/*/../c will match the string a/b/../c but not the string a/c. 1 - (default) Remove cases where a double-dot .. follows a pattern portion that is not **, ., .., or empty ''. For example, the pattern ./a/b/../* is converted to ./a/*, and so it will match the path string ./a/c, but not the path string ./a/b/../c. Dots and empty path portions in the pattern are preserved. 2 (or higher) - Much more aggressive optimizations, suitable for use with file-walking cases: Remove cases where a double-dot .. follows a pattern portion that is not **, ., or empty ''. Remove empty and . portions of the pattern, where safe to do so (ie, anywhere other than the last position, the first position, or the second position in a pattern starting with /, as this may indicate a UNC path on Windows). Convert patterns containing <pre>/**/../<p>/<rest> into the equivalent <pre>/{..,**}/<p>/<rest>, where <p> is a a pattern portion other than ., .., **, or empty ''. Dedupe patterns where a ** portion is present in one and omitted in another, and it is not the final path portion, and they are otherwise equivalent. So {a/**/b,a/b} becomes a/**/b, because ** matches against an empty path portion. Dedupe patterns where a * portion is present in one, and a non-dot pattern other than **, ., .., or '' is in the same position in the other. So a/{*,x}/b becomes a/*/b, because * can match against x. While these optimizations improve the performance of file-walking use cases such as glob (ie, the reason this module exists), there are cases where it will fail to match a literal string that would have been matched in optimization level 1 or 0. Specifically, while the Minimatch.match() method will optimize the file path string in the same ways, resulting in the same matches, it will fail when tested with the regular expression provided by Minimatch.makeRe(), unless the path string is first processed with minimatch.levelTwoFileOptimize() or similar. platform When set to win32, this will trigger all windows-specific behaviors (special handling for UNC paths, and treating \\ as separators in file paths for comparison.) Defaults to the value of process.platform. Comparisons to other fnmatch/glob implementations While strict compliance with the existing standards is a worthwhile goal, some discrepancies exist between minimatch and other implementations. Some are intentional, and some are unavoidable. If the pattern starts with a ! character, then it is negated. Set the nonegate flag to suppress this behavior, and treat leading ! characters normally. This is perhaps relevant if you wish to start the pattern with a negative extglob pattern like !(a|B). Multiple ! characters at the start of a pattern will negate the pattern multiple times. If a pattern starts with #, then it is treated as a comment, and will not match anything. Use \\# to match a literal # at the start of a line, or set the nocomment flag to suppress this behavior. The double-star character ** is supported by default, unless the noglobstar flag is set. This is supported in the manner of bsdglob and bash 4.1, where ** only has special significance if it is the only thing in a path part. That is, a/**/b will match a/x/y/b, but a/**b will not. If an escaped pattern has no matches, and the nonull flag is set, then minimatch.match returns the pattern as-provided, rather than interpreting the character escapes. For example, minimatch.match([], \"\\\\*a\\\\?\") will return \"\\\\*a\\\\?\" rather than \"*a?\". This is akin to setting the nullglob option in bash, except that it does not resolve escaped pattern characters. If brace expansion is not disabled, then it is performed before any other interpretation of the glob pattern. Thus, a pattern like +(a|{b),c)}, which would not be valid in bash or zsh, is expanded first into the set of +(a|b) and +(a|c), and those patterns are checked for validity. Since those two are valid, matching proceeds. Negated extglob patterns are handled as closely as possible to Bash semantics, but there are some cases with negative extglobs which are exceedingly difficult to express in a JavaScript regular expression. In particular the negated pattern <start>!(<pattern>*|)* will in bash match anything that does not start with <start><pattern>. However, <start>!(<pattern>*)* will match paths starting with <start><pattern>, because the empty string can match against the negated portion. In this library, <start>!(<pattern>*|)* will not match any pattern starting with <start>, due to a difference in precisely which patterns are considered \"greedy\" in Regular Expressions vs bash path expansion. This may be fixable, but not without incurring some complexity and performance costs, and the trade-off seems to not be worth pursuing. Note that fnmatch(3) in libc is an extremely naive string comparison matcher, which does not do anything special for slashes. This library is designed to be used in glob searching and file walkers, and so it does do special things with /. Thus, foo* will not match foo/bar in this library, even though it would in fnmatch(3)."
  },
  "node_modules/run-parallel/README.html": {
    "href": "node_modules/run-parallel/README.html",
    "title": "run-parallel | accouter",
    "keywords": "run-parallel Run an array of functions in parallel install npm install run-parallel usage parallel(tasks, [callback]) Run the tasks array of functions in parallel, without waiting until the previous function has completed. If any of the functions pass an error to its callback, the main callback is immediately called with the value of the error. Once the tasks have completed, the results are passed to the final callback as an array. It is also possible to use an object instead of an array. Each property will be run as a function and the results will be passed to the final callback as an object instead of an array. This can be a more readable way of handling the results. arguments tasks - An array or object containing functions to run. Each function is passed a callback(err, result) which it must call on completion with an error err (which can be null) and an optional result value. callback(err, results) - An optional callback to run once all the functions have completed. This function gets a results array (or object) containing all the result arguments passed to the task callbacks. example var parallel = require('run-parallel') parallel([ function (callback) { setTimeout(function () { callback(null, 'one') }, 200) }, function (callback) { setTimeout(function () { callback(null, 'two') }, 100) } ], // optional callback function (err, results) { // the results array will equal ['one','two'] even though // the second function had a shorter timeout. }) This module is basically equavalent to async.parallel, but it's handy to just have the one function you need instead of the kitchen sink. Modularity! Especially handy if you're serving to the browser and need to reduce your javascript bundle size. Works great in the browser with browserify! see also run-auto run-parallel-limit run-series run-waterfall license MIT. Copyright (c) Feross Aboukhadijeh."
  },
  "node_modules/rx/code-of-conduct.html": {
    "href": "node_modules/rx/code-of-conduct.html",
    "title": "Code of Conduct | accouter",
    "keywords": "Code of Conduct Adapted from the Rust Code of Conduct We are committed to providing a friendly, safe and welcoming environment for all, regardless of gender, sexual orientation, disability, ethnicity, religion, or similar personal characteristic. On any communication medium, please avoid using overtly sexual nicknames or other nicknames that might detract from a friendly, safe and welcoming environment for all. Please be kind and courteous. There's no need to be mean or rude. Respect that people have differences of opinion and that every design or implementation choice carries a trade-off and numerous costs. There is seldom a right answer. Please keep unstructured critique to a minimum. If you have solid ideas you want to experiment with, make a fork and see how it works. We will exclude you from interaction if you insult, demean or harass anyone. That is not welcome behavior. We interpret the term \"harassment\" as including the definition in the Citizen Code of Conduct; if you have any lack of clarity about what might be included in that concept, please read their definition. In particular, we don't tolerate behavior that excludes people in socially marginalized groups. Private harassment is also unacceptable. No matter who you are, if you feel you have been or are being harassed or made uncomfortable by a community member, please contact one the RxJS team immediately. Whether you're a regular contributor or a newcomer, we care about making this community a safe place for you and we've got your back. Likewise any spamming, trolling, flaming, baiting or other attention-stealing behavior is not welcome."
  },
  "node_modules/rx/contributing.html": {
    "href": "node_modules/rx/contributing.html",
    "title": "Contributing to RxJS | accouter",
    "keywords": "Contributing to RxJS Want to contribute to the Reactive Extensions for JavaScript (RxJS)? There are many ways of helping whether contributing code, documentation, examples, podcasts, videos and presentations. Get Involved! In the issue tracker, bugs can only be assigned to people who have commit access. Also, we aspire to make as many bugs as possible \"owned\" by assigning them to a core Rx contributor. Therefore, just because a bug is assigned doesn't mean it's being actively worked on. We (the core contributors) are all busy, and welcome help from the community. If you see a bug you'd like to work on that's assigned but appears to be dormant, communicate with the bug's owner with an @-reply in a comment on the issue page. If you see a bug you'd like to work on that's unassigned, it's fair game: comment to say you'd like to work on it so that we know it's getting attention. Pull Requests To make a pull request, you will need a GitHub account; if you're unclear on this process, see GitHub's documentation on forking and pull requests. Pull requests should be targeted at RxJS's master branch. Before pushing to your Github repo and issuing the pull request, please do two things: Rebase your local changes against the master branch. Resolve any conflicts that arise. Run the full RxJS test suite by running grunt in the root of the repository. Pull requests will be treated as \"review requests\", and we will give feedback we expect to see corrected on style and substance before pulling. Changes contributed via pull request should focus on a single issue at a time, like any other. We will not look kindly on pull-requests that try to \"sneak\" unrelated changes in. Note for bug fixes, regression tests should be included, denoted by Issue Number so that we have full traceability. What Are We Looking For? For documentation, we are looking for the following: API Documentation that is missing or out of date \"How Do I?\" examples Comparison to other libraries Comparison to Promises Introduction material Tutorials For coding, we have strict standards that must be adhere to when working on RxJS. In order for us to accept pull requests, they must abide by the following: Coding Standard Tests Documentation Coding Standard For RxJS, we follow the Google JavaScript Style Guide and adhere to it strictly in areas such as documentation using JSDoc. The only exception to extending native prototypes is to polyfill behavior which may not exist in all browsers yet, for example, many of the Array#extras are implemented in compatibility builds. We also strictly follow our design guidelines as well. Supporting Multiple Platforms RxJS runs on a number of platforms and supports many styles of programming. RxJS supports Universal Module Definition (UMD) which allows the library to work in a number of environments such as Asynchronous Module Definition (AMD), CommonJS, Node.js, RingoJS, Narwhal, the browser and other environments such as Windows Script Host (WSH) and embedded devices such as Tessel. RxJS is committed to using the latest JavaScript standards as they start to arrive, for example, supporting generators, Maps, Sets, and Observable versions of new Array methods. We also are committed to supporting legacy code as well through compatibility builds, even supporting browsers back to IE6, Firefox 3, and older versions of Node.js. Should behavior not exist in those platforms, that behavior must be polyfilled, and made available in *.compat.js files only. For example, we have rx.lite.js which supports modern browsers greater than or equal to IE9, and rx.lite.compat.js for older browsers before IE9 and modern Firefox builds. In special cases such as event handling is different, we must provide a mainstream version of the file as well as a compat file, the latter which is included in the compat file. Implementing Custom Operators We welcome custom operators to RxJS if they make sense in the core RxJS, as opposed to belonging in user land. There are a number of rules that must be adhered to when implementing a custom operator including: Prefer composition over implementing a totally new operator from scratch If the operator introduces any notion of concurrency, then a scheduler must introduced. Usage of concurrency primitives such as setTimeout, setInterval, etc are forbidden. This is to ensure easy testability. The scheduler must be optional with the appropriate default picked Rx.Scheduler.immediate for any immediate blocking operations Rx.Scheduler.currentThread for any immediate blocking operators that require re-entrant behavior such as recursive scheduling. Rx.Scheduler.timeout for any operator that has a notion of time To make this concrete, let's implement a custom operator such as an implementation of _.reject from Underscore.js / Lo-Dash. /** * The opposite of _.filter this method returns the elements of a collection that the callback does **not** return truthy for. * @param {Function} [callback] The function called per iteration. * @param {Any} [thisArg] The this binding of callback. * @returns {Observable} An Observable sequence which contains items that the callback does not return truthy for. */ Rx.Observable.prototype.reject = function (callback, thisArg) { callback || (callback = Rx.helpers.identity); var source = this; return new Rx.AnonymousObservable(function (observer) { var i = 0; return source.subscribe( function (x) { var noYield = true; try { noYield = callback.call(thisArg, x, i++, source); } catch (e) { observer.onError(e); return; } if (!noYield) { observer.onNext(x); } }, observer.onError.bind(observer), observer.onCompleted.bind(observer) ); }); }; Of course, we could have implemented this using composition as well, such as using Rx.Observable.prototype.filter. /** * The opposite of _.filter this method returns the elements of a collection that the callback does **not** return truthy for. * @param {Function} [callback] The function called per iteration. * @param {Any} [thisArg] The this binding of callback. * @returns {Observable} An Observable sequence which contains items that the callback does not return truthy for. */ Rx.Observable.prototype.reject = function (callback, thisArg) { callback || (callback = Rx.helpers.identity); return this.filter(function (x, i, o) { return !callback.call(thisArg, x, i o); }); }; To show an operator that introduces a level of concurrency, let's implement a custom operator such as an implementation of _.pairs from Underscore.js / Lo-Dash. Note that since this requires recursion to implement properly, we'll use the Rx.Scheduler.currentThread scheduler. var keysFunction = Object.keys || someKeysPolyfill; /** * Creates an Observable with an of an object’s key-value pairs. * @param {Object} obj The object to inspect. * @returns {Observable} An Observable with an of an object’s key-value pairs. */ Rx.Observable.pairs = function (obj, scheduler) { scheduler || (scheduler = Rx.Scheduler.currentThread); return new Rx.AnonymousObservable(function (observer) { var keys = keysFunction(object), i = 0, len = keys.length; return scheduler.scheduleRecursive(function (self) { if (i < len) { var key = keys[i++], value = obj[key]; observer.onNext([key, value]); self(); } else { observer.onCompleted(); } }); }); }; Note that all operators must have the documentation and must be split out into its own file. This allows us to be able to put it in different files, or make it available in custom builds. Tests When a new operator is written for RxJS, in order to accepted, must be accompanied by tests. RxJS currently uses QUnit as a straight forward way to test our code. These tests are automatically executed by our Grunt setup to concatenate files, minimize, create source maps, and finally run all the tests in the tests folder. Each file that we produce, for example, rx.js has an accompanying test file such as rx.html, which includes tests for all operators included in that file. Each operator under test must be in its own file to cover the following cases: Never Empty Single/Multiple Values Error in the sequence Never ending sequences Early disposal in sequences If the operator has a callback, then it must cover the following cases: Success with all values in the callback Success with the context, if any allowed in the operator signature If an error is thrown To get a good feeling on what kind of rigor is required for testing, check out the following examples: concatMap from Documentation Documentation is also a must, as all external operators and types must be documented and put in the API Folder. Each operator on an Observable must have its own file in the Operators Folder. For operators, they must be linked from the Observable API document. In addition, each operator must be listed in which file it belongs in the Libraries Folder. The standard format of operators must be such as the of operator which includes: File Location Method signature Method description List of Arguments Return type (if there is one) An example File Distribution(s) NuGet Distribution NPM Distribution Unit Tests"
  },
  "node_modules/rx/readme.html": {
    "href": "node_modules/rx/readme.html",
    "title": "The Reactive Extensions for JavaScript (RxJS) 4.0... | accouter",
    "keywords": "The Need to go Reactive | About the Reactive Extensions | Batteries Included | Why RxJS? | Dive In! | Resources | Getting Started | What about my libraries? | Compatibility | Contributing | License The Reactive Extensions for JavaScript (RxJS) 4.0... ...is a set of libraries to compose asynchronous and event-based programs using observable collections and Array#extras style composition in JavaScript The project is actively developed by Microsoft, in collaboration with a community of open source developers. The Need to go Reactive Applications, especially on the web have changed over the years from being a simple static page, to DHTML with animations, to the Ajax revolution. Each time, we're adding more complexity, more data, and asynchronous behavior to our applications. How do we manage it all? How do we scale it? By moving towards \"Reactive Architectures\" which are event-driven, resilient and responsive. With the Reactive Extensions, you have all the tools you need to help build these systems. About the Reactive Extensions The Reactive Extensions for JavaScript (RxJS) is a set of libraries for composing asynchronous and event-based programs using observable sequences and fluent query operators that many of you already know by Array#extras in JavaScript. Using RxJS, developers represent asynchronous data streams with Observables, query asynchronous data streams using our many operators, and parameterize the concurrency in the asynchronous data streams using Schedulers. Simply put, RxJS = Observables + Operators + Schedulers. Whether you are authoring a web-based application in JavaScript or a server-side application in Node.js, you have to deal with asynchronous and event-based programming. Although some patterns are emerging such as the Promise pattern, handling exceptions, cancellation, and synchronization is difficult and error-prone. Using RxJS, you can represent multiple asynchronous data streams (that come from diverse sources, e.g., stock quote, tweets, computer events, web service requests, etc.), and subscribe to the event stream using the Observer object. The Observable notifies the subscribed Observer instance whenever an event occurs. Because observable sequences are data streams, you can query them using standard query operators implemented by the Observable type. Thus you can filter, project, aggregate, compose and perform time-based operations on multiple events easily by using these operators. In addition, there are a number of other reactive stream specific operators that allow powerful queries to be written. Cancellation, exceptions, and synchronization are also handled gracefully by using the methods on the Observable object. But the best news of all is that you already know how to program like this. Take for example the following JavaScript code, where we get some stock data and then manipulate and iterate the results. /* Get stock data somehow */ const source = getAsyncStockData(); const subscription = source .filter(quote => quote.price > 30) .map(quote => quote.price) .forEach(price => console.log(`Prices higher than $30: ${price}`); Now what if this data were to come as some sort of event, for example a stream, such as a WebSocket? Then we could pretty much write the same query to iterate our data, with very little change. /* Get stock data somehow */ const source = getAsyncStockData(); const subscription = source .filter(quote => quote.price > 30) .map(quote => quote.price) .subscribe( price => console.log(`Prices higher than $30: ${price}`), err => console.log(`Something went wrong: ${err.message}`); ); /* When we're done */ subscription.dispose(); The only difference is that we can handle the errors inline with our subscription. And when we're no longer interested in receiving the data as it comes streaming in, we call dispose on our subscription. Note the use of subscribe instead of forEach. We could also use forEach which is an alias for subscribe but we highly suggest you use subscribe. Batteries Included Sure, there are a lot of libraries to get started with RxJS. Confused on where to get started? Start out with the complete set of operators with rx.all.js, then you can reduce it to the number of operators that you really need, and perhaps stick with something as small as rx.lite.js. If you're an implementor of RxJS, then you can start out with rx.core.js. This set of libraries include: The complete library: rx.all.js Main Libraries: rx.js rx.aggregates.js rx.async.js rx.binding.js rx.coincidence.js rx.experimental.js rx.joinpatterns.js rx.testing.js rx.time.js rx.virtualtime.js Lite Libraries: rx.lite.js rx.lite.extras.js rx.lite.aggregates.js rx.lite.async.js rx.lite.coincidence.js rx.lite.experimental.js rx.lite.joinpatterns.js rx.lite.testing.js rx.lite.time.js rx.lite.virtualtime.js Core Libraries: rx.core.js rx.core.binding.js rx.core.testing.js Why RxJS? One question you may ask yourself is why RxJS? What about Promises? Promises are good for solving asynchronous operations such as querying a service with an XMLHttpRequest, where the expected behavior is one value and then completion. Reactive Extensions for JavaScript unify both the world of Promises, callbacks as well as evented data such as DOM Input, Web Workers, and Web Sockets. Unifying these concepts enables rich composition. To give you an idea about rich composition, we can create an autocompletion service which takes user input from a text input and then throttles queries a service (to avoid flooding the service with calls for every key stroke). First, we'll reference the JavaScript files, including jQuery, although RxJS has no dependencies on jQuery... <script src=\"https://code.jquery.com/jquery.js\"></script> <script src=\"rx.lite.js\"></script> Next, we'll get the user input from an input, listening to the keyup event by using the Rx.Observable.fromEvent method. This will either use the event binding from jQuery, Zepto, AngularJS, Backbone.js and Ember.js if available, and if not, falls back to the native event binding. This gives you consistent ways of thinking of events depending on your framework, so there are no surprises. const $input = $('#input'); const $results = $('#results'); /* Only get the value from each key up */ var keyups = Rx.Observable.fromEvent($input, 'keyup') .pluck('target', 'value') .filter(text => text.length > 2 ); /* Now debounce the input for 500ms */ var debounced = keyups .debounce(500 /* ms */); /* Now get only distinct values, so we eliminate the arrows and other control characters */ var distinct = debounced .distinctUntilChanged(); Now, let's query Wikipedia! In RxJS, we can instantly bind to any Promises A+ implementation through the Rx.Observable.fromPromise method. Or, directly return it and RxJS will wrap it for you. function searchWikipedia (term) { return $.ajax({ url: 'https://en.wikipedia.org/w/api.php', dataType: 'jsonp', data: { action: 'opensearch', format: 'json', search: term } }).promise(); } Once that is created, we can tie together the distinct throttled input and query the service. In this case, we'll call flatMapLatest to get the value and ensure we're not introducing any out of order sequence calls. var suggestions = distinct .flatMapLatest(searchWikipedia); Finally, we call the subscribe method on our observable sequence to start pulling data. suggestions.subscribe( data => { $results .empty() .append($.map(data[1], value => $('<li>').text(value))) }, error=> { $results .empty() .append($('<li>')) .text('Error:' + error); }); And there you have it! Dive In! Please check out: Our Code of Conduct The full documentation Our many great examples Our design guidelines Our contribution guidelines Our complete Unit Tests Our recipes Resources Contact us Twitter @ReactiveX Gitter.im StackOverflow rxjs Tutorials The introduction to Reactive Programming you've been missing 2 minute introduction to Rx Learn RxJS - @jhusain RxJS Koans RxJS Workshop from BuildStuff 2014 Rx Workshop Reactive Programming and MVC RxJS lessons - egghead.io RxJS Training - @andrestaltz Reference Material Rx Marbles RxJS GitBook Intro to Rx 101 Rx Samples Wiki RxJS Design Guidelines Visualizing Reactive Streams Your Mouse is a Database Essential tools RxVision Percussion Books RxJS Intro to Rx Programming Reactive Extensions and LINQ Reactive Programming with RxJS Community Examples Presentations Videos and Podcasts Getting Started There are a number of ways to get started with RxJS. The files are available on cdnjs and jsDelivr. Download the Source git clone https://github.com/Reactive-Extensions/rxjs.git cd ./rxjs Installing with NPM ```bash` $ npm install rx $ npm install -g rx ### Using with Node.js and Ringo.js ```js var Rx = require('rx'); Installing with Bower $ bower install rxjs Installing with Jam $ jam install rx Installing All of RxJS via NuGet $ Install-Package RxJS-All Install individual packages via NuGet: Install-Package RxJS-All Install-Package RxJS-Lite Install-Package RxJS-Main Install-Package RxJS-Aggregates Install-Package RxJS-Async Install-Package RxJS-BackPressure Install-Package RxJS-Binding Install-Package RxJS-Coincidence Install-Package RxJS-Experimental Install-Package RxJS-JoinPatterns Install-Package RxJS-Testing Install-Package RxJS-Time In a Browser: <!-- Just the core RxJS --> <script src=\"rx.js\"></script> <!-- Or all of RxJS minus testing --> <script src=\"rx.all.js\"></script> <!-- Or keeping it lite --> <script src=\"rx.lite.js\"></script> Along with a number of our extras for RxJS: <script src=\"rx.aggregates.js\"></script> <script src=\"rx.async.js\"></script> <script src=\"rx.backpressure.js\"></script> <script src=\"rx.binding.js\"></script> <script src=\"rx.coincidencejs\"></script> <script src=\"rx.experimental.js\"></script> <script src=\"rx.joinpatterns.js\"></script> <script src=\"rx.time.js\"></script> <script src=\"rx.virtualtime.js\"></script> <script src=\"rx.testing.js\"></script> Using RxJS with an AMD loader such as Require.js require({ 'paths': { 'rx': 'path/to/rx-lite.js' } }, ['rx'], (Rx) => { const obs = Rx.Observable.of(42); obs.forEach(x => console.log(x)); }); What about my libraries? The Reactive Extensions for JavaScript have no external dependencies on any library, so they'll work well with just about any library. We provide bridges and support for various libraries including: Node.js React Rx-React RxReact cycle-react Flux Rx-Flux ReactiveFlux Thundercats.js Flurx RR Ember RxEmber AngularJS HTML DOM jQuery (1.4+) MooTools Dojo 1.7+ ExtJS Compatibility RxJS has been thoroughly tested against all major browsers and supports IE6+, Chrome 4+, FireFox 1+, and Node.js v0.4+. Contributing There are lots of ways to contribute to the project, and we appreciate our contributors. If you wish to contribute, check out our style guide. You can contribute by reviewing and sending feedback on code checkins, suggesting and trying out new features as they are implemented, submit bugs and help us verify fixes as they are checked in, as well as submit code fixes or code contributions of your own. Note that all code submissions will be rigorously reviewed and tested by the Rx Team, and only those that meet an extremely high bar for both quality and design/roadmap appropriateness will be merged into the source. First-time contributors must sign a Contribution License Agreement. If your Pull Request has the label cla-required, this is an indication that you haven't yet signed such an agreement. License Copyright (c) Microsoft Open Technologies, Inc. All rights reserved. Microsoft Open Technologies would like to thank its contributors, a list of whom are at https://github.com/Reactive-Extensions/RxJS/wiki/Contributors. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
  },
  "node_modules/safe-array-concat/CHANGELOG.html": {
    "href": "node_modules/safe-array-concat/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.1.2 - 2024-03-09 Commits [types] use a generic a1d744d [Dev Deps] update @ljharb/tsconfig, set-function-length 3d3da0a v1.1.1 - 2024-03-09 Commits [types] use shared config f509f80 [actions] remove redundant finisher; use reusable workflows b5f5ff4 [types] use handwritten d.ts instead of emit e717048 [Dev Deps] update set-function-length, tape dde26a7 [Deps] update call-bind, get-intrinsic d5d2cde [Dev Deps] update tape 9454c5a [Tests] add @arethetypeswrong/cli [00a5243`](https://github.com/ljharb/safe-array-concat/commit/00a5243a5b923ff2b694b3b5ef4ce39027e30f6e) [Deps] update get-intrinsic c935764 v1.1.0 - 2024-01-15 Commits [New] add types bd92413 [Dev Deps] update aud, mock-property, npmignore, set-function-length, tape 497ffcb [Deps] update call-bind, get-intrinsic 770f870 [Dev Deps] update mock-property, tape be76bd9 [Tests] use set-function-length/env 89b1167 [meta] add missing npmrc values 3185cc7 [meta] add sideEffects flag df6c7eb v1.0.1 - 2023-09-05 Fixed [Perf] set Symbol.isConcatSpreadable only when required #2 Commits [Dev Deps] update @ljharb/eslint-config, aud, tape c0791b0 [Deps] update get-intrinsic 7d07ae6 v1.0.0 - 2023-04-20 Commits Initial implementation, tests, readme 31b8e70 Initial commit 83d38c6 npm init 516fdc2 Only apps should have lockfiles 9cfa07b"
  },
  "node_modules/safe-array-concat/README.html": {
    "href": "node_modules/safe-array-concat/README.html",
    "title": "safe-array-concat | accouter",
    "keywords": "safe-array-concat Array.prototype.concat, but made safe by ignoring Symbol.isConcatSpreadable Getting started npm install --save safe-array-concat Usage/Examples var safeConcat = require('safe-array-concat'); var assert = require('assert'); assert.deepEqual([].concat([1, 2], 3, [[4]]), [1, 2, 3, [4]], 'arrays spread as expected with normal concat'); assert.deepEqual(safeConcat([1, 2], 3, [[4]]), [1, 2, 3, [4]], 'arrays spread as expected with safe concat'); String.prototype[Symbol.isConcatSpreadable] = true; assert.deepEqual([].concat('foo', Object('bar')), ['foo', 'b', 'a', 'r'], 'spreadable String objects are spread with normal concat!!!'); assert.deepEqual(safeConcat('foo', Object('bar')), ['foo', Object('bar')], 'spreadable String objects are not spread with safe concat'); Array.prototype[Symbol.isConcatSpreadable] = false; assert.deepEqual([].concat([1, 2], 3, [[4]]), [[], [1, 2], 3, [[4]]], 'non-concat-spreadable arrays do not spread with normal concat!!!'); assert.deepEqual(safeConcat([1, 2], 3, [[4]]), [1, 2, 3, [4]], 'non-concat-spreadable arrays still spread with safe concat'); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/safe-buffer/README.html": {
    "href": "node_modules/safe-buffer/README.html",
    "title": "safe-buffer | accouter",
    "keywords": "safe-buffer Safer Node.js Buffer API Use the new Node.js Buffer APIs (Buffer.from, Buffer.alloc, Buffer.allocUnsafe, Buffer.allocUnsafeSlow) in all versions of Node.js. Uses the built-in implementation when available. install npm install safe-buffer usage The goal of this package is to provide a safe replacement for the node.js Buffer. It's a drop-in replacement for Buffer. You can use it by adding one require line to the top of your node.js modules: var Buffer = require('safe-buffer').Buffer // Existing buffer code will continue to work without issues: new Buffer('hey', 'utf8') new Buffer([1, 2, 3], 'utf8') new Buffer(obj) new Buffer(16) // create an uninitialized buffer (potentially unsafe) // But you can use these new explicit APIs to make clear what you want: Buffer.from('hey', 'utf8') // convert from many types to a Buffer Buffer.alloc(16) // create a zero-filled buffer (safe) Buffer.allocUnsafe(16) // create an uninitialized buffer (potentially unsafe) api Class Method: Buffer.from(array) array {Array} Allocates a new Buffer using an array of octets. const buf = Buffer.from([0x62,0x75,0x66,0x66,0x65,0x72]); // creates a new Buffer containing ASCII bytes // ['b','u','f','f','e','r'] A TypeError will be thrown if array is not an Array. Class Method: Buffer.from(arrayBuffer[, byteOffset[, length]]) arrayBuffer {ArrayBuffer} The .buffer property of a TypedArray or a new ArrayBuffer() byteOffset {Number} Default: 0 length {Number} Default: arrayBuffer.length - byteOffset When passed a reference to the .buffer property of a TypedArray instance, the newly created Buffer will share the same allocated memory as the TypedArray. const arr = new Uint16Array(2); arr[0] = 5000; arr[1] = 4000; const buf = Buffer.from(arr.buffer); // shares the memory with arr; console.log(buf); // Prints: <Buffer 88 13 a0 0f> // changing the TypedArray changes the Buffer also arr[1] = 6000; console.log(buf); // Prints: <Buffer 88 13 70 17> The optional byteOffset and length arguments specify a memory range within the arrayBuffer that will be shared by the Buffer. const ab = new ArrayBuffer(10); const buf = Buffer.from(ab, 0, 2); console.log(buf.length); // Prints: 2 A TypeError will be thrown if arrayBuffer is not an ArrayBuffer. Class Method: Buffer.from(buffer) buffer {Buffer} Copies the passed buffer data onto a new Buffer instance. const buf1 = Buffer.from('buffer'); const buf2 = Buffer.from(buf1); buf1[0] = 0x61; console.log(buf1.toString()); // 'auffer' console.log(buf2.toString()); // 'buffer' (copy is not changed) A TypeError will be thrown if buffer is not a Buffer. Class Method: Buffer.from(str[, encoding]) str {String} String to encode. encoding {String} Encoding to use, Default: 'utf8' Creates a new Buffer containing the given JavaScript string str. If provided, the encoding parameter identifies the character encoding. If not provided, encoding defaults to 'utf8'. const buf1 = Buffer.from('this is a tést'); console.log(buf1.toString()); // prints: this is a tést console.log(buf1.toString('ascii')); // prints: this is a tC)st const buf2 = Buffer.from('7468697320697320612074c3a97374', 'hex'); console.log(buf2.toString()); // prints: this is a tést A TypeError will be thrown if str is not a string. Class Method: Buffer.alloc(size[, fill[, encoding]]) size {Number} fill {Value} Default: undefined encoding {String} Default: utf8 Allocates a new Buffer of size bytes. If fill is undefined, the Buffer will be zero-filled. const buf = Buffer.alloc(5); console.log(buf); // <Buffer 00 00 00 00 00> The size must be less than or equal to the value of require('buffer').kMaxLength (on 64-bit architectures, kMaxLength is (2^31)-1). Otherwise, a [RangeError][] is thrown. A zero-length Buffer will be created if a size less than or equal to 0 is specified. If fill is specified, the allocated Buffer will be initialized by calling buf.fill(fill). See [buf.fill()][] for more information. const buf = Buffer.alloc(5, 'a'); console.log(buf); // <Buffer 61 61 61 61 61> If both fill and encoding are specified, the allocated Buffer will be initialized by calling buf.fill(fill, encoding). For example: const buf = Buffer.alloc(11, 'aGVsbG8gd29ybGQ=', 'base64'); console.log(buf); // <Buffer 68 65 6c 6c 6f 20 77 6f 72 6c 64> Calling Buffer.alloc(size) can be significantly slower than the alternative Buffer.allocUnsafe(size) but ensures that the newly created Buffer instance contents will never contain sensitive data. A TypeError will be thrown if size is not a number. Class Method: Buffer.allocUnsafe(size) size {Number} Allocates a new non-zero-filled Buffer of size bytes. The size must be less than or equal to the value of require('buffer').kMaxLength (on 64-bit architectures, kMaxLength is (2^31)-1). Otherwise, a [RangeError][] is thrown. A zero-length Buffer will be created if a size less than or equal to 0 is specified. The underlying memory for Buffer instances created in this way is not initialized. The contents of the newly created Buffer are unknown and may contain sensitive data. Use [buf.fill(0)][] to initialize such Buffer instances to zeroes. const buf = Buffer.allocUnsafe(5); console.log(buf); // <Buffer 78 e0 82 02 01> // (octets will be different, every time) buf.fill(0); console.log(buf); // <Buffer 00 00 00 00 00> A TypeError will be thrown if size is not a number. Note that the Buffer module pre-allocates an internal Buffer instance of size Buffer.poolSize that is used as a pool for the fast allocation of new Buffer instances created using Buffer.allocUnsafe(size) (and the deprecated new Buffer(size) constructor) only when size is less than or equal to Buffer.poolSize >> 1 (floor of Buffer.poolSize divided by two). The default value of Buffer.poolSize is 8192 but can be modified. Use of this pre-allocated internal memory pool is a key difference between calling Buffer.alloc(size, fill) vs. Buffer.allocUnsafe(size).fill(fill). Specifically, Buffer.alloc(size, fill) will never use the internal Buffer pool, while Buffer.allocUnsafe(size).fill(fill) will use the internal Buffer pool if size is less than or equal to half Buffer.poolSize. The difference is subtle but can be important when an application requires the additional performance that Buffer.allocUnsafe(size) provides. Class Method: Buffer.allocUnsafeSlow(size) size {Number} Allocates a new non-zero-filled and non-pooled Buffer of size bytes. The size must be less than or equal to the value of require('buffer').kMaxLength (on 64-bit architectures, kMaxLength is (2^31)-1). Otherwise, a [RangeError][] is thrown. A zero-length Buffer will be created if a size less than or equal to 0 is specified. The underlying memory for Buffer instances created in this way is not initialized. The contents of the newly created Buffer are unknown and may contain sensitive data. Use [buf.fill(0)][] to initialize such Buffer instances to zeroes. When using Buffer.allocUnsafe() to allocate new Buffer instances, allocations under 4KB are, by default, sliced from a single pre-allocated Buffer. This allows applications to avoid the garbage collection overhead of creating many individually allocated Buffers. This approach improves both performance and memory usage by eliminating the need to track and cleanup as many Persistent objects. However, in the case where a developer may need to retain a small chunk of memory from a pool for an indeterminate amount of time, it may be appropriate to create an un-pooled Buffer instance using Buffer.allocUnsafeSlow() then copy out the relevant bits. // need to keep around a few small chunks of memory const store = []; socket.on('readable', () => { const data = socket.read(); // allocate for retained data const sb = Buffer.allocUnsafeSlow(10); // copy the data into the new allocation data.copy(sb, 0, 0, 10); store.push(sb); }); Use of Buffer.allocUnsafeSlow() should be used only as a last resort after a developer has observed undue memory retention in their applications. A TypeError will be thrown if size is not a number. All the Rest The rest of the Buffer API is exactly the same as in node.js. See the docs. Related links Node.js issue: Buffer(number) is unsafe Node.js Enhancement Proposal: Buffer.from/Buffer.alloc/Buffer.zalloc/Buffer() soft-deprecate Why is Buffer unsafe? Today, the node.js Buffer constructor is overloaded to handle many different argument types like String, Array, Object, TypedArrayView (Uint8Array, etc.), ArrayBuffer, and also Number. The API is optimized for convenience: you can throw any type at it, and it will try to do what you want. Because the Buffer constructor is so powerful, you often see code like this: // Convert UTF-8 strings to hex function toHex (str) { return new Buffer(str).toString('hex') } But what happens if toHex is called with a Number argument? Remote Memory Disclosure If an attacker can make your program call the Buffer constructor with a Number argument, then they can make it allocate uninitialized memory from the node.js process. This could potentially disclose TLS private keys, user data, or database passwords. When the Buffer constructor is passed a Number argument, it returns an UNINITIALIZED block of memory of the specified size. When you create a Buffer like this, you MUST overwrite the contents before returning it to the user. From the node.js docs: new Buffer(size) size Number The underlying memory for Buffer instances created in this way is not initialized. The contents of a newly created Buffer are unknown and could contain sensitive data. Use buf.fill(0) to initialize a Buffer to zeroes. (Emphasis our own.) Whenever the programmer intended to create an uninitialized Buffer you often see code like this: var buf = new Buffer(16) // Immediately overwrite the uninitialized buffer with data from another buffer for (var i = 0; i < buf.length; i++) { buf[i] = otherBuf[i] } Would this ever be a problem in real code? Yes. It's surprisingly common to forget to check the type of your variables in a dynamically-typed language like JavaScript. Usually the consequences of assuming the wrong type is that your program crashes with an uncaught exception. But the failure mode for forgetting to check the type of arguments to the Buffer constructor is more catastrophic. Here's an example of a vulnerable service that takes a JSON payload and converts it to hex: // Take a JSON payload {str: \"some string\"} and convert it to hex var server = http.createServer(function (req, res) { var data = '' req.setEncoding('utf8') req.on('data', function (chunk) { data += chunk }) req.on('end', function () { var body = JSON.parse(data) res.end(new Buffer(body.str).toString('hex')) }) }) server.listen(8080) In this example, an http client just has to send: { \"str\": 1000 } and it will get back 1,000 bytes of uninitialized memory from the server. This is a very serious bug. It's similar in severity to the the Heartbleed bug that allowed disclosure of OpenSSL process memory by remote attackers. Which real-world packages were vulnerable? bittorrent-dht Mathias Buus and I (Feross Aboukhadijeh) found this issue in one of our own packages, bittorrent-dht. The bug would allow anyone on the internet to send a series of messages to a user of bittorrent-dht and get them to reveal 20 bytes at a time of uninitialized memory from the node.js process. Here's the commit that fixed it. We released a new fixed version, created a Node Security Project disclosure, and deprecated all vulnerable versions on npm so users will get a warning to upgrade to a newer version. ws That got us wondering if there were other vulnerable packages. Sure enough, within a short period of time, we found the same issue in ws, the most popular WebSocket implementation in node.js. If certain APIs were called with Number parameters instead of String or Buffer as expected, then uninitialized server memory would be disclosed to the remote peer. These were the vulnerable methods: socket.send(number) socket.ping(number) socket.pong(number) Here's a vulnerable socket server with some echo functionality: server.on('connection', function (socket) { socket.on('message', function (message) { message = JSON.parse(message) if (message.type === 'echo') { socket.send(message.data) // send back the user's message } }) }) socket.send(number) called on the server, will disclose server memory. Here's the release where the issue was fixed, with a more detailed explanation. Props to Arnout Kazemier for the quick fix. Here's the Node Security Project disclosure. What's the solution? It's important that node.js offers a fast way to get memory otherwise performance-critical applications would needlessly get a lot slower. But we need a better way to signal our intent as programmers. When we want uninitialized memory, we should request it explicitly. Sensitive functionality should not be packed into a developer-friendly API that loosely accepts many different types. This type of API encourages the lazy practice of passing variables in without checking the type very carefully. A new API: Buffer.allocUnsafe(number) The functionality of creating buffers with uninitialized memory should be part of another API. We propose Buffer.allocUnsafe(number). This way, it's not part of an API that frequently gets user input of all sorts of different types passed into it. var buf = Buffer.allocUnsafe(16) // careful, uninitialized memory! // Immediately overwrite the uninitialized buffer with data from another buffer for (var i = 0; i < buf.length; i++) { buf[i] = otherBuf[i] } How do we fix node.js core? We sent a PR to node.js core (merged as semver-major) which defends against one case: var str = 16 new Buffer(str, 'utf8') In this situation, it's implied that the programmer intended the first argument to be a string, since they passed an encoding as a second argument. Today, node.js will allocate uninitialized memory in the case of new Buffer(number, encoding), which is probably not what the programmer intended. But this is only a partial solution, since if the programmer does new Buffer(variable) (without an encoding parameter) there's no way to know what they intended. If variable is sometimes a number, then uninitialized memory will sometimes be returned. What's the real long-term fix? We could deprecate and remove new Buffer(number) and use Buffer.allocUnsafe(number) when we need uninitialized memory. But that would break 1000s of packages. We believe the best solution is to: 1. Change new Buffer(number) to return safe, zeroed-out memory 2. Create a new API for creating uninitialized Buffers. We propose: Buffer.allocUnsafe(number) Update We now support adding three new APIs: Buffer.from(value) - convert from any type to a buffer Buffer.alloc(size) - create a zero-filled buffer Buffer.allocUnsafe(size) - create an uninitialized buffer with given size This solves the core problem that affected ws and bittorrent-dht which is Buffer(variable) getting tricked into taking a number argument. This way, existing code continues working and the impact on the npm ecosystem will be minimal. Over time, npm maintainers can migrate performance-critical code to use Buffer.allocUnsafe(number) instead of new Buffer(number). Conclusion We think there's a serious design issue with the Buffer API as it exists today. It promotes insecure software by putting high-risk functionality into a convenient API with friendly \"developer ergonomics\". This wasn't merely a theoretical exercise because we found the issue in some of the most popular npm packages. Fortunately, there's an easy fix that can be applied today. Use safe-buffer in place of buffer. var Buffer = require('safe-buffer').Buffer Eventually, we hope that node.js core can switch to this new, safer behavior. We believe the impact on the ecosystem would be minimal since it's not a breaking change. Well-maintained, popular packages would be updated to use Buffer.alloc quickly, while older, insecure packages would magically become safe from this attack vector. links Node.js PR: buffer: throw if both length and enc are passed Node Security Project disclosure for ws Node Security Project disclosure forbittorrent-dht credit The original issues in bittorrent-dht (disclosure) and ws (disclosure) were discovered by Mathias Buus and Feross Aboukhadijeh. Thanks to Adam Baldwin for helping disclose these issues and for his work running the Node Security Project. Thanks to John Hiesey for proofreading this README and auditing the code. license MIT. Copyright (C) Feross Aboukhadijeh"
  },
  "node_modules/safe-regex-test/CHANGELOG.html": {
    "href": "node_modules/safe-regex-test/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.3 - 2024-02-06 Commits [Refactor] use es-errors, so things that only need those do not need get-intrinsic d6ba2f9 [Deps] update call-bind, get-intrinsic 5a3b1d7 [Dev Deps] update tape 75fb719 v1.0.2 - 2024-01-11 Commits [meta] package.json sideEffects should be boolean 094bb88 v1.0.1 - 2024-01-09 Commits [Tests] add nyc for coverage 7e3f525 [Dev Deps] update @ljharb/eslint-config, aud, npmignore, object-inspect, tape e7e0169 [actions] update rebase action 2962694 [readme] add testing badges; remove david-dm badges e9dfd83 [Dev Deps] update @ljharb/eslint-config, aud, object-inspect, tape 496fe99 [Deps] update call-bind, get-intrinsic d94c5ba [meta] add missing engines.node f3d4711 [Deps] update get-intrinsic 0eeedd7 [meta] add sideEffects flag fe1655f v1.0.0 - 2022-09-22 Commits Initial implementation, tests, readme 0273e9f Initial commit b6c1edf npm init c7f5765 Only apps should have lockfiles 1162bf0"
  },
  "node_modules/safe-regex-test/README.html": {
    "href": "node_modules/safe-regex-test/README.html",
    "title": "safe-regex-test | accouter",
    "keywords": "safe-regex-test Give a regex, get a robust predicate function that tests it against a string. This will work even if RegExp.prototype is altered later. Getting started npm install --save safe-regex-test Usage/Examples var regexTester = require('safe-regex-test'); var assert = require('assert'); var tester = regexTester('a'); assert.ok(tester('a')); assert.notOk(tester('b')); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/safer-buffer/Porting-Buffer.html": {
    "href": "node_modules/safer-buffer/Porting-Buffer.html",
    "title": "Porting to the Buffer.from/Buffer.alloc API | accouter",
    "keywords": "Porting to the Buffer.from/Buffer.alloc API Overview Variant 1: Drop support for Node.js ≤ 4.4.x and 5.0.0 — 5.9.x. (recommended) Variant 2: Use a polyfill Variant 3: manual detection, with safeguards Finding problematic bits of code using grep Just run grep -nrE '[^a-zA-Z](Slow)?Buffer\\s*\\(' --exclude-dir node_modules. It will find all the potentially unsafe places in your own code (with some considerably unlikely exceptions). Finding problematic bits of code using Node.js 8 If you’re using Node.js ≥ 8.0.0 (which is recommended), Node.js exposes multiple options that help with finding the relevant pieces of code: --trace-warnings will make Node.js show a stack trace for this warning and other warnings that are printed by Node.js. --trace-deprecation does the same thing, but only for deprecation warnings. --pending-deprecation will show more types of deprecation warnings. In particular, it will show the Buffer() deprecation warning, even on Node.js 8. You can set these flags using an environment variable: $ export NODE_OPTIONS='--trace-warnings --pending-deprecation' $ cat example.js 'use strict'; const foo = new Buffer('foo'); $ node example.js (node:7147) [DEP0005] DeprecationWarning: The Buffer() and new Buffer() constructors are not recommended for use due to security and usability concerns. Please use the new Buffer.alloc(), Buffer.allocUnsafe(), or Buffer.from() construction methods instead. at showFlaggedDeprecation (buffer.js:127:13) at new Buffer (buffer.js:148:3) at Object.<anonymous> (/path/to/example.js:2:13) [... more stack trace lines ...] Finding problematic bits of code using linters Eslint rules no-buffer-constructor or node/no-deprecated-api also find calls to deprecated Buffer() API. Those rules are included in some pre-sets. There is a drawback, though, that it doesn't always work correctly when Buffer is overriden e.g. with a polyfill, so recommended is a combination of this and some other method described above. Variant 1: Drop support for Node.js ≤ 4.4.x and 5.0.0 — 5.9.x. This is the recommended solution nowadays that would imply only minimal overhead. The Node.js 5.x release line has been unsupported since July 2016, and the Node.js 4.x release line reaches its End of Life in April 2018 (→ Schedule). This means that these versions of Node.js will not receive any updates, even in case of security issues, so using these release lines should be avoided, if at all possible. What you would do in this case is to convert all new Buffer() or Buffer() calls to use Buffer.alloc() or Buffer.from(), in the following way: For new Buffer(number), replace it with Buffer.alloc(number). For new Buffer(string) (or new Buffer(string, encoding)), replace it with Buffer.from(string) (or Buffer.from(string, encoding)). For all other combinations of arguments (these are much rarer), also replace new Buffer(...arguments) with Buffer.from(...arguments). Note that Buffer.alloc() is also faster on the current Node.js versions than new Buffer(size).fill(0), which is what you would otherwise need to ensure zero-filling. Enabling eslint rule no-buffer-constructor or node/no-deprecated-api is recommended to avoid accidential unsafe Buffer API usage. There is also a JSCodeshift codemod for automatically migrating Buffer constructors to Buffer.alloc() or Buffer.from(). Note that it currently only works with cases where the arguments are literals or where the constructor is invoked with two arguments. If you currently support those older Node.js versions and dropping them would be a semver-major change for you, or if you support older branches of your packages, consider using Variant 2 or Variant 3 on older branches, so people using those older branches will also receive the fix. That way, you will eradicate potential issues caused by unguarded Buffer API usage and your users will not observe a runtime deprecation warning when running your code on Node.js 10. Variant 2: Use a polyfill Utilize safer-buffer as a polyfill to support older Node.js versions. You would take exacly the same steps as in Variant 1, but with a polyfill const Buffer = require('safer-buffer').Buffer in all files where you use the new Buffer api. Make sure that you do not use old new Buffer API — in any files where the line above is added, using old new Buffer() API will throw. It will be easy to notice that in CI, though. Alternatively, you could use buffer-from and/or buffer-alloc ponyfills — those are great, the only downsides being 4 deps in the tree and slightly more code changes to migrate off them (as you would be using e.g. Buffer.from under a different name). If you need only Buffer.from polyfilled — buffer-from alone which comes with no extra dependencies. Alternatively, you could use safe-buffer — it also provides a polyfill, but takes a different approach which has it's drawbacks. It will allow you to also use the older new Buffer() API in your code, though — but that's arguably a benefit, as it is problematic, can cause issues in your code, and will start emitting runtime deprecation warnings starting with Node.js 10. Note that in either case, it is important that you also remove all calls to the old Buffer API manually — just throwing in safe-buffer doesn't fix the problem by itself, it just provides a polyfill for the new API. I have seen people doing that mistake. Enabling eslint rule no-buffer-constructor or node/no-deprecated-api is recommended. Don't forget to drop the polyfill usage once you drop support for Node.js < 4.5.0. Variant 3 — manual detection, with safeguards This is useful if you create Buffer instances in only a few places (e.g. one), or you have your own wrapper around them. Buffer(0) This special case for creating empty buffers can be safely replaced with Buffer.concat([]), which returns the same result all the way down to Node.js 0.8.x. Buffer(notNumber) Before: var buf = new Buffer(notNumber, encoding); After: var buf; if (Buffer.from && Buffer.from !== Uint8Array.from) { buf = Buffer.from(notNumber, encoding); } else { if (typeof notNumber === 'number') throw new Error('The \"size\" argument must be of type number.'); buf = new Buffer(notNumber, encoding); } encoding is optional. Note that the typeof notNumber before new Buffer is required (for cases when notNumber argument is not hard-coded) and is not caused by the deprecation of Buffer constructor — it's exactly why the Buffer constructor is deprecated. Ecosystem packages lacking this type-check caused numereous security issues — situations when unsanitized user input could end up in the Buffer(arg) create problems ranging from DoS to leaking sensitive information to the attacker from the process memory. When notNumber argument is hardcoded (e.g. literal \"abc\" or [0,1,2]), the typeof check can be omitted. Also note that using TypeScript does not fix this problem for you — when libs written in TypeScript are used from JS, or when user input ends up there — it behaves exactly as pure JS, as all type checks are translation-time only and are not present in the actual JS code which TS compiles to. Buffer(number) For Node.js 0.10.x (and below) support: var buf; if (Buffer.alloc) { buf = Buffer.alloc(number); } else { buf = new Buffer(number); buf.fill(0); } Otherwise (Node.js ≥ 0.12.x): const buf = Buffer.alloc ? Buffer.alloc(number) : new Buffer(number).fill(0); Regarding Buffer.allocUnsafe Be extra cautious when using Buffer.allocUnsafe: Don't use it if you don't have a good reason to e.g. you probably won't ever see a performance difference for small buffers, in fact, those might be even faster with Buffer.alloc(), if your code is not in the hot code path — you also probably won't notice a difference, keep in mind that zero-filling minimizes the potential risks. If you use it, make sure that you never return the buffer in a partially-filled state, if you are writing to it sequentially — always truncate it to the actuall written length Errors in handling buffers allocated with Buffer.allocUnsafe could result in various issues, ranged from undefined behaviour of your code to sensitive data (user input, passwords, certs) leaking to the remote attacker. Note that the same applies to new Buffer usage without zero-filling, depending on the Node.js version (and lacking type checks also adds DoS to the list of potential problems). FAQ What is wrong with the Buffer constructor? The Buffer constructor could be used to create a buffer in many different ways: new Buffer(42) creates a Buffer of 42 bytes. Before Node.js 8, this buffer contained arbitrary memory for performance reasons, which could include anything ranging from program source code to passwords and encryption keys. new Buffer('abc') creates a Buffer that contains the UTF-8-encoded version of the string 'abc'. A second argument could specify another encoding: For example, new Buffer(string, 'base64') could be used to convert a Base64 string into the original sequence of bytes that it represents. There are several other combinations of arguments. This meant that, in code like var buffer = new Buffer(foo);, it is not possible to tell what exactly the contents of the generated buffer are without knowing the type of foo. Sometimes, the value of foo comes from an external source. For example, this function could be exposed as a service on a web server, converting a UTF-8 string into its Base64 form: function stringToBase64(req, res) { // The request body should have the format of `{ string: 'foobar' }` const rawBytes = new Buffer(req.body.string) const encoded = rawBytes.toString('base64') res.end({ encoded: encoded }) } Note that this code does not validate the type of req.body.string: req.body.string is expected to be a string. If this is the case, all goes well. req.body.string is controlled by the client that sends the request. If req.body.string is the number 50, the rawBytes would be 50 bytes: Before Node.js 8, the content would be uninitialized After Node.js 8, the content would be 50 bytes with the value 0 Because of the missing type check, an attacker could intentionally send a number as part of the request. Using this, they can either: Read uninitialized memory. This will leak passwords, encryption keys and other kinds of sensitive information. (Information leak) Force the program to allocate a large amount of memory. For example, when specifying 500000000 as the input value, each request will allocate 500MB of memory. This can be used to either exhaust the memory available of a program completely and make it crash, or slow it down significantly. (Denial of Service) Both of these scenarios are considered serious security issues in a real-world web server context. when using Buffer.from(req.body.string) instead, passing a number will always throw an exception instead, giving a controlled behaviour that can always be handled by the program. The Buffer() constructor has been deprecated for a while. Is this really an issue? Surveys of code in the npm ecosystem have shown that the Buffer() constructor is still widely used. This includes new code, and overall usage of such code has actually been increasing."
  },
  "node_modules/safer-buffer/Readme.html": {
    "href": "node_modules/safer-buffer/Readme.html",
    "title": "safer-buffer | accouter",
    "keywords": "safer-buffer Modern Buffer API polyfill without footguns, working on Node.js from 0.8 to current. How to use? First, port all Buffer() and new Buffer() calls to Buffer.alloc() and Buffer.from() API. Then, to achieve compatibility with outdated Node.js versions (<4.5.0 and 5.x <5.9.0), use const Buffer = require('safer-buffer').Buffer in all files where you make calls to the new Buffer API. Use var instead of const if you need that for your Node.js version range support. Also, see the porting Buffer guide. Do I need it? Hopefully, not — dropping support for outdated Node.js versions should be fine nowdays, and that is the recommended path forward. You do need to port to the Buffer.alloc() and Buffer.from() though. See the porting guide for a better description. Why not safe-buffer? In short: while safe-buffer serves as a polyfill for the new API, it allows old API usage and itself contains footguns. safe-buffer could be used safely to get the new API while still keeping support for older Node.js versions (like this module), but while analyzing ecosystem usage of the old Buffer API I found out that safe-buffer is itself causing problems in some cases. For example, consider the following snippet: $ cat example.unsafe.js console.log(Buffer(20)) $ ./node-v6.13.0-linux-x64/bin/node example.unsafe.js <Buffer 0a 00 00 00 00 00 00 00 28 13 de 02 00 00 00 00 05 00 00 00> $ standard example.unsafe.js standard: Use JavaScript Standard Style (https://standardjs.com) /home/chalker/repo/safer-buffer/example.unsafe.js:2:13: 'Buffer()' was deprecated since v6. Use 'Buffer.alloc()' or 'Buffer.from()' (use 'https://www.npmjs.com/package/safe-buffer' for '<4.5.0') instead. This is allocates and writes to console an uninitialized chunk of memory. standard linter (among others) catch that and warn people to avoid using unsafe API. Let's now throw in safe-buffer! $ cat example.safe-buffer.js const Buffer = require('safe-buffer').Buffer console.log(Buffer(20)) $ standard example.safe-buffer.js $ ./node-v6.13.0-linux-x64/bin/node example.safe-buffer.js <Buffer 08 00 00 00 00 00 00 00 28 58 01 82 fe 7f 00 00 00 00 00 00> See the problem? Adding in safe-buffer magically removes the lint warning, but the behavior remains identiсal to what we had before, and when launched on Node.js 6.x LTS — this dumps out chunks of uninitialized memory. And this code will still emit runtime warnings on Node.js 10.x and above. That was done by design. I first considered changing safe-buffer, prohibiting old API usage or emitting warnings on it, but that significantly diverges from safe-buffer design. After some discussion, it was decided to move my approach into a separate package, and this is that separate package. This footgun is not imaginary — I observed top-downloaded packages doing that kind of thing, «fixing» the lint warning by blindly including safe-buffer without any actual changes. Also in some cases, even if the API was migrated to use of safe Buffer API — a random pull request can bring unsafe Buffer API usage back to the codebase by adding new calls — and that could go unnoticed even if you have a linter prohibiting that (becase of the reason stated above), and even pass CI. I also observed that being done in popular packages. Some examples: webdriverio (a module with 548 759 downloads/month), websocket-stream (218 288 d/m, fix in maxogden/websocket-stream#142), node-serialport (113 138 d/m, fix in node-serialport/node-serialport#1510), karma (3 973 193 d/m, fix in karma-runner/karma#2947), spdy-transport (5 970 727 d/m, fix in spdy-http2/spdy-transport#53). And there are a lot more over the ecosystem. I filed a PR at mysticatea/eslint-plugin-node#110 to partially fix that (for cases when that lint rule is used), but it is a semver-major change for linter rules and presets, so it would take significant time for that to reach actual setups. It also hasn't been released yet (2018-03-20). Also, safer-buffer discourages the usage of .allocUnsafe(), which is often done by a mistake. It still supports it with an explicit concern barier, by placing it under require('safer-buffer/dangereous'). But isn't throwing bad? Not really. It's an error that could be noticed and fixed early, instead of causing havoc later like unguarded new Buffer() calls that end up receiving user input can do. This package affects only the files where var Buffer = require('safer-buffer').Buffer was done, so it is really simple to keep track of things and make sure that you don't mix old API usage with that. Also, CI should hint anything that you might have missed. New commits, if tested, won't land new usage of unsafe Buffer API this way. Node.js 10.x also deals with that by printing a runtime depecation warning. Would it affect third-party modules? No, unless you explicitly do an awful thing like monkey-patching or overriding the built-in Buffer. Don't do that. But I don't want throwing… That is also fine! Also, it could be better in some cases when you don't comprehensive enough test coverage. In that case — just don't override Buffer and use var SaferBuffer = require('safer-buffer').Buffer instead. That way, everything using Buffer natively would still work, but there would be two drawbacks: Buffer.from/Buffer.alloc won't be polyfilled — use SaferBuffer.from and SaferBuffer.alloc instead. You are still open to accidentally using the insecure deprecated API — use a linter to catch that. Note that using a linter to catch accidential Buffer constructor usage in this case is strongly recommended. Buffer is not overriden in this usecase, so linters won't get confused. «Without footguns»? Well, it is still possible to do some things with Buffer API, e.g. accessing .buffer property on older versions and duping things from there. You shouldn't do that in your code, probabably. The intention is to remove the most significant footguns that affect lots of packages in the ecosystem, and to do it in the proper way. Also, this package doesn't protect against security issues affecting some Node.js versions, so for usage in your own production code, it is still recommended to update to a Node.js version supported by upstream."
  },
  "node_modules/sass-true/CHANGELOG.html": {
    "href": "node_modules/sass-true/CHANGELOG.html",
    "title": "True Changelog | accouter",
    "keywords": "True Changelog 8.0.0 (02/23/24) FEATURE: Add True sass option (string or Sass implementation instance, defaults to 'sass') to allow using either sass or embedded-sass. FEATURE: Add the Node.js package importer to the Sass importers option by default, if Dart Sass v1.71 or later is available. Users can opt out by providing their own importers option, e.g. { importers: [] }. BREAKING: Drop support for node < 18 INTERNAL: Remove sass as a peer-dependency. INTERNAL: Update dependencies 7.0.1 (01/04/24) FEATURE: Validate runSass arguments and warn if using v6 API. DOCUMENTATION: Add note that { style: 'compressed' } is not supported. DOCUMENTATION: Add note about possible Jest error and workaround. INTERNAL: Update dependencies 7.0.0 (12/14/22) FEATURE: contains() checks multiple block with matching selectors. #243 BREAKING: Upgrade to newer Sass API Add True sourceType option (path [default] or string) Reverse order of expected arguments to runSass: 1) True options, 2) source path (or string), 3) optional Sass options Note that some of the Sass options have changed. For example, includePaths is now loadPaths, outputStyle is now style, importer is now importers, etc. See the Dart Sass documentation for more details. BREAKING: Require sass (>=1.45.0) as a peer-dependency, removing True sass option BREAKING: Drop support for node < 14.15.0 INTERNAL: Use both Jest and Mocha for internal testing INTERNAL: Remove documentation from npm package INTERNAL: Update dependencies Migrating from v6 runSass arguments have changed: v6: const path = require('path'); const sass = require('node-sass'); const sassTrue = require('sass-true'); const sassFile = path.join(__dirname, 'test.scss'); sassTrue.runSass( // Sass options [required] { file: sassFile, includePaths: ['node_modules'] }, // True options [required] { describe, it, sass }, ); const sassString = ` h1 { font-size: 40px; }`; sassTrue.runSass( // Sass options [required] { data: sassString, includePaths: ['node_modules'], }, // True options [required] { describe, it, sass }, ); v7: const path = require('path'); const sassTrue = require('sass-true'); const sassFile = path.join(__dirname, 'test.scss'); sassTrue.runSass( // True options [required] { describe, it }, // Sass source (path) [required] sassFile, // Sass options [optional] { loadPaths: ['node_modules'] }, ); const sassString = ` h1 { font-size: 40px; }`; sassTrue.runSass( // True options [required] { describe, it, sourceType: 'string' }, // Sass source (string) [required] sassString, // Sass options [optional] { loadPaths: ['node_modules'] }, ); 7.0.0-beta.0 (09/16/22) BREAKING: Upgrade to newer Sass API Add True sourceType option (path [default] or string) Reverse order of expected arguments to runSass: 1) True options, 2) source path (or string), 3) optional Sass options BREAKING: Require sass as a peer-dependency, removing True sass option BREAKING: Drop support for node < 14.15.0 INTERNAL: Use both Jest and Mocha for internal testing INTERNAL: Update dependencies 6.1.0 (03/02/22) No changes since v6.1.0-beta.1 6.1.0-beta.1 (02/24/22) FEATURE: Clearer formatting of failing test diffs #210 INTERNAL: Limit files included in npm package #189 INTERNAL: Convert JS to TypeScript and bundle type definitions #212 -- thanks to @robertmaier for the initial PR #206 INTERNAL: Remove documentation static-site from True repository INTERNAL: Use Jest for internal testing (replaces Mocha) INTERNAL: Switch from Travis CI to GitHub Actions for CI INTERNAL: Update dependencies 6.0.1 (10/16/20) Remove eyeglass specific-version requirement. Update documentation 6.0.0 (07/22/20) BREAKING: Switch to Dart Sass with Sass module system, dropping support for Node Sass. BREAKING: Drop support for node < 10 BREAKING: Rename $true-terminal-output setting to $terminal-output when importing as a module (with @use). Projects not using Sass modules can still @import '<path>/sass-true/sass/true' and access the setting as $true-terminal-output FEATURE: Added _index.scss at the project root, for simpler import path: @use '<path>/sass-true' FEATURE: New sass/_throw.scss module provides: error() function & mixin for establishing \"catchable\" errors global $catch-errors toggles how error() output is handled FEATURE: Support testing content properties which include a curly brace. Update dependencies 5.0.0 (06/03/19) BREAKING: Update API for runSass, which now accepts two arguments: a sassOptions object and a trueOptions object. BREAKING: Drop support for node < 8 Add docs and testing for usage with Jest #135 Add sass option to runSass for passing a different Sass implementation than node-sass #137 Remove node-sass from peerDependencies Fix deprecated use of assert.fail #138 Update dev dependencies 4.0.0 (04/09/18) BREAKING: Move node-sass to peerDependencies Update dependencies Add JS coverage reporting 3.1.0 (03/06/18) NEW: Add contains() mixin for more minute output comparisons. Works the same as expect(), but doesn't require a complete match. Update docs 3.0.2 (10/6/17) Dependency updates 3.0.1 (9/13/17) Update docs 3.0.0 (8/26/17) Update dependencies & release 3.0.0-beta.1 (6/1/17) Added describe and it mixins, as alias for test-module and test respectively. Added $inspect argument to assert-equal and assert-unequal mixins, for comparing inspect($assert) == inspect($expected) instead of $assert == $expected. This helps with several of the equality edge-cases listed below (rounding and units). BREAKING: No more Ruby gem or Ruby CLI BREAKING: No more bower package BREAKING: Removes special-handling of equality, in favor of allowing Sass to determine the best comparisons. There are a few edge-cases to be aware of: In some versions of Sass, manipulated numbers and colors are compared without rounding, so 1/3 != 0.333333 and lighten(#246, 15%) != #356a9f. Use the $inspect argument to compare rounded output values. In all versions of Sass, unitless numbers are considered comparable to all units, so 1 == 1x where x represents any unit. Use the $inspect argument to compare output values with units. Lists compare both values and delimiter, so (one two three) != (one, two, three). This can be particularly confusing for single-item lists, which still have a delimiter assigned, even though it is not used. 2.2.2 (4/11/17) assert-true returns false on empty strings and lists assert-false returns true on empty strings and lists Module/Test/Assertion stats are included in reports 2.2.1 (2/7/17) Output CSS context around Mocha parsing errors. Added $fail-on-error argument to report() mixin. Set to true if you need the Sass compiler to fail on broken tests. Fix bug with assert-false causing it to fail on null values. Allow unquoted descriptions and test/module names. Fix bug throwing off test-count and reporting. 2.1.4 (12/22/16) Fix default assertion messages Upgrade dependencies 2.0.2 (5/13/15) Fixes debug inspector. 2.0.1 (5/9/15) Improve internal logic, and namespace private functions behind _true-*. Add assert(), input, and expect mixins for testing CSS output. Support for LibSass. Add Mocha JS integration. — Create NPM package. Simplify output options down to single $true-terminal-output setting. Add eyeglass support. 1.0.1 (10/18/14) LibSass 3.0 compatability. 1.0.0 (10/3/14) Add command-line interface: true-cli <path-to-file> Use -s flag for silent output Check for unit differences between numbers. Add assertion-failure details to css output. 0.2.0 (7/15/14) Simplified reporting in both terminal and CSS. Remove default-module-output, $default-test-output and $default-final-output. Replace them with $true settings map: (output: css, summary: terminal css). output handles test/module output, summary handles final output. Assertions are always output to the terminal if they fail. Update to use Sass map variables. Add report function and report mixin, for reporting final results. Only register as a compass extension if compass is present. Compass is no longer an explicit dependency. Adjust the output styles to work with Sass 3.4 and have more visual consistency. 0.1.5 (6/10/13) Append actual results to custom failure messages. 0.1.4 (6/9/13) Null result is considered a failure. Allow output to be turned off for certain modules/tests/assertions. 0.1.3 (6/7/13) Nest assertions within test() {} named tests. Cleaner css output. 0.1.2 (6/7/13) Use nesting for modules with test-module() {} Added failure message argument to all assertions. 0.1.1 (6/6/13) Fix bug in lib/true.rb compass plugin registration. 0.1.0 (6/6/13) assert-true(), assert-false(), assert-equal(), and assert-unequal(). pass() and fail() for tracking and reporting individual results. start-test-module() and report-test-result() for module results. Includes tests of the testing tools!"
  },
  "node_modules/sass-true/README.html": {
    "href": "node_modules/sass-true/README.html",
    "title": "True | accouter",
    "keywords": "True To make true; shape, adjust, place, etc., exactly or accurately: True the wheels of a bicycle after striking a pothole. To make even, symmetrical, level, etc. (often followed by up): True up the sides of a door. To test your Sass code; debug, perfect, etc. (often using True): True your sweet plugin before you deploy. True is a unit-testing tool for Sass code. All of the tests are written in plain Sass, and can be compiled using Dart Sass – but we also provide integration with JavaScript test runners (e.g. Mocha or Jest), for extra features and improved reporting. Install In command line: npm install --save-dev sass-true Import in your test directory, like any other Sass file: @use 'pkg:sass-true' as *; If you are not using the Sass Node.js package importer, you may need to include the full path name: // This is only an example, your path may be different @use '../node_modules/sass-true' as *; Or if you are using the JavaScript test runner integration: @use 'true' as *; One Setting $terminal-output (boolean), defaults to true true will show detailed information in the terminal for debugging failed assertions or reporting final results. This is the default, and best for compiling without a JavaScript test runner. false will turn off all terminal output from Sass, though Mocha/Jest will continue to use the terminal for reporting. If you are still using @import rather than @use, there is an import path available - which retains the legacy prefixed $true-terminal-output variable name: // Your path may be different @import '../node_modules/sass-true/sass/true'; Usage True is based on common JS-testing patterns, allowing both a test-module/test syntax, and the newer describe/it for defining the structure: @include test-module('Zip [function]') { @include test('Zips multiple lists into a single multi-dimensional list') { // Assert the expected results @include assert-equal(zip(a b c, 1 2 3), (a 1, b 2, c 3)); } } This is the same as… @include describe('Zip [function]') { @include it('Zips multiple lists into a single multi-dimensional list') { // Assert the expected results @include assert-equal(zip(a b c, 1 2 3), (a 1, b 2, c 3)); } } Sass is able to compare values internally, meaning function-output and variable values can easily be compared and reported during Sass compilation. CSS output tests, on the other hand, have to be compared after compilation is complete. You can do that by hand if you want (git diff is helpful for noticing changes), or you can use a test runner such as Mocha or Jest. Output tests fit the same structure, but assertions take a slightly different form, with an outer assert mixin, and a matching pair of output and expect to contain the output-values. // Test CSS output from mixins @include it('Outputs a font size and line height based on keyword') { @include assert { @include output { @include font-size('large'); } @include expect { font-size: 2rem; line-height: 3rem; } } } You can optionally show a summary report in CSS and/or the command line, after the tests have completed: @include report; See the full documentation online for more details. See CHANGELOG.md when upgrading from an older version of True. Using Mocha, Jest, or other JS test runners Install true via npm: npm install --save-dev sass-true [Optional] Install Dart Sass (sass or sass-embedded), if not already installed. npm install --save-dev sass Write some Sass tests in test/test.scss (see above). Write a shim JS test file in test/sass.test.js: const path = require('node:path'); const sassTrue = require('sass-true'); const sassFile = path.join(__dirname, 'test.scss'); sassTrue.runSass({ describe, it }, sassFile); Run Mocha/Jest, and see your Sass tests reported in the command line. Note: Because of differences between Jest globals and Node globals, Dart Sass often errors when trying to compile in a Jest environment (e.g. J.getInterceptor$ax(...).map$1$1 is not a function). This can usually be fixed by installing jest-environment-node-single-context and setting testEnvironment: 'jest-environment-node-single-context' in jest.config.js. See possible related issues. Note: Jest does not watch for changes in Sass files by default. To use jest --watch with True, add \"scss\" to your moduleFileExtensions setting. You can call runSass more than once, if you have multiple Sass test files you want to run separately. The first argument is an object with required describe and it options, and optional sass, contextLines and sourceType options. Any JS test runner with equivalents to Mocha's or Jest's describe and it should be usable in the same way: just pass your test runner's describe and it equivalents in the first argument to runSass. The sass option is an optional string name of a Dart Sass implementation installed in the current environment (e.g. 'embedded-sass' or 'sass'), or a Dart Sass implementation instance itself. If none is provided, this defaults to 'sass'. If True can't parse the CSS output, it'll give you some context lines of CSS as part of the error message. This context will likely be helpful in understanding the parse failure. By default it provides up to 10 lines of context; if you need more, you can provide a numeric contextLines option: the maximum number of context lines to provide. The second argument is a string representing either the path to a source Sass file (passed through to Sass' compile function), or a string of source Sass (passed through to Sass' compileString function). By default it is expected to be a path, and sass.compile is used. To pass in a source string (and use sass.compileString), add sourceType: 'string' to your options passed in as the first argument to runSass. The third (optional) argument to runSass accepts the same options that Sass' compile or compileString expect (e.g. importers, loadPaths, or style), and these are passed directly through to Sass. By default, True makes two modifications to these options. First, True's sass path is added to the loadPaths option, so @use 'true'; works in your Sass test file. Second, if Dart Sass v1.71 or greater is installed, importers is set to an array containing the Node.js package importer, which supports pkg: imports to resolve @use and @import for external modules installed via npm or Yarn. If importers is set (even as an empty array importers: []), it will override this default importer. Note: True requires the default Sass 'expanded' output style, and will not work if { style: 'compressed' } is used in the third argument to runSass. Custom Importers If you use tilde notation (e.g. @use '~accoutrement/sass/tools') or another method for importing Sass files from node_modules, you'll need to tell runSass how to handle that. That will require writing a custom importer and passing it into the configuration for runSass: const path = require('node:path'); const { pathToFileURL } = require('node:url'); const sassTrue = require('sass-true'); const importers = [ { findFileUrl(url) { if (!url.startsWith('~')) { return null; } return new URL( pathToFileURL(path.resolve('node_modules', url.substring(1))), ); }, }, ]; const sassFile = path.join(__dirname, 'test.scss'); sassTrue.runSass({ describe, it }, sassFile, { importers });"
  },
  "node_modules/sass/README.html": {
    "href": "node_modules/sass/README.html",
    "title": "| accouter",
    "keywords": "A pure JavaScript implementation of Sass. Sass makes CSS fun again. This package is a distribution of Dart Sass, compiled to pure JavaScript with no native code or external dependencies. It provides a command-line sass executable and a Node.js API. Usage See Also Behavioral Differences from Ruby Sass Usage You can install Sass globally using npm install -g sass which will provide access to the sass executable. You can also add it to your project using npm install --save-dev sass. This provides the executable as well as a library: const sass = require('sass'); const result = sass.compile(scssFilename); // OR // Note that `compileAsync()` is substantially slower than `compile()`. const result = await sass.compileAsync(scssFilename); See the Sass website for full API documentation. Legacy API Dart Sass also supports an older JavaScript API that's fully compatible with Node Sass (with a few exceptions listed below), with support for both the render() and renderSync() functions. This API is considered deprecated and will be removed in Dart Sass 2.0.0, so it should be avoided in new projects. Sass's support for the legacy JavaScript API has the following limitations: Only the \"expanded\" and \"compressed\" values of outputStyle are supported. Dart Sass doesn't support the precision option. Dart Sass defaults to a sufficiently high precision for all existing browsers, and making this customizable would make the code substantially less efficient. Dart Sass doesn't support the sourceComments option. Source maps are the recommended way of locating the origin of generated selectors. See Also Dart Sass, from which this package is compiled, can be used either as a stand-alone executable or as a Dart library. Running Dart Sass on the Dart VM is substantially faster than running the pure JavaScript version, so this may be appropriate for performance-sensitive applications. The Dart API is also (currently) more user-friendly than the JavaScript API. See the Dart Sass README for details on how to use it. Node Sass, which is a wrapper around LibSass, the C++ implementation of Sass. Node Sass supports the same API as this package and is also faster (although it's usually a little slower than Dart Sass). However, it requires a native library which may be difficult to install, and it's generally slower to add features and fix bugs. Behavioral Differences from Ruby Sass There are a few intentional behavioral differences between Dart Sass and Ruby Sass. These are generally places where Ruby Sass has an undesired behavior, and it's substantially easier to implement the correct behavior than it would be to implement compatible behavior. These should all have tracking bugs against Ruby Sass to update the reference behavior. @extend only accepts simple selectors, as does the second argument of selector-extend(). See issue 1599. Subject selectors are not supported. See issue 1126. Pseudo selector arguments are parsed as <declaration-value>s rather than having a more limited custom parsing. See issue 2120. The numeric precision is set to 10. See issue 1122. The indented syntax parser is more flexible: it doesn't require consistent indentation across the whole document. See issue 2176. Colors do not support channel-by-channel arithmetic. See issue 2144. Unitless numbers aren't == to unit numbers with the same value. In addition, map keys follow the same logic as ==-equality. See issue 1496. rgba() and hsla() alpha values with percentage units are interpreted as percentages. Other units are forbidden. See issue 1525. Too many variable arguments passed to a function is an error. See issue 1408. Allow @extend to reach outside a media query if there's an identical @extend defined outside that query. This isn't tracked explicitly, because it'll be irrelevant when issue 1050 is fixed. Some selector pseudos containing placeholder selectors will be compiled where they wouldn't be in Ruby Sass. This better matches the semantics of the selectors in question, and is more efficient. See issue 2228. The old-style :property value syntax is not supported in the indented syntax. See issue 2245. The reference combinator is not supported. See issue 303. Universal selector unification is symmetrical. See issue 2247. @extend doesn't produce an error if it matches but fails to unify. See issue 2250. Dart Sass currently only supports UTF-8 documents. We'd like to support more, but Dart currently doesn't support them. See dart-lang/sdk#11744, for example. Disclaimer: this is not an official Google product."
  },
  "node_modules/sass/node_modules/immutable/README.html": {
    "href": "node_modules/sass/node_modules/immutable/README.html",
    "title": "Immutable collections for JavaScript | accouter",
    "keywords": "Immutable collections for JavaScript Chat on slack Read the docs and eat your vegetables. Docs are automatically generated from README.md and immutable.d.ts. Please contribute! Also, don't miss the wiki which contains articles on additional specific topics. Can't find something? Open an issue. Table of contents: Introduction Getting started The case for Immutability JavaScript-first API Nested Structures Equality treats Collections as Values Batching Mutations Lazy Seq Additional Tools and Resources Contributing Introduction Immutable data cannot be changed once created, leading to much simpler application development, no defensive copying, and enabling advanced memoization and change detection techniques with simple logic. Persistent data presents a mutative API which does not update the data in-place, but instead always yields new updated data. Immutable.js provides many Persistent Immutable data structures including: List, Stack, Map, OrderedMap, Set, OrderedSet and Record. These data structures are highly efficient on modern JavaScript VMs by using structural sharing via hash maps tries and vector tries as popularized by Clojure and Scala, minimizing the need to copy or cache data. Immutable.js also provides a lazy Seq, allowing efficient chaining of collection methods like map and filter without creating intermediate representations. Create some Seq with Range and Repeat. Want to hear more? Watch the presentation about Immutable.js: Getting started Install immutable using npm. # using npm npm install immutable # using Yarn yarn add immutable # using pnpm pnpm add immutable # using Bun bun add immutable Then require it into any module. const { Map } = require('immutable'); const map1 = Map({ a: 1, b: 2, c: 3 }); const map2 = map1.set('b', 50); map1.get('b') + ' vs. ' + map2.get('b'); // 2 vs. 50 Browser Immutable.js has no dependencies, which makes it predictable to include in a Browser. It's highly recommended to use a module bundler like webpack, rollup, or browserify. The immutable npm module works without any additional consideration. All examples throughout the documentation will assume use of this kind of tool. Alternatively, Immutable.js may be directly included as a script tag. Download or link to a CDN such as CDNJS or jsDelivr. Use a script tag to directly add Immutable to the global scope: <script src=\"immutable.min.js\"></script> <script> var map1 = Immutable.Map({ a: 1, b: 2, c: 3 }); var map2 = map1.set('b', 50); map1.get('b'); // 2 map2.get('b'); // 50 </script> Or use an AMD-style loader (such as RequireJS): require(['./immutable.min.js'], function (Immutable) { var map1 = Immutable.Map({ a: 1, b: 2, c: 3 }); var map2 = map1.set('b', 50); map1.get('b'); // 2 map2.get('b'); // 50 }); Flow & TypeScript Use these Immutable collections and sequences as you would use native collections in your Flowtype or TypeScript programs while still taking advantage of type generics, error detection, and auto-complete in your IDE. Installing immutable via npm brings with it type definitions for Flow (v0.55.0 or higher) and TypeScript (v2.1.0 or higher), so you shouldn't need to do anything at all! Using TypeScript with Immutable.js v4 Immutable.js type definitions embrace ES2015. While Immutable.js itself supports legacy browsers and environments, its type definitions require TypeScript's 2015 lib. Include either \"target\": \"es2015\" or \"lib\": \"es2015\" in your tsconfig.json, or provide --target es2015 or --lib es2015 to the tsc command. const { Map } = require('immutable'); const map1 = Map({ a: 1, b: 2, c: 3 }); const map2 = map1.set('b', 50); map1.get('b') + ' vs. ' + map2.get('b'); // 2 vs. 50 Using TypeScript with Immutable.js v3 and earlier: Previous versions of Immutable.js include a reference file which you can include via relative path to the type definitions at the top of your file. ///<reference path='./node_modules/immutable/dist/immutable.d.ts'/> import Immutable from 'immutable'; var map1: Immutable.Map<string, number>; map1 = Immutable.Map({ a: 1, b: 2, c: 3 }); var map2 = map1.set('b', 50); map1.get('b'); // 2 map2.get('b'); // 50 The case for Immutability Much of what makes application development difficult is tracking mutation and maintaining state. Developing with immutable data encourages you to think differently about how data flows through your application. Subscribing to data events throughout your application creates a huge overhead of book-keeping which can hurt performance, sometimes dramatically, and creates opportunities for areas of your application to get out of sync with each other due to easy to make programmer error. Since immutable data never changes, subscribing to changes throughout the model is a dead-end and new data can only ever be passed from above. This model of data flow aligns well with the architecture of React and especially well with an application designed using the ideas of Flux. When data is passed from above rather than being subscribed to, and you're only interested in doing work when something has changed, you can use equality. Immutable collections should be treated as values rather than objects. While objects represent some thing which could change over time, a value represents the state of that thing at a particular instance of time. This principle is most important to understanding the appropriate use of immutable data. In order to treat Immutable.js collections as values, it's important to use the Immutable.is() function or .equals() method to determine value equality instead of the === operator which determines object reference identity. const { Map } = require('immutable'); const map1 = Map({ a: 1, b: 2, c: 3 }); const map2 = Map({ a: 1, b: 2, c: 3 }); map1.equals(map2); // true map1 === map2; // false Note: As a performance optimization Immutable.js attempts to return the existing collection when an operation would result in an identical collection, allowing for using === reference equality to determine if something definitely has not changed. This can be extremely useful when used within a memoization function which would prefer to re-run the function if a deeper equality check could potentially be more costly. The === equality check is also used internally by Immutable.is and .equals() as a performance optimization. const { Map } = require('immutable'); const map1 = Map({ a: 1, b: 2, c: 3 }); const map2 = map1.set('b', 2); // Set to same value map1 === map2; // true If an object is immutable, it can be \"copied\" simply by making another reference to it instead of copying the entire object. Because a reference is much smaller than the object itself, this results in memory savings and a potential boost in execution speed for programs which rely on copies (such as an undo-stack). const { Map } = require('immutable'); const map = Map({ a: 1, b: 2, c: 3 }); const mapCopy = map; // Look, \"copies\" are free! JavaScript-first API While Immutable.js is inspired by Clojure, Scala, Haskell and other functional programming environments, it's designed to bring these powerful concepts to JavaScript, and therefore has an Object-Oriented API that closely mirrors that of ES2015 Array, Map, and Set. The difference for the immutable collections is that methods which would mutate the collection, like push, set, unshift or splice, instead return a new immutable collection. Methods which return new arrays, like slice or concat, instead return new immutable collections. const { List } = require('immutable'); const list1 = List([1, 2]); const list2 = list1.push(3, 4, 5); const list3 = list2.unshift(0); const list4 = list1.concat(list2, list3); assert.equal(list1.size, 2); assert.equal(list2.size, 5); assert.equal(list3.size, 6); assert.equal(list4.size, 13); assert.equal(list4.get(0), 1); Almost all of the methods on Array will be found in similar form on Immutable.List, those of Map found on Immutable.Map, and those of Set found on Immutable.Set, including collection operations like forEach() and map(). const { Map } = require('immutable'); const alpha = Map({ a: 1, b: 2, c: 3, d: 4 }); alpha.map((v, k) => k.toUpperCase()).join(); // 'A,B,C,D' Convert from raw JavaScript objects and arrays. Designed to inter-operate with your existing JavaScript, Immutable.js accepts plain JavaScript Arrays and Objects anywhere a method expects a Collection. const { Map, List } = require('immutable'); const map1 = Map({ a: 1, b: 2, c: 3, d: 4 }); const map2 = Map({ c: 10, a: 20, t: 30 }); const obj = { d: 100, o: 200, g: 300 }; const map3 = map1.merge(map2, obj); // Map { a: 20, b: 2, c: 10, d: 100, t: 30, o: 200, g: 300 } const list1 = List([1, 2, 3]); const list2 = List([4, 5, 6]); const array = [7, 8, 9]; const list3 = list1.concat(list2, array); // List [ 1, 2, 3, 4, 5, 6, 7, 8, 9 ] This is possible because Immutable.js can treat any JavaScript Array or Object as a Collection. You can take advantage of this in order to get sophisticated collection methods on JavaScript Objects, which otherwise have a very sparse native API. Because Seq evaluates lazily and does not cache intermediate results, these operations can be extremely efficient. const { Seq } = require('immutable'); const myObject = { a: 1, b: 2, c: 3 }; Seq(myObject) .map(x => x * x) .toObject(); // { a: 1, b: 4, c: 9 } Keep in mind, when using JS objects to construct Immutable Maps, that JavaScript Object properties are always strings, even if written in a quote-less shorthand, while Immutable Maps accept keys of any type. const { fromJS } = require('immutable'); const obj = { 1: 'one' }; console.log(Object.keys(obj)); // [ \"1\" ] console.log(obj['1'], obj[1]); // \"one\", \"one\" const map = fromJS(obj); console.log(map.get('1'), map.get(1)); // \"one\", undefined Property access for JavaScript Objects first converts the key to a string, but since Immutable Map keys can be of any type the argument to get() is not altered. Converts back to raw JavaScript objects. All Immutable.js Collections can be converted to plain JavaScript Arrays and Objects shallowly with toArray() and toObject() or deeply with toJS(). All Immutable Collections also implement toJSON() allowing them to be passed to JSON.stringify directly. They also respect the custom toJSON() methods of nested objects. const { Map, List } = require('immutable'); const deep = Map({ a: 1, b: 2, c: List([3, 4, 5]) }); console.log(deep.toObject()); // { a: 1, b: 2, c: List [ 3, 4, 5 ] } console.log(deep.toArray()); // [ 1, 2, List [ 3, 4, 5 ] ] console.log(deep.toJS()); // { a: 1, b: 2, c: [ 3, 4, 5 ] } JSON.stringify(deep); // '{\"a\":1,\"b\":2,\"c\":[3,4,5]}' Embraces ES2015 Immutable.js supports all JavaScript environments, including legacy browsers (even IE11). However it also takes advantage of features added to JavaScript in ES2015, the latest standard version of JavaScript, including Iterators, Arrow Functions, Classes, and Modules. It's inspired by the native Map and Set collections added to ES2015. All examples in the Documentation are presented in ES2015. To run in all browsers, they need to be translated to ES5. // ES2015 const mapped = foo.map(x => x * x); // ES5 var mapped = foo.map(function (x) { return x * x; }); All Immutable.js collections are Iterable, which allows them to be used anywhere an Iterable is expected, such as when spreading into an Array. const { List } = require('immutable'); const aList = List([1, 2, 3]); const anArray = [0, ...aList, 4, 5]; // [ 0, 1, 2, 3, 4, 5 ] Note: A Collection is always iterated in the same order, however that order may not always be well defined, as is the case for the Map and Set. Nested Structures The collections in Immutable.js are intended to be nested, allowing for deep trees of data, similar to JSON. const { fromJS } = require('immutable'); const nested = fromJS({ a: { b: { c: [3, 4, 5] } } }); // Map { a: Map { b: Map { c: List [ 3, 4, 5 ] } } } A few power-tools allow for reading and operating on nested data. The most useful are mergeDeep, getIn, setIn, and updateIn, found on List, Map and OrderedMap. const { fromJS } = require('immutable'); const nested = fromJS({ a: { b: { c: [3, 4, 5] } } }); const nested2 = nested.mergeDeep({ a: { b: { d: 6 } } }); // Map { a: Map { b: Map { c: List [ 3, 4, 5 ], d: 6 } } } console.log(nested2.getIn(['a', 'b', 'd'])); // 6 const nested3 = nested2.updateIn(['a', 'b', 'd'], value => value + 1); console.log(nested3); // Map { a: Map { b: Map { c: List [ 3, 4, 5 ], d: 7 } } } const nested4 = nested3.updateIn(['a', 'b', 'c'], list => list.push(6)); // Map { a: Map { b: Map { c: List [ 3, 4, 5, 6 ], d: 7 } } } Equality treats Collections as Values Immutable.js collections are treated as pure data values. Two immutable collections are considered value equal (via .equals() or is()) if they represent the same collection of values. This differs from JavaScript's typical reference equal (via === or ==) for Objects and Arrays which only determines if two variables represent references to the same object instance. Consider the example below where two identical Map instances are not reference equal but are value equal. // First consider: const obj1 = { a: 1, b: 2, c: 3 }; const obj2 = { a: 1, b: 2, c: 3 }; obj1 !== obj2; // two different instances are always not equal with === const { Map, is } = require('immutable'); const map1 = Map({ a: 1, b: 2, c: 3 }); const map2 = Map({ a: 1, b: 2, c: 3 }); map1 !== map2; // two different instances are not reference-equal map1.equals(map2); // but are value-equal if they have the same values is(map1, map2); // alternatively can use the is() function Value equality allows Immutable.js collections to be used as keys in Maps or values in Sets, and retrieved with different but equivalent collections: const { Map, Set } = require('immutable'); const map1 = Map({ a: 1, b: 2, c: 3 }); const map2 = Map({ a: 1, b: 2, c: 3 }); const set = Set().add(map1); set.has(map2); // true because these are value-equal Note: is() uses the same measure of equality as Object.is for scalar strings and numbers, but uses value equality for Immutable collections, determining if both are immutable and all keys and values are equal using the same measure of equality. Performance tradeoffs While value equality is useful in many circumstances, it has different performance characteristics than reference equality. Understanding these tradeoffs may help you decide which to use in each case, especially when used to memoize some operation. When comparing two collections, value equality may require considering every item in each collection, on an O(N) time complexity. For large collections of values, this could become a costly operation. Though if the two are not equal and hardly similar, the inequality is determined very quickly. In contrast, when comparing two collections with reference equality, only the initial references to memory need to be compared which is not based on the size of the collections, which has an O(1) time complexity. Checking reference equality is always very fast, however just because two collections are not reference-equal does not rule out the possibility that they may be value-equal. Return self on no-op optimization When possible, Immutable.js avoids creating new objects for updates where no change in value occurred, to allow for efficient reference equality checking to quickly determine if no change occurred. const { Map } = require('immutable'); const originalMap = Map({ a: 1, b: 2, c: 3 }); const updatedMap = originalMap.set('b', 2); updatedMap === originalMap; // No-op .set() returned the original reference. However updates which do result in a change will return a new reference. Each of these operations occur independently, so two similar updates will not return the same reference: const { Map } = require('immutable'); const originalMap = Map({ a: 1, b: 2, c: 3 }); const updatedMap = originalMap.set('b', 1000); // New instance, leaving the original immutable. updatedMap !== originalMap; const anotherUpdatedMap = originalMap.set('b', 1000); // Despite both the results of the same operation, each created a new reference. anotherUpdatedMap !== updatedMap; // However the two are value equal. anotherUpdatedMap.equals(updatedMap); Batching Mutations If a tree falls in the woods, does it make a sound? If a pure function mutates some local data in order to produce an immutable return value, is that ok? — Rich Hickey, Clojure Applying a mutation to create a new immutable object results in some overhead, which can add up to a minor performance penalty. If you need to apply a series of mutations locally before returning, Immutable.js gives you the ability to create a temporary mutable (transient) copy of a collection and apply a batch of mutations in a performant manner by using withMutations. In fact, this is exactly how Immutable.js applies complex mutations itself. As an example, building list2 results in the creation of 1, not 3, new immutable Lists. const { List } = require('immutable'); const list1 = List([1, 2, 3]); const list2 = list1.withMutations(function (list) { list.push(4).push(5).push(6); }); assert.equal(list1.size, 3); assert.equal(list2.size, 6); Note: Immutable.js also provides asMutable and asImmutable, but only encourages their use when withMutations will not suffice. Use caution to not return a mutable copy, which could result in undesired behavior. Important!: Only a select few methods can be used in withMutations including set, push and pop. These methods can be applied directly against a persistent data-structure where other methods like map, filter, sort, and splice will always return new immutable data-structures and never mutate a mutable collection. Lazy Seq Seq describes a lazy operation, allowing them to efficiently chain use of all the higher-order collection methods (such as map and filter) by not creating intermediate collections. Seq is immutable — Once a Seq is created, it cannot be changed, appended to, rearranged or otherwise modified. Instead, any mutative method called on a Seq will return a new Seq. Seq is lazy — Seq does as little work as necessary to respond to any method call. Values are often created during iteration, including implicit iteration when reducing or converting to a concrete data structure such as a List or JavaScript Array. For example, the following performs no work, because the resulting Seq's values are never iterated: const { Seq } = require('immutable'); const oddSquares = Seq([1, 2, 3, 4, 5, 6, 7, 8]) .filter(x => x % 2 !== 0) .map(x => x * x); Once the Seq is used, it performs only the work necessary. In this example, no intermediate arrays are ever created, filter is called three times, and map is only called once: oddSquares.get(1); // 9 Any collection can be converted to a lazy Seq with Seq(). const { Map, Seq } = require('immutable'); const map = Map({ a: 1, b: 2, c: 3 }); const lazySeq = Seq(map); Seq allows for the efficient chaining of operations, allowing for the expression of logic that can otherwise be very tedious: lazySeq .flip() .map(key => key.toUpperCase()) .flip(); // Seq { A: 1, B: 2, C: 3 } As well as expressing logic that would otherwise seem memory or time limited, for example Range is a special kind of Lazy sequence. const { Range } = require('immutable'); Range(1, Infinity) .skip(1000) .map(n => -n) .filter(n => n % 2 === 0) .take(2) .reduce((r, n) => r * n, 1); // 1006008 Comparison of filter(), groupBy(), and partition() The filter(), groupBy(), and partition() methods are similar in that they all divide a collection into parts based on applying a function to each element. All three call the predicate or grouping function once for each item in the input collection. All three return zero or more collections of the same type as their input. The returned collections are always distinct from the input (according to ===), even if the contents are identical. Of these methods, filter() is the only one that is lazy and the only one which discards items from the input collection. It is the simplest to use, and the fact that it returns exactly one collection makes it easy to combine with other methods to form a pipeline of operations. The partition() method is similar to an eager version of filter(), but it returns two collections; the first contains the items that would have been discarded by filter(), and the second contains the items that would have been kept. It always returns an array of exactly two collections, which can make it easier to use than groupBy(). Compared to making two separate calls to filter(), partition() makes half as many calls it the predicate passed to it. The groupBy() method is a more generalized version of partition() that can group by an arbitrary function rather than just a predicate. It returns a map with zero or more entries, where the keys are the values returned by the grouping function, and the values are nonempty collections of the corresponding arguments. Although groupBy() is more powerful than partition(), it can be harder to use because it is not always possible predict in advance how many entries the returned map will have and what their keys will be. Summary filter partition groupBy ease of use easiest moderate hardest generality least moderate most laziness lazy eager eager # of returned sub-collections 1 2 0 or more sub-collections may be empty yes yes no can discard items yes no no wrapping container none array Map/OrderedMap Additional Tools and Resources Atom-store A Clojure-inspired atom implementation in Javascript with configurability for external persistance. Chai Immutable If you are using the Chai Assertion Library, this provides a set of assertions to use against Immutable.js collections. Fantasy-land Specification for interoperability of common algebraic structures in JavaScript. Immutagen A library for simulating immutable generators in JavaScript. Immutable-cursor Immutable cursors incorporating the Immutable.js interface over Clojure-inspired atom. Immutable-ext Fantasyland extensions for immutablejs Immutable-js-tools Util tools for immutable.js Immutable-Redux redux-immutable is used to create an equivalent function of Redux combineReducers that works with Immutable.js state. Immutable-Treeutils Functional tree traversal helpers for ImmutableJS data structures. Irecord An immutable store that exposes an RxJS observable. Great for React. Mudash Lodash wrapper providing Immutable.JS support. React-Immutable-PropTypes PropType validators that work with Immutable.js. Redux-Immutablejs Redux Immutable facilities. Rxstate Simple opinionated state management library based on RxJS and Immutable.js. Transit-Immutable-js Transit serialisation for Immutable.js. See also: Transit-js Have an additional tool designed to work with Immutable.js? Submit a PR to add it to this list in alphabetical order. Contributing Use Github issues for requests. We actively welcome pull requests, learn how to contribute. Immutable.js is maintained within the Contributor Covenant's Code of Conduct. Changelog Changes are tracked as Github releases. License Immutable.js is MIT-licensed. Thanks Phil Bagwell, for his inspiration and research in persistent data structures. Hugh Jackson, for providing the npm package name. If you're looking for his unsupported package, see this repository."
  },
  "node_modules/semver/README.html": {
    "href": "node_modules/semver/README.html",
    "title": "semver(1) -- The semantic versioner for npm | accouter",
    "keywords": "semver(1) -- The semantic versioner for npm Install npm install semver Usage As a node module: const semver = require('semver') semver.valid('1.2.3') // '1.2.3' semver.valid('a.b.c') // null semver.clean(' =v1.2.3 ') // '1.2.3' semver.satisfies('1.2.3', '1.x || >=2.5.0 || 5.0.0 - 7.2.3') // true semver.gt('1.2.3', '9.8.7') // false semver.lt('1.2.3', '9.8.7') // true semver.minVersion('>=1.0.0') // '1.0.0' semver.valid(semver.coerce('v2')) // '2.0.0' semver.valid(semver.coerce('42.6.7.9.3-alpha')) // '42.6.7' You can also just load the module for the function that you care about if you'd like to minimize your footprint. // load the whole API at once in a single object const semver = require('semver') // or just load the bits you need // all of them listed here, just pick and choose what you want // classes const SemVer = require('semver/classes/semver') const Comparator = require('semver/classes/comparator') const Range = require('semver/classes/range') // functions for working with versions const semverParse = require('semver/functions/parse') const semverValid = require('semver/functions/valid') const semverClean = require('semver/functions/clean') const semverInc = require('semver/functions/inc') const semverDiff = require('semver/functions/diff') const semverMajor = require('semver/functions/major') const semverMinor = require('semver/functions/minor') const semverPatch = require('semver/functions/patch') const semverPrerelease = require('semver/functions/prerelease') const semverCompare = require('semver/functions/compare') const semverRcompare = require('semver/functions/rcompare') const semverCompareLoose = require('semver/functions/compare-loose') const semverCompareBuild = require('semver/functions/compare-build') const semverSort = require('semver/functions/sort') const semverRsort = require('semver/functions/rsort') // low-level comparators between versions const semverGt = require('semver/functions/gt') const semverLt = require('semver/functions/lt') const semverEq = require('semver/functions/eq') const semverNeq = require('semver/functions/neq') const semverGte = require('semver/functions/gte') const semverLte = require('semver/functions/lte') const semverCmp = require('semver/functions/cmp') const semverCoerce = require('semver/functions/coerce') // working with ranges const semverSatisfies = require('semver/functions/satisfies') const semverMaxSatisfying = require('semver/ranges/max-satisfying') const semverMinSatisfying = require('semver/ranges/min-satisfying') const semverToComparators = require('semver/ranges/to-comparators') const semverMinVersion = require('semver/ranges/min-version') const semverValidRange = require('semver/ranges/valid') const semverOutside = require('semver/ranges/outside') const semverGtr = require('semver/ranges/gtr') const semverLtr = require('semver/ranges/ltr') const semverIntersects = require('semver/ranges/intersects') const semverSimplifyRange = require('semver/ranges/simplify') const semverRangeSubset = require('semver/ranges/subset') As a command-line utility: $ semver -h A JavaScript implementation of the https://semver.org/ specification Copyright Isaac Z. Schlueter Usage: semver [options] <version> [<version> [...]] Prints valid versions sorted by SemVer precedence Options: -r --range <range> Print versions that match the specified range. -i --increment [<level>] Increment a version by the specified level. Level can be one of: major, minor, patch, premajor, preminor, prepatch, or prerelease. Default level is 'patch'. Only one version may be specified. --preid <identifier> Identifier to be used to prefix premajor, preminor, prepatch or prerelease version increments. -l --loose Interpret versions and ranges loosely -n <0|1> This is the base to be used for the prerelease identifier. -p --include-prerelease Always include prerelease versions in range matching -c --coerce Coerce a string into SemVer if possible (does not imply --loose) --rtl Coerce version strings right to left --ltr Coerce version strings left to right (default) Program exits successfully if any valid version satisfies all supplied ranges, and prints all satisfying versions. If no satisfying versions are found, then exits failure. Versions are printed in ascending order, so supplying multiple versions to the utility will just sort them. Versions A \"version\" is described by the v2.0.0 specification found at https://semver.org/. A leading \"=\" or \"v\" character is stripped off and ignored. Ranges A version range is a set of comparators that specify versions that satisfy the range. A comparator is composed of an operator and a version. The set of primitive operators is: < Less than <= Less than or equal to > Greater than >= Greater than or equal to = Equal. If no operator is specified, then equality is assumed, so this operator is optional but MAY be included. For example, the comparator >=1.2.7 would match the versions 1.2.7, 1.2.8, 2.5.3, and 1.3.9, but not the versions 1.2.6 or 1.1.0. The comparator >1 is equivalent to >=2.0.0 and would match the versions 2.0.0 and 3.1.0, but not the versions 1.0.1 or 1.1.0. Comparators can be joined by whitespace to form a comparator set, which is satisfied by the intersection of all of the comparators it includes. A range is composed of one or more comparator sets, joined by ||. A version matches a range if and only if every comparator in at least one of the ||-separated comparator sets is satisfied by the version. For example, the range >=1.2.7 <1.3.0 would match the versions 1.2.7, 1.2.8, and 1.2.99, but not the versions 1.2.6, 1.3.0, or 1.1.0. The range 1.2.7 || >=1.2.9 <2.0.0 would match the versions 1.2.7, 1.2.9, and 1.4.6, but not the versions 1.2.8 or 2.0.0. Prerelease Tags If a version has a prerelease tag (for example, 1.2.3-alpha.3) then it will only be allowed to satisfy comparator sets if at least one comparator with the same [major, minor, patch] tuple also has a prerelease tag. For example, the range >1.2.3-alpha.3 would be allowed to match the version 1.2.3-alpha.7, but it would not be satisfied by 3.4.5-alpha.9, even though 3.4.5-alpha.9 is technically \"greater than\" 1.2.3-alpha.3 according to the SemVer sort rules. The version range only accepts prerelease tags on the 1.2.3 version. Version 3.4.5 would satisfy the range because it does not have a prerelease flag, and 3.4.5 is greater than 1.2.3-alpha.7. The purpose of this behavior is twofold. First, prerelease versions frequently are updated very quickly, and contain many breaking changes that are (by the author's design) not yet fit for public consumption. Therefore, by default, they are excluded from range-matching semantics. Second, a user who has opted into using a prerelease version has indicated the intent to use that specific set of alpha/beta/rc versions. By including a prerelease tag in the range, the user is indicating that they are aware of the risk. However, it is still not appropriate to assume that they have opted into taking a similar risk on the next set of prerelease versions. Note that this behavior can be suppressed (treating all prerelease versions as if they were normal versions, for range-matching) by setting the includePrerelease flag on the options object to any functions that do range matching. Prerelease Identifiers The method .inc takes an additional identifier string argument that will append the value of the string as a prerelease identifier: semver.inc('1.2.3', 'prerelease', 'beta') // '1.2.4-beta.0' command-line example: $ semver 1.2.3 -i prerelease --preid beta 1.2.4-beta.0 Which then can be used to increment further: $ semver 1.2.4-beta.0 -i prerelease 1.2.4-beta.1 Prerelease Identifier Base The method .inc takes an optional parameter 'identifierBase' string that will let you let your prerelease number as zero-based or one-based. Set to false to omit the prerelease number altogether. If you do not specify this parameter, it will default to zero-based. semver.inc('1.2.3', 'prerelease', 'beta', '1') // '1.2.4-beta.1' semver.inc('1.2.3', 'prerelease', 'beta', false) // '1.2.4-beta' command-line example: $ semver 1.2.3 -i prerelease --preid beta -n 1 1.2.4-beta.1 $ semver 1.2.3 -i prerelease --preid beta -n false 1.2.4-beta Advanced Range Syntax Advanced range syntax desugars to primitive comparators in deterministic ways. Advanced ranges may be combined in the same way as primitive comparators using white space or ||. Hyphen Ranges X.Y.Z - A.B.C Specifies an inclusive set. 1.2.3 - 2.3.4 := >=1.2.3 <=2.3.4 If a partial version is provided as the first version in the inclusive range, then the missing pieces are replaced with zeroes. 1.2 - 2.3.4 := >=1.2.0 <=2.3.4 If a partial version is provided as the second version in the inclusive range, then all versions that start with the supplied parts of the tuple are accepted, but nothing that would be greater than the provided tuple parts. 1.2.3 - 2.3 := >=1.2.3 <2.4.0-0 1.2.3 - 2 := >=1.2.3 <3.0.0-0 X-Ranges 1.2.x 1.X 1.2.* * Any of X, x, or * may be used to \"stand in\" for one of the numeric values in the [major, minor, patch] tuple. * := >=0.0.0 (Any non-prerelease version satisfies, unless includePrerelease is specified, in which case any version at all satisfies) 1.x := >=1.0.0 <2.0.0-0 (Matching major version) 1.2.x := >=1.2.0 <1.3.0-0 (Matching major and minor versions) A partial version range is treated as an X-Range, so the special character is in fact optional. \"\" (empty string) := * := >=0.0.0 1 := 1.x.x := >=1.0.0 <2.0.0-0 1.2 := 1.2.x := >=1.2.0 <1.3.0-0 Tilde Ranges ~1.2.3 ~1.2 ~1 Allows patch-level changes if a minor version is specified on the comparator. Allows minor-level changes if not. ~1.2.3 := >=1.2.3 <1.(2+1).0 := >=1.2.3 <1.3.0-0 ~1.2 := >=1.2.0 <1.(2+1).0 := >=1.2.0 <1.3.0-0 (Same as 1.2.x) ~1 := >=1.0.0 <(1+1).0.0 := >=1.0.0 <2.0.0-0 (Same as 1.x) ~0.2.3 := >=0.2.3 <0.(2+1).0 := >=0.2.3 <0.3.0-0 ~0.2 := >=0.2.0 <0.(2+1).0 := >=0.2.0 <0.3.0-0 (Same as 0.2.x) ~0 := >=0.0.0 <(0+1).0.0 := >=0.0.0 <1.0.0-0 (Same as 0.x) ~1.2.3-beta.2 := >=1.2.3-beta.2 <1.3.0-0 Note that prereleases in the 1.2.3 version will be allowed, if they are greater than or equal to beta.2. So, 1.2.3-beta.4 would be allowed, but 1.2.4-beta.2 would not, because it is a prerelease of a different [major, minor, patch] tuple. Caret Ranges ^1.2.3 ^0.2.5 ^0.0.4 Allows changes that do not modify the left-most non-zero element in the [major, minor, patch] tuple. In other words, this allows patch and minor updates for versions 1.0.0 and above, patch updates for versions 0.X >=0.1.0, and no updates for versions 0.0.X. Many authors treat a 0.x version as if the x were the major \"breaking-change\" indicator. Caret ranges are ideal when an author may make breaking changes between 0.2.4 and 0.3.0 releases, which is a common practice. However, it presumes that there will not be breaking changes between 0.2.4 and 0.2.5. It allows for changes that are presumed to be additive (but non-breaking), according to commonly observed practices. ^1.2.3 := >=1.2.3 <2.0.0-0 ^0.2.3 := >=0.2.3 <0.3.0-0 ^0.0.3 := >=0.0.3 <0.0.4-0 ^1.2.3-beta.2 := >=1.2.3-beta.2 <2.0.0-0 Note that prereleases in the 1.2.3 version will be allowed, if they are greater than or equal to beta.2. So, 1.2.3-beta.4 would be allowed, but 1.2.4-beta.2 would not, because it is a prerelease of a different [major, minor, patch] tuple. ^0.0.3-beta := >=0.0.3-beta <0.0.4-0 Note that prereleases in the 0.0.3 version only will be allowed, if they are greater than or equal to beta. So, 0.0.3-pr.2 would be allowed. When parsing caret ranges, a missing patch value desugars to the number 0, but will allow flexibility within that value, even if the major and minor versions are both 0. ^1.2.x := >=1.2.0 <2.0.0-0 ^0.0.x := >=0.0.0 <0.1.0-0 ^0.0 := >=0.0.0 <0.1.0-0 A missing minor and patch values will desugar to zero, but also allow flexibility within those values, even if the major version is zero. ^1.x := >=1.0.0 <2.0.0-0 ^0.x := >=0.0.0 <1.0.0-0 Range Grammar Putting all this together, here is a Backus-Naur grammar for ranges, for the benefit of parser authors: range-set ::= range ( logical-or range ) * logical-or ::= ( ' ' ) * '||' ( ' ' ) * range ::= hyphen | simple ( ' ' simple ) * | '' hyphen ::= partial ' - ' partial simple ::= primitive | partial | tilde | caret primitive ::= ( '<' | '>' | '>=' | '<=' | '=' ) partial partial ::= xr ( '.' xr ( '.' xr qualifier ? )? )? xr ::= 'x' | 'X' | '*' | nr nr ::= '0' | ['1'-'9'] ( ['0'-'9'] ) * tilde ::= '~' partial caret ::= '^' partial qualifier ::= ( '-' pre )? ( '+' build )? pre ::= parts build ::= parts parts ::= part ( '.' part ) * part ::= nr | [-0-9A-Za-z]+ Functions All methods and classes take a final options object argument. All options in this object are false by default. The options supported are: loose: Be more forgiving about not-quite-valid semver strings. (Any resulting output will always be 100% strict compliant, of course.) For backwards compatibility reasons, if the options argument is a boolean value instead of an object, it is interpreted to be the loose param. includePrerelease: Set to suppress the default behavior of excluding prerelease tagged versions from ranges unless they are explicitly opted into. Strict-mode Comparators and Ranges will be strict about the SemVer strings that they parse. valid(v): Return the parsed version, or null if it's not valid. inc(v, release, options, identifier, identifierBase): Return the version incremented by the release type (major, premajor, minor, preminor, patch, prepatch, or prerelease), or null if it's not valid premajor in one call will bump the version up to the next major version and down to a prerelease of that major version. preminor, and prepatch work the same way. If called from a non-prerelease version, prerelease will work the same as prepatch. It increments the patch version and then makes a prerelease. If the input version is already a prerelease it simply increments it. identifier can be used to prefix premajor, preminor, prepatch, or prerelease version increments. identifierBase is the base to be used for the prerelease identifier. prerelease(v): Returns an array of prerelease components, or null if none exist. Example: prerelease('1.2.3-alpha.1') -> ['alpha', 1] major(v): Return the major version number. minor(v): Return the minor version number. patch(v): Return the patch version number. intersects(r1, r2, loose): Return true if the two supplied ranges or comparators intersect. parse(v): Attempt to parse a string as a semantic version, returning either a SemVer object or null. Comparison gt(v1, v2): v1 > v2 gte(v1, v2): v1 >= v2 lt(v1, v2): v1 < v2 lte(v1, v2): v1 <= v2 eq(v1, v2): v1 == v2 This is true if they're logically equivalent, even if they're not the same string. You already know how to compare strings. neq(v1, v2): v1 != v2 The opposite of eq. cmp(v1, comparator, v2): Pass in a comparison string, and it'll call the corresponding function above. \"===\" and \"!==\" do simple string comparison, but are included for completeness. Throws if an invalid comparison string is provided. compare(v1, v2): Return 0 if v1 == v2, or 1 if v1 is greater, or -1 if v2 is greater. Sorts in ascending order if passed to Array.sort(). rcompare(v1, v2): The reverse of compare. Sorts an array of versions in descending order when passed to Array.sort(). compareBuild(v1, v2): The same as compare but considers build when two versions are equal. Sorts in ascending order if passed to Array.sort(). compareLoose(v1, v2): Short for ``compare(v1, v2, { loose: true })`. diff(v1, v2): Returns the difference between two versions by the release type (major, premajor, minor, preminor, patch, prepatch, or prerelease), or null if the versions are the same. Sorting sort(versions): Returns a sorted array of versions based on the compareBuild function. rsort(versions): The reverse of sort. Returns an array of versions based on the compareBuild function in descending order. Comparators intersects(comparator): Return true if the comparators intersect Ranges validRange(range): Return the valid range or null if it's not valid satisfies(version, range): Return true if the version satisfies the range. maxSatisfying(versions, range): Return the highest version in the list that satisfies the range, or null if none of them do. minSatisfying(versions, range): Return the lowest version in the list that satisfies the range, or null if none of them do. minVersion(range): Return the lowest version that can match the given range. gtr(version, range): Return true if the version is greater than all the versions possible in the range. ltr(version, range): Return true if the version is less than all the versions possible in the range. outside(version, range, hilo): Return true if the version is outside the bounds of the range in either the high or low direction. The hilo argument must be either the string '>' or '<'. (This is the function called by gtr and ltr.) intersects(range): Return true if any of the range comparators intersect. simplifyRange(versions, range): Return a \"simplified\" range that matches the same items in the versions list as the range specified. Note that it does not guarantee that it would match the same versions in all cases, only for the set of versions provided. This is useful when generating ranges by joining together multiple versions with || programmatically, to provide the user with something a bit more ergonomic. If the provided range is shorter in string-length than the generated range, then that is returned. subset(subRange, superRange): Return true if the subRange range is entirely contained by the superRange range. Note that, since ranges may be non-contiguous, a version might not be greater than a range, less than a range, or satisfy a range! For example, the range 1.2 <1.2.9 || >2.0.0 would have a hole from 1.2.9 until 2.0.0, so version 1.2.10 would not be greater than the range (because 2.0.1 satisfies, which is higher), nor less than the range (since 1.2.8 satisfies, which is lower), and it also does not satisfy the range. If you want to know if a version satisfies or does not satisfy a range, use the satisfies(version, range) function. Coercion coerce(version, options): Coerces a string to semver if possible This aims to provide a very forgiving translation of a non-semver string to semver. It looks for the first digit in a string and consumes all remaining characters which satisfy at least a partial semver (e.g., 1, 1.2, 1.2.3) up to the max permitted length (256 characters). Longer versions are simply truncated (4.6.3.9.2-alpha2 becomes 4.6.3). All surrounding text is simply ignored (v3.4 replaces v3.3.1 becomes 3.4.0). Only text which lacks digits will fail coercion (version one is not valid). The maximum length for any semver component considered for coercion is 16 characters; longer components will be ignored (10000000000000000.4.7.4 becomes 4.7.4). The maximum value for any semver component is Number.MAX_SAFE_INTEGER || (2**53 - 1); higher value components are invalid (9999999999999999.4.7.4 is likely invalid). If the options.rtl flag is set, then coerce will return the right-most coercible tuple that does not share an ending index with a longer coercible tuple. For example, 1.2.3.4 will return 2.3.4 in rtl mode, not 4.0.0. 1.2.3/4 will return 4.0.0, because the 4 is not a part of any other overlapping SemVer tuple. If the options.includePrerelease flag is set, then the coerce result will contain prerelease and build parts of a version. For example, 1.2.3.4-rc.1+rev.2 will preserve prerelease rc.1 and build rev.2 in the result. Clean clean(version): Clean a string to be a valid semver if possible This will return a cleaned and trimmed semver version. If the provided version is not valid a null will be returned. This does not work for ranges. ex. s.clean(' = v 2.1.5foo'): null s.clean(' = v 2.1.5foo', { loose: true }): '2.1.5-foo' s.clean(' = v 2.1.5-foo'): null s.clean(' = v 2.1.5-foo', { loose: true }): '2.1.5-foo' s.clean('=v2.1.5'): '2.1.5' s.clean(' =v2.1.5'): '2.1.5' s.clean(' 2.1.5 '): '2.1.5' s.clean('~1.0.0'): null Constants As a convenience, helper constants are exported to provide information about what node-semver supports: RELEASE_TYPES major premajor minor preminor patch prepatch prerelease const semver = require('semver'); if (semver.RELEASE_TYPES.includes(arbitraryUserInput)) { console.log('This is a valid release type!'); } else { console.warn('This is NOT a valid release type!'); } SEMVER_SPEC_VERSION 2.0.0 const semver = require('semver'); console.log('We are currently using the semver specification version:', semver.SEMVER_SPEC_VERSION); Exported Modules You may pull in just the part of this semver utility that you need if you are sensitive to packing and tree-shaking concerns. The main require('semver') export uses getter functions to lazily load the parts of the API that are used. The following modules are available: require('semver') require('semver/classes') require('semver/classes/comparator') require('semver/classes/range') require('semver/classes/semver') require('semver/functions/clean') require('semver/functions/cmp') require('semver/functions/coerce') require('semver/functions/compare') require('semver/functions/compare-build') require('semver/functions/compare-loose') require('semver/functions/diff') require('semver/functions/eq') require('semver/functions/gt') require('semver/functions/gte') require('semver/functions/inc') require('semver/functions/lt') require('semver/functions/lte') require('semver/functions/major') require('semver/functions/minor') require('semver/functions/neq') require('semver/functions/parse') require('semver/functions/patch') require('semver/functions/prerelease') require('semver/functions/rcompare') require('semver/functions/rsort') require('semver/functions/satisfies') require('semver/functions/sort') require('semver/functions/valid') require('semver/ranges/gtr') require('semver/ranges/intersects') require('semver/ranges/ltr') require('semver/ranges/max-satisfying') require('semver/ranges/min-satisfying') require('semver/ranges/min-version') require('semver/ranges/outside') require('semver/ranges/simplify') require('semver/ranges/subset') require('semver/ranges/to-comparators') require('semver/ranges/valid')"
  },
  "node_modules/send/HISTORY.html": {
    "href": "node_modules/send/HISTORY.html",
    "title": "0.16.2 / 2018-02-07 | accouter",
    "keywords": "0.16.2 / 2018-02-07 Fix incorrect end tag in default error & redirects deps: depd@~1.1.2 perf: remove argument reassignment deps: encodeurl@~1.0.2 Fix encoding % as last character deps: statuses@~1.4.0 0.16.1 / 2017-09-29 Fix regression in edge-case behavior for empty path 0.16.0 / 2017-09-27 Add immutable option Fix missing </html> in default error & redirects Use instance methods on steam to check for listeners deps: mime@1.4.1 Add 70 new types for file extensions Set charset as \"UTF-8\" for .js and .json perf: improve path validation speed 0.15.6 / 2017-09-22 deps: debug@2.6.9 perf: improve If-Match token parsing 0.15.5 / 2017-09-20 deps: etag@~1.8.1 perf: replace regular expression with substring deps: fresh@0.5.2 Fix handling of modified headers with invalid dates perf: improve ETag match loop perf: improve If-None-Match token parsing 0.15.4 / 2017-08-05 deps: debug@2.6.8 deps: depd@~1.1.1 Remove unnecessary Buffer loading deps: http-errors@~1.6.2 deps: depd@1.1.1 0.15.3 / 2017-05-16 deps: debug@2.6.7 deps: ms@2.0.0 deps: ms@2.0.0 0.15.2 / 2017-04-26 deps: debug@2.6.4 Fix DEBUG_MAX_ARRAY_LENGTH deps: ms@0.7.3 deps: ms@1.0.0 0.15.1 / 2017-03-04 Fix issue when Date.parse does not return NaN on invalid date Fix strict violation in broken environments 0.15.0 / 2017-02-25 Support If-Match and If-Unmodified-Since headers Add res and path arguments to directory event Remove usage of res._headers private field Improves compatibility with Node.js 8 nightly Send complete HTML document in redirect & error responses Set default CSP header in redirect & error responses Use res.getHeaderNames() when available Use res.headersSent when available deps: debug@2.6.1 Allow colors in workers Deprecated DEBUG_FD environment variable set to 3 or higher Fix error when running under React Native Use same color for same namespace deps: ms@0.7.2 deps: etag@~1.8.0 deps: fresh@0.5.0 Fix false detection of no-cache request directive Fix incorrect result when If-None-Match has both * and ETags Fix weak ETag matching to match spec perf: delay reading header values until needed perf: enable strict mode perf: hoist regular expressions perf: remove duplicate conditional perf: remove unnecessary boolean coercions perf: skip checking modified time if ETag check failed perf: skip parsing If-None-Match when no ETag header perf: use Date.parse instead of new Date deps: http-errors@~1.6.1 Make message property enumerable for HttpErrors deps: setprototypeof@1.0.3 0.14.2 / 2017-01-23 deps: http-errors@~1.5.1 deps: inherits@2.0.3 deps: setprototypeof@1.0.2 deps: statuses@'>= 1.3.1 < 2' deps: ms@0.7.2 deps: statuses@~1.3.1 0.14.1 / 2016-06-09 Fix redirect error when path contains raw non-URL characters Fix redirect when path starts with multiple forward slashes 0.14.0 / 2016-06-06 Add acceptRanges option Add cacheControl option Attempt to combine multiple ranges into single range Correctly inherit from Stream class Fix Content-Range header in 416 responses when using start/end options Fix Content-Range header missing from default 416 responses Ignore non-byte Range headers deps: http-errors@~1.5.0 Add HttpError export, for err instanceof createError.HttpError Support new code 421 Misdirected Request Use setprototypeof module to replace __proto__ setting deps: inherits@2.0.1 deps: statuses@'>= 1.3.0 < 2' perf: enable strict mode deps: range-parser@~1.2.0 Fix incorrectly returning -1 when there is at least one valid range perf: remove internal function deps: statuses@~1.3.0 Add 421 Misdirected Request perf: enable strict mode perf: remove argument reassignment 0.13.2 / 2016-03-05 Fix invalid Content-Type header when send.mime.default_type unset 0.13.1 / 2016-01-16 deps: depd@~1.1.0 Support web browser loading perf: enable strict mode deps: destroy@~1.0.4 perf: enable strict mode deps: escape-html@~1.0.3 perf: enable strict mode perf: optimize string replacement perf: use faster string coercion deps: range-parser@~1.0.3 perf: enable strict mode 0.13.0 / 2015-06-16 Allow Node.js HTTP server to set Date response header Fix incorrectly removing Content-Location on 304 response Improve the default redirect response headers Send appropriate headers on default error response Use http-errors for standard emitted errors Use statuses instead of http module for status messages deps: escape-html@1.0.2 deps: etag@~1.7.0 Improve stat performance by removing hashing deps: fresh@0.3.0 Add weak ETag matching support deps: on-finished@~2.3.0 Add defined behavior for HTTP CONNECT requests Add defined behavior for HTTP Upgrade requests deps: ee-first@1.1.1 perf: enable strict mode perf: remove unnecessary array allocations 0.12.3 / 2015-05-13 deps: debug@~2.2.0 deps: ms@0.7.1 deps: depd@~1.0.1 deps: etag@~1.6.0 Improve support for JXcore Support \"fake\" stats objects in environments without fs deps: ms@0.7.1 Prevent extraordinarily long inputs deps: on-finished@~2.2.1 0.12.2 / 2015-03-13 Throw errors early for invalid extensions or index options deps: debug@~2.1.3 Fix high intensity foreground color for bold deps: ms@0.7.0 0.12.1 / 2015-02-17 Fix regression sending zero-length files 0.12.0 / 2015-02-16 Always read the stat size from the file Fix mutating passed-in options deps: mime@1.3.4 0.11.1 / 2015-01-20 Fix root path disclosure 0.11.0 / 2015-01-05 deps: debug@~2.1.1 deps: etag@~1.5.1 deps: crc@3.2.1 deps: ms@0.7.0 Add milliseconds Add msecs Add secs Add mins Add hrs Add yrs deps: on-finished@~2.2.0 0.10.1 / 2014-10-22 deps: on-finished@~2.1.1 Fix handling of pipelined requests 0.10.0 / 2014-10-15 deps: debug@~2.1.0 Implement DEBUG_FD env variable support deps: depd@~1.0.0 deps: etag@~1.5.0 Improve string performance Slightly improve speed for weak ETags over 1KB 0.9.3 / 2014-09-24 deps: etag@~1.4.0 Support \"fake\" stats objects 0.9.2 / 2014-09-15 deps: depd@0.4.5 deps: etag@~1.3.1 deps: range-parser@~1.0.2 0.9.1 / 2014-09-07 deps: fresh@0.2.4 0.9.0 / 2014-09-07 Add lastModified option Use etag to generate ETag header deps: debug@~2.0.0 0.8.5 / 2014-09-04 Fix malicious path detection for empty string path 0.8.4 / 2014-09-04 Fix a path traversal issue when using root 0.8.3 / 2014-08-16 deps: destroy@1.0.3 renamed from dethroy deps: on-finished@2.1.0 0.8.2 / 2014-08-14 Work around fd leak in Node.js 0.10 for fs.ReadStream deps: dethroy@1.0.2 0.8.1 / 2014-08-05 Fix extensions behavior when file already has extension 0.8.0 / 2014-08-05 Add extensions option 0.7.4 / 2014-08-04 Fix serving index files without root dir 0.7.3 / 2014-07-29 Fix incorrect 403 on Windows and Node.js 0.11 0.7.2 / 2014-07-27 deps: depd@0.4.4 Work-around v8 generating empty stack traces 0.7.1 / 2014-07-26 deps: depd@0.4.3 Fix exception when global Error.stackTraceLimit is too low 0.7.0 / 2014-07-20 Deprecate hidden option; use dotfiles option Add dotfiles option deps: debug@1.0.4 deps: depd@0.4.2 Add TRACE_DEPRECATION environment variable Remove non-standard grey color from color output Support --no-deprecation argument Support --trace-deprecation argument 0.6.0 / 2014-07-11 Deprecate from option; use root option Deprecate send.etag() -- use etag in options Deprecate send.hidden() -- use hidden in options Deprecate send.index() -- use index in options Deprecate send.maxage() -- use maxAge in options Deprecate send.root() -- use root in options Cap maxAge value to 1 year deps: debug@1.0.3 Add support for multiple wildcards in namespaces 0.5.0 / 2014-06-28 Accept string for maxAge (converted by ms) Add headers event Include link in default redirect response Use EventEmitter.listenerCount to count listeners 0.4.3 / 2014-06-11 Do not throw un-catchable error on file open race condition Use escape-html for HTML escaping deps: debug@1.0.2 fix some debugging output colors on node.js 0.8 deps: finished@1.2.2 deps: fresh@0.2.2 0.4.2 / 2014-06-09 fix \"event emitter leak\" warnings deps: debug@1.0.1 deps: finished@1.2.1 0.4.1 / 2014-06-02 Send max-age in Cache-Control in correct format 0.4.0 / 2014-05-27 Calculate ETag with md5 for reduced collisions Fix wrong behavior when index file matches directory Ignore stream errors after request ends Goodbye EBADF, read Skip directories in index file search deps: debug@0.8.1 0.3.0 / 2014-04-24 Fix sending files with dots without root set Coerce option types Accept API options in options object Set etags to \"weak\" Include file path in etag Make \"Can't set headers after they are sent.\" catchable Send full entity-body for multi range requests Default directory access to 403 when index disabled Support multiple index paths Support \"If-Range\" header Control whether to generate etags deps: mime@1.2.11 0.2.0 / 2014-01-29 update range-parser and fresh 0.1.4 / 2013-08-11 update fresh 0.1.3 / 2013-07-08 Revert \"Fix fd leak\" 0.1.2 / 2013-07-03 Fix fd leak 0.1.0 / 2012-08-25 add options parameter to send() that is passed to fs.createReadStream() [kanongil] 0.0.4 / 2012-08-16 allow custom \"Accept-Ranges\" definition 0.0.3 / 2012-07-16 fix normalization of the root directory. Closes #3 0.0.2 / 2012-07-09 add passing of req explicitly for now (YUCK) 0.0.1 / 2010-01-03 Initial release"
  },
  "node_modules/send/README.html": {
    "href": "node_modules/send/README.html",
    "title": "send | accouter",
    "keywords": "send Send is a library for streaming files from the file system as a http response supporting partial responses (Ranges), conditional-GET negotiation (If-Match, If-Unmodified-Since, If-None-Match, If-Modified-Since), high test coverage, and granular events which may be leveraged to take appropriate actions in your application or framework. Looking to serve up entire folders mapped to URLs? Try serve-static. Installation This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install send API var send = require('send') send(req, path, [options]) Create a new SendStream for the given path to send to a res. The req is the Node.js HTTP request and the path is a urlencoded path to send (urlencoded, not the actual file-system path). Options acceptRanges Enable or disable accepting ranged requests, defaults to true. Disabling this will not send Accept-Ranges and ignore the contents of the Range request header. cacheControl Enable or disable setting Cache-Control response header, defaults to true. Disabling this will ignore the immutable and maxAge options. dotfiles Set how \"dotfiles\" are treated when encountered. A dotfile is a file or directory that begins with a dot (\".\"). Note this check is done on the path itself without checking if the path actually exists on the disk. If root is specified, only the dotfiles above the root are checked (i.e. the root itself can be within a dotfile when when set to \"deny\"). 'allow' No special treatment for dotfiles. 'deny' Send a 403 for any request for a dotfile. 'ignore' Pretend like the dotfile does not exist and 404. The default value is similar to 'ignore', with the exception that this default will not ignore the files within a directory that begins with a dot, for backward-compatibility. end Byte offset at which the stream ends, defaults to the length of the file minus 1. The end is inclusive in the stream, meaning end: 3 will include the 4th byte in the stream. etag Enable or disable etag generation, defaults to true. extensions If a given file doesn't exist, try appending one of the given extensions, in the given order. By default, this is disabled (set to false). An example value that will serve extension-less HTML files: ['html', 'htm']. This is skipped if the requested file already has an extension. immutable Enable or diable the immutable directive in the Cache-Control response header, defaults to false. If set to true, the maxAge option should also be specified to enable caching. The immutable directive will prevent supported clients from making conditional requests during the life of the maxAge option to check if the file has changed. index By default send supports \"index.html\" files, to disable this set false or to supply a new index pass a string or an array in preferred order. lastModified Enable or disable Last-Modified header, defaults to true. Uses the file system's last modified value. maxAge Provide a max-age in milliseconds for http caching, defaults to 0. This can also be a string accepted by the ms module. root Serve files relative to path. start Byte offset at which the stream starts, defaults to 0. The start is inclusive, meaning start: 2 will include the 3rd byte in the stream. Events The SendStream is an event emitter and will emit the following events: error an error occurred (err) directory a directory was requested (res, path) file a file was requested (path, stat) headers the headers are about to be set on a file (res, path, stat) stream file streaming has started (stream) end streaming has completed .pipe The pipe method is used to pipe the response into the Node.js HTTP response object, typically send(req, path, options).pipe(res). .mime The mime export is the global instance of of the mime npm module. This is used to configure the MIME types that are associated with file extensions as well as other options for how to resolve the MIME type of a file (like the default type to use for an unknown file extension). Error-handling By default when no error listeners are present an automatic response will be made, otherwise you have full control over the response, aka you may show a 5xx page etc. Caching It does not perform internal caching, you should use a reverse proxy cache such as Varnish for this, or those fancy things called CDNs. If your application is small enough that it would benefit from single-node memory caching, it's small enough that it does not need caching at all ;). Debugging To enable debug() instrumentation output export DEBUG: $ DEBUG=send node app Running tests $ npm install $ npm test Examples Small example var http = require('http') var parseUrl = require('parseurl') var send = require('send') var server = http.createServer(function onRequest (req, res) { send(req, parseUrl(req).pathname).pipe(res) }) server.listen(3000) Custom file types var http = require('http') var parseUrl = require('parseurl') var send = require('send') // Default unknown types to text/plain send.mime.default_type = 'text/plain' // Add a custom type send.mime.define({ 'application/x-my-type': ['x-mt', 'x-mtt'] }) var server = http.createServer(function onRequest (req, res) { send(req, parseUrl(req).pathname).pipe(res) }) server.listen(3000) Custom directory index view This is a example of serving up a structure of directories with a custom function to render a listing of a directory. var http = require('http') var fs = require('fs') var parseUrl = require('parseurl') var send = require('send') // Transfer arbitrary files from within /www/example.com/public/* // with a custom handler for directory listing var server = http.createServer(function onRequest (req, res) { send(req, parseUrl(req).pathname, {index: false, root: '/www/example.com/public'}) .once('directory', directory) .pipe(res) }) server.listen(3000) // Custom directory handler function directory (res, path) { var stream = this // redirect to trailing slash for consistent url if (!stream.hasTrailingSlash()) { return stream.redirect(path) } // get directory list fs.readdir(path, function onReaddir (err, list) { if (err) return stream.error(err) // render an index for the directory res.setHeader('Content-Type', 'text/plain; charset=UTF-8') res.end(list.join('\\n') + '\\n') }) } Serving from a root directory with custom error-handling var http = require('http') var parseUrl = require('parseurl') var send = require('send') var server = http.createServer(function onRequest (req, res) { // your custom error-handling logic: function error (err) { res.statusCode = err.status || 500 res.end(err.message) } // your custom headers function headers (res, path, stat) { // serve all files for download res.setHeader('Content-Disposition', 'attachment') } // your custom directory handling logic: function redirect () { res.statusCode = 301 res.setHeader('Location', req.url + '/') res.end('Redirecting to ' + req.url + '/') } // transfer arbitrary files from within // /www/example.com/public/* send(req, parseUrl(req).pathname, {root: '/www/example.com/public'}) .on('error', error) .on('directory', redirect) .on('headers', headers) .pipe(res) }) server.listen(3000) License MIT"
  },
  "node_modules/send/node_modules/depd/History.html": {
    "href": "node_modules/send/node_modules/depd/History.html",
    "title": "1.1.2 / 2018-01-11 | accouter",
    "keywords": "1.1.2 / 2018-01-11 perf: remove argument reassignment Support Node.js 0.6 to 9.x 1.1.1 / 2017-07-27 Remove unnecessary Buffer loading Support Node.js 0.6 to 8.x 1.1.0 / 2015-09-14 Enable strict mode in more places Support io.js 3.x Support io.js 2.x Support web browser loading Requires bundler like Browserify or webpack 1.0.1 / 2015-04-07 Fix TypeErrors when under 'use strict' code Fix useless type name on auto-generated messages Support io.js 1.x Support Node.js 0.12 1.0.0 / 2014-09-17 No changes 0.4.5 / 2014-09-09 Improve call speed to functions using the function wrapper Support Node.js 0.6 0.4.4 / 2014-07-27 Work-around v8 generating empty stack traces 0.4.3 / 2014-07-26 Fix exception when global Error.stackTraceLimit is too low 0.4.2 / 2014-07-19 Correct call site for wrapped functions and properties 0.4.1 / 2014-07-19 Improve automatic message generation for function properties 0.4.0 / 2014-07-19 Add TRACE_DEPRECATION environment variable Remove non-standard grey color from color output Support --no-deprecation argument Support --trace-deprecation argument Support deprecate.property(fn, prop, message) 0.3.0 / 2014-06-16 Add NO_DEPRECATION environment variable 0.2.0 / 2014-06-15 Add deprecate.property(obj, prop, message) Remove supports-color dependency for node.js 0.8 0.1.0 / 2014-06-15 Add deprecate.function(fn, message) Add process.on('deprecation', fn) emitter Automatically generate message when omitted from deprecate() 0.0.1 / 2014-06-15 Fix warning for dynamic calls at singe call site 0.0.0 / 2014-06-15 Initial implementation"
  },
  "node_modules/send/node_modules/depd/Readme.html": {
    "href": "node_modules/send/node_modules/depd/Readme.html",
    "title": "depd | accouter",
    "keywords": "depd Deprecate all the things With great modules comes great responsibility; mark things deprecated! Install This module is installed directly using npm: $ npm install depd This module can also be bundled with systems like Browserify or webpack, though by default this module will alter it's API to no longer display or track deprecations. API var deprecate = require('depd')('my-module') This library allows you to display deprecation messages to your users. This library goes above and beyond with deprecation warnings by introspection of the call stack (but only the bits that it is interested in). Instead of just warning on the first invocation of a deprecated function and never again, this module will warn on the first invocation of a deprecated function per unique call site, making it ideal to alert users of all deprecated uses across the code base, rather than just whatever happens to execute first. The deprecation warnings from this module also include the file and line information for the call into the module that the deprecated function was in. NOTE this library has a similar interface to the debug module, and this module uses the calling file to get the boundary for the call stacks, so you should always create a new deprecate object in each file and not within some central file. depd(namespace) Create a new deprecate function that uses the given namespace name in the messages and will display the call site prior to the stack entering the file this function was called from. It is highly suggested you use the name of your module as the namespace. deprecate(message) Call this function from deprecated code to display a deprecation message. This message will appear once per unique caller site. Caller site is the first call site in the stack in a different file from the caller of this function. If the message is omitted, a message is generated for you based on the site of the deprecate() call and will display the name of the function called, similar to the name displayed in a stack trace. deprecate.function(fn, message) Call this function to wrap a given function in a deprecation message on any call to the function. An optional message can be supplied to provide a custom message. deprecate.property(obj, prop, message) Call this function to wrap a given property on object in a deprecation message on any accessing or setting of the property. An optional message can be supplied to provide a custom message. The method must be called on the object where the property belongs (not inherited from the prototype). If the property is a data descriptor, it will be converted to an accessor descriptor in order to display the deprecation message. process.on('deprecation', fn) This module will allow easy capturing of deprecation errors by emitting the errors as the type \"deprecation\" on the global process. If there are no listeners for this type, the errors are written to STDERR as normal, but if there are any listeners, nothing will be written to STDERR and instead only emitted. From there, you can write the errors in a different format or to a logging source. The error represents the deprecation and is emitted only once with the same rules as writing to STDERR. The error has the following properties: message - This is the message given by the library name - This is always 'DeprecationError' namespace - This is the namespace the deprecation came from stack - This is the stack of the call to the deprecated thing Example error.stack output: DeprecationError: my-cool-module deprecated oldfunction at Object.<anonymous> ([eval]-wrapper:6:22) at Module._compile (module.js:456:26) at evalScript (node.js:532:25) at startup (node.js:80:7) at node.js:902:3 process.env.NO_DEPRECATION As a user of modules that are deprecated, the environment variable NO_DEPRECATION is provided as a quick solution to silencing deprecation warnings from being output. The format of this is similar to that of DEBUG: $ NO_DEPRECATION=my-module,othermod node app.js This will suppress deprecations from being output for \"my-module\" and \"othermod\". The value is a list of comma-separated namespaces. To suppress every warning across all namespaces, use the value * for a namespace. Providing the argument --no-deprecation to the node executable will suppress all deprecations (only available in Node.js 0.8 or higher). NOTE This will not suppress the deperecations given to any \"deprecation\" event listeners, just the output to STDERR. process.env.TRACE_DEPRECATION As a user of modules that are deprecated, the environment variable TRACE_DEPRECATION is provided as a solution to getting more detailed location information in deprecation warnings by including the entire stack trace. The format of this is the same as NO_DEPRECATION: $ TRACE_DEPRECATION=my-module,othermod node app.js This will include stack traces for deprecations being output for \"my-module\" and \"othermod\". The value is a list of comma-separated namespaces. To trace every warning across all namespaces, use the value * for a namespace. Providing the argument --trace-deprecation to the node executable will trace all deprecations (only available in Node.js 0.8 or higher). NOTE This will not trace the deperecations silenced by NO_DEPRECATION. Display When a user calls a function in your library that you mark deprecated, they will see the following written to STDERR (in the given colors, similar colors and layout to the debug module): bright cyan bright yellow | | reset cyan | | | | ▼ ▼ ▼ ▼ my-cool-module deprecated oldfunction [eval]-wrapper:6:22 ▲ ▲ ▲ ▲ | | | | namespace | | location of mycoolmod.oldfunction() call | deprecation message the word \"deprecated\" If the user redirects their STDERR to a file or somewhere that does not support colors, they see (similar layout to the debug module): Sun, 15 Jun 2014 05:21:37 GMT my-cool-module deprecated oldfunction at [eval]-wrapper:6:22 ▲ ▲ ▲ ▲ ▲ | | | | | timestamp of message namespace | | location of mycoolmod.oldfunction() call | deprecation message the word \"deprecated\" Examples Deprecating all calls to a function This will display a deprecated message about \"oldfunction\" being deprecated from \"my-module\" on STDERR. var deprecate = require('depd')('my-cool-module') // message automatically derived from function name // Object.oldfunction exports.oldfunction = deprecate.function(function oldfunction () { // all calls to function are deprecated }) // specific message exports.oldfunction = deprecate.function(function () { // all calls to function are deprecated }, 'oldfunction') Conditionally deprecating a function call This will display a deprecated message about \"weirdfunction\" being deprecated from \"my-module\" on STDERR when called with less than 2 arguments. var deprecate = require('depd')('my-cool-module') exports.weirdfunction = function () { if (arguments.length < 2) { // calls with 0 or 1 args are deprecated deprecate('weirdfunction args < 2') } } When calling deprecate as a function, the warning is counted per call site within your own module, so you can display different deprecations depending on different situations and the users will still get all the warnings: var deprecate = require('depd')('my-cool-module') exports.weirdfunction = function () { if (arguments.length < 2) { // calls with 0 or 1 args are deprecated deprecate('weirdfunction args < 2') } else if (typeof arguments[0] !== 'string') { // calls with non-string first argument are deprecated deprecate('weirdfunction non-string first arg') } } Deprecating property access This will display a deprecated message about \"oldprop\" being deprecated from \"my-module\" on STDERR when accessed. A deprecation will be displayed when setting the value and when getting the value. var deprecate = require('depd')('my-cool-module') exports.oldprop = 'something' // message automatically derives from property name deprecate.property(exports, 'oldprop') // explicit message deprecate.property(exports, 'oldprop', 'oldprop >= 0.10') License MIT"
  },
  "node_modules/send/node_modules/http-errors/HISTORY.html": {
    "href": "node_modules/send/node_modules/http-errors/HISTORY.html",
    "title": "2018-03-29 / 1.6.3 | accouter",
    "keywords": "2018-03-29 / 1.6.3 deps: depd@~1.1.2 perf: remove argument reassignment deps: setprototypeof@1.1.0 deps: statuses@'>= 1.3.1 < 2' 2017-08-04 / 1.6.2 deps: depd@1.1.1 Remove unnecessary Buffer loading 2017-02-20 / 1.6.1 deps: setprototypeof@1.0.3 Fix shim for old browsers 2017-02-14 / 1.6.0 Accept custom 4xx and 5xx status codes in factory Add deprecation message to \"I'mateapot\" export Deprecate passing status code as anything except first argument in factory Deprecate using non-error status codes Make message property enumerable for HttpErrors 2016-11-16 / 1.5.1 deps: inherits@2.0.3 Fix issue loading in browser deps: setprototypeof@1.0.2 deps: statuses@'>= 1.3.1 < 2' 2016-05-18 / 1.5.0 Support new code 421 Misdirected Request Use setprototypeof module to replace __proto__ setting deps: statuses@'>= 1.3.0 < 2' Add 421 Misdirected Request perf: enable strict mode perf: enable strict mode 2016-01-28 / 1.4.0 Add HttpError export, for err instanceof createError.HttpError deps: inherits@2.0.1 deps: statuses@'>= 1.2.1 < 2' Fix message for status 451 Remove incorrect nginx status code 2015-02-02 / 1.3.1 Fix regression where status can be overwritten in createError props 2015-02-01 / 1.3.0 Construct errors using defined constructors from createError Fix error names that are not identifiers createError[\"I'mateapot\"] is now createError.ImATeapot Set a meaningful name property on constructed errors 2014-12-09 / 1.2.8 Fix stack trace from exported function Remove arguments.callee usage 2014-10-14 / 1.2.7 Remove duplicate line 2014-10-02 / 1.2.6 Fix expose to be true for ClientError constructor 2014-09-28 / 1.2.5 deps: statuses@1 2014-09-21 / 1.2.4 Fix dependency version to work with old npms 2014-09-21 / 1.2.3 deps: statuses@~1.1.0 2014-09-21 / 1.2.2 Fix publish error 2014-09-21 / 1.2.1 Support Node.js 0.6 Use inherits instead of util 2014-09-09 / 1.2.0 Fix the way inheriting functions Support expose being provided in properties argument 2014-09-08 / 1.1.0 Default status to 500 Support provided error to extend 2014-09-08 / 1.0.1 Fix accepting string message 2014-09-08 / 1.0.0 Initial release"
  },
  "node_modules/send/node_modules/http-errors/README.html": {
    "href": "node_modules/send/node_modules/http-errors/README.html",
    "title": "http-errors | accouter",
    "keywords": "http-errors Create HTTP errors for Express, Koa, Connect, etc. with ease. Install This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install http-errors Example var createError = require('http-errors') var express = require('express') var app = express() app.use(function (req, res, next) { if (!req.user) return next(createError(401, 'Please login to view this page.')) next() }) API This is the current API, currently extracted from Koa and subject to change. All errors inherit from JavaScript Error and the exported createError.HttpError. Error Properties expose - can be used to signal if message should be sent to the client, defaulting to false when status >= 500 headers - can be an object of header names to values to be sent to the client, defaulting to undefined. When defined, the key names should all be lower-cased message - the traditional error message, which should be kept short and all single line status - the status code of the error, mirroring statusCode for general compatibility statusCode - the status code of the error, defaulting to 500 createError([status], [message], [properties]) var err = createError(404, 'This video does not exist!') status: 500 - the status code as a number message - the message of the error, defaulting to node's text for that status code. properties - custom properties to attach to the object new createError[code || name]([msg])) var err = new createError.NotFound() code - the status code as a number name - the name of the error as a \"bumpy case\", i.e. NotFound or InternalServerError. List of all constructors Status Code Constructor Name 400 BadRequest 401 Unauthorized 402 PaymentRequired 403 Forbidden 404 NotFound 405 MethodNotAllowed 406 NotAcceptable 407 ProxyAuthenticationRequired 408 RequestTimeout 409 Conflict 410 Gone 411 LengthRequired 412 PreconditionFailed 413 PayloadTooLarge 414 URITooLong 415 UnsupportedMediaType 416 RangeNotSatisfiable 417 ExpectationFailed 418 ImATeapot 421 MisdirectedRequest 422 UnprocessableEntity 423 Locked 424 FailedDependency 425 UnorderedCollection 426 UpgradeRequired 428 PreconditionRequired 429 TooManyRequests 431 RequestHeaderFieldsTooLarge 451 UnavailableForLegalReasons 500 InternalServerError 501 NotImplemented 502 BadGateway 503 ServiceUnavailable 504 GatewayTimeout 505 HTTPVersionNotSupported 506 VariantAlsoNegotiates 507 InsufficientStorage 508 LoopDetected 509 BandwidthLimitExceeded 510 NotExtended 511 NetworkAuthenticationRequired License MIT"
  },
  "node_modules/send/node_modules/inherits/README.html": {
    "href": "node_modules/send/node_modules/inherits/README.html",
    "title": "| accouter",
    "keywords": "Browser-friendly inheritance fully compatible with standard node.js inherits. This package exports standard inherits from node.js util module in node environment, but also provides alternative browser-friendly implementation through browser field. Alternative implementation is a literal copy of standard one located in standalone module to avoid requiring of util. It also has a shim for old browsers with no Object.create support. While keeping you sure you are using standard inherits implementation in node.js environment, it allows bundlers such as browserify to not include full util package to your client code if all you need is just inherits function. It worth, because browser shim for util package is large and inherits is often the single function you need from it. It's recommended to use this package instead of require('util').inherits for any code that has chances to be used not only in node.js but in browser too. usage var inherits = require('inherits'); // then use exactly as the standard one note on version ~1.0 Version ~1.0 had completely different motivation and is not compatible neither with 2.0 nor with standard node.js inherits. If you are using version ~1.0 and planning to switch to ~2.0, be careful: new version uses super_ instead of super for referencing superclass new version overwrites current prototype while old one preserves any existing fields on it"
  },
  "node_modules/send/node_modules/setprototypeof/README.html": {
    "href": "node_modules/send/node_modules/setprototypeof/README.html",
    "title": "Polyfill for Object.setPrototypeOf | accouter",
    "keywords": "Polyfill for Object.setPrototypeOf A simple cross platform implementation to set the prototype of an instianted object. Supports all modern browsers and at least back to IE8. Usage: $ npm install --save setprototypeof var setPrototypeOf = require('setprototypeof'); var obj = {}; setPrototypeOf(obj, { foo: function() { return 'bar'; } }); obj.foo(); // bar TypeScript is also supported: import setPrototypeOf = require('setprototypeof');"
  },
  "node_modules/send/node_modules/statuses/HISTORY.html": {
    "href": "node_modules/send/node_modules/statuses/HISTORY.html",
    "title": "1.4.0 / 2017-10-20 | accouter",
    "keywords": "1.4.0 / 2017-10-20 Add STATUS_CODES export 1.3.1 / 2016-11-11 Fix return type in JSDoc 1.3.0 / 2016-05-17 Add 421 Misdirected Request perf: enable strict mode 1.2.1 / 2015-02-01 Fix message for status 451 451 Unavailable For Legal Reasons 1.2.0 / 2014-09-28 Add 208 Already Repored Add 226 IM Used Add 306 (Unused) Add 415 Unable For Legal Reasons Add 508 Loop Detected 1.1.1 / 2014-09-24 Add missing 308 to codes.json 1.1.0 / 2014-09-21 Add codes.json for universal support 1.0.4 / 2014-08-20 Package cleanup 1.0.3 / 2014-06-08 Add 308 to .redirect category 1.0.2 / 2014-03-13 Add .retry category 1.0.1 / 2014-03-12 Initial release"
  },
  "node_modules/send/node_modules/statuses/README.html": {
    "href": "node_modules/send/node_modules/statuses/README.html",
    "title": "Statuses | accouter",
    "keywords": "Statuses HTTP status utility for node. This module provides a list of status codes and messages sourced from a few different projects: The IANA Status Code Registry The Node.js project The NGINX project The Apache HTTP Server project Installation This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install statuses API var status = require('statuses') var code = status(Integer || String) If Integer or String is a valid HTTP code or status message, then the appropriate code will be returned. Otherwise, an error will be thrown. status(403) // => 403 status('403') // => 403 status('forbidden') // => 403 status('Forbidden') // => 403 status(306) // throws, as it's not supported by node.js status.STATUS_CODES Returns an object which maps status codes to status messages, in the same format as the Node.js http module. status.codes Returns an array of all the status codes as Integers. var msg = status[code] Map of code to status message. undefined for invalid codes. status[404] // => 'Not Found' var code = status[msg] Map of status message to code. msg can either be title-cased or lower-cased. undefined for invalid status messages. status['not found'] // => 404 status['Not Found'] // => 404 status.redirect[code] Returns true if a status code is a valid redirect status. status.redirect[200] // => undefined status.redirect[301] // => true status.empty[code] Returns true if a status code expects an empty body. status.empty[200] // => undefined status.empty[204] // => true status.empty[304] // => true status.retry[code] Returns true if you should retry the rest. status.retry[501] // => undefined status.retry[503] // => true"
  },
  "node_modules/serialize-javascript/README.html": {
    "href": "node_modules/serialize-javascript/README.html",
    "title": "Serialize JavaScript | accouter",
    "keywords": "Serialize JavaScript Serialize JavaScript to a superset of JSON that includes regular expressions, dates and functions. Overview The code in this package began its life as an internal module to express-state. To expand its usefulness, it now lives as serialize-javascript — an independent package on npm. You're probably wondering: What about JSON.stringify()!? We've found that sometimes we need to serialize JavaScript functions, regexps, dates, sets or maps. A great example is a web app that uses client-side URL routing where the route definitions are regexps that need to be shared from the server to the client. But this module is also great for communicating between node processes. The string returned from this package's single export function is literal JavaScript which can be saved to a .js file, or be embedded into an HTML document by making the content of a <script> element. HTML characters and JavaScript line terminators are escaped automatically. Please note that serialization for ES6 Sets & Maps requires support for Array.from (not available in IE or Node < 0.12), or an Array.from polyfill. Installation Install using npm: $ npm install serialize-javascript Usage var serialize = require('serialize-javascript'); serialize({ str : 'string', num : 0, obj : {foo: 'foo'}, arr : [1, 2, 3], bool : true, nil : null, undef: undefined, inf : Infinity, date : new Date(\"Thu, 28 Apr 2016 22:02:17 GMT\"), map : new Map([['hello', 'world']]), set : new Set([123, 456]), fn : function echo(arg) { return arg; }, re : /([^\\s]+)/g, big : BigInt(10), }); The above will produce the following string output: '{\"str\":\"string\",\"num\":0,\"obj\":{\"foo\":\"foo\"},\"arr\":[1,2,3],\"bool\":true,\"nil\":null,\"undef\":undefined,\"inf\":Infinity,\"date\":new Date(\"2016-04-28T22:02:17.000Z\"),\"map\":new Map([[\"hello\",\"world\"]]),\"set\":new Set([123,456]),\"fn\":function echo(arg) { return arg; },\"re\":new RegExp(\"([^\\\\\\\\s]+)\", \"g\"),\"big\":BigInt(\"10\")}' Note: to produced a beautified string, you can pass an optional second argument to serialize() to define the number of spaces to be used for the indentation. Automatic Escaping of HTML Characters A primary feature of this package is to serialize code to a string of literal JavaScript which can be embedded in an HTML document by adding it as the contents of the <script> element. In order to make this safe, HTML characters and JavaScript line terminators are escaped automatically. serialize({ haxorXSS: '</script>' }); The above will produce the following string, HTML-escaped output which is safe to put into an HTML document as it will not cause the inline script element to terminate: '{\"haxorXSS\":\"\\\\u003C\\\\u002Fscript\\\\u003E\"}' You can pass an optional unsafe argument to serialize() for straight serialization. Options The serialize() function accepts an options object as its second argument. All options are being defaulted to undefined: options.space This option is the same as the space argument that can be passed to JSON.stringify. It can be used to add whitespace and indentation to the serialized output to make it more readable. serialize(obj, {space: 2}); options.isJSON This option is a signal to serialize() that the object being serialized does not contain any function or regexps values. This enables a hot-path that allows serialization to be over 3x faster. If you're serializing a lot of data, and know its pure JSON, then you can enable this option for a speed-up. Note: That when using this option, the output will still be escaped to protect against XSS. serialize(obj, {isJSON: true}); options.unsafe This option is to signal serialize() that we want to do a straight conversion, without the XSS protection. This options needs to be explicitly set to true. HTML characters and JavaScript line terminators will not be escaped. You will have to roll your own. serialize(obj, {unsafe: true}); options.ignoreFunction This option is to signal serialize() that we do not want serialize JavaScript function. Just treat function like JSON.stringify do, but other features will work as expected. serialize(obj, {ignoreFunction: true}); Deserializing For some use cases you might also need to deserialize the string. This is explicitly not part of this module. However, you can easily write it yourself: function deserialize(serializedJavascript){ return eval('(' + serializedJavascript + ')'); } Note: Don't forget the parentheses around the serialized javascript, as the opening bracket { will be considered to be the start of a body. License This software is free to use under the Yahoo! Inc. BSD license. See the LICENSE file for license text and copyright information."
  },
  "node_modules/serve-index/HISTORY.html": {
    "href": "node_modules/serve-index/HISTORY.html",
    "title": "1.9.1 / 2017-09-28 | accouter",
    "keywords": "1.9.1 / 2017-09-28 deps: accepts@~1.3.4 deps: mime-types@~2.1.16 deps: debug@2.6.9 deps: http-errors@~1.6.2 deps: depd@1.1.1 deps: mime-types@~2.1.17 Add new mime types deps: mime-db@~1.30.0 deps: parseurl@~1.3.2 perf: reduce overhead for full URLs perf: unroll the \"fast-path\" RegExp 1.9.0 / 2017-05-25 Set X-Content-Type-Options: nosniff header deps: batch@0.6.1 deps: debug@2.6.8 Allow colors in workers Deprecated DEBUG_FD environment variable set to 3 or higher Fix DEBUG_MAX_ARRAY_LENGTH Fix error when running under React Native Use same color for same namespace deps: ms@2.0.0 deps: http-errors@~1.6.1 Make message property enumerable for HttpErrors deps: inherits@2.0.3 deps: setprototypeof@1.0.3 deps: statuses@'>= 1.3.1 < 2' deps: mime-types@~2.1.15 Add new mime types Add audio/mp3 1.8.0 / 2016-06-17 Make inline file search case-insensitive deps: accepts@~1.3.3 deps: mime-types@~2.1.11 deps: negotiator@0.6.1 perf: improve header parsing speed deps: http-errors@~1.5.0 Use setprototypeof module to replace __proto__ setting deps: inherits@2.0.1 deps: statuses@'>= 1.3.0 < 2' perf: enable strict mode deps: mime-types@~2.1.11 Add new mime types Update primary extension for audio/mp4 deps: mime-db@~1.23.0 1.7.3 / 2016-01-24 deps: accepts@~1.2.13 deps: mime-types@~2.1.6 deps: batch@0.5.3 Fix invalid dependency for browserify deps: escape-html@~1.0.3 perf: enable strict mode perf: optimize string replacement perf: use faster string coercion deps: mime-types@~2.1.9 Add new mime types deps: parseurl@~1.3.1 perf: enable strict mode 1.7.2 / 2015-07-30 deps: accepts@~1.2.12 deps: mime-types@~2.1.4 deps: mime-types@~2.1.4 Add new mime types 1.7.1 / 2015-07-05 deps: accepts@~1.2.10 deps: mime-types@~2.1.2 deps: mime-types@~2.1.2 Add new mime types 1.7.0 / 2015-06-15 Accept function value for template option Send non-chunked response for OPTIONS Stat parent directory when necessary Use Date.prototype.toLocaleDateString to format date deps: accepts@~1.2.9 deps: mime-types@~2.1.1 deps: negotiator@0.5.3 perf: avoid argument reassignment & argument slice perf: avoid negotiator recursive construction perf: enable strict mode perf: remove unnecessary bitwise operator deps: escape-html@1.0.2 deps: mime-types@~2.1.1 Add new mime types perf: enable strict mode perf: remove argument reassignment 1.6.4 / 2015-05-12 deps: accepts@~1.2.7 deps: mime-types@~2.0.11 deps: negotiator@0.5.3 deps: debug@~2.2.0 deps: ms@0.7.1 deps: mime-types@~2.0.11 Add new mime types 1.6.3 / 2015-03-13 Properly escape file names in HTML deps: accepts@~1.2.5 deps: mime-types@~2.0.10 deps: debug@~2.1.3 Fix high intensity foreground color for bold deps: ms@0.7.0 deps: escape-html@1.0.1 deps: mime-types@~2.0.10 Add new mime types 1.6.2 / 2015-02-16 deps: accepts@~1.2.4 deps: mime-types@~2.0.9 deps: negotiator@0.5.1 deps: http-errors@~1.3.1 Construct errors using defined constructors from createError Fix error names that are not identifiers Set a meaningful name property on constructed errors deps: mime-types@~2.0.9 Add new mime types deps: mime-db@~1.7.0 1.6.1 / 2015-01-31 deps: accepts@~1.2.3 deps: mime-types@~2.0.8 deps: mime-types@~2.0.8 Add new mime types deps: mime-db@~1.6.0 1.6.0 / 2015-01-01 Add link to root directory deps: accepts@~1.2.2 deps: mime-types@~2.0.7 deps: negotiator@0.5.0 deps: batch@0.5.2 deps: debug@~2.1.1 deps: mime-types@~2.0.7 Add new mime types Fix missing extensions Fix various invalid MIME type entries Remove example template MIME types deps: mime-db@~1.5.0 1.5.3 / 2014-12-10 deps: accepts@~1.1.4 deps: mime-types@~2.0.4 deps: http-errors@~1.2.8 Fix stack trace from exported function deps: mime-types@~2.0.4 Add new mime types deps: mime-db@~1.3.0 1.5.2 / 2014-12-03 Fix icon name background alignment on mobile view 1.5.1 / 2014-11-22 deps: accepts@~1.1.3 deps: mime-types@~2.0.3 deps: mime-types@~2.0.3 Add new mime types deps: mime-db@~1.2.0 1.5.0 / 2014-10-16 Create errors with http-errors deps: debug@~2.1.0 Implement DEBUG_FD env variable support deps: mime-types@~2.0.2 deps: mime-db@~1.1.0 1.4.1 / 2014-10-15 deps: accepts@~1.1.2 Fix error when media type has invalid parameter deps: negotiator@0.4.9 1.4.0 / 2014-10-03 Add dir argument to filter function Support using tokens multiple times 1.3.1 / 2014-10-01 Fix incorrect 403 on Windows and Node.js 0.11 deps: accepts@~1.1.1 deps: mime-types@~2.0.2 deps: negotiator@0.4.8 1.3.0 / 2014-09-20 Add icon for mkv files Lookup icon by mime type for greater icon support 1.2.1 / 2014-09-05 deps: accepts@~1.1.0 deps: debug@~2.0.0 1.2.0 / 2014-08-25 Add debug messages Resolve relative paths at middleware setup 1.1.6 / 2014-08-10 Fix URL parsing deps: parseurl@~1.3.0 1.1.5 / 2014-07-27 Fix Content-Length calculation for multi-byte file names deps: accepts@~1.0.7 deps: negotiator@0.4.7 1.1.4 / 2014-06-20 deps: accepts@~1.0.5 1.1.3 / 2014-06-20 deps: accepts@~1.0.4 use mime-types 1.1.2 / 2014-06-19 deps: batch@0.5.1 1.1.1 / 2014-06-11 deps: accepts@1.0.3 1.1.0 / 2014-05-29 Fix content negotiation when no Accept header Properly support all HTTP methods Support vanilla node.js http servers Treat ENAMETOOLONG as code 414 Use accepts for negotiation 1.0.3 / 2014-05-20 Fix error from non-statable files in HTML view 1.0.2 / 2014-04-28 Add stylesheet option deps: negotiator@0.4.3 1.0.1 / 2014-03-05 deps: negotiator@0.4.2 1.0.0 / 2014-03-05 Genesis from connect"
  },
  "node_modules/serve-index/README.html": {
    "href": "node_modules/serve-index/README.html",
    "title": "serve-index | accouter",
    "keywords": "serve-index Serves pages that contain directory listings for a given path. Install This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install serve-index API var serveIndex = require('serve-index') serveIndex(path, options) Returns middlware that serves an index of the directory in the given path. The path is based off the req.url value, so a req.url of '/some/dir with a path of 'public' will look at 'public/some/dir'. If you are using something like express, you can change the URL \"base\" with app.use (see the express example). Options Serve index accepts these properties in the options object. filter Apply this filter function to files. Defaults to false. The filter function is called for each file, with the signature filter(filename, index, files, dir) where filename is the name of the file, index is the array index, files is the array of files and dir is the absolute path the file is located (and thus, the directory the listing is for). hidden Display hidden (dot) files. Defaults to false. icons Display icons. Defaults to false. stylesheet Optional path to a CSS stylesheet. Defaults to a built-in stylesheet. template Optional path to an HTML template or a function that will render a HTML string. Defaults to a built-in template. When given a string, the string is used as a file path to load and then the following tokens are replaced in templates: {directory} with the name of the directory. {files} with the HTML of an unordered list of file links. {linked-path} with the HTML of a link to the directory. {style} with the specified stylesheet and embedded images. When given as a function, the function is called as template(locals, callback) and it needs to invoke callback(error, htmlString). The following are the provided locals: directory is the directory being displayed (where / is the root). displayIcons is a Boolean for if icons should be rendered or not. fileList is a sorted array of files in the directory. The array contains objects with the following properties: name is the relative name for the file. stat is a fs.Stats object for the file. path is the full filesystem path to directory. style is the default stylesheet or the contents of the stylesheet option. viewName is the view name provided by the view option. view Display mode. tiles and details are available. Defaults to tiles. Examples Serve directory indexes with vanilla node.js http server var finalhandler = require('finalhandler') var http = require('http') var serveIndex = require('serve-index') var serveStatic = require('serve-static') // Serve directory indexes for public/ftp folder (with icons) var index = serveIndex('public/ftp', {'icons': true}) // Serve up public/ftp folder files var serve = serveStatic('public/ftp') // Create server var server = http.createServer(function onRequest(req, res){ var done = finalhandler(req, res) serve(req, res, function onNext(err) { if (err) return done(err) index(req, res, done) }) }) // Listen server.listen(3000) Serve directory indexes with express var express = require('express') var serveIndex = require('serve-index') var app = express() // Serve URLs like /ftp/thing as public/ftp/thing // The express.static serves the file contents // The serveIndex is this module serving the directory app.use('/ftp', express.static('public/ftp'), serveIndex('public/ftp', {'icons': true})) // Listen app.listen(3000) License MIT. The Silk icons are created by/copyright of FAMFAMFAM."
  },
  "node_modules/serve-index/node_modules/depd/History.html": {
    "href": "node_modules/serve-index/node_modules/depd/History.html",
    "title": "1.1.2 / 2018-01-11 | accouter",
    "keywords": "1.1.2 / 2018-01-11 perf: remove argument reassignment Support Node.js 0.6 to 9.x 1.1.1 / 2017-07-27 Remove unnecessary Buffer loading Support Node.js 0.6 to 8.x 1.1.0 / 2015-09-14 Enable strict mode in more places Support io.js 3.x Support io.js 2.x Support web browser loading Requires bundler like Browserify or webpack 1.0.1 / 2015-04-07 Fix TypeErrors when under 'use strict' code Fix useless type name on auto-generated messages Support io.js 1.x Support Node.js 0.12 1.0.0 / 2014-09-17 No changes 0.4.5 / 2014-09-09 Improve call speed to functions using the function wrapper Support Node.js 0.6 0.4.4 / 2014-07-27 Work-around v8 generating empty stack traces 0.4.3 / 2014-07-26 Fix exception when global Error.stackTraceLimit is too low 0.4.2 / 2014-07-19 Correct call site for wrapped functions and properties 0.4.1 / 2014-07-19 Improve automatic message generation for function properties 0.4.0 / 2014-07-19 Add TRACE_DEPRECATION environment variable Remove non-standard grey color from color output Support --no-deprecation argument Support --trace-deprecation argument Support deprecate.property(fn, prop, message) 0.3.0 / 2014-06-16 Add NO_DEPRECATION environment variable 0.2.0 / 2014-06-15 Add deprecate.property(obj, prop, message) Remove supports-color dependency for node.js 0.8 0.1.0 / 2014-06-15 Add deprecate.function(fn, message) Add process.on('deprecation', fn) emitter Automatically generate message when omitted from deprecate() 0.0.1 / 2014-06-15 Fix warning for dynamic calls at singe call site 0.0.0 / 2014-06-15 Initial implementation"
  },
  "node_modules/serve-index/node_modules/depd/Readme.html": {
    "href": "node_modules/serve-index/node_modules/depd/Readme.html",
    "title": "depd | accouter",
    "keywords": "depd Deprecate all the things With great modules comes great responsibility; mark things deprecated! Install This module is installed directly using npm: $ npm install depd This module can also be bundled with systems like Browserify or webpack, though by default this module will alter it's API to no longer display or track deprecations. API var deprecate = require('depd')('my-module') This library allows you to display deprecation messages to your users. This library goes above and beyond with deprecation warnings by introspection of the call stack (but only the bits that it is interested in). Instead of just warning on the first invocation of a deprecated function and never again, this module will warn on the first invocation of a deprecated function per unique call site, making it ideal to alert users of all deprecated uses across the code base, rather than just whatever happens to execute first. The deprecation warnings from this module also include the file and line information for the call into the module that the deprecated function was in. NOTE this library has a similar interface to the debug module, and this module uses the calling file to get the boundary for the call stacks, so you should always create a new deprecate object in each file and not within some central file. depd(namespace) Create a new deprecate function that uses the given namespace name in the messages and will display the call site prior to the stack entering the file this function was called from. It is highly suggested you use the name of your module as the namespace. deprecate(message) Call this function from deprecated code to display a deprecation message. This message will appear once per unique caller site. Caller site is the first call site in the stack in a different file from the caller of this function. If the message is omitted, a message is generated for you based on the site of the deprecate() call and will display the name of the function called, similar to the name displayed in a stack trace. deprecate.function(fn, message) Call this function to wrap a given function in a deprecation message on any call to the function. An optional message can be supplied to provide a custom message. deprecate.property(obj, prop, message) Call this function to wrap a given property on object in a deprecation message on any accessing or setting of the property. An optional message can be supplied to provide a custom message. The method must be called on the object where the property belongs (not inherited from the prototype). If the property is a data descriptor, it will be converted to an accessor descriptor in order to display the deprecation message. process.on('deprecation', fn) This module will allow easy capturing of deprecation errors by emitting the errors as the type \"deprecation\" on the global process. If there are no listeners for this type, the errors are written to STDERR as normal, but if there are any listeners, nothing will be written to STDERR and instead only emitted. From there, you can write the errors in a different format or to a logging source. The error represents the deprecation and is emitted only once with the same rules as writing to STDERR. The error has the following properties: message - This is the message given by the library name - This is always 'DeprecationError' namespace - This is the namespace the deprecation came from stack - This is the stack of the call to the deprecated thing Example error.stack output: DeprecationError: my-cool-module deprecated oldfunction at Object.<anonymous> ([eval]-wrapper:6:22) at Module._compile (module.js:456:26) at evalScript (node.js:532:25) at startup (node.js:80:7) at node.js:902:3 process.env.NO_DEPRECATION As a user of modules that are deprecated, the environment variable NO_DEPRECATION is provided as a quick solution to silencing deprecation warnings from being output. The format of this is similar to that of DEBUG: $ NO_DEPRECATION=my-module,othermod node app.js This will suppress deprecations from being output for \"my-module\" and \"othermod\". The value is a list of comma-separated namespaces. To suppress every warning across all namespaces, use the value * for a namespace. Providing the argument --no-deprecation to the node executable will suppress all deprecations (only available in Node.js 0.8 or higher). NOTE This will not suppress the deperecations given to any \"deprecation\" event listeners, just the output to STDERR. process.env.TRACE_DEPRECATION As a user of modules that are deprecated, the environment variable TRACE_DEPRECATION is provided as a solution to getting more detailed location information in deprecation warnings by including the entire stack trace. The format of this is the same as NO_DEPRECATION: $ TRACE_DEPRECATION=my-module,othermod node app.js This will include stack traces for deprecations being output for \"my-module\" and \"othermod\". The value is a list of comma-separated namespaces. To trace every warning across all namespaces, use the value * for a namespace. Providing the argument --trace-deprecation to the node executable will trace all deprecations (only available in Node.js 0.8 or higher). NOTE This will not trace the deperecations silenced by NO_DEPRECATION. Display When a user calls a function in your library that you mark deprecated, they will see the following written to STDERR (in the given colors, similar colors and layout to the debug module): bright cyan bright yellow | | reset cyan | | | | ▼ ▼ ▼ ▼ my-cool-module deprecated oldfunction [eval]-wrapper:6:22 ▲ ▲ ▲ ▲ | | | | namespace | | location of mycoolmod.oldfunction() call | deprecation message the word \"deprecated\" If the user redirects their STDERR to a file or somewhere that does not support colors, they see (similar layout to the debug module): Sun, 15 Jun 2014 05:21:37 GMT my-cool-module deprecated oldfunction at [eval]-wrapper:6:22 ▲ ▲ ▲ ▲ ▲ | | | | | timestamp of message namespace | | location of mycoolmod.oldfunction() call | deprecation message the word \"deprecated\" Examples Deprecating all calls to a function This will display a deprecated message about \"oldfunction\" being deprecated from \"my-module\" on STDERR. var deprecate = require('depd')('my-cool-module') // message automatically derived from function name // Object.oldfunction exports.oldfunction = deprecate.function(function oldfunction () { // all calls to function are deprecated }) // specific message exports.oldfunction = deprecate.function(function () { // all calls to function are deprecated }, 'oldfunction') Conditionally deprecating a function call This will display a deprecated message about \"weirdfunction\" being deprecated from \"my-module\" on STDERR when called with less than 2 arguments. var deprecate = require('depd')('my-cool-module') exports.weirdfunction = function () { if (arguments.length < 2) { // calls with 0 or 1 args are deprecated deprecate('weirdfunction args < 2') } } When calling deprecate as a function, the warning is counted per call site within your own module, so you can display different deprecations depending on different situations and the users will still get all the warnings: var deprecate = require('depd')('my-cool-module') exports.weirdfunction = function () { if (arguments.length < 2) { // calls with 0 or 1 args are deprecated deprecate('weirdfunction args < 2') } else if (typeof arguments[0] !== 'string') { // calls with non-string first argument are deprecated deprecate('weirdfunction non-string first arg') } } Deprecating property access This will display a deprecated message about \"oldprop\" being deprecated from \"my-module\" on STDERR when accessed. A deprecation will be displayed when setting the value and when getting the value. var deprecate = require('depd')('my-cool-module') exports.oldprop = 'something' // message automatically derives from property name deprecate.property(exports, 'oldprop') // explicit message deprecate.property(exports, 'oldprop', 'oldprop >= 0.10') License MIT"
  },
  "node_modules/serve-index/node_modules/http-errors/HISTORY.html": {
    "href": "node_modules/serve-index/node_modules/http-errors/HISTORY.html",
    "title": "2018-03-29 / 1.6.3 | accouter",
    "keywords": "2018-03-29 / 1.6.3 deps: depd@~1.1.2 perf: remove argument reassignment deps: setprototypeof@1.1.0 deps: statuses@'>= 1.3.1 < 2' 2017-08-04 / 1.6.2 deps: depd@1.1.1 Remove unnecessary Buffer loading 2017-02-20 / 1.6.1 deps: setprototypeof@1.0.3 Fix shim for old browsers 2017-02-14 / 1.6.0 Accept custom 4xx and 5xx status codes in factory Add deprecation message to \"I'mateapot\" export Deprecate passing status code as anything except first argument in factory Deprecate using non-error status codes Make message property enumerable for HttpErrors 2016-11-16 / 1.5.1 deps: inherits@2.0.3 Fix issue loading in browser deps: setprototypeof@1.0.2 deps: statuses@'>= 1.3.1 < 2' 2016-05-18 / 1.5.0 Support new code 421 Misdirected Request Use setprototypeof module to replace __proto__ setting deps: statuses@'>= 1.3.0 < 2' Add 421 Misdirected Request perf: enable strict mode perf: enable strict mode 2016-01-28 / 1.4.0 Add HttpError export, for err instanceof createError.HttpError deps: inherits@2.0.1 deps: statuses@'>= 1.2.1 < 2' Fix message for status 451 Remove incorrect nginx status code 2015-02-02 / 1.3.1 Fix regression where status can be overwritten in createError props 2015-02-01 / 1.3.0 Construct errors using defined constructors from createError Fix error names that are not identifiers createError[\"I'mateapot\"] is now createError.ImATeapot Set a meaningful name property on constructed errors 2014-12-09 / 1.2.8 Fix stack trace from exported function Remove arguments.callee usage 2014-10-14 / 1.2.7 Remove duplicate line 2014-10-02 / 1.2.6 Fix expose to be true for ClientError constructor 2014-09-28 / 1.2.5 deps: statuses@1 2014-09-21 / 1.2.4 Fix dependency version to work with old npms 2014-09-21 / 1.2.3 deps: statuses@~1.1.0 2014-09-21 / 1.2.2 Fix publish error 2014-09-21 / 1.2.1 Support Node.js 0.6 Use inherits instead of util 2014-09-09 / 1.2.0 Fix the way inheriting functions Support expose being provided in properties argument 2014-09-08 / 1.1.0 Default status to 500 Support provided error to extend 2014-09-08 / 1.0.1 Fix accepting string message 2014-09-08 / 1.0.0 Initial release"
  },
  "node_modules/serve-index/node_modules/http-errors/README.html": {
    "href": "node_modules/serve-index/node_modules/http-errors/README.html",
    "title": "http-errors | accouter",
    "keywords": "http-errors Create HTTP errors for Express, Koa, Connect, etc. with ease. Install This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install http-errors Example var createError = require('http-errors') var express = require('express') var app = express() app.use(function (req, res, next) { if (!req.user) return next(createError(401, 'Please login to view this page.')) next() }) API This is the current API, currently extracted from Koa and subject to change. All errors inherit from JavaScript Error and the exported createError.HttpError. Error Properties expose - can be used to signal if message should be sent to the client, defaulting to false when status >= 500 headers - can be an object of header names to values to be sent to the client, defaulting to undefined. When defined, the key names should all be lower-cased message - the traditional error message, which should be kept short and all single line status - the status code of the error, mirroring statusCode for general compatibility statusCode - the status code of the error, defaulting to 500 createError([status], [message], [properties]) var err = createError(404, 'This video does not exist!') status: 500 - the status code as a number message - the message of the error, defaulting to node's text for that status code. properties - custom properties to attach to the object new createError[code || name]([msg])) var err = new createError.NotFound() code - the status code as a number name - the name of the error as a \"bumpy case\", i.e. NotFound or InternalServerError. List of all constructors Status Code Constructor Name 400 BadRequest 401 Unauthorized 402 PaymentRequired 403 Forbidden 404 NotFound 405 MethodNotAllowed 406 NotAcceptable 407 ProxyAuthenticationRequired 408 RequestTimeout 409 Conflict 410 Gone 411 LengthRequired 412 PreconditionFailed 413 PayloadTooLarge 414 URITooLong 415 UnsupportedMediaType 416 RangeNotSatisfiable 417 ExpectationFailed 418 ImATeapot 421 MisdirectedRequest 422 UnprocessableEntity 423 Locked 424 FailedDependency 425 UnorderedCollection 426 UpgradeRequired 428 PreconditionRequired 429 TooManyRequests 431 RequestHeaderFieldsTooLarge 451 UnavailableForLegalReasons 500 InternalServerError 501 NotImplemented 502 BadGateway 503 ServiceUnavailable 504 GatewayTimeout 505 HTTPVersionNotSupported 506 VariantAlsoNegotiates 507 InsufficientStorage 508 LoopDetected 509 BandwidthLimitExceeded 510 NotExtended 511 NetworkAuthenticationRequired License MIT"
  },
  "node_modules/serve-index/node_modules/inherits/README.html": {
    "href": "node_modules/serve-index/node_modules/inherits/README.html",
    "title": "| accouter",
    "keywords": "Browser-friendly inheritance fully compatible with standard node.js inherits. This package exports standard inherits from node.js util module in node environment, but also provides alternative browser-friendly implementation through browser field. Alternative implementation is a literal copy of standard one located in standalone module to avoid requiring of util. It also has a shim for old browsers with no Object.create support. While keeping you sure you are using standard inherits implementation in node.js environment, it allows bundlers such as browserify to not include full util package to your client code if all you need is just inherits function. It worth, because browser shim for util package is large and inherits is often the single function you need from it. It's recommended to use this package instead of require('util').inherits for any code that has chances to be used not only in node.js but in browser too. usage var inherits = require('inherits'); // then use exactly as the standard one note on version ~1.0 Version ~1.0 had completely different motivation and is not compatible neither with 2.0 nor with standard node.js inherits. If you are using version ~1.0 and planning to switch to ~2.0, be careful: new version uses super_ instead of super for referencing superclass new version overwrites current prototype while old one preserves any existing fields on it"
  },
  "node_modules/serve-index/node_modules/setprototypeof/README.html": {
    "href": "node_modules/serve-index/node_modules/setprototypeof/README.html",
    "title": "Polyfill for Object.setPrototypeOf | accouter",
    "keywords": "Polyfill for Object.setPrototypeOf A simple cross platform implementation to set the prototype of an instianted object. Supports all modern browsers and at least back to IE8. Usage: $ npm install --save setprototypeof var setPrototypeOf = require('setprototypeof'); var obj = {}; setPrototypeOf(obj, { foo: function() { return 'bar'; } }); obj.foo(); // bar TypeScript is also supported: import setPrototypeOf = require('setprototypeof');"
  },
  "node_modules/serve-index/node_modules/statuses/HISTORY.html": {
    "href": "node_modules/serve-index/node_modules/statuses/HISTORY.html",
    "title": "1.5.0 / 2018-03-27 | accouter",
    "keywords": "1.5.0 / 2018-03-27 Add 103 Early Hints 1.4.0 / 2017-10-20 Add STATUS_CODES export 1.3.1 / 2016-11-11 Fix return type in JSDoc 1.3.0 / 2016-05-17 Add 421 Misdirected Request perf: enable strict mode 1.2.1 / 2015-02-01 Fix message for status 451 451 Unavailable For Legal Reasons 1.2.0 / 2014-09-28 Add 208 Already Repored Add 226 IM Used Add 306 (Unused) Add 415 Unable For Legal Reasons Add 508 Loop Detected 1.1.1 / 2014-09-24 Add missing 308 to codes.json 1.1.0 / 2014-09-21 Add codes.json for universal support 1.0.4 / 2014-08-20 Package cleanup 1.0.3 / 2014-06-08 Add 308 to .redirect category 1.0.2 / 2014-03-13 Add .retry category 1.0.1 / 2014-03-12 Initial release"
  },
  "node_modules/serve-index/node_modules/statuses/README.html": {
    "href": "node_modules/serve-index/node_modules/statuses/README.html",
    "title": "Statuses | accouter",
    "keywords": "Statuses HTTP status utility for node. This module provides a list of status codes and messages sourced from a few different projects: The IANA Status Code Registry The Node.js project The NGINX project The Apache HTTP Server project Installation This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install statuses API var status = require('statuses') var code = status(Integer || String) If Integer or String is a valid HTTP code or status message, then the appropriate code will be returned. Otherwise, an error will be thrown. status(403) // => 403 status('403') // => 403 status('forbidden') // => 403 status('Forbidden') // => 403 status(306) // throws, as it's not supported by node.js status.STATUS_CODES Returns an object which maps status codes to status messages, in the same format as the Node.js http module. status.codes Returns an array of all the status codes as Integers. var msg = status[code] Map of code to status message. undefined for invalid codes. status[404] // => 'Not Found' var code = status[msg] Map of status message to code. msg can either be title-cased or lower-cased. undefined for invalid status messages. status['not found'] // => 404 status['Not Found'] // => 404 status.redirect[code] Returns true if a status code is a valid redirect status. status.redirect[200] // => undefined status.redirect[301] // => true status.empty[code] Returns true if a status code expects an empty body. status.empty[200] // => undefined status.empty[204] // => true status.empty[304] // => true status.retry[code] Returns true if you should retry the rest. status.retry[501] // => undefined status.retry[503] // => true"
  },
  "node_modules/serve-static/HISTORY.html": {
    "href": "node_modules/serve-static/HISTORY.html",
    "title": "1.13.2 / 2018-02-07 | accouter",
    "keywords": "1.13.2 / 2018-02-07 Fix incorrect end tag in redirects deps: encodeurl@~1.0.2 Fix encoding % as last character deps: send@0.16.2 deps: depd@~1.1.2 deps: encodeurl@~1.0.2 deps: statuses@~1.4.0 1.13.1 / 2017-09-29 Fix regression when root is incorrectly set to a file deps: send@0.16.1 1.13.0 / 2017-09-27 deps: send@0.16.0 Add 70 new types for file extensions Add immutable option Fix missing </html> in default error & redirects Set charset as \"UTF-8\" for .js and .json Use instance methods on steam to check for listeners deps: mime@1.4.1 perf: improve path validation speed 1.12.6 / 2017-09-22 deps: send@0.15.6 deps: debug@2.6.9 perf: improve If-Match token parsing perf: improve slash collapsing 1.12.5 / 2017-09-21 deps: parseurl@~1.3.2 perf: reduce overhead for full URLs perf: unroll the \"fast-path\" RegExp deps: send@0.15.5 Fix handling of modified headers with invalid dates deps: etag@~1.8.1 deps: fresh@0.5.2 1.12.4 / 2017-08-05 deps: send@0.15.4 deps: debug@2.6.8 deps: depd@~1.1.1 deps: http-errors@~1.6.2 1.12.3 / 2017-05-16 deps: send@0.15.3 deps: debug@2.6.7 1.12.2 / 2017-04-26 deps: send@0.15.2 deps: debug@2.6.4 1.12.1 / 2017-03-04 deps: send@0.15.1 Fix issue when Date.parse does not return NaN on invalid date Fix strict violation in broken environments 1.12.0 / 2017-02-25 Send complete HTML document in redirect response Set default CSP header in redirect response deps: send@0.15.0 Fix false detection of no-cache request directive Fix incorrect result when If-None-Match has both * and ETags Fix weak ETag matching to match spec Remove usage of res._headers private field Support If-Match and If-Unmodified-Since headers Use res.getHeaderNames() when available Use res.headersSent when available deps: debug@2.6.1 deps: etag@~1.8.0 deps: fresh@0.5.0 deps: http-errors@~1.6.1 1.11.2 / 2017-01-23 deps: send@0.14.2 deps: http-errors@~1.5.1 deps: ms@0.7.2 deps: statuses@~1.3.1 1.11.1 / 2016-06-10 Fix redirect error when req.url contains raw non-URL characters deps: send@0.14.1 1.11.0 / 2016-06-07 Use status code 301 for redirects deps: send@0.14.0 Add acceptRanges option Add cacheControl option Attempt to combine multiple ranges into single range Correctly inherit from Stream class Fix Content-Range header in 416 responses when using start/end options Fix Content-Range header missing from default 416 responses Ignore non-byte Range headers deps: http-errors@~1.5.0 deps: range-parser@~1.2.0 deps: statuses@~1.3.0 perf: remove argument reassignment 1.10.3 / 2016-05-30 deps: send@0.13.2 Fix invalid Content-Type header when send.mime.default_type unset 1.10.2 / 2016-01-19 deps: parseurl@~1.3.1 perf: enable strict mode 1.10.1 / 2016-01-16 deps: escape-html@~1.0.3 perf: enable strict mode perf: optimize string replacement perf: use faster string coercion deps: send@0.13.1 deps: depd@~1.1.0 deps: destroy@~1.0.4 deps: escape-html@~1.0.3 deps: range-parser@~1.0.3 1.10.0 / 2015-06-17 Add fallthrough option Allows declaring this middleware is the final destination Provides better integration with Express patterns Fix reading options from options prototype Improve the default redirect response headers deps: escape-html@1.0.2 deps: send@0.13.0 Allow Node.js HTTP server to set Date response header Fix incorrectly removing Content-Location on 304 response Improve the default redirect response headers Send appropriate headers on default error response Use http-errors for standard emitted errors Use statuses instead of http module for status messages deps: escape-html@1.0.2 deps: etag@~1.7.0 deps: fresh@0.3.0 deps: on-finished@~2.3.0 perf: enable strict mode perf: remove unnecessary array allocations perf: enable strict mode perf: remove argument reassignment 1.9.3 / 2015-05-14 deps: send@0.12.3 deps: debug@~2.2.0 deps: depd@~1.0.1 deps: etag@~1.6.0 deps: ms@0.7.1 deps: on-finished@~2.2.1 1.9.2 / 2015-03-14 deps: send@0.12.2 Throw errors early for invalid extensions or index options deps: debug@~2.1.3 1.9.1 / 2015-02-17 deps: send@0.12.1 Fix regression sending zero-length files 1.9.0 / 2015-02-16 deps: send@0.12.0 Always read the stat size from the file Fix mutating passed-in options deps: mime@1.3.4 1.8.1 / 2015-01-20 Fix redirect loop in Node.js 0.11.14 deps: send@0.11.1 Fix root path disclosure 1.8.0 / 2015-01-05 deps: send@0.11.0 deps: debug@~2.1.1 deps: etag@~1.5.1 deps: ms@0.7.0 deps: on-finished@~2.2.0 1.7.2 / 2015-01-02 Fix potential open redirect when mounted at root 1.7.1 / 2014-10-22 deps: send@0.10.1 deps: on-finished@~2.1.1 1.7.0 / 2014-10-15 deps: send@0.10.0 deps: debug@~2.1.0 deps: depd@~1.0.0 deps: etag@~1.5.0 1.6.5 / 2015-02-04 Fix potential open redirect when mounted at root Back-ported from v1.7.2 1.6.4 / 2014-10-08 Fix redirect loop when index file serving disabled 1.6.3 / 2014-09-24 deps: send@0.9.3 deps: etag@~1.4.0 1.6.2 / 2014-09-15 deps: send@0.9.2 deps: depd@0.4.5 deps: etag@~1.3.1 deps: range-parser@~1.0.2 1.6.1 / 2014-09-07 deps: send@0.9.1 deps: fresh@0.2.4 1.6.0 / 2014-09-07 deps: send@0.9.0 Add lastModified option Use etag to generate ETag header deps: debug@~2.0.0 1.5.4 / 2014-09-04 deps: send@0.8.5 Fix a path traversal issue when using root Fix malicious path detection for empty string path 1.5.3 / 2014-08-17 deps: send@0.8.3 1.5.2 / 2014-08-14 deps: send@0.8.2 Work around fd leak in Node.js 0.10 for fs.ReadStream 1.5.1 / 2014-08-09 Fix parsing of weird req.originalUrl values deps: parseurl@~1.3.0 deps: utils-merge@1.0.0 1.5.0 / 2014-08-05 deps: send@0.8.1 Add extensions option 1.4.4 / 2014-08-04 deps: send@0.7.4 Fix serving index files without root dir 1.4.3 / 2014-07-29 deps: send@0.7.3 Fix incorrect 403 on Windows and Node.js 0.11 1.4.2 / 2014-07-27 deps: send@0.7.2 deps: depd@0.4.4 1.4.1 / 2014-07-26 deps: send@0.7.1 deps: depd@0.4.3 1.4.0 / 2014-07-21 deps: parseurl@~1.2.0 Cache URLs based on original value Remove no-longer-needed URL mis-parse work-around Simplify the \"fast-path\" RegExp deps: send@0.7.0 Add dotfiles option deps: debug@1.0.4 deps: depd@0.4.2 1.3.2 / 2014-07-11 deps: send@0.6.0 Cap maxAge value to 1 year deps: debug@1.0.3 1.3.1 / 2014-07-09 deps: parseurl@~1.1.3 faster parsing of href-only URLs 1.3.0 / 2014-06-28 Add setHeaders option Include HTML link in redirect response deps: send@0.5.0 Accept string for maxAge (converted by ms) 1.2.3 / 2014-06-11 deps: send@0.4.3 Do not throw un-catchable error on file open race condition Use escape-html for HTML escaping deps: debug@1.0.2 deps: finished@1.2.2 deps: fresh@0.2.2 1.2.2 / 2014-06-09 deps: send@0.4.2 fix \"event emitter leak\" warnings deps: debug@1.0.1 deps: finished@1.2.1 1.2.1 / 2014-06-02 use escape-html for escaping deps: send@0.4.1 Send max-age in Cache-Control in correct format 1.2.0 / 2014-05-29 deps: send@0.4.0 Calculate ETag with md5 for reduced collisions Fix wrong behavior when index file matches directory Ignore stream errors after request ends Skip directories in index file search deps: debug@0.8.1 1.1.0 / 2014-04-24 Accept options directly to send module deps: send@0.3.0 1.0.4 / 2014-04-07 Resolve relative paths at middleware setup Use parseurl to parse the URL from request 1.0.3 / 2014-03-20 Do not rely on connect-like environments 1.0.2 / 2014-03-06 deps: send@0.2.0 1.0.1 / 2014-03-05 Add mime export for back-compat 1.0.0 / 2014-03-05 Genesis from connect"
  },
  "node_modules/serve-static/README.html": {
    "href": "node_modules/serve-static/README.html",
    "title": "serve-static | accouter",
    "keywords": "serve-static Install This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install serve-static API var serveStatic = require('serve-static') serveStatic(root, options) Create a new middleware function to serve files from within a given root directory. The file to serve will be determined by combining req.url with the provided root directory. When a file is not found, instead of sending a 404 response, this module will instead call next() to move on to the next middleware, allowing for stacking and fall-backs. Options acceptRanges Enable or disable accepting ranged requests, defaults to true. Disabling this will not send Accept-Ranges and ignore the contents of the Range request header. cacheControl Enable or disable setting Cache-Control response header, defaults to true. Disabling this will ignore the immutable and maxAge options. dotfiles Set how \"dotfiles\" are treated when encountered. A dotfile is a file or directory that begins with a dot (\".\"). Note this check is done on the path itself without checking if the path actually exists on the disk. If root is specified, only the dotfiles above the root are checked (i.e. the root itself can be within a dotfile when set to \"deny\"). 'allow' No special treatment for dotfiles. 'deny' Deny a request for a dotfile and 403/next(). 'ignore' Pretend like the dotfile does not exist and 404/next(). The default value is similar to 'ignore', with the exception that this default will not ignore the files within a directory that begins with a dot. etag Enable or disable etag generation, defaults to true. extensions Set file extension fallbacks. When set, if a file is not found, the given extensions will be added to the file name and search for. The first that exists will be served. Example: ['html', 'htm']. The default value is false. fallthrough Set the middleware to have client errors fall-through as just unhandled requests, otherwise forward a client error. The difference is that client errors like a bad request or a request to a non-existent file will cause this middleware to simply next() to your next middleware when this value is true. When this value is false, these errors (even 404s), will invoke next(err). Typically true is desired such that multiple physical directories can be mapped to the same web address or for routes to fill in non-existent files. The value false can be used if this middleware is mounted at a path that is designed to be strictly a single file system directory, which allows for short-circuiting 404s for less overhead. This middleware will also reply to all methods. The default value is true. immutable Enable or disable the immutable directive in the Cache-Control response header, defaults to false. If set to true, the maxAge option should also be specified to enable caching. The immutable directive will prevent supported clients from making conditional requests during the life of the maxAge option to check if the file has changed. index By default this module will send \"index.html\" files in response to a request on a directory. To disable this set false or to supply a new index pass a string or an array in preferred order. lastModified Enable or disable Last-Modified header, defaults to true. Uses the file system's last modified value. maxAge Provide a max-age in milliseconds for http caching, defaults to 0. This can also be a string accepted by the ms module. redirect Redirect to trailing \"/\" when the pathname is a dir. Defaults to true. setHeaders Function to set custom headers on response. Alterations to the headers need to occur synchronously. The function is called as fn(res, path, stat), where the arguments are: res the response object path the file path that is being sent stat the stat object of the file that is being sent Examples Serve files with vanilla node.js http server var finalhandler = require('finalhandler') var http = require('http') var serveStatic = require('serve-static') // Serve up public/ftp folder var serve = serveStatic('public/ftp', {'index': ['index.html', 'index.htm']}) // Create server var server = http.createServer(function onRequest (req, res) { serve(req, res, finalhandler(req, res)) }) // Listen server.listen(3000) Serve all files as downloads var contentDisposition = require('content-disposition') var finalhandler = require('finalhandler') var http = require('http') var serveStatic = require('serve-static') // Serve up public/ftp folder var serve = serveStatic('public/ftp', { 'index': false, 'setHeaders': setHeaders }) // Set header to force download function setHeaders (res, path) { res.setHeader('Content-Disposition', contentDisposition(path)) } // Create server var server = http.createServer(function onRequest (req, res) { serve(req, res, finalhandler(req, res)) }) // Listen server.listen(3000) Serving using express Simple This is a simple example of using Express. var express = require('express') var serveStatic = require('serve-static') var app = express() app.use(serveStatic('public/ftp', {'index': ['default.html', 'default.htm']})) app.listen(3000) Multiple roots This example shows a simple way to search through multiple directories. Files are look for in public-optimized/ first, then public/ second as a fallback. var express = require('express') var path = require('path') var serveStatic = require('serve-static') var app = express() app.use(serveStatic(path.join(__dirname, 'public-optimized'))) app.use(serveStatic(path.join(__dirname, 'public'))) app.listen(3000) Different settings for paths This example shows how to set a different max age depending on the served file type. In this example, HTML files are not cached, while everything else is for 1 day. var express = require('express') var path = require('path') var serveStatic = require('serve-static') var app = express() app.use(serveStatic(path.join(__dirname, 'public'), { maxAge: '1d', setHeaders: setCustomCacheControl })) app.listen(3000) function setCustomCacheControl (res, path) { if (serveStatic.mime.lookup(path) === 'text/html') { // Custom Cache-Control for HTML files res.setHeader('Cache-Control', 'public, max-age=0') } } License MIT"
  },
  "node_modules/server-destroy/README.html": {
    "href": "node_modules/server-destroy/README.html",
    "title": "server-destroy | accouter",
    "keywords": "server-destroy Enable destroying a server, and all currently open connections. Usage var enableDestroy = require('server-destroy'); var server = http.createServer(function(req, res) { // do stuff, blah blah blah }); server.listen(PORT); // enhance with a 'destroy' function enableDestroy(server); // some time later... server.destroy();"
  },
  "node_modules/set-function-length/CHANGELOG.html": {
    "href": "node_modules/set-function-length/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.2.2 - 2024-03-09 Commits [types] use shared config 027032f [actions] remove redundant finisher; use reusable workflow 1fd4fb1 [types] use a handwritten d.ts file instead of emit 01b9761 [Deps] update define-data-property, get-intrinsic, has-property-descriptors bee8eaf [Dev Deps] update call-bind, tape 5dae579 [Tests] use @arethetypeswrong/cli 7e22425 v1.2.1 - 2024-02-06 Commits [Dev Deps] update call-bind, tape, typescript d9a4601 [Deps] update define-data-property, get-intrinsic 38d39ae [Refactor] use es-errors, so things that only need those do not need get-intrinsic b4bfe5a v1.2.0 - 2024-01-14 Commits [New] add types f6d9088 [Fix] ensure env properties are always booleans 0c42f84 [Dev Deps] update aud, call-bind, npmignore, tape 2b75f75 [Deps] update get-intrinsic, has-property-descriptors 19bf0fc [meta] add sideEffects flag 8bb9b78 v1.1.1 - 2023-10-19 Fixed [Fix] move define-data-property to runtime deps #2 Commits [Dev Deps] update object-inspect; add missing call-bind 5aecf79 v1.1.0 - 2023-10-13 Commits [New] add env entry point 475c87a [Tests] add coverage with nyc 14f0bf8 [eslint] fix linting failure fb516f9 [Deps] update define-data-property d727e7c v1.0.1 - 2023-10-12 Commits [Refactor] use get-intrinsic, since it‘s in the dep graph anyways 278a954 [meta] add exports 72acfe5 v1.0.0 - 2023-10-12 Commits Initial implementation, tests, readme fce14e1 Initial commit ca7ba85 npm init 6a7e493 Only apps should have lockfiles d2bf6c4"
  },
  "node_modules/set-function-length/README.html": {
    "href": "node_modules/set-function-length/README.html",
    "title": "set-function-length | accouter",
    "keywords": "set-function-length Set a function’s length. Arguments: fn: the function length: the new length. Must be an integer between 0 and 2**32. loose: Optional. If true, and the length fails to be set, do not throw. Default false. Returns fn. Usage var setFunctionLength = require('set-function-length'); var assert = require('assert'); function zero() {} function one(_) {} function two(_, __) {} assert.equal(zero.length, 0); assert.equal(one.length, 1); assert.equal(two.length, 2); assert.equal(setFunctionLength(zero, 10), zero); assert.equal(setFunctionLength(one, 11), one); assert.equal(setFunctionLength(two, 12), two); assert.equal(zero.length, 10); assert.equal(one.length, 11); assert.equal(two.length, 12);"
  },
  "node_modules/set-function-name/CHANGELOG.html": {
    "href": "node_modules/set-function-name/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v2.0.2 - 2024-02-19 Commits [meta] add types ae747cd [Dev Deps] update aud, npmignore, object-inspect, tape 01aafcb [Deps] update define-data-property, has-property-descriptors 0ef6338 [Refactor] use es-errors 0b23e87 v2.0.1 - 2023-09-13 Commits [Fix] move functions-have-names to runtime deps db2eda8 v2.0.0 - 2023-09-12 Commits [eslint] add npm run lint 23e1fcd [actions] add reused GHA 525127e [meta] add .gitignore aa3abdf [Tests] switch tests to use tape; add posttest 8ad6d30 [readme] add readme 732c46c [New] add optional loose argument f5e4771 [meta] relicense package to MIT; fix repo URLs 13948f8 [meta] add auto-changelog 7ab201c [Breaking] throw if a non-function is provided cf6fc8f [Breaking] drop UMD, just use CJS 47abfe8 [Refactor] use define-data-property and has-property-descriptors 9921c2b [meta] use npmignore to autogenerate an npmignore file c5dbe4f Only apps should have lockfiles 98bbfa1 [meta] add safe-publish-latest 8916cd8 [meta] add engines 2427c8e v1.0.0 - 2017-09-14 Commits Initial commit. Including tests. f26a1f2 add .npmignore to ignore test directory 9cac96f"
  },
  "node_modules/set-function-name/README.html": {
    "href": "node_modules/set-function-name/README.html",
    "title": "set-function-name | accouter",
    "keywords": "set-function-name Set a function’s name. Arguments: fn: the function name: the new name loose: Optional. If true, and the name fails to be set, do not throw. Default false. Returns fn. Usage var setFunctionName = require('set-function-name'); var assert = require('assert'); const obj = { concise() {}, arrow: () => {}, named: function named() {}, anon: function () {}, }; assert.equal(obj.concise.name, 'concise'); assert.equal(obj.arrow.name, 'arrow'); assert.equal(obj.named.name, 'named'); assert.equal(obj.anon.name, 'anon'); assert.equal(setFunctionName(obj.concise, 'brief'), obj.concise); assert.equal(setFunctionName(obj.arrow, 'pointy'), obj.arrow); assert.equal(setFunctionName(obj.named, ''), obj.named); assert.equal(setFunctionName(obj.anon, 'anonymous'), obj.anon); assert.equal(obj.concise.name, 'brief'); assert.equal(obj.arrow.name, 'pointy'); assert.equal(obj.named.name, ''); assert.equal(obj.anon.name, 'anonymous');"
  },
  "node_modules/setprototypeof/README.html": {
    "href": "node_modules/setprototypeof/README.html",
    "title": "Polyfill for Object.setPrototypeOf | accouter",
    "keywords": "Polyfill for Object.setPrototypeOf A simple cross platform implementation to set the prototype of an instianted object. Supports all modern browsers and at least back to IE8. Usage: $ npm install --save setprototypeof var setPrototypeOf = require('setprototypeof') var obj = {} setPrototypeOf(obj, { foo: function () { return 'bar' } }) obj.foo() // bar TypeScript is also supported: import setPrototypeOf from 'setprototypeof'"
  },
  "node_modules/shebang-command/readme.html": {
    "href": "node_modules/shebang-command/readme.html",
    "title": "shebang-command | accouter",
    "keywords": "shebang-command Get the command from a shebang Install $ npm install --save shebang-command Usage const shebangCommand = require('shebang-command'); shebangCommand('#!/usr/bin/env node'); //=> 'node' shebangCommand('#!/bin/bash'); //=> 'bash' API shebangCommand(string) string Type: string String containing a shebang. License MIT © Kevin Martensson"
  },
  "node_modules/shebang-regex/readme.html": {
    "href": "node_modules/shebang-regex/readme.html",
    "title": "shebang-regex | accouter",
    "keywords": "shebang-regex Regular expression for matching a shebang Install $ npm install --save shebang-regex Usage var shebangRegex = require('shebang-regex'); var str = '#!/usr/bin/env node\\nconsole.log(\"unicorns\");'; shebangRegex.test(str); //=> true shebangRegex.exec(str)[0]; //=> '#!/usr/bin/env node' License MIT © Sindre Sorhus"
  },
  "node_modules/shell-quote/CHANGELOG.html": {
    "href": "node_modules/shell-quote/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.8.1 - 2023-04-07 Fixed [Fix] parse: preserve whitespace in comments #6 [Fix] properly support the escape option #5 Commits [Refactor] parse: hoist getVar to module level b42ac73 [Refactor] hoist some vars to module level 8f0c5c3 [Refactor] parse: use slice over substr, cache some values fcb2e1a [Refactor] parse: a bit of cleanup 6780ec5 [Refactor] parse: tweak the regex to not match nothing 227d474 [Tests] increase coverage a66de94 [Refactor] parse: avoid shadowing a function arg 1d58679 v1.8.0 - 2023-01-30 Commits [New] extract parse and quote to their own deep imports 553fdfc [Tests] add nyc coverage fd7ddcd [New] Add support for here strings (&lt;&lt;&lt;) 9802fb3 [New] parse: Add syntax support for duplicating input file descriptors 216b198 [Dev Deps] update @ljharb/eslint-config, aud, tape 85f8e31 [Tests] add evalmd c5549fc [actions] update checkout action 62e9b49 v1.7.4 - 2022-10-12 Merged Add node_modules to .gitignore #48 Commits [eslint] fix indentation and whitespace aaa9d1f [eslint] additional cleanup 397cb62 [meta] add auto-changelog 497fca5 [actions] add reusable workflows 4763c36 [eslint] add eslint 6ee1437 [readme] rename, add badges 7eb5134 [meta] update URLs 67381b6 [meta] create FUNDING.yml; add funding in package.json 8641572 [meta] use npmignore to autogenerate an npmignore file 2e2007a Only apps should have lockfiles f97411e [Dev Deps] update tape 051f608 [meta] add safe-publish-latest 18cadf9 [Tests] add aud in posttest dc1cc12 1.7.3 Fix a security issue where the regex for windows drive letters allowed some shell meta-characters to escape the quoting rules. (CVE-2021-42740) 1.7.2 Fix a regression introduced in 1.6.3. This reverts the Windows path quoting fix. (144e1c2) 1.7.1 Fix $ being removed when not part of an environment variable name. (@Adman in #32) 1.7.0 Add support for parsing >> and >& redirection operators. (@forivall in #16) Add support for parsing <( process substitution operator. (@cuonglm in #15) 1.6.3 Fix Windows path quoting problems. (@dy in #34) v1.6.2 - 2019-08-13 Merged Use native JSON and Array methods #21 Commits fix whitespace 72fb5a8 Disable package-lock.json d450577 1.6.1 - 2016-06-17 Commits Fix some more escaping for .quote() ace52f4 Fix escaping for greater than and less than 70e9eb2 1.6.0 - 2016-04-23 Commits add comment parsing feature b8b5c31 1.5.0 - 2016-03-16 Commits add escape option to .parse 4d400e7 1.4.3 - 2015-03-07 Commits Fix quote() with special chars 811b5a0 1.4.2 - 2014-07-20 Commits Handle non-strings when quoting d435827 falseys ok 22dbd94 all the falseys test c99dca5 1.4.1 - 2013-12-24 Commits es5 shims 00dc6ab separate shim file to get the coverage up e29a216 use array-{filter,map,reduce} 97a2fc9 add testling badge 44c98b1 upgrade tape 3fc22d3 1.4.0 - 2013-10-17 Merged Add MIT LICENSE file #6 Commits Rewrite parser as a character based scanner c7ca9a2 Add tests for glob patterns 3418892 Update algo description e1442cf Fix test case for backslash in double quotes 89bc550 Add failing tests for crazy quoting tricks 58a5e48 1.3.3 - 2013-06-24 Commits failing set test with an env cb 9fb2096 remove the broken special case f9a0ee5 1.3.2 - 2013-06-24 Commits tests for setting env vars f44b039 fixed the parse test, broke the op tests 74d6686 factored out single and double quote regex de9e0a5 updated set env test, already passes 7d5636b ops fixed 2b4e1b1 passing all tests 44177e3 backreferences in negated capture groups don't actually work e189d9d another crazy ridiculous passing parse test d1beb6b failing test for quoted whitespace and nested quotes 9a4c11c failing test for quotes embedded inside barewords d997384 1.3.1 - 2013-05-13 Commits pass objects through f9c0514 1.3.0 - 2013-05-13 Commits hacky tokenizer is much simpler 7e91b18 nearly passing with a clunky state env parser, array issues d6d6416 test for functional env expansion 666395f upgrade travis versions, tape f6f8bd6 1.3.0, document env() lookups 041c5da first half of functional env() works 7a0cf79 env() objects even work inside quote strings 16139f5 another check just to make sure env() works 914a1a9 1.2.0 - 2013-05-13 Commits failing test for special shell parameter env vars 728862a add the special vars to the replace regex but the chunker breaks on them d1ff82a fixed the env test, everything is fine a45897f 1.1.0 - 2013-05-13 Commits quote all ops objects ac7be63 test for parsed ops objects in quote() 59fb71b another test for op object quoting 5819a31 1.0.0 - 2013-05-13 Commits document ops, op example a6381e6 some more passing double-char op tests fbc6e5c failing test for | and & ops d817736 labeled regex states 8c008b2 refactored the chunker regex into a string 0331c7f simple failing double-char op test e51fa90 failing expanded single-op tests for ; and () 710bb24 now passing all the single-char op tests e3e9ac1 using the control ops directly from the docs f535987 first part of op parsing works e6f9199 failing redirect tests cb94c10 another double-char op test just to be sure 5cf1bf2 1.0.0 for ops 17a40ed adding redirect <> ops to CONTROL makes the tests pass 48b1eb9 double-char op test now passing 3998b0f using the meta chars directly from the docs b009ef6 the spec says tabs are also allowed 2adb373 op test completely passing 20a0147 0.1.1 - 2013-04-17 Commits Return empty list when parsing an empty (or whitespace-only) string 1475717 0.1.0 - 2013-04-14 Commits externalize the regex declaration 37d6058 modernize the readme 24106f5 factor out interpolation 1b21b01 half the env tests are working with basic interpolation 5891471 env parse example 5757c42 failing tests for unimplemented env interpolation 590534a denormalize the interpolate logic to make room for special cases c669d2e cleaner implementation recursing on the double quote case adae66f one test was wrong, checking for pre escapes 42b5f83 finally passing all the tests efa4084 one more test passing with quote recursion e9537b9 use tape everywhere ed0c1c6 some extra metacharacter tests just to be sure a6782ae minor fix to an env test 601b340 document parse env cc0efba better parse recursion to capture the containing quotes 8467961 now just 2 tests failing with a subtle regex reordering 5448a02 pass another test by using \"\" as the undefined 46e6cf4 fixed a failing env test 17d1fda actually the test was wrong, module works fine 9d7b727 another test to be even more sure 5afd47b failing test for: echo \"foo = \"foo\"\" 8dbb280 0.0.1 - 2012-05-18 Commits fixed unescaped metachars and bump 5ce339f failing test for unescaped metachars a315125 fix for escaped spaces 669b616 failing test for escaped space c6ff3dc 0.0.0 - 2012-05-18 Commits readme with examples 6373c0f package.json bc27efa passing the parse test 69c0f85 crazy initial thing d6469c9 passing quote tests e1d6695 failing parse test 980aa58 using travis 1c72261 expand more escape sequences in parse() 8b2224c"
  },
  "node_modules/shell-quote/README.html": {
    "href": "node_modules/shell-quote/README.html",
    "title": "shell-quote | accouter",
    "keywords": "shell-quote Parse and quote shell commands. example quote var quote = require('shell-quote/quote'); var s = quote([ 'a', 'b c d', '$f', '\"g\"' ]); console.log(s); output a 'b c d' \\$f '\"g\"' parse var parse = require('shell-quote/parse'); var xs = parse('a \"b c\" \\\\$def \\'it\\\\\\'s great\\''); console.dir(xs); output [ 'a', 'b c', '\\\\$def', 'it\\'s great' ] parse with an environment variable var parse = require('shell-quote/parse'); var xs = parse('beep --boop=\"$PWD\"', { PWD: '/home/robot' }); console.dir(xs); output [ 'beep', '--boop=/home/robot' ] parse with custom escape character var parse = require('shell-quote/parse'); var xs = parse('beep ^--boop=\"$PWD\"', { PWD: '/home/robot' }, { escape: '^' }); console.dir(xs); output [ 'beep --boop=/home/robot' ] parsing shell operators var parse = require('shell-quote/parse'); var xs = parse('beep || boop > /byte'); console.dir(xs); output: [ 'beep', { op: '||' }, 'boop', { op: '>' }, '/byte' ] parsing shell comment var parse = require('shell-quote/parse'); var xs = parse('beep > boop # > kaboom'); console.dir(xs); output: [ 'beep', { op: '>' }, 'boop', { comment: '> kaboom' } ] methods var quote = require('shell-quote/quote'); var parse = require('shell-quote/parse'); quote(args) Return a quoted string for the array args suitable for using in shell commands. parse(cmd, env={}) Return an array of arguments from the quoted string cmd. Interpolate embedded bash-style $VARNAME and ${VARNAME} variables with the env object which like bash will replace undefined variables with \"\". env is usually an object but it can also be a function to perform lookups. When env(key) returns a string, its result will be output just like env[key] would. When env(key) returns an object, it will be inserted into the result array like the operator objects. When a bash operator is encountered, the element in the array with be an object with an \"op\" key set to the operator string. For example: 'beep || boop > /byte' parses as: [ 'beep', { op: '||' }, 'boop', { op: '>' }, '/byte' ] install With npm do: npm install shell-quote license MIT"
  },
  "node_modules/shell-quote/security.html": {
    "href": "node_modules/shell-quote/security.html",
    "title": "Security Policy | accouter",
    "keywords": "Security Policy Supported Versions Only the latest major version is supported at any given time. Reporting a Vulnerability To report a security vulnerability, please use the Tidelift security contact. Tidelift will coordinate the fix and disclosure."
  },
  "node_modules/side-channel/CHANGELOG.html": {
    "href": "node_modules/side-channel/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.6 - 2024-02-29 Commits add types 9beef66 [meta] simplify exports 4334cf9 [Deps] update call-bind d6043c4 [Dev Deps] update tape 6aca376 v1.0.5 - 2024-02-06 Commits [actions] reuse common workflows 3d2e1ff [meta] use npmignore to autogenerate an npmignore file 04296ea [meta] add .editorconfig; add eclint 130f0a6 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, safe-publish-latest, tape d480c2f [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape ecbe70e [actions] update rebase action 75240b9 [Dev Deps] update @ljharb/eslint-config, aud, npmignore, tape ae8d281 [Dev Deps] update @ljharb/eslint-config, aud, tape 7125b88 [Deps] update call-bind, get-intrinsic, object-inspect 82577c9 [Deps] update call-bind, get-intrinsic, object-inspect 550aadf [Tests] increase coverage 5130877 [Deps] update get-intrinsic, object-inspect ba0194c [meta] add missing engines.node 985fd24 [Refactor] use es-errors, so things that only need those do not need get-intrinsic 40227a8 [Deps] update get-intrinsic a989b40 [Deps] update object-inspect aec42d2 v1.0.4 - 2020-12-29 Commits [Tests] migrate tests to Github Actions 10909cb [Refactor] Use a linked list rather than an array, and move accessed nodes to the beginning 195613f [meta] do not publish github action workflow files 290ec29 [Tests] run nyc on all tests; use tape runner ea6d030 [actions] add \"Allow Edits\" workflow d464d8f [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog 02daca8 [Refactor] use call-bind and get-intrinsic instead of es-abstract e09d481 [Deps] update object.assign ee83aa8 [actions] update rebase action to use checkout v2 7726b0b v1.0.3 - 2020-08-23 Commits [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape 1f10561 [Deps] update es-abstract, object-inspect bc20159 [Dev Deps] update @ljharb/eslint-config, tape b9b2b22 [Dev Deps] update eslint, @ljharb/eslint-config, tape 7055ab4 [Dev Deps] update auto-changelog; add aud d278c37 [actions] switch Automatic Rebase workflow to pull_request_target event 3bcf982 [Tests] only audit prod deps 18d01c4 [Deps] update es-abstract 6ab096d [Dev Deps] update tape 9dc174c [Deps] update es-abstract 431d0f0 [Deps] update es-abstract 49869fd [meta] Add package.json to package's exports 77d9cdc v1.0.2 - 2019-12-20 Commits [Dev Deps] update @ljharb/eslint-config, tape 4a526df [Deps] update es-abstract d4f6e62 v1.0.1 - 2019-12-01 Commits [Fix] add missing \"exports\" d212907 v1.0.0 - 2019-12-01 Commits Initial implementation dbebd3a Initial tests 73bdefe Initial commit 43c03e1 npm init 5c090a7 [meta] add auto-changelog a5c4e56 [actions] add automatic rebasing / merge commit blocking bab1683 [meta] add funding field; create FUNDING.yml 63d7aea [Tests] add npm run lint 46a5a81 Only apps should have lockfiles 8b16b03 [meta] add safe-publish-latest 2f098ef"
  },
  "node_modules/side-channel/README.html": {
    "href": "node_modules/side-channel/README.html",
    "title": "side-channel | accouter",
    "keywords": "side-channel Store information about any JS value in a side channel. Uses WeakMap if available."
  },
  "node_modules/signal-exit/README.html": {
    "href": "node_modules/signal-exit/README.html",
    "title": "signal-exit | accouter",
    "keywords": "signal-exit When you want to fire an event no matter how a process exits: reaching the end of execution. explicitly having process.exit(code) called. having process.kill(pid, sig) called. receiving a fatal signal from outside the process Use signal-exit. // Hybrid module, either works import { onExit } from 'signal-exit' // or: // const { onExit } = require('signal-exit') onExit((code, signal) => { console.log('process exited!', code, signal) }) API remove = onExit((code, signal) => {}, options) The return value of the function is a function that will remove the handler. Note that the function only fires for signals if the signal would cause the process to exit. That is, there are no other listeners, and it is a fatal signal. If the global process object is not suitable for this purpose (ie, it's unset, or doesn't have an emit method, etc.) then the onExit function is a no-op that returns a no-op remove method. Options alwaysLast: Run this handler after any other signal or exit handlers. This causes process.emit to be monkeypatched. Capturing Signal Exits If the handler returns an exact boolean true, and the exit is a due to signal, then the signal will be considered handled, and will not trigger a synthetic process.kill(process.pid, signal) after firing the onExit handlers. In this case, it your responsibility as the caller to exit with a signal (for example, by calling process.kill()) if you wish to preserve the same exit status that would otherwise have occurred. If you do not, then the process will likely exit gracefully with status 0 at some point, assuming that no other terminating signal or other exit trigger occurs. Prior to calling handlers, the onExit machinery is unloaded, so any subsequent exits or signals will not be handled, even if the signal is captured and the exit is thus prevented. Note that numeric code exits may indicate that the process is already committed to exiting, for example due to a fatal exception or unhandled promise rejection, and so there is no way to prevent it safely. Browser Fallback The 'signal-exit/browser' module is the same fallback shim that just doesn't do anything, but presents the same function interface. Patches welcome to add something that hooks onto window.onbeforeunload or similar, but it might just not be a thing that makes sense there."
  },
  "node_modules/simple-update-notifier/README.html": {
    "href": "node_modules/simple-update-notifier/README.html",
    "title": "simple-update-notifier | accouter",
    "keywords": "simple-update-notifier Simple update notifier to check for npm updates for cli applications. Checks for updates for an npm module and outputs to the command line if there is one available. The result is cached for the specified time so it doesn't check every time the app runs. Install npm install simple-update-notifier OR yarn add simple-update-notifier Usage import updateNotifier from 'simple-update-notifier'; import packageJson from './package.json' assert { type: 'json' }; updateNotifier({ pkg: packageJson }); Options pkg Type: object name Required Type: string version Required Type: string updateCheckInterval Type: number Default: 1000 * 60 * 60 * 24 (1 day) How often to check for updates. shouldNotifyInNpmScript Type: boolean Default: false Allows notification to be shown when running as an npm script. distTag Type: string Default: 'latest' Which dist-tag to use to find the latest version. alwaysRun Type: boolean Default: false When set, updateCheckInterval will not be respected and a check for an update will always be performed. debug Type: boolean Default: false When set, logs explaining the decision will be output to stderr whenever the module opts to not print an update notification"
  },
  "node_modules/slash/readme.html": {
    "href": "node_modules/slash/readme.html",
    "title": "slash | accouter",
    "keywords": "slash Convert Windows backslash paths to slash paths: foo\\\\bar ➔ foo/bar Forward-slash paths can be used in Windows as long as they're not extended-length paths and don't contain any non-ascii characters. This was created since the path methods in Node.js outputs \\\\ paths on Windows. Install $ npm install slash Usage import path from 'path'; import slash from 'slash'; const string = path.join('foo', 'bar'); // Unix => foo/bar // Windows => foo\\\\bar slash(string); // Unix => foo/bar // Windows => foo/bar API slash(path) Type: string Accepts a Windows backslash path and returns a path with forward slashes. Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "node_modules/socket.io-adapter/Readme.html": {
    "href": "node_modules/socket.io-adapter/Readme.html",
    "title": "socket.io-adapter | accouter",
    "keywords": "socket.io-adapter Default socket.io in-memory adapter class. Compatibility table: Adapter version Socket.IO server version 1.x.x 1.x.x / 2.x.x 2.x.x 3.x.x How to use This module is not intended for end-user usage, but can be used as an interface to inherit from other adapters you might want to build. As an example of an adapter that builds on top of this, please take a look at socket.io-redis. License MIT"
  },
  "node_modules/socket.io-adapter/node_modules/debug/README.html": {
    "href": "node_modules/socket.io-adapter/node_modules/debug/README.html",
    "title": "debug | accouter",
    "keywords": "debug A tiny JavaScript debugging utility modelled after Node.js core's debugging technique. Works in Node.js and web browsers. Installation $ npm install debug Usage debug exposes a function; simply pass this function the name of your module, and it will return a decorated version of console.error for you to pass debug statements to. This will allow you to toggle the debug output for different parts of your module as well as the module as a whole. Example app.js: var debug = require('debug')('http') , http = require('http') , name = 'My App'; // fake app debug('booting %o', name); http.createServer(function(req, res){ debug(req.method + ' ' + req.url); res.end('hello\\n'); }).listen(3000, function(){ debug('listening'); }); // fake worker of some kind require('./worker'); Example worker.js: var a = require('debug')('worker:a') , b = require('debug')('worker:b'); function work() { a('doing lots of uninteresting work'); setTimeout(work, Math.random() * 1000); } work(); function workb() { b('doing some work'); setTimeout(workb, Math.random() * 2000); } workb(); The DEBUG environment variable is then used to enable these based on space or comma-delimited names. Here are some examples: Windows command prompt notes CMD On Windows the environment variable is set using the set command. set DEBUG=*,-not_this Example: set DEBUG=* & node app.js PowerShell (VS Code default) PowerShell uses different syntax to set environment variables. $env:DEBUG = \"*,-not_this\" Example: $env:DEBUG='app';node app.js Then, run the program to be debugged as usual. npm script example: \"windowsDebug\": \"@powershell -Command $env:DEBUG='*';node app.js\", Namespace Colors Every debug instance has a color generated for it based on its namespace name. This helps when visually parsing the debug output to identify which debug instance a debug line belongs to. Node.js In Node.js, colors are enabled when stderr is a TTY. You also should install the supports-color module alongside debug, otherwise debug will only use a small handful of basic colors. Web Browser Colors are also enabled on \"Web Inspectors\" that understand the %c formatting option. These are WebKit web inspectors, Firefox (since version 31) and the Firebug plugin for Firefox (any version). Millisecond diff When actively developing an application it can be useful to see when the time spent between one debug() call and the next. Suppose for example you invoke debug() before requesting a resource, and after as well, the \"+NNNms\" will show you how much time was spent between calls. When stdout is not a TTY, Date#toISOString() is used, making it more useful for logging the debug information as shown below: Conventions If you're using this in one or more of your libraries, you should use the name of your library so that developers may toggle debugging as desired without guessing names. If you have more than one debuggers you should prefix them with your library name and use \":\" to separate features. For example \"bodyParser\" from Connect would then be \"connect:bodyParser\". If you append a \"*\" to the end of your name, it will always be enabled regardless of the setting of the DEBUG environment variable. You can then use it for normal output as well as debug output. Wildcards The * character may be used as a wildcard. Suppose for example your library has debuggers named \"connect:bodyParser\", \"connect:compress\", \"connect:session\", instead of listing all three with DEBUG=connect:bodyParser,connect:compress,connect:session, you may simply do DEBUG=connect:*, or to run everything using this module simply use DEBUG=*. You can also exclude specific debuggers by prefixing them with a \"-\" character. For example, DEBUG=*,-connect:* would include all debuggers except those starting with \"connect:\". Environment Variables When running through Node.js, you can set a few environment variables that will change the behavior of the debug logging: Name Purpose DEBUG Enables/disables specific debugging namespaces. DEBUG_HIDE_DATE Hide date from debug output (non-TTY). DEBUG_COLORS Whether or not to use colors in the debug output. DEBUG_DEPTH Object inspection depth. DEBUG_SHOW_HIDDEN Shows hidden properties on inspected objects. Note: The environment variables beginning with DEBUG_ end up being converted into an Options object that gets used with %o/%O formatters. See the Node.js documentation for util.inspect() for the complete list. Formatters Debug uses printf-style formatting. Below are the officially supported formatters: Formatter Representation %O Pretty-print an Object on multiple lines. %o Pretty-print an Object all on a single line. %s String. %d Number (both integer and float). %j JSON. Replaced with the string '[Circular]' if the argument contains circular references. %% Single percent sign ('%'). This does not consume an argument. Custom formatters You can add custom formatters by extending the debug.formatters object. For example, if you wanted to add support for rendering a Buffer as hex with %h, you could do something like: const createDebug = require('debug') createDebug.formatters.h = (v) => { return v.toString('hex') } // …elsewhere const debug = createDebug('foo') debug('this is hex: %h', new Buffer('hello world')) // foo this is hex: 68656c6c6f20776f726c6421 +0ms Browser Support You can build a browser-ready script using browserify, or just use the browserify-as-a-service build, if you don't want to build it yourself. Debug's enable state is currently persisted by localStorage. Consider the situation shown below where you have worker:a and worker:b, and wish to debug both. You can enable this using localStorage.debug: localStorage.debug = 'worker:*' And then refresh the page. a = debug('worker:a'); b = debug('worker:b'); setInterval(function(){ a('doing some work'); }, 1000); setInterval(function(){ b('doing some work'); }, 1200); In Chromium-based web browsers (e.g. Brave, Chrome, and Electron), the JavaScript console will—by default—only show messages logged by debug if the \"Verbose\" log level is enabled. Output streams By default debug will log to stderr, however this can be configured per-namespace by overriding the log method: Example stdout.js: var debug = require('debug'); var error = debug('app:error'); // by default stderr is used error('goes to stderr!'); var log = debug('app:log'); // set this namespace to log via console.log log.log = console.log.bind(console); // don't forget to bind to console! log('goes to stdout'); error('still goes to stderr!'); // set all output to go via console.info // overrides all per-namespace log settings debug.log = console.info.bind(console); error('now goes to stdout via console.info'); log('still goes to stdout, but via console.info now'); Extend You can simply extend debugger const log = require('debug')('auth'); //creates new debug instance with extended namespace const logSign = log.extend('sign'); const logLogin = log.extend('login'); log('hello'); // auth hello logSign('hello'); //auth:sign hello logLogin('hello'); //auth:login hello Set dynamically You can also enable debug dynamically by calling the enable() method : let debug = require('debug'); console.log(1, debug.enabled('test')); debug.enable('test'); console.log(2, debug.enabled('test')); debug.disable(); console.log(3, debug.enabled('test')); print : 1 false 2 true 3 false Usage : enable(namespaces) namespaces can include modes separated by a colon and wildcards. Note that calling enable() completely overrides previously set DEBUG variable : $ DEBUG=foo node -e 'var dbg = require(\"debug\"); dbg.enable(\"bar\"); console.log(dbg.enabled(\"foo\"))' => false disable() Will disable all namespaces. The functions returns the namespaces currently enabled (and skipped). This can be useful if you want to disable debugging temporarily without knowing what was enabled to begin with. For example: let debug = require('debug'); debug.enable('foo:*,-foo:bar'); let namespaces = debug.disable(); debug.enable(namespaces); Note: There is no guarantee that the string will be identical to the initial enable string, but semantically they will be identical. Checking whether a debug target is enabled After you've created a debug instance, you can determine whether or not it is enabled by checking the enabled property: const debug = require('debug')('http'); if (debug.enabled) { // do stuff... } You can also manually toggle this property to force the debug instance to be enabled or disabled. Usage in child processes Due to the way debug detects if the output is a TTY or not, colors are not shown in child processes when stderr is piped. A solution is to pass the DEBUG_COLORS=1 environment variable to the child process. For example: worker = fork(WORKER_WRAP_PATH, [workerPath], { stdio: [ /* stdin: */ 0, /* stdout: */ 'pipe', /* stderr: */ 'pipe', 'ipc', ], env: Object.assign({}, process.env, { DEBUG_COLORS: 1 // without this settings, colors won't be shown }), }); worker.stderr.pipe(process.stderr, { end: false }); Authors TJ Holowaychuk Nathan Rajlich Andrew Rhyne Josh Junon Backers Support us with a monthly donation and help us continue our activities. [Become a backer] Sponsors Become a sponsor and get your logo on our README on Github with a link to your site. [Become a sponsor] License (The MIT License) Copyright (c) 2014-2017 TJ Holowaychuk <tj@vision-media.ca&gt; Copyright (c) 2018-2021 Josh Junon Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/socket.io-adapter/node_modules/ms/license.html": {
    "href": "node_modules/socket.io-adapter/node_modules/ms/license.html",
    "title": "| accouter",
    "keywords": "The MIT License (MIT) Copyright (c) 2016 Zeit, Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/socket.io-adapter/node_modules/ms/readme.html": {
    "href": "node_modules/socket.io-adapter/node_modules/ms/readme.html",
    "title": "ms | accouter",
    "keywords": "ms Use this package to easily convert various time formats to milliseconds. Examples ms('2 days') // 172800000 ms('1d') // 86400000 ms('10h') // 36000000 ms('2.5 hrs') // 9000000 ms('2h') // 7200000 ms('1m') // 60000 ms('5s') // 5000 ms('1y') // 31557600000 ms('100') // 100 ms('-3 days') // -259200000 ms('-1h') // -3600000 ms('-200') // -200 Convert from Milliseconds ms(60000) // \"1m\" ms(2 * 60000) // \"2m\" ms(-3 * 60000) // \"-3m\" ms(ms('10 hours')) // \"10h\" Time Format Written-Out ms(60000, { long: true }) // \"1 minute\" ms(2 * 60000, { long: true }) // \"2 minutes\" ms(-3 * 60000, { long: true }) // \"-3 minutes\" ms(ms('10 hours'), { long: true }) // \"10 hours\" Features Works both in Node.js and in the browser If a number is supplied to ms, a string with a unit is returned If a string that contains the number is supplied, it returns it as a number (e.g.: it returns 100 for '100') If you pass a string with a number and a valid unit, the number of equivalent milliseconds is returned Related Packages ms.macro - Run ms as a macro at build-time. Caught a Bug? Fork this repository to your own GitHub account and then clone it to your local device Link the package to the global module directory: npm link Within the module you want to test your local development instance of ms, just link it to the dependencies: npm link ms. Instead of the default one from npm, Node.js will now use your clone of ms! As always, you can run the tests using: npm test"
  },
  "node_modules/socket.io-client/README.html": {
    "href": "node_modules/socket.io-client/README.html",
    "title": "socket.io-client | accouter",
    "keywords": "socket.io-client Documentation Please see the documentation here. The source code of the website can be found here. Contributions are welcome! Debug / logging In order to see all the client debug output, run the following command on the browser console – including the desired scope – and reload your app page: localStorage.debug = '*'; And then, filter by the scopes you're interested in. See also: https://socket.io/docs/v4/logging-and-debugging/ License MIT"
  },
  "node_modules/socket.io-client/node_modules/debug/README.html": {
    "href": "node_modules/socket.io-client/node_modules/debug/README.html",
    "title": "debug | accouter",
    "keywords": "debug A tiny JavaScript debugging utility modelled after Node.js core's debugging technique. Works in Node.js and web browsers. Installation $ npm install debug Usage debug exposes a function; simply pass this function the name of your module, and it will return a decorated version of console.error for you to pass debug statements to. This will allow you to toggle the debug output for different parts of your module as well as the module as a whole. Example app.js: var debug = require('debug')('http') , http = require('http') , name = 'My App'; // fake app debug('booting %o', name); http.createServer(function(req, res){ debug(req.method + ' ' + req.url); res.end('hello\\n'); }).listen(3000, function(){ debug('listening'); }); // fake worker of some kind require('./worker'); Example worker.js: var a = require('debug')('worker:a') , b = require('debug')('worker:b'); function work() { a('doing lots of uninteresting work'); setTimeout(work, Math.random() * 1000); } work(); function workb() { b('doing some work'); setTimeout(workb, Math.random() * 2000); } workb(); The DEBUG environment variable is then used to enable these based on space or comma-delimited names. Here are some examples: Windows command prompt notes CMD On Windows the environment variable is set using the set command. set DEBUG=*,-not_this Example: set DEBUG=* & node app.js PowerShell (VS Code default) PowerShell uses different syntax to set environment variables. $env:DEBUG = \"*,-not_this\" Example: $env:DEBUG='app';node app.js Then, run the program to be debugged as usual. npm script example: \"windowsDebug\": \"@powershell -Command $env:DEBUG='*';node app.js\", Namespace Colors Every debug instance has a color generated for it based on its namespace name. This helps when visually parsing the debug output to identify which debug instance a debug line belongs to. Node.js In Node.js, colors are enabled when stderr is a TTY. You also should install the supports-color module alongside debug, otherwise debug will only use a small handful of basic colors. Web Browser Colors are also enabled on \"Web Inspectors\" that understand the %c formatting option. These are WebKit web inspectors, Firefox (since version 31) and the Firebug plugin for Firefox (any version). Millisecond diff When actively developing an application it can be useful to see when the time spent between one debug() call and the next. Suppose for example you invoke debug() before requesting a resource, and after as well, the \"+NNNms\" will show you how much time was spent between calls. When stdout is not a TTY, Date#toISOString() is used, making it more useful for logging the debug information as shown below: Conventions If you're using this in one or more of your libraries, you should use the name of your library so that developers may toggle debugging as desired without guessing names. If you have more than one debuggers you should prefix them with your library name and use \":\" to separate features. For example \"bodyParser\" from Connect would then be \"connect:bodyParser\". If you append a \"*\" to the end of your name, it will always be enabled regardless of the setting of the DEBUG environment variable. You can then use it for normal output as well as debug output. Wildcards The * character may be used as a wildcard. Suppose for example your library has debuggers named \"connect:bodyParser\", \"connect:compress\", \"connect:session\", instead of listing all three with DEBUG=connect:bodyParser,connect:compress,connect:session, you may simply do DEBUG=connect:*, or to run everything using this module simply use DEBUG=*. You can also exclude specific debuggers by prefixing them with a \"-\" character. For example, DEBUG=*,-connect:* would include all debuggers except those starting with \"connect:\". Environment Variables When running through Node.js, you can set a few environment variables that will change the behavior of the debug logging: Name Purpose DEBUG Enables/disables specific debugging namespaces. DEBUG_HIDE_DATE Hide date from debug output (non-TTY). DEBUG_COLORS Whether or not to use colors in the debug output. DEBUG_DEPTH Object inspection depth. DEBUG_SHOW_HIDDEN Shows hidden properties on inspected objects. Note: The environment variables beginning with DEBUG_ end up being converted into an Options object that gets used with %o/%O formatters. See the Node.js documentation for util.inspect() for the complete list. Formatters Debug uses printf-style formatting. Below are the officially supported formatters: Formatter Representation %O Pretty-print an Object on multiple lines. %o Pretty-print an Object all on a single line. %s String. %d Number (both integer and float). %j JSON. Replaced with the string '[Circular]' if the argument contains circular references. %% Single percent sign ('%'). This does not consume an argument. Custom formatters You can add custom formatters by extending the debug.formatters object. For example, if you wanted to add support for rendering a Buffer as hex with %h, you could do something like: const createDebug = require('debug') createDebug.formatters.h = (v) => { return v.toString('hex') } // …elsewhere const debug = createDebug('foo') debug('this is hex: %h', new Buffer('hello world')) // foo this is hex: 68656c6c6f20776f726c6421 +0ms Browser Support You can build a browser-ready script using browserify, or just use the browserify-as-a-service build, if you don't want to build it yourself. Debug's enable state is currently persisted by localStorage. Consider the situation shown below where you have worker:a and worker:b, and wish to debug both. You can enable this using localStorage.debug: localStorage.debug = 'worker:*' And then refresh the page. a = debug('worker:a'); b = debug('worker:b'); setInterval(function(){ a('doing some work'); }, 1000); setInterval(function(){ b('doing some work'); }, 1200); In Chromium-based web browsers (e.g. Brave, Chrome, and Electron), the JavaScript console will—by default—only show messages logged by debug if the \"Verbose\" log level is enabled. Output streams By default debug will log to stderr, however this can be configured per-namespace by overriding the log method: Example stdout.js: var debug = require('debug'); var error = debug('app:error'); // by default stderr is used error('goes to stderr!'); var log = debug('app:log'); // set this namespace to log via console.log log.log = console.log.bind(console); // don't forget to bind to console! log('goes to stdout'); error('still goes to stderr!'); // set all output to go via console.info // overrides all per-namespace log settings debug.log = console.info.bind(console); error('now goes to stdout via console.info'); log('still goes to stdout, but via console.info now'); Extend You can simply extend debugger const log = require('debug')('auth'); //creates new debug instance with extended namespace const logSign = log.extend('sign'); const logLogin = log.extend('login'); log('hello'); // auth hello logSign('hello'); //auth:sign hello logLogin('hello'); //auth:login hello Set dynamically You can also enable debug dynamically by calling the enable() method : let debug = require('debug'); console.log(1, debug.enabled('test')); debug.enable('test'); console.log(2, debug.enabled('test')); debug.disable(); console.log(3, debug.enabled('test')); print : 1 false 2 true 3 false Usage : enable(namespaces) namespaces can include modes separated by a colon and wildcards. Note that calling enable() completely overrides previously set DEBUG variable : $ DEBUG=foo node -e 'var dbg = require(\"debug\"); dbg.enable(\"bar\"); console.log(dbg.enabled(\"foo\"))' => false disable() Will disable all namespaces. The functions returns the namespaces currently enabled (and skipped). This can be useful if you want to disable debugging temporarily without knowing what was enabled to begin with. For example: let debug = require('debug'); debug.enable('foo:*,-foo:bar'); let namespaces = debug.disable(); debug.enable(namespaces); Note: There is no guarantee that the string will be identical to the initial enable string, but semantically they will be identical. Checking whether a debug target is enabled After you've created a debug instance, you can determine whether or not it is enabled by checking the enabled property: const debug = require('debug')('http'); if (debug.enabled) { // do stuff... } You can also manually toggle this property to force the debug instance to be enabled or disabled. Usage in child processes Due to the way debug detects if the output is a TTY or not, colors are not shown in child processes when stderr is piped. A solution is to pass the DEBUG_COLORS=1 environment variable to the child process. For example: worker = fork(WORKER_WRAP_PATH, [workerPath], { stdio: [ /* stdin: */ 0, /* stdout: */ 'pipe', /* stderr: */ 'pipe', 'ipc', ], env: Object.assign({}, process.env, { DEBUG_COLORS: 1 // without this settings, colors won't be shown }), }); worker.stderr.pipe(process.stderr, { end: false }); Authors TJ Holowaychuk Nathan Rajlich Andrew Rhyne Josh Junon Backers Support us with a monthly donation and help us continue our activities. [Become a backer] Sponsors Become a sponsor and get your logo on our README on Github with a link to your site. [Become a sponsor] License (The MIT License) Copyright (c) 2014-2017 TJ Holowaychuk <tj@vision-media.ca&gt; Copyright (c) 2018-2021 Josh Junon Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/socket.io-client/node_modules/ms/license.html": {
    "href": "node_modules/socket.io-client/node_modules/ms/license.html",
    "title": "| accouter",
    "keywords": "The MIT License (MIT) Copyright (c) 2016 Zeit, Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/socket.io-client/node_modules/ms/readme.html": {
    "href": "node_modules/socket.io-client/node_modules/ms/readme.html",
    "title": "ms | accouter",
    "keywords": "ms Use this package to easily convert various time formats to milliseconds. Examples ms('2 days') // 172800000 ms('1d') // 86400000 ms('10h') // 36000000 ms('2.5 hrs') // 9000000 ms('2h') // 7200000 ms('1m') // 60000 ms('5s') // 5000 ms('1y') // 31557600000 ms('100') // 100 ms('-3 days') // -259200000 ms('-1h') // -3600000 ms('-200') // -200 Convert from Milliseconds ms(60000) // \"1m\" ms(2 * 60000) // \"2m\" ms(-3 * 60000) // \"-3m\" ms(ms('10 hours')) // \"10h\" Time Format Written-Out ms(60000, { long: true }) // \"1 minute\" ms(2 * 60000, { long: true }) // \"2 minutes\" ms(-3 * 60000, { long: true }) // \"-3 minutes\" ms(ms('10 hours'), { long: true }) // \"10 hours\" Features Works both in Node.js and in the browser If a number is supplied to ms, a string with a unit is returned If a string that contains the number is supplied, it returns it as a number (e.g.: it returns 100 for '100') If you pass a string with a number and a valid unit, the number of equivalent milliseconds is returned Related Packages ms.macro - Run ms as a macro at build-time. Caught a Bug? Fork this repository to your own GitHub account and then clone it to your local device Link the package to the global module directory: npm link Within the module you want to test your local development instance of ms, just link it to the dependencies: npm link ms. Instead of the default one from npm, Node.js will now use your clone of ms! As always, you can run the tests using: npm test"
  },
  "node_modules/socket.io-parser/Readme.html": {
    "href": "node_modules/socket.io-parser/Readme.html",
    "title": "socket.io-parser | accouter",
    "keywords": "socket.io-parser A socket.io encoder and decoder written in JavaScript complying with version 5 of socket.io-protocol. Used by socket.io and socket.io-client. Compatibility table: Parser version Socket.IO server version Protocol revision 3.x 1.x / 2.x 4 4.x 3.x 5 Parser API socket.io-parser is the reference implementation of socket.io-protocol. Read the full API here: socket.io-protocol. Example Usage Encoding and decoding a packet var parser = require('socket.io-parser'); var encoder = new parser.Encoder(); var packet = { type: parser.EVENT, data: 'test-packet', id: 13 }; encoder.encode(packet, function(encodedPackets) { var decoder = new parser.Decoder(); decoder.on('decoded', function(decodedPacket) { // decodedPacket.type == parser.EVENT // decodedPacket.data == 'test-packet' // decodedPacket.id == 13 }); for (var i = 0; i < encodedPackets.length; i++) { decoder.add(encodedPackets[i]); } }); Encoding and decoding a packet with binary data var parser = require('socket.io-parser'); var encoder = new parser.Encoder(); var packet = { type: parser.BINARY_EVENT, data: {i: new Buffer(1234), j: new Blob([new ArrayBuffer(2)])}, id: 15 }; encoder.encode(packet, function(encodedPackets) { var decoder = new parser.Decoder(); decoder.on('decoded', function(decodedPacket) { // decodedPacket.type == parser.BINARY_EVENT // Buffer.isBuffer(decodedPacket.data.i) == true // Buffer.isBuffer(decodedPacket.data.j) == true // decodedPacket.id == 15 }); for (var i = 0; i < encodedPackets.length; i++) { decoder.add(encodedPackets[i]); } }); See the test suite for more examples of how socket.io-parser is used. License MIT"
  },
  "node_modules/socket.io-parser/node_modules/debug/README.html": {
    "href": "node_modules/socket.io-parser/node_modules/debug/README.html",
    "title": "debug | accouter",
    "keywords": "debug A tiny JavaScript debugging utility modelled after Node.js core's debugging technique. Works in Node.js and web browsers. Installation $ npm install debug Usage debug exposes a function; simply pass this function the name of your module, and it will return a decorated version of console.error for you to pass debug statements to. This will allow you to toggle the debug output for different parts of your module as well as the module as a whole. Example app.js: var debug = require('debug')('http') , http = require('http') , name = 'My App'; // fake app debug('booting %o', name); http.createServer(function(req, res){ debug(req.method + ' ' + req.url); res.end('hello\\n'); }).listen(3000, function(){ debug('listening'); }); // fake worker of some kind require('./worker'); Example worker.js: var a = require('debug')('worker:a') , b = require('debug')('worker:b'); function work() { a('doing lots of uninteresting work'); setTimeout(work, Math.random() * 1000); } work(); function workb() { b('doing some work'); setTimeout(workb, Math.random() * 2000); } workb(); The DEBUG environment variable is then used to enable these based on space or comma-delimited names. Here are some examples: Windows command prompt notes CMD On Windows the environment variable is set using the set command. set DEBUG=*,-not_this Example: set DEBUG=* & node app.js PowerShell (VS Code default) PowerShell uses different syntax to set environment variables. $env:DEBUG = \"*,-not_this\" Example: $env:DEBUG='app';node app.js Then, run the program to be debugged as usual. npm script example: \"windowsDebug\": \"@powershell -Command $env:DEBUG='*';node app.js\", Namespace Colors Every debug instance has a color generated for it based on its namespace name. This helps when visually parsing the debug output to identify which debug instance a debug line belongs to. Node.js In Node.js, colors are enabled when stderr is a TTY. You also should install the supports-color module alongside debug, otherwise debug will only use a small handful of basic colors. Web Browser Colors are also enabled on \"Web Inspectors\" that understand the %c formatting option. These are WebKit web inspectors, Firefox (since version 31) and the Firebug plugin for Firefox (any version). Millisecond diff When actively developing an application it can be useful to see when the time spent between one debug() call and the next. Suppose for example you invoke debug() before requesting a resource, and after as well, the \"+NNNms\" will show you how much time was spent between calls. When stdout is not a TTY, Date#toISOString() is used, making it more useful for logging the debug information as shown below: Conventions If you're using this in one or more of your libraries, you should use the name of your library so that developers may toggle debugging as desired without guessing names. If you have more than one debuggers you should prefix them with your library name and use \":\" to separate features. For example \"bodyParser\" from Connect would then be \"connect:bodyParser\". If you append a \"*\" to the end of your name, it will always be enabled regardless of the setting of the DEBUG environment variable. You can then use it for normal output as well as debug output. Wildcards The * character may be used as a wildcard. Suppose for example your library has debuggers named \"connect:bodyParser\", \"connect:compress\", \"connect:session\", instead of listing all three with DEBUG=connect:bodyParser,connect:compress,connect:session, you may simply do DEBUG=connect:*, or to run everything using this module simply use DEBUG=*. You can also exclude specific debuggers by prefixing them with a \"-\" character. For example, DEBUG=*,-connect:* would include all debuggers except those starting with \"connect:\". Environment Variables When running through Node.js, you can set a few environment variables that will change the behavior of the debug logging: Name Purpose DEBUG Enables/disables specific debugging namespaces. DEBUG_HIDE_DATE Hide date from debug output (non-TTY). DEBUG_COLORS Whether or not to use colors in the debug output. DEBUG_DEPTH Object inspection depth. DEBUG_SHOW_HIDDEN Shows hidden properties on inspected objects. Note: The environment variables beginning with DEBUG_ end up being converted into an Options object that gets used with %o/%O formatters. See the Node.js documentation for util.inspect() for the complete list. Formatters Debug uses printf-style formatting. Below are the officially supported formatters: Formatter Representation %O Pretty-print an Object on multiple lines. %o Pretty-print an Object all on a single line. %s String. %d Number (both integer and float). %j JSON. Replaced with the string '[Circular]' if the argument contains circular references. %% Single percent sign ('%'). This does not consume an argument. Custom formatters You can add custom formatters by extending the debug.formatters object. For example, if you wanted to add support for rendering a Buffer as hex with %h, you could do something like: const createDebug = require('debug') createDebug.formatters.h = (v) => { return v.toString('hex') } // …elsewhere const debug = createDebug('foo') debug('this is hex: %h', new Buffer('hello world')) // foo this is hex: 68656c6c6f20776f726c6421 +0ms Browser Support You can build a browser-ready script using browserify, or just use the browserify-as-a-service build, if you don't want to build it yourself. Debug's enable state is currently persisted by localStorage. Consider the situation shown below where you have worker:a and worker:b, and wish to debug both. You can enable this using localStorage.debug: localStorage.debug = 'worker:*' And then refresh the page. a = debug('worker:a'); b = debug('worker:b'); setInterval(function(){ a('doing some work'); }, 1000); setInterval(function(){ b('doing some work'); }, 1200); In Chromium-based web browsers (e.g. Brave, Chrome, and Electron), the JavaScript console will—by default—only show messages logged by debug if the \"Verbose\" log level is enabled. Output streams By default debug will log to stderr, however this can be configured per-namespace by overriding the log method: Example stdout.js: var debug = require('debug'); var error = debug('app:error'); // by default stderr is used error('goes to stderr!'); var log = debug('app:log'); // set this namespace to log via console.log log.log = console.log.bind(console); // don't forget to bind to console! log('goes to stdout'); error('still goes to stderr!'); // set all output to go via console.info // overrides all per-namespace log settings debug.log = console.info.bind(console); error('now goes to stdout via console.info'); log('still goes to stdout, but via console.info now'); Extend You can simply extend debugger const log = require('debug')('auth'); //creates new debug instance with extended namespace const logSign = log.extend('sign'); const logLogin = log.extend('login'); log('hello'); // auth hello logSign('hello'); //auth:sign hello logLogin('hello'); //auth:login hello Set dynamically You can also enable debug dynamically by calling the enable() method : let debug = require('debug'); console.log(1, debug.enabled('test')); debug.enable('test'); console.log(2, debug.enabled('test')); debug.disable(); console.log(3, debug.enabled('test')); print : 1 false 2 true 3 false Usage : enable(namespaces) namespaces can include modes separated by a colon and wildcards. Note that calling enable() completely overrides previously set DEBUG variable : $ DEBUG=foo node -e 'var dbg = require(\"debug\"); dbg.enable(\"bar\"); console.log(dbg.enabled(\"foo\"))' => false disable() Will disable all namespaces. The functions returns the namespaces currently enabled (and skipped). This can be useful if you want to disable debugging temporarily without knowing what was enabled to begin with. For example: let debug = require('debug'); debug.enable('foo:*,-foo:bar'); let namespaces = debug.disable(); debug.enable(namespaces); Note: There is no guarantee that the string will be identical to the initial enable string, but semantically they will be identical. Checking whether a debug target is enabled After you've created a debug instance, you can determine whether or not it is enabled by checking the enabled property: const debug = require('debug')('http'); if (debug.enabled) { // do stuff... } You can also manually toggle this property to force the debug instance to be enabled or disabled. Usage in child processes Due to the way debug detects if the output is a TTY or not, colors are not shown in child processes when stderr is piped. A solution is to pass the DEBUG_COLORS=1 environment variable to the child process. For example: worker = fork(WORKER_WRAP_PATH, [workerPath], { stdio: [ /* stdin: */ 0, /* stdout: */ 'pipe', /* stderr: */ 'pipe', 'ipc', ], env: Object.assign({}, process.env, { DEBUG_COLORS: 1 // without this settings, colors won't be shown }), }); worker.stderr.pipe(process.stderr, { end: false }); Authors TJ Holowaychuk Nathan Rajlich Andrew Rhyne Josh Junon Backers Support us with a monthly donation and help us continue our activities. [Become a backer] Sponsors Become a sponsor and get your logo on our README on Github with a link to your site. [Become a sponsor] License (The MIT License) Copyright (c) 2014-2017 TJ Holowaychuk <tj@vision-media.ca&gt; Copyright (c) 2018-2021 Josh Junon Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/socket.io-parser/node_modules/ms/license.html": {
    "href": "node_modules/socket.io-parser/node_modules/ms/license.html",
    "title": "| accouter",
    "keywords": "The MIT License (MIT) Copyright (c) 2016 Zeit, Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/socket.io-parser/node_modules/ms/readme.html": {
    "href": "node_modules/socket.io-parser/node_modules/ms/readme.html",
    "title": "ms | accouter",
    "keywords": "ms Use this package to easily convert various time formats to milliseconds. Examples ms('2 days') // 172800000 ms('1d') // 86400000 ms('10h') // 36000000 ms('2.5 hrs') // 9000000 ms('2h') // 7200000 ms('1m') // 60000 ms('5s') // 5000 ms('1y') // 31557600000 ms('100') // 100 ms('-3 days') // -259200000 ms('-1h') // -3600000 ms('-200') // -200 Convert from Milliseconds ms(60000) // \"1m\" ms(2 * 60000) // \"2m\" ms(-3 * 60000) // \"-3m\" ms(ms('10 hours')) // \"10h\" Time Format Written-Out ms(60000, { long: true }) // \"1 minute\" ms(2 * 60000, { long: true }) // \"2 minutes\" ms(-3 * 60000, { long: true }) // \"-3 minutes\" ms(ms('10 hours'), { long: true }) // \"10 hours\" Features Works both in Node.js and in the browser If a number is supplied to ms, a string with a unit is returned If a string that contains the number is supplied, it returns it as a number (e.g.: it returns 100 for '100') If you pass a string with a number and a valid unit, the number of equivalent milliseconds is returned Related Packages ms.macro - Run ms as a macro at build-time. Caught a Bug? Fork this repository to your own GitHub account and then clone it to your local device Link the package to the global module directory: npm link Within the module you want to test your local development instance of ms, just link it to the dependencies: npm link ms. Instead of the default one from npm, Node.js will now use your clone of ms! As always, you can run the tests using: npm test"
  },
  "node_modules/socket.io/Readme.html": {
    "href": "node_modules/socket.io/Readme.html",
    "title": "socket.io | accouter",
    "keywords": "socket.io Features Socket.IO enables real-time bidirectional event-based communication. It consists of: a Node.js server (this repository) a Javascript client library for the browser (or a Node.js client) Some implementations in other languages are also available: Java C++ Swift Dart Python .NET Rust PHP Its main features are: Reliability Connections are established even in the presence of: proxies and load balancers. personal firewall and antivirus software. For this purpose, it relies on Engine.IO, which first establishes a long-polling connection, then tries to upgrade to better transports that are \"tested\" on the side, like WebSocket. Please see the Goals section for more information. Auto-reconnection support Unless instructed otherwise a disconnected client will try to reconnect forever, until the server is available again. Please see the available reconnection options here. Disconnection detection A heartbeat mechanism is implemented at the Engine.IO level, allowing both the server and the client to know when the other one is not responding anymore. That functionality is achieved with timers set on both the server and the client, with timeout values (the pingInterval and pingTimeout parameters) shared during the connection handshake. Those timers require any subsequent client calls to be directed to the same server, hence the sticky-session requirement when using multiples nodes. Binary support Any serializable data structures can be emitted, including: ArrayBuffer and Blob in the browser ArrayBuffer and Buffer in Node.js Simple and convenient API Sample code: io.on('connection', socket => { socket.emit('request', /* … */); // emit an event to the socket io.emit('broadcast', /* … */); // emit an event to all connected sockets socket.on('reply', () => { /* … */ }); // listen to the event }); Cross-browser Browser support is tested in Sauce Labs: Multiplexing support In order to create separation of concerns within your application (for example per module, or based on permissions), Socket.IO allows you to create several Namespaces, which will act as separate communication channels but will share the same underlying connection. Room support Within each Namespace, you can define arbitrary channels, called Rooms, that sockets can join and leave. You can then broadcast to any given room, reaching every socket that has joined it. This is a useful feature to send notifications to a group of users, or to a given user connected on several devices for example. Note: Socket.IO is not a WebSocket implementation. Although Socket.IO indeed uses WebSocket as a transport when possible, it adds some metadata to each packet: the packet type, the namespace and the ack id when a message acknowledgement is needed. That is why a WebSocket client will not be able to successfully connect to a Socket.IO server, and a Socket.IO client will not be able to connect to a WebSocket server (like ws://echo.websocket.org) either. Please see the protocol specification here. Installation // with npm npm install socket.io // with yarn yarn add socket.io How to use The following example attaches socket.io to a plain Node.JS HTTP server listening on port 3000. const server = require('http').createServer(); const io = require('socket.io')(server); io.on('connection', client => { client.on('event', data => { /* … */ }); client.on('disconnect', () => { /* … */ }); }); server.listen(3000); Standalone const io = require('socket.io')(); io.on('connection', client => { ... }); io.listen(3000); Module syntax import { Server } from \"socket.io\"; const io = new Server(server); io.listen(3000); In conjunction with Express Starting with 3.0, express applications have become request handler functions that you pass to http or http Server instances. You need to pass the Server to socket.io, not the express application function. Also make sure to call .listen on the server, not the app. const app = require('express')(); const server = require('http').createServer(app); const io = require('socket.io')(server); io.on('connection', () => { /* … */ }); server.listen(3000); In conjunction with Koa Like Express.JS, Koa works by exposing an application as a request handler function, but only by calling the callback method. const app = require('koa')(); const server = require('http').createServer(app.callback()); const io = require('socket.io')(server); io.on('connection', () => { /* … */ }); server.listen(3000); In conjunction with Fastify To integrate Socket.io in your Fastify application you just need to register fastify-socket.io plugin. It will create a decorator called io. const app = require('fastify')(); app.register(require('fastify-socket.io')); app.io.on('connection', () => { /* … */ }); app.listen(3000); Documentation Please see the documentation here. The source code of the website can be found here. Contributions are welcome! Debug / logging Socket.IO is powered by debug. In order to see all the debug output, run your app with the environment variable DEBUG including the desired scope. To see the output from all of Socket.IO's debugging scopes you can use: DEBUG=socket.io* node myapp Testing npm test This runs the gulp task test. By default the test will be run with the source code in lib directory. Set the environmental variable TEST_VERSION to compat to test the transpiled es5-compat version of the code. The gulp task test will always transpile the source code into es5 and export to dist first before running the test. Backers Support us with a monthly donation and help us continue our activities. [Become a backer] Sponsors Become a sponsor and get your logo on our README on Github with a link to your site. [Become a sponsor] License MIT"
  },
  "node_modules/socket.io/node_modules/debug/README.html": {
    "href": "node_modules/socket.io/node_modules/debug/README.html",
    "title": "debug | accouter",
    "keywords": "debug A tiny JavaScript debugging utility modelled after Node.js core's debugging technique. Works in Node.js and web browsers. Installation $ npm install debug Usage debug exposes a function; simply pass this function the name of your module, and it will return a decorated version of console.error for you to pass debug statements to. This will allow you to toggle the debug output for different parts of your module as well as the module as a whole. Example app.js: var debug = require('debug')('http') , http = require('http') , name = 'My App'; // fake app debug('booting %o', name); http.createServer(function(req, res){ debug(req.method + ' ' + req.url); res.end('hello\\n'); }).listen(3000, function(){ debug('listening'); }); // fake worker of some kind require('./worker'); Example worker.js: var a = require('debug')('worker:a') , b = require('debug')('worker:b'); function work() { a('doing lots of uninteresting work'); setTimeout(work, Math.random() * 1000); } work(); function workb() { b('doing some work'); setTimeout(workb, Math.random() * 2000); } workb(); The DEBUG environment variable is then used to enable these based on space or comma-delimited names. Here are some examples: Windows command prompt notes CMD On Windows the environment variable is set using the set command. set DEBUG=*,-not_this Example: set DEBUG=* & node app.js PowerShell (VS Code default) PowerShell uses different syntax to set environment variables. $env:DEBUG = \"*,-not_this\" Example: $env:DEBUG='app';node app.js Then, run the program to be debugged as usual. npm script example: \"windowsDebug\": \"@powershell -Command $env:DEBUG='*';node app.js\", Namespace Colors Every debug instance has a color generated for it based on its namespace name. This helps when visually parsing the debug output to identify which debug instance a debug line belongs to. Node.js In Node.js, colors are enabled when stderr is a TTY. You also should install the supports-color module alongside debug, otherwise debug will only use a small handful of basic colors. Web Browser Colors are also enabled on \"Web Inspectors\" that understand the %c formatting option. These are WebKit web inspectors, Firefox (since version 31) and the Firebug plugin for Firefox (any version). Millisecond diff When actively developing an application it can be useful to see when the time spent between one debug() call and the next. Suppose for example you invoke debug() before requesting a resource, and after as well, the \"+NNNms\" will show you how much time was spent between calls. When stdout is not a TTY, Date#toISOString() is used, making it more useful for logging the debug information as shown below: Conventions If you're using this in one or more of your libraries, you should use the name of your library so that developers may toggle debugging as desired without guessing names. If you have more than one debuggers you should prefix them with your library name and use \":\" to separate features. For example \"bodyParser\" from Connect would then be \"connect:bodyParser\". If you append a \"*\" to the end of your name, it will always be enabled regardless of the setting of the DEBUG environment variable. You can then use it for normal output as well as debug output. Wildcards The * character may be used as a wildcard. Suppose for example your library has debuggers named \"connect:bodyParser\", \"connect:compress\", \"connect:session\", instead of listing all three with DEBUG=connect:bodyParser,connect:compress,connect:session, you may simply do DEBUG=connect:*, or to run everything using this module simply use DEBUG=*. You can also exclude specific debuggers by prefixing them with a \"-\" character. For example, DEBUG=*,-connect:* would include all debuggers except those starting with \"connect:\". Environment Variables When running through Node.js, you can set a few environment variables that will change the behavior of the debug logging: Name Purpose DEBUG Enables/disables specific debugging namespaces. DEBUG_HIDE_DATE Hide date from debug output (non-TTY). DEBUG_COLORS Whether or not to use colors in the debug output. DEBUG_DEPTH Object inspection depth. DEBUG_SHOW_HIDDEN Shows hidden properties on inspected objects. Note: The environment variables beginning with DEBUG_ end up being converted into an Options object that gets used with %o/%O formatters. See the Node.js documentation for util.inspect() for the complete list. Formatters Debug uses printf-style formatting. Below are the officially supported formatters: Formatter Representation %O Pretty-print an Object on multiple lines. %o Pretty-print an Object all on a single line. %s String. %d Number (both integer and float). %j JSON. Replaced with the string '[Circular]' if the argument contains circular references. %% Single percent sign ('%'). This does not consume an argument. Custom formatters You can add custom formatters by extending the debug.formatters object. For example, if you wanted to add support for rendering a Buffer as hex with %h, you could do something like: const createDebug = require('debug') createDebug.formatters.h = (v) => { return v.toString('hex') } // …elsewhere const debug = createDebug('foo') debug('this is hex: %h', new Buffer('hello world')) // foo this is hex: 68656c6c6f20776f726c6421 +0ms Browser Support You can build a browser-ready script using browserify, or just use the browserify-as-a-service build, if you don't want to build it yourself. Debug's enable state is currently persisted by localStorage. Consider the situation shown below where you have worker:a and worker:b, and wish to debug both. You can enable this using localStorage.debug: localStorage.debug = 'worker:*' And then refresh the page. a = debug('worker:a'); b = debug('worker:b'); setInterval(function(){ a('doing some work'); }, 1000); setInterval(function(){ b('doing some work'); }, 1200); In Chromium-based web browsers (e.g. Brave, Chrome, and Electron), the JavaScript console will—by default—only show messages logged by debug if the \"Verbose\" log level is enabled. Output streams By default debug will log to stderr, however this can be configured per-namespace by overriding the log method: Example stdout.js: var debug = require('debug'); var error = debug('app:error'); // by default stderr is used error('goes to stderr!'); var log = debug('app:log'); // set this namespace to log via console.log log.log = console.log.bind(console); // don't forget to bind to console! log('goes to stdout'); error('still goes to stderr!'); // set all output to go via console.info // overrides all per-namespace log settings debug.log = console.info.bind(console); error('now goes to stdout via console.info'); log('still goes to stdout, but via console.info now'); Extend You can simply extend debugger const log = require('debug')('auth'); //creates new debug instance with extended namespace const logSign = log.extend('sign'); const logLogin = log.extend('login'); log('hello'); // auth hello logSign('hello'); //auth:sign hello logLogin('hello'); //auth:login hello Set dynamically You can also enable debug dynamically by calling the enable() method : let debug = require('debug'); console.log(1, debug.enabled('test')); debug.enable('test'); console.log(2, debug.enabled('test')); debug.disable(); console.log(3, debug.enabled('test')); print : 1 false 2 true 3 false Usage : enable(namespaces) namespaces can include modes separated by a colon and wildcards. Note that calling enable() completely overrides previously set DEBUG variable : $ DEBUG=foo node -e 'var dbg = require(\"debug\"); dbg.enable(\"bar\"); console.log(dbg.enabled(\"foo\"))' => false disable() Will disable all namespaces. The functions returns the namespaces currently enabled (and skipped). This can be useful if you want to disable debugging temporarily without knowing what was enabled to begin with. For example: let debug = require('debug'); debug.enable('foo:*,-foo:bar'); let namespaces = debug.disable(); debug.enable(namespaces); Note: There is no guarantee that the string will be identical to the initial enable string, but semantically they will be identical. Checking whether a debug target is enabled After you've created a debug instance, you can determine whether or not it is enabled by checking the enabled property: const debug = require('debug')('http'); if (debug.enabled) { // do stuff... } You can also manually toggle this property to force the debug instance to be enabled or disabled. Usage in child processes Due to the way debug detects if the output is a TTY or not, colors are not shown in child processes when stderr is piped. A solution is to pass the DEBUG_COLORS=1 environment variable to the child process. For example: worker = fork(WORKER_WRAP_PATH, [workerPath], { stdio: [ /* stdin: */ 0, /* stdout: */ 'pipe', /* stderr: */ 'pipe', 'ipc', ], env: Object.assign({}, process.env, { DEBUG_COLORS: 1 // without this settings, colors won't be shown }), }); worker.stderr.pipe(process.stderr, { end: false }); Authors TJ Holowaychuk Nathan Rajlich Andrew Rhyne Josh Junon Backers Support us with a monthly donation and help us continue our activities. [Become a backer] Sponsors Become a sponsor and get your logo on our README on Github with a link to your site. [Become a sponsor] License (The MIT License) Copyright (c) 2014-2017 TJ Holowaychuk <tj@vision-media.ca&gt; Copyright (c) 2018-2021 Josh Junon Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/socket.io/node_modules/ms/license.html": {
    "href": "node_modules/socket.io/node_modules/ms/license.html",
    "title": "| accouter",
    "keywords": "The MIT License (MIT) Copyright (c) 2016 Zeit, Inc. Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/socket.io/node_modules/ms/readme.html": {
    "href": "node_modules/socket.io/node_modules/ms/readme.html",
    "title": "ms | accouter",
    "keywords": "ms Use this package to easily convert various time formats to milliseconds. Examples ms('2 days') // 172800000 ms('1d') // 86400000 ms('10h') // 36000000 ms('2.5 hrs') // 9000000 ms('2h') // 7200000 ms('1m') // 60000 ms('5s') // 5000 ms('1y') // 31557600000 ms('100') // 100 ms('-3 days') // -259200000 ms('-1h') // -3600000 ms('-200') // -200 Convert from Milliseconds ms(60000) // \"1m\" ms(2 * 60000) // \"2m\" ms(-3 * 60000) // \"-3m\" ms(ms('10 hours')) // \"10h\" Time Format Written-Out ms(60000, { long: true }) // \"1 minute\" ms(2 * 60000, { long: true }) // \"2 minutes\" ms(-3 * 60000, { long: true }) // \"-3 minutes\" ms(ms('10 hours'), { long: true }) // \"10 hours\" Features Works both in Node.js and in the browser If a number is supplied to ms, a string with a unit is returned If a string that contains the number is supplied, it returns it as a number (e.g.: it returns 100 for '100') If you pass a string with a number and a valid unit, the number of equivalent milliseconds is returned Related Packages ms.macro - Run ms as a macro at build-time. Caught a Bug? Fork this repository to your own GitHub account and then clone it to your local device Link the package to the global module directory: npm link Within the module you want to test your local development instance of ms, just link it to the dependencies: npm link ms. Instead of the default one from npm, Node.js will now use your clone of ms! As always, you can run the tests using: npm test"
  },
  "node_modules/source-map-js/README.html": {
    "href": "node_modules/source-map-js/README.html",
    "title": "Source Map JS | accouter",
    "keywords": "Source Map JS Difference between original source-map: TL,DR: it's fork of original source-map@0.6, but with perfomance optimizations. This journey starts from source-map@0.7.0. Some part of it was rewritten to Rust and WASM and API became async. It's still a major block for many libraries like PostCSS or Sass for example because they need to migrate the whole API to the async way. This is the reason why 0.6.1 has 2x more downloads than 0.7.3 while it's faster several times. More important that WASM version has some optimizations in JS code too. This is why community asked to create branch for 0.6 version and port these optimizations but, sadly, the answer was «no». A bit later I discovered the issue created by Ben Rothman (@benthemonkey) with no response at all. Roman Dvornov (@lahmatiy) wrote a serveral posts (russian, only, sorry) about source-map library in his own Telegram channel. He mentioned the article «Maybe you don't need Rust and WASM to speed up your JS» written by Vyacheslav Egorov (@mraleph). This article contains optimizations and hacks that lead to almost the same performance compare to WASM implementation. I decided to fork the original source-map and port these optimizations from the article and several others PR from the original source-map. This is a library to generate and consume the source map format described here. Use with Node $ npm install source-map-js Table of Contents Examples Consuming a source map Generating a source map With SourceNode (high level API) With SourceMapGenerator (low level API) API SourceMapConsumer new SourceMapConsumer(rawSourceMap) SourceMapConsumer.prototype.computeColumnSpans() SourceMapConsumer.prototype.originalPositionFor(generatedPosition) SourceMapConsumer.prototype.generatedPositionFor(originalPosition) SourceMapConsumer.prototype.allGeneratedPositionsFor(originalPosition) SourceMapConsumer.prototype.hasContentsOfAllSources() SourceMapConsumer.prototype.sourceContentFor(source[, returnNullOnMissing]) SourceMapConsumer.prototype.eachMapping(callback, context, order) SourceMapGenerator new SourceMapGenerator([startOfSourceMap]) SourceMapGenerator.fromSourceMap(sourceMapConsumer) SourceMapGenerator.prototype.addMapping(mapping) SourceMapGenerator.prototype.setSourceContent(sourceFile, sourceContent) SourceMapGenerator.prototype.applySourceMap(sourceMapConsumer[, sourceFile[, sourceMapPath]]) SourceMapGenerator.prototype.toString() SourceNode new SourceNode([line, column, source[, chunk[, name]]]) SourceNode.fromStringWithSourceMap(code, sourceMapConsumer[, relativePath]) SourceNode.prototype.add(chunk) SourceNode.prototype.prepend(chunk) SourceNode.prototype.setSourceContent(sourceFile, sourceContent) SourceNode.prototype.walk(fn) SourceNode.prototype.walkSourceContents(fn) SourceNode.prototype.join(sep) SourceNode.prototype.replaceRight(pattern, replacement) SourceNode.prototype.toString() SourceNode.prototype.toStringWithSourceMap([startOfSourceMap]) Examples Consuming a source map var rawSourceMap = { version: 3, file: 'min.js', names: ['bar', 'baz', 'n'], sources: ['one.js', 'two.js'], sourceRoot: 'http://example.com/www/js/', mappings: 'CAAC,IAAI,IAAM,SAAUA,GAClB,OAAOC,IAAID;CCDb,IAAI,IAAM,SAAUE,GAClB,OAAOA' }; var smc = new SourceMapConsumer(rawSourceMap); console.log(smc.sources); // [ 'http://example.com/www/js/one.js', // 'http://example.com/www/js/two.js' ] console.log(smc.originalPositionFor({ line: 2, column: 28 })); // { source: 'http://example.com/www/js/two.js', // line: 2, // column: 10, // name: 'n' } console.log(smc.generatedPositionFor({ source: 'http://example.com/www/js/two.js', line: 2, column: 10 })); // { line: 2, column: 28 } smc.eachMapping(function (m) { // ... }); Generating a source map In depth guide: Compiling to JavaScript, and Debugging with Source Maps With SourceNode (high level API) function compile(ast) { switch (ast.type) { case 'BinaryExpression': return new SourceNode( ast.location.line, ast.location.column, ast.location.source, [compile(ast.left), \" + \", compile(ast.right)] ); case 'Literal': return new SourceNode( ast.location.line, ast.location.column, ast.location.source, String(ast.value) ); // ... default: throw new Error(\"Bad AST\"); } } var ast = parse(\"40 + 2\", \"add.js\"); console.log(compile(ast).toStringWithSourceMap({ file: 'add.js' })); // { code: '40 + 2', // map: [object SourceMapGenerator] } With SourceMapGenerator (low level API) var map = new SourceMapGenerator({ file: \"source-mapped.js\" }); map.addMapping({ generated: { line: 10, column: 35 }, source: \"foo.js\", original: { line: 33, column: 2 }, name: \"christopher\" }); console.log(map.toString()); // '{\"version\":3,\"file\":\"source-mapped.js\",\"sources\":[\"foo.js\"],\"names\":[\"christopher\"],\"mappings\":\";;;;;;;;;mCAgCEA\"}' API Get a reference to the module: // Node.js var sourceMap = require('source-map'); // Browser builds var sourceMap = window.sourceMap; // Inside Firefox const sourceMap = require(\"devtools/toolkit/sourcemap/source-map.js\"); SourceMapConsumer A SourceMapConsumer instance represents a parsed source map which we can query for information about the original file positions by giving it a file position in the generated source. new SourceMapConsumer(rawSourceMap) The only parameter is the raw source map (either as a string which can be JSON.parse'd, or an object). According to the spec, source maps have the following attributes: version: Which version of the source map spec this map is following. sources: An array of URLs to the original source files. names: An array of identifiers which can be referenced by individual mappings. sourceRoot: Optional. The URL root from which all sources are relative. sourcesContent: Optional. An array of contents of the original source files. mappings: A string of base64 VLQs which contain the actual mappings. file: Optional. The generated filename this source map is associated with. var consumer = new sourceMap.SourceMapConsumer(rawSourceMapJsonData); SourceMapConsumer.prototype.computeColumnSpans() Compute the last column for each generated mapping. The last column is inclusive. // Before: consumer.allGeneratedPositionsFor({ line: 2, source: \"foo.coffee\" }) // [ { line: 2, // column: 1 }, // { line: 2, // column: 10 }, // { line: 2, // column: 20 } ] consumer.computeColumnSpans(); // After: consumer.allGeneratedPositionsFor({ line: 2, source: \"foo.coffee\" }) // [ { line: 2, // column: 1, // lastColumn: 9 }, // { line: 2, // column: 10, // lastColumn: 19 }, // { line: 2, // column: 20, // lastColumn: Infinity } ] SourceMapConsumer.prototype.originalPositionFor(generatedPosition) Returns the original source, line, and column information for the generated source's line and column positions provided. The only argument is an object with the following properties: line: The line number in the generated source. Line numbers in this library are 1-based (note that the underlying source map specification uses 0-based line numbers -- this library handles the translation). column: The column number in the generated source. Column numbers in this library are 0-based. bias: Either SourceMapConsumer.GREATEST_LOWER_BOUND or SourceMapConsumer.LEAST_UPPER_BOUND. Specifies whether to return the closest element that is smaller than or greater than the one we are searching for, respectively, if the exact element cannot be found. Defaults to SourceMapConsumer.GREATEST_LOWER_BOUND. and an object is returned with the following properties: source: The original source file, or null if this information is not available. line: The line number in the original source, or null if this information is not available. The line number is 1-based. column: The column number in the original source, or null if this information is not available. The column number is 0-based. name: The original identifier, or null if this information is not available. consumer.originalPositionFor({ line: 2, column: 10 }) // { source: 'foo.coffee', // line: 2, // column: 2, // name: null } consumer.originalPositionFor({ line: 99999999999999999, column: 999999999999999 }) // { source: null, // line: null, // column: null, // name: null } SourceMapConsumer.prototype.generatedPositionFor(originalPosition) Returns the generated line and column information for the original source, line, and column positions provided. The only argument is an object with the following properties: source: The filename of the original source. line: The line number in the original source. The line number is 1-based. column: The column number in the original source. The column number is 0-based. and an object is returned with the following properties: line: The line number in the generated source, or null. The line number is 1-based. column: The column number in the generated source, or null. The column number is 0-based. consumer.generatedPositionFor({ source: \"example.js\", line: 2, column: 10 }) // { line: 1, // column: 56 } SourceMapConsumer.prototype.allGeneratedPositionsFor(originalPosition) Returns all generated line and column information for the original source, line, and column provided. If no column is provided, returns all mappings corresponding to a either the line we are searching for or the next closest line that has any mappings. Otherwise, returns all mappings corresponding to the given line and either the column we are searching for or the next closest column that has any offsets. The only argument is an object with the following properties: source: The filename of the original source. line: The line number in the original source. The line number is 1-based. column: Optional. The column number in the original source. The column number is 0-based. and an array of objects is returned, each with the following properties: line: The line number in the generated source, or null. The line number is 1-based. column: The column number in the generated source, or null. The column number is 0-based. consumer.allGeneratedpositionsfor({ line: 2, source: \"foo.coffee\" }) // [ { line: 2, // column: 1 }, // { line: 2, // column: 10 }, // { line: 2, // column: 20 } ] SourceMapConsumer.prototype.hasContentsOfAllSources() Return true if we have the embedded source content for every source listed in the source map, false otherwise. In other words, if this method returns true, then consumer.sourceContentFor(s) will succeed for every source s in consumer.sources. // ... if (consumer.hasContentsOfAllSources()) { consumerReadyCallback(consumer); } else { fetchSources(consumer, consumerReadyCallback); } // ... SourceMapConsumer.prototype.sourceContentFor(source[, returnNullOnMissing]) Returns the original source content for the source provided. The only argument is the URL of the original source file. If the source content for the given source is not found, then an error is thrown. Optionally, pass true as the second param to have null returned instead. consumer.sources // [ \"my-cool-lib.clj\" ] consumer.sourceContentFor(\"my-cool-lib.clj\") // \"...\" consumer.sourceContentFor(\"this is not in the source map\"); // Error: \"this is not in the source map\" is not in the source map consumer.sourceContentFor(\"this is not in the source map\", true); // null SourceMapConsumer.prototype.eachMapping(callback, context, order) Iterate over each mapping between an original source/line/column and a generated line/column in this source map. callback: The function that is called with each mapping. Mappings have the form { source, generatedLine, generatedColumn, originalLine, originalColumn, name } context: Optional. If specified, this object will be the value of this every time that callback is called. order: Either SourceMapConsumer.GENERATED_ORDER or SourceMapConsumer.ORIGINAL_ORDER. Specifies whether you want to iterate over the mappings sorted by the generated file's line/column order or the original's source/line/column order, respectively. Defaults to SourceMapConsumer.GENERATED_ORDER. consumer.eachMapping(function (m) { console.log(m); }) // ... // { source: 'illmatic.js', // generatedLine: 1, // generatedColumn: 0, // originalLine: 1, // originalColumn: 0, // name: null } // { source: 'illmatic.js', // generatedLine: 2, // generatedColumn: 0, // originalLine: 2, // originalColumn: 0, // name: null } // ... SourceMapGenerator An instance of the SourceMapGenerator represents a source map which is being built incrementally. new SourceMapGenerator([startOfSourceMap]) You may pass an object with the following properties: file: The filename of the generated source that this source map is associated with. sourceRoot: A root for all relative URLs in this source map. skipValidation: Optional. When true, disables validation of mappings as they are added. This can improve performance but should be used with discretion, as a last resort. Even then, one should avoid using this flag when running tests, if possible. ignoreInvalidMapping: Optional. When true, instead of throwing error on invalid mapping, it will be ignored. var generator = new sourceMap.SourceMapGenerator({ file: \"my-generated-javascript-file.js\", sourceRoot: \"http://example.com/app/js/\" }); SourceMapGenerator.fromSourceMap(sourceMapConsumer, sourceMapGeneratorOptions) Creates a new SourceMapGenerator from an existing SourceMapConsumer instance. sourceMapConsumer The SourceMap. sourceMapGeneratorOptions options that will be passed to the SourceMapGenerator constructor which used under the hood. var generator = sourceMap.SourceMapGenerator.fromSourceMap(consumer, { ignoreInvalidMapping: true, }); SourceMapGenerator.prototype.addMapping(mapping) Add a single mapping from original source line and column to the generated source's line and column for this source map being created. The mapping object should have the following properties: generated: An object with the generated line and column positions. original: An object with the original line and column positions. source: The original source file (relative to the sourceRoot). name: An optional original token name for this mapping. generator.addMapping({ source: \"module-one.scm\", original: { line: 128, column: 0 }, generated: { line: 3, column: 456 } }) SourceMapGenerator.prototype.setSourceContent(sourceFile, sourceContent) Set the source content for an original source file. sourceFile the URL of the original source file. sourceContent the content of the source file. generator.setSourceContent(\"module-one.scm\", fs.readFileSync(\"path/to/module-one.scm\")) SourceMapGenerator.prototype.applySourceMap(sourceMapConsumer[, sourceFile[, sourceMapPath]]) Applies a SourceMap for a source file to the SourceMap. Each mapping to the supplied source file is rewritten using the supplied SourceMap. Note: The resolution for the resulting mappings is the minimum of this map and the supplied map. sourceMapConsumer: The SourceMap to be applied. sourceFile: Optional. The filename of the source file. If omitted, sourceMapConsumer.file will be used, if it exists. Otherwise an error will be thrown. sourceMapPath: Optional. The dirname of the path to the SourceMap to be applied. If relative, it is relative to the SourceMap. This parameter is needed when the two SourceMaps aren't in the same directory, and the SourceMap to be applied contains relative source paths. If so, those relative source paths need to be rewritten relative to the SourceMap. If omitted, it is assumed that both SourceMaps are in the same directory, thus not needing any rewriting. (Supplying '.' has the same effect.) SourceMapGenerator.prototype.toString() Renders the source map being generated to a string. generator.toString() // '{\"version\":3,\"sources\":[\"module-one.scm\"],\"names\":[],\"mappings\":\"...snip...\",\"file\":\"my-generated-javascript-file.js\",\"sourceRoot\":\"http://example.com/app/js/\"}' SourceNode SourceNodes provide a way to abstract over interpolating and/or concatenating snippets of generated JavaScript source code, while maintaining the line and column information associated between those snippets and the original source code. This is useful as the final intermediate representation a compiler might use before outputting the generated JS and source map. new SourceNode([line, column, source[, chunk[, name]]]) line: The original line number associated with this source node, or null if it isn't associated with an original line. The line number is 1-based. column: The original column number associated with this source node, or null if it isn't associated with an original column. The column number is 0-based. source: The original source's filename; null if no filename is provided. chunk: Optional. Is immediately passed to SourceNode.prototype.add, see below. name: Optional. The original identifier. var node = new SourceNode(1, 2, \"a.cpp\", [ new SourceNode(3, 4, \"b.cpp\", \"extern int status;\\n\"), new SourceNode(5, 6, \"c.cpp\", \"std::string* make_string(size_t n);\\n\"), new SourceNode(7, 8, \"d.cpp\", \"int main(int argc, char** argv) {}\\n\"), ]); SourceNode.fromStringWithSourceMap(code, sourceMapConsumer[, relativePath]) Creates a SourceNode from generated code and a SourceMapConsumer. code: The generated code sourceMapConsumer The SourceMap for the generated code relativePath The optional path that relative sources in sourceMapConsumer should be relative to. var consumer = new SourceMapConsumer(fs.readFileSync(\"path/to/my-file.js.map\", \"utf8\")); var node = SourceNode.fromStringWithSourceMap(fs.readFileSync(\"path/to/my-file.js\"), consumer); SourceNode.prototype.add(chunk) Add a chunk of generated JS to this source node. chunk: A string snippet of generated JS code, another instance of SourceNode, or an array where each member is one of those things. node.add(\" + \"); node.add(otherNode); node.add([leftHandOperandNode, \" + \", rightHandOperandNode]); SourceNode.prototype.prepend(chunk) Prepend a chunk of generated JS to this source node. chunk: A string snippet of generated JS code, another instance of SourceNode, or an array where each member is one of those things. node.prepend(\"/** Build Id: f783haef86324gf **/\\n\\n\"); SourceNode.prototype.setSourceContent(sourceFile, sourceContent) Set the source content for a source file. This will be added to the SourceMap in the sourcesContent field. sourceFile: The filename of the source file sourceContent: The content of the source file node.setSourceContent(\"module-one.scm\", fs.readFileSync(\"path/to/module-one.scm\")) SourceNode.prototype.walk(fn) Walk over the tree of JS snippets in this node and its children. The walking function is called once for each snippet of JS and is passed that snippet and the its original associated source's line/column location. fn: The traversal function. var node = new SourceNode(1, 2, \"a.js\", [ new SourceNode(3, 4, \"b.js\", \"uno\"), \"dos\", [ \"tres\", new SourceNode(5, 6, \"c.js\", \"quatro\") ] ]); node.walk(function (code, loc) { console.log(\"WALK:\", code, loc); }) // WALK: uno { source: 'b.js', line: 3, column: 4, name: null } // WALK: dos { source: 'a.js', line: 1, column: 2, name: null } // WALK: tres { source: 'a.js', line: 1, column: 2, name: null } // WALK: quatro { source: 'c.js', line: 5, column: 6, name: null } SourceNode.prototype.walkSourceContents(fn) Walk over the tree of SourceNodes. The walking function is called for each source file content and is passed the filename and source content. fn: The traversal function. var a = new SourceNode(1, 2, \"a.js\", \"generated from a\"); a.setSourceContent(\"a.js\", \"original a\"); var b = new SourceNode(1, 2, \"b.js\", \"generated from b\"); b.setSourceContent(\"b.js\", \"original b\"); var c = new SourceNode(1, 2, \"c.js\", \"generated from c\"); c.setSourceContent(\"c.js\", \"original c\"); var node = new SourceNode(null, null, null, [a, b, c]); node.walkSourceContents(function (source, contents) { console.log(\"WALK:\", source, \":\", contents); }) // WALK: a.js : original a // WALK: b.js : original b // WALK: c.js : original c SourceNode.prototype.join(sep) Like Array.prototype.join except for SourceNodes. Inserts the separator between each of this source node's children. sep: The separator. var lhs = new SourceNode(1, 2, \"a.rs\", \"my_copy\"); var operand = new SourceNode(3, 4, \"a.rs\", \"=\"); var rhs = new SourceNode(5, 6, \"a.rs\", \"orig.clone()\"); var node = new SourceNode(null, null, null, [ lhs, operand, rhs ]); var joinedNode = node.join(\" \"); SourceNode.prototype.replaceRight(pattern, replacement) Call String.prototype.replace on the very right-most source snippet. Useful for trimming white space from the end of a source node, etc. pattern: The pattern to replace. replacement: The thing to replace the pattern with. // Trim trailing white space. node.replaceRight(/\\s*$/, \"\"); SourceNode.prototype.toString() Return the string representation of this source node. Walks over the tree and concatenates all the various snippets together to one string. var node = new SourceNode(1, 2, \"a.js\", [ new SourceNode(3, 4, \"b.js\", \"uno\"), \"dos\", [ \"tres\", new SourceNode(5, 6, \"c.js\", \"quatro\") ] ]); node.toString() // 'unodostresquatro' SourceNode.prototype.toStringWithSourceMap([startOfSourceMap]) Returns the string representation of this tree of source nodes, plus a SourceMapGenerator which contains all the mappings between the generated and original sources. The arguments are the same as those to new SourceMapGenerator. var node = new SourceNode(1, 2, \"a.js\", [ new SourceNode(3, 4, \"b.js\", \"uno\"), \"dos\", [ \"tres\", new SourceNode(5, 6, \"c.js\", \"quatro\") ] ]); node.toStringWithSourceMap({ file: \"my-output-file.js\" }) // { code: 'unodostresquatro', // map: [object SourceMapGenerator] }"
  },
  "node_modules/spdx-correct/README.html": {
    "href": "node_modules/spdx-correct/README.html",
    "title": "| accouter",
    "keywords": "Usage var correct = require('spdx-correct') var assert = require('assert') assert.strictEqual(correct('mit'), 'MIT') assert.strictEqual(correct('Apache 2'), 'Apache-2.0') assert(correct('No idea what license') === null) // disable upgrade option assert(correct('GPL-3.0'), 'GPL-3.0-or-later') assert(correct('GPL-3.0', { upgrade: false }), 'GPL-3.0') Contributors spdx-correct has benefited from the work of several contributors. See the GitHub repository for more information."
  },
  "node_modules/spdx-exceptions/README.html": {
    "href": "node_modules/spdx-exceptions/README.html",
    "title": "| accouter",
    "keywords": "The package exports an array of strings. Each string is an identifier for a license exception under the Software Package Data Exchange (SPDX) software license metadata standard. Copyright and Licensing SPDX \"SPDX\" is a federally registered United States trademark of The Linux Foundation Corporation. From version 2.0 of the SPDX specification: Copyright © 2010-2015 Linux Foundation and its Contributors. Licensed under the Creative Commons Attribution License 3.0 Unported. All other rights are expressly reserved. The Linux Foundation and the SPDX working groups are good people. Only they decide what \"SPDX\" means, as a standard and otherwise. I respect their work and their rights. You should, too. This Package I created this package by copying exception identifiers out of the SPDX specification. That work was mechanical, routine, and required no creativity whatsoever. - Kyle Mitchell, package author United States users concerned about intellectual property may wish to discuss the following Supreme Court decisions with their attorneys: Baker v. Selden, 101 U.S. 99 (1879) Feist Publications, Inc., v. Rural Telephone Service Co., 499 U.S. 340 (1991)"
  },
  "node_modules/spdx-expression-parse/README.html": {
    "href": "node_modules/spdx-expression-parse/README.html",
    "title": "| accouter",
    "keywords": "This package parses SPDX license expression strings describing license terms, like package.json license strings, into consistently structured ECMAScript objects. The npm command-line interface depends on this package, as do many automatic license-audit tools. In a nutshell: var parse = require('spdx-expression-parse') var assert = require('assert') assert.deepEqual( // Licensed under the terms of the Two-Clause BSD License. parse('BSD-2-Clause'), {license: 'BSD-2-Clause'} ) assert.throws(function () { // An invalid SPDX license expression. // Should be `Apache-2.0`. parse('Apache 2') }) assert.deepEqual( // Dual licensed under either: // - LGPL 2.1 // - a combination of Three-Clause BSD and MIT parse('(LGPL-2.1 OR BSD-3-Clause AND MIT)'), { left: {license: 'LGPL-2.1'}, conjunction: 'or', right: { left: {license: 'BSD-3-Clause'}, conjunction: 'and', right: {license: 'MIT'} } } ) The syntax comes from the Software Package Data eXchange (SPDX), a standard from the Linux Foundation for shareable data about software package license terms. SPDX aims to make sharing and auditing license data easy, especially for users of open-source software. The bulk of the SPDX standard describes syntax and semantics of XML metadata files. This package implements two lightweight, plain-text components of that larger standard: The license list, a mapping from specific string identifiers, like Apache-2.0, to standard form license texts and bolt-on license exceptions. The spdx-license-ids and spdx-exceptions packages implement the license list. spdx-expression-parse depends on and require()s them. Any license identifier from the license list is a valid license expression: var identifiers = [] .concat(require('spdx-license-ids')) .concat(require('spdx-license-ids/deprecated')) identifiers.forEach(function (id) { assert.deepEqual(parse(id), {license: id}) }) So is any license identifier WITH a standardized license exception: identifiers.forEach(function (id) { require('spdx-exceptions').forEach(function (e) { assert.deepEqual( parse(id + ' WITH ' + e), {license: id, exception: e} ) }) }) The license expression language, for describing simple and complex license terms, like MIT for MIT-licensed and (GPL-2.0 OR Apache-2.0) for dual-licensing under GPL 2.0 and Apache 2.0. spdx-expression-parse itself implements license expression language, exporting a parser. assert.deepEqual( // Licensed under a combination of: // - the MIT License AND // - a combination of: // - LGPL 2.1 (or a later version) AND // - Three-Clause BSD parse('(MIT AND (LGPL-2.1+ AND BSD-3-Clause))'), { left: {license: 'MIT'}, conjunction: 'and', right: { left: {license: 'LGPL-2.1', plus: true}, conjunction: 'and', right: {license: 'BSD-3-Clause'} } } ) The Linux Foundation and its contributors license the SPDX standard under the terms of the Creative Commons Attribution License 3.0 Unported (SPDX: \"CC-BY-3.0\"). \"SPDX\" is a United States federally registered trademark of the Linux Foundation. The authors of this package license their work under the terms of the MIT License."
  },
  "node_modules/spdx-license-ids/README.html": {
    "href": "node_modules/spdx-license-ids/README.html",
    "title": "spdx-license-ids | accouter",
    "keywords": "spdx-license-ids A list of SPDX license identifiers Installation Download JSON directly, or use npm: npm install spdx-license-ids Node.js API require('spdx-license-ids') Type: string[] All license IDs except for the currently deprecated ones. const ids = require('spdx-license-ids'); //=> ['0BSD', 'AAL', 'ADSL', 'AFL-1.1', 'AFL-1.2', 'AFL-2.0', 'AFL-2.1', 'AFL-3.0', 'AGPL-1.0-only', ...] ids.includes('BSD-3-Clause'); //=> true ids.includes('CC-BY-1.0'); //=> true ids.includes('GPL-3.0'); //=> false require('spdx-license-ids/deprecated') Type: string[] Deprecated license IDs. const deprecatedIds = require('spdx-license-ids/deprecated'); //=> ['AGPL-1.0', 'AGPL-3.0', 'GFDL-1.1', 'GFDL-1.2', 'GFDL-1.3', 'GPL-1.0', 'GPL-2.0', ...] deprecatedIds.includes('BSD-3-Clause'); //=> false deprecatedIds.includes('CC-BY-1.0'); //=> false deprecatedIds.includes('GPL-3.0'); //=> true License Creative Commons Zero v1.0 Universal"
  },
  "node_modules/statuses/HISTORY.html": {
    "href": "node_modules/statuses/HISTORY.html",
    "title": "1.3.1 / 2016-11-11 | accouter",
    "keywords": "1.3.1 / 2016-11-11 Fix return type in JSDoc 1.3.0 / 2016-05-17 Add 421 Misdirected Request perf: enable strict mode 1.2.1 / 2015-02-01 Fix message for status 451 451 Unavailable For Legal Reasons 1.2.0 / 2014-09-28 Add 208 Already Repored Add 226 IM Used Add 306 (Unused) Add 415 Unable For Legal Reasons Add 508 Loop Detected 1.1.1 / 2014-09-24 Add missing 308 to codes.json 1.1.0 / 2014-09-21 Add codes.json for universal support 1.0.4 / 2014-08-20 Package cleanup 1.0.3 / 2014-06-08 Add 308 to .redirect category 1.0.2 / 2014-03-13 Add .retry category 1.0.1 / 2014-03-12 Initial release"
  },
  "node_modules/statuses/README.html": {
    "href": "node_modules/statuses/README.html",
    "title": "Statuses | accouter",
    "keywords": "Statuses HTTP status utility for node. API var status = require('statuses') var code = status(Integer || String) If Integer or String is a valid HTTP code or status message, then the appropriate code will be returned. Otherwise, an error will be thrown. status(403) // => 403 status('403') // => 403 status('forbidden') // => 403 status('Forbidden') // => 403 status(306) // throws, as it's not supported by node.js status.codes Returns an array of all the status codes as Integers. var msg = status[code] Map of code to status message. undefined for invalid codes. status[404] // => 'Not Found' var code = status[msg] Map of status message to code. msg can either be title-cased or lower-cased. undefined for invalid status messages. status['not found'] // => 404 status['Not Found'] // => 404 status.redirect[code] Returns true if a status code is a valid redirect status. status.redirect[200] // => undefined status.redirect[301] // => true status.empty[code] Returns true if a status code expects an empty body. status.empty[200] // => undefined status.empty[204] // => true status.empty[304] // => true status.retry[code] Returns true if you should retry the rest. status.retry[501] // => undefined status.retry[503] // => true Adding Status Codes The status codes are primarily sourced from http://www.iana.org/assignments/http-status-codes/http-status-codes-1.csv. Additionally, custom codes are added from http://en.wikipedia.org/wiki/List_of_HTTP_status_codes. These are added manually in the lib/*.json files. If you would like to add a status code, add it to the appropriate JSON file. To rebuild codes.json, run the following: # update src/iana.json npm run fetch # build codes.json npm run build"
  },
  "node_modules/stream-throttle/README.html": {
    "href": "node_modules/stream-throttle/README.html",
    "title": "stream-throttle | accouter",
    "keywords": "stream-throttle A rate limiter for Node.js streams. API usage This module exports two classes, Throttle and ThrottleGroup. Throttle creates a single throttled stream, based on stream.Transform. It accepts an opts parameter with the following keys: opts.rate is the throttling rate, in bytes per second. opts.chunksize (optional) is the maximum chunk size into which larger writes are decomposed; the default is opts.rate/10. The opts object may also contain options to be passed to the stream.Transform constructor. For example, the following code throttles stdin to stdout at 10 bytes per second: process.stdin.pipe(new Throttle({rate: 10})).pipe(process.stdout) ThrottleGroup allows the creation of a group of streams whose aggregate bandwidth is throttled. The constructor accepts the same opts argument as for Throttle. Call throttle on a ThrottleGroup object to create a new throttled stream belonging to the group. For example, the following code creates two HTTP connections to www.google.com:80, and throttles their aggregate (downstream) bandwidth to 10 KB/s: var addr = { host: 'www.google.com', port: 80 }; var tg = new ThrottleGroup({rate: 10240}); var conn1 = net.createConnection(addr), conn2 = net.createConnection(addr); var thr1 = conn1.pipe(tg.throttle()), thr2 = conn2.pipe(tg.throttle()); // Reads from thr1 and thr2 are throttled to 10 KB/s in aggregate Command line usage This package installs a throttleproxy binary which implements a command-line utility for throttling connections. Run throttleproxy -h for instructions. Contributing Feel free to open an issue or send a pull request. License BSD-style. See the LICENSE file. Author Copyright © 2013 Tiago Quelhas. Contact me at <tiagoq@gmail.com>."
  },
  "node_modules/string-width-cjs/readme.html": {
    "href": "node_modules/string-width-cjs/readme.html",
    "title": "string-width | accouter",
    "keywords": "string-width Get the visual width of a string - the number of columns required to display it Some Unicode characters are fullwidth and use double the normal width. ANSI escape codes are stripped and doesn't affect the width. Useful to be able to measure the actual width of command-line output. Install $ npm install string-width Usage const stringWidth = require('string-width'); stringWidth('a'); //=> 1 stringWidth('古'); //=> 2 stringWidth('\\u001B[1m古\\u001B[22m'); //=> 2 Related string-width-cli - CLI for this module string-length - Get the real length of a string widest-line - Get the visual width of the widest line in a string Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "node_modules/string-width/readme.html": {
    "href": "node_modules/string-width/readme.html",
    "title": "string-width | accouter",
    "keywords": "string-width Get the visual width of a string - the number of columns required to display it Some Unicode characters are fullwidth and use double the normal width. ANSI escape codes are stripped and doesn't affect the width. Useful to be able to measure the actual width of command-line output. Install $ npm install string-width Usage const stringWidth = require('string-width'); stringWidth('a'); //=> 1 stringWidth('古'); //=> 2 stringWidth('\\u001B[1m古\\u001B[22m'); //=> 2 Related string-width-cli - CLI for this module string-length - Get the real length of a string widest-line - Get the visual width of the widest line in a string Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "node_modules/string.prototype.padend/CHANGELOG.html": {
    "href": "node_modules/string.prototype.padend/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v3.1.6 - 2024-03-21 Commits [actions] use reusable workflows 54902fb [Deps] update call-bind, define-properties, es-abstract b545f14 [Refactor] use es-object-atoms where possible eb54e52 [Dev Deps] update aud, npmignore, tape b1398f3 [Tests] use call-bind instead of function-bind 3bae558 v3.1.5 - 2023-09-04 Commits [Deps] update define-properties, es-abstract b5aa85c [Dev Deps] update @es-shims/api, @ljharb/eslint-config, aud, tape bdce52b v3.1.4 - 2022-11-07 Commits [actions] reuse common workflows 1599a3a [meta] use npmignore to autogenerate an npmignore file 626d38c [Dev Deps] update eslint, @ljharb/eslint-config, @es-shims/api, safe-publish-latest, tape 9aa073a [meta] add auto-changelog e48bc74 [Deps] update define-properties, es-abstract 7113258 [Dev Deps] update eslint, @ljharb/eslint-config, aud, functions-have-names, tape 800dfc3 [actions] update rebase action to use reusable workflow a3f9ddb [actions] update codecov uploader 6d2290f 3.1.3 / 2021-10-04 [Robustness] remove runtime .push call [readme] add github actions/codecov badges [Deps] update es-abstract [meta] use prepublishOnly script for npm 7+ [Dev Deps] update eslint, @ljharb/eslint-config, @es-shims/api, aud, tape [actions] update workflows [actions] use node/install instead of node/run; use codecov action 3.1.2 / 2021-02-20 [meta] do not publish github action workflow files [Deps] update call-bind, es-abstract [Dev Deps] update eslint, @ljharb/eslint-config, aud, functions-have-names, has-strict-mode, tape [actions] update workflows [Tests] increase coverage 3.1.1 / 2020-11-21 [Deps] update es-abstract; use call-bind where applicable [Dev Deps] update eslint, @ljharb/eslint-config, functions-have-names, tape; add aud, `safe-publish-latest [meta] gitignore nyc output [actions] add \"Allow Edits\" workflow [actions] switch Automatic Rebase workflow to pull_request_target event [Tests] migrate tests to Github Actions [Tests] run nyc on all tests [Tests] add implementation test; run es-shim-api in postlint; use tape runner 3.1.0 / 2019-12-14 [New] add auto entry point [Refactor] use split-up es-abstract (77% bundle size decrease) [readme] remove testling [readme] Stage 4 [Deps] update define-properties, es-abstract, function-bind [Dev Deps] update eslint, @ljharb/eslint-config, covert, tape, @es-shims/api; use functions-have-names [meta] add funding field [meta] Only apps should have lockfiles [Tests] use shared travis-ci configs [Tests] use npx aud instead of nsp or npm audit with hoops [Tests] remove jscs [actions] add automatic rebasing / merge commit blocking 3.0.0 / 2015-11-17 Renamed to padStart/padEnd per November 2015 TC39 meeting. 2.0.0 / 2015-09-25 Implement the es-shim API. [Tests] up to io.js v3.3, node v4.1 [Deps] update es-abstract [Dev Deps] Update tape, jscs, eslint, @ljharb/eslint-config, nsp [Refactor] Remove redundant max operation, per https://github.com/ljharb/proposal-string-pad-left-right/pull/2 1.0.0 / 2015-07-30 v1.0.0"
  },
  "node_modules/string.prototype.padend/README.html": {
    "href": "node_modules/string.prototype.padend/README.html",
    "title": "String.prototype.padEnd | accouter",
    "keywords": "String.prototype.padEnd An ES2017 spec-compliant String.prototype.padEnd shim. Invoke its \"shim\" method to shim String.prototype.padEnd if it is unavailable. This package implements the es-shim API interface. It works in an ES3-supported environment and complies with the spec. Most common usage: var padEnd = require('string.prototype.padend'); assert(padEnd('foo', 5, 'bar') === 'fooba'); padEnd.shim(); assert(padEnd('foo', 2) === 'foo'.padEnd(2)); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/string.prototype.trim/CHANGELOG.html": {
    "href": "node_modules/string.prototype.trim/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.2.9 - 2024-03-16 Commits [Refactor] use es-object-atoms; update call-bind, define-properties, es-abstract f6fe1af [Dev Deps] update aud, npmignore, tape d4e2b81 v1.2.8 - 2023-09-07 Commits [Tests] add passing test cases 2ab172c [Deps] update es-abstract 8c16598 [Dev Deps] update @es-shims/api, @ljharb/eslint-config, aud, tape 2b99fad [Dev Deps] update @ljharb/eslint-config, @ljharb/eslint-config, aud, tape 97be2b5 [Deps] update define-properties, es-abstract 1fdc65f v1.2.7 - 2022-11-07 Commits [meta] use npmignore to autogenerate an npmignore file 3e6de84 [actions] update rebase action to use reusable workflow b725a04 [Deps] update es-abstract b707a17 [Dev Deps] update aud, tape 5295419 v1.2.6 - 2022-04-24 Commits [actions] reuse common workflows dbfc093 [Fix] as of unicode v6, the mongolian vowel separator is no longer whitespace 56bbb86 [Dev Deps] update eslint, @ljharb/eslint-config, @es-shims/api, safe-publish-latest, tape 7fa437e [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, functions-have-names, tape 716a060 [actions] update codecov uploader 9a39958 [Fix] ensure main entry point properly checks the receiver in ES3 engines 24220c4 [Deps] update define-properties, es-abstract c6008ea v1.2.5 - 2021-10-03 Commits [actions] use node/install instead of node/run; use codecov action 37d5a61 [Dev Deps] update eslint, @ljharb/eslint-config, @es-shims/api, aud, auto-changelog, tape 4c4a85e [readme] add github actions/codecov badges 9980eee [Deps] update es-abstract 6c1da80 [readme] remove defunct testling badge 8d282d1 [Dev Deps] update eslint, tape 8856c26 [actions] update workflows 62cd341 [meta] use prepublishOnly script for npm 7+ abd99c4 [Deps] update es-abstract 802cb7b v1.2.4 - 2021-02-21 Commits [meta] do not publish github action workflow files 936161b [readme] remove travis badge 9a28c39 [Dev Deps] update eslint, @ljharb/eslint-config, aud, functions-have-names, has-strict-mode, tape 7b4be8d [Tests] increase coverage 31b8735 [actions] update workflows eda6ab7 [Deps] update call-bind, es-abstract 083f88f v1.2.3 - 2020-11-21 Commits [Tests] migrate tests to Github Actions 6768c8d [Tests] run nyc on all tests 2fd5baa [Deps] update es-abstract; use call-bind where applicable e4e8c6e [Dev Deps] update eslint, aud, auto-changelog a21c1d5 v1.2.2 - 2020-09-15 Commits [Tests] use nyc for coverage [0884270`](https://github.com/es-shims/String.prototype.trim/commit/0884270b26f7e6f7602d9f355dc3b4d5cd12d97e) [Tests] add implementation tests 475c480 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape d70d913 [actions] add \"Allow Edits\" workflow 6e6be23 [Refactor] use RequireObjectCoercible instead of CheckObjectCoercible 5bfaf17 [Dev Deps] update eslint, @ljharb/eslint-config, tape, functions-have-names; add safe-publish-latest 65be600 [Deps] update es-abstract, remove function-bind 5f4d1ec [Refactor] switch from 2019 to 2020 AOs 4c2d5d2 [Dev Deps] update auto-changelog, tape c7fc9e2 [Dev Deps] update auto-changelog; add aud e1dec36 [actions] switch Automatic Rebase workflow to pull_request_target event 35826c2 [Deps] update es-abstract 54095ef [Deps] update es-abstract 486dd9c v1.2.1 - 2019-12-16 Commits [Tests] use shared travis-ci configs 52f7e64 [meta] add auto-changelog 6284c06 [meta] remove unused Makefile and associated utilities 8c781cd [Dev Deps] update eslint, @ljharb/eslint-config, functions-have-names c54b481 [Refactor] use split-up es-abstract (57% bundle size decrease) b0378c9 [actions] add automatic rebasing / merge commit blocking bffe893 [meta] add funding field 0559449 [Deps] update es-abstract c44d307 v1.2.0 - 2019-07-24 Commits [Tests] up to node v12.6, v11.15, v10.16, v9.11, v8.16, v7.10, v6.17, 4.9; use nvm install-latest-npm b857148 [Tests] remove jscs ad1dea7 [Dev Deps] update eslint, @ljharb/eslint-config, covert, replace, semver, tape fcbc11d [Dev Deps] update tape, jscs, nsp, eslint, @ljharb/eslint-config 06a4ffa [Dev Deps] update jscs, nsp, eslint, @es-shims/api 3554fb1 [Dev Deps] update nsp, eslint, @ljharb/eslint-config 804b2f2 [Dev Deps] update tape, jscs, nsp, eslint, semver, @ljharb/eslint-config 6a69408 [Dev Deps] update jscs, eslint, @ljharb/eslint-config e89adee [Dev Deps] update jscs, eslint, @ljharb/eslint-config 1280e56 [New] add auto entry point bb00b15 [Tests] fix tests for the mongolian vowel separator a35f627 [Tests] up to node v5.9, v4.4 b541b9b [Dev Deps] update jscs, nsp, eslint b52022d [Tests] use pretest/posttest for linting/security 39f5684 [Tests] use npx aud instead of nsp or npm audit with hoops 8c358c2 [Tests] up to node v6.2 2ac7e1f Only apps should have lockfiles cb15ed5 [Deps] update define-properties, es-abstract, function-bind 5e0371a [Dev Deps] update eslint, @ljharb/eslint-config, @es-shims/api 37bae7f [Tests] on node v5.6, v4.3 33017cf [Tests] allow coverage to fail 0d7b1e3 [Tests] use functions-have-names 3e68777 [Tests] on node v5.12 32ea49d [Deps] update es-abstract 15f7f24 [Tests] on node v5.10 080c50f [Deps] update function-bind 532480e v1.1.2 - 2016-02-06 Commits [Dev Deps] update tape, jscs, nsp, eslint, semver, @ljharb/eslint-config df94d07 [Dev Deps] update tape, jscs, eslint, @ljharb/eslint-config ef78d89 [Dev Deps] update jscs, eslint, @ljharb/eslint-config b746516 package.json: use object form of \"authors\", add \"contributors\" a799df1 [Tests] up to node v5.5, don’t allow 0.8 to fail 7fea308 [Dev Deps] update jscs, nsp, eslint, semver, @ljharb/eslint-config d14c7c1 [Tests] up to io.js v3.3, node v4.1 2903359 [Tests] fix npm upgrades for older nodes 0a6cbfa [Deps] update define-properties, es-abstract 39ccb08 [Deps] update es-abstract c40e4fb Use the polyfill, not the implementation, as the default export. 0fe847e [Tests] on node v4.2 589743c [Deps] update es-abstract 85bad8e added assert aa81ac5 v1.1.1 - 2015-08-16 Commits [Docs] remove \"if\" around .shim call in example b9ce088 v1.1.0 - 2015-08-16 Commits Implement the es-shim API. 5812703 Move implementation to implementation.js e455b2a Fix make release efd2071 [Dev Deps] update jscs 6c2fa95 [Deps] update es-abstract de4cd87 [Dev Deps] update tape 2d07fe1 [Dev Deps] update tape e697efe Switch from vb.teelaun.ch to versionbadg.es for the npm version badge SVG. 6065103 v1.0.0 - 2015-08-08 Commits Dotfiles / Makefile b7f0e52 Tests 4d61441 package.json 2a2e0f2 Initial commit 51aa18f Read me 5681192 Implementation 87f08c5"
  },
  "node_modules/string.prototype.trim/README.html": {
    "href": "node_modules/string.prototype.trim/README.html",
    "title": "String.prototype.trim | accouter",
    "keywords": "String.prototype.trim ![npm badge][npm-badge-png] An ES5 spec-compliant String.prototype.trim shim. Invoke its \"shim\" method to shim String.prototype.trim if it is unavailable. This package implements the es-shim API interface. It works in an ES3-supported environment and complies with the spec (both ES5 and current). Most common usage: var assert = require('assert'); var trim = require('string.prototype.trim'); assert(trim(' \\t\\na \\t\\n') === 'a'); trim.shim(); // will be a no-op if not needed assert(trim(' \\t\\na \\t\\n') === ' \\t\\na \\t\\n'.trim()); Engine Bugs Some implementations of String#trim incorrectly trim zero-width spaces. This shim detects and corrects this behavior. Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/string.prototype.trimend/CHANGELOG.html": {
    "href": "node_modules/string.prototype.trimend/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.8 - 2024-03-16 Commits [Refactor] replace es-abstract with es-object-atoms 0df2b01 [Dev Deps] update aud, npmignore, tape 190e9c5 v1.0.7 - 2023-09-07 Commits [Dev Deps] update @es-shims/api, @ljharb/eslint-config, aud, tape 1a10293 [Deps] update define-properties, es-abstract 6ba2e19 v1.0.6 - 2022-11-07 Commits [meta] use npmignore to autogenerate an npmignore file 1d1e717 [actions] update rebase action to use reusable workflow 83f2683 [Dev Deps] update aud, tape a3a9129 [Deps] update es-abstract a6e476d v1.0.5 - 2022-05-02 Commits [actions] reuse common workflows 69a56ce [actions] use node/install instead of node/run; use codecov action 5d7db31 [Fix] ensure main entry point properly checks the receiver in ES3 engines bb1983d [Fix] as of unicode v6, the mongolian vowel separator is no longer whitespace 10a1091 [Dev Deps] update eslint, @ljharb/eslint-config, @es-shims/api, safe-publish-latest, tape a08e14b [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, functions-have-names, tape 1c4c8da [actions] update codecov uploader 70c4a7c [Dev Deps] update eslint, @ljharb/eslint-config, @es-shims/api, aud, auto-changelog, tape 4b08ed7 [readme] add github actions/codecov badges 9805501 [Dev Deps] update eslint, tape 50ec335 [actions] update workflows bf9c32e [meta] use prepublishOnly script for npm 7+ 9d921bd [Deps] update define-properties 15617ce v1.0.4 - 2021-02-23 Commits [meta] do not publish github action workflow files 08e735c [readme] remove travis badge 10e0e47 [Dev Deps] update eslint, @ljharb/eslint-config, functions-have-names, has-strict-mode, tape 0871432 [Tests] increase coverage 711e6a6 [actions] update workflows deb0d06 [Dev Deps] update eslint, @ljharb/eslint-config, aud, tape e250b4a [meta] gitignore coverage output 55231df [Deps] update call-bind 0580f5f v1.0.3 - 2020-11-21 Commits [Tests] migrate tests to Github Actions 23e7a09 [Tests] add implementation test; run es-shim-api in postlint; use tape runner 26e8623 [Tests] run nyc on all tests a72a546 [Deps] replace es-abstract with call-bind f07b87d [Dev Deps] update eslint, aud; add safe-publish-latest 122ecb7 v1.0.2 - 2020-10-20 Commits [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape a003e71 [actions] add \"Allow Edits\" workflow 0b4b43c [Deps] update es-abstract 75ca6b0 [actions] switch Automatic Rebase workflow to pull_request_target event 552016c v1.0.1 - 2020-04-09 Commits [meta] add some missing repo metadata 6abe248 [Dev Deps] update auto-changelog e2eaab2 v1.0.0 - 2020-03-30 Commits [Breaking] convert to es-shim API 2c6ef13 [meta] add auto-changelog 6f1fcc1 [meta] update readme ed4ce0d [Tests] add npm run lint eadaf2c Only apps should have lockfiles 44d355f [actions] add automatic rebasing / merge commit blocking e78bf8e [Tests] use shared travis-ci configs 983c563 [meta] add funding field 35139d6 [meta] fix non-updated version number a2d308b v0.1.0 - 2017-12-19 Commits updated README f1c71a0 v0.0.1 - 2017-12-19 Commits finished polyfill e58d550 created README file f78628a Initial commit 9199478 typo d1f4558"
  },
  "node_modules/string.prototype.trimend/README.html": {
    "href": "node_modules/string.prototype.trimend/README.html",
    "title": "String.prototype.trimEnd | accouter",
    "keywords": "String.prototype.trimEnd An ES2019-spec-compliant String.prototype.trimEnd shim. Invoke its \"shim\" method to shim String.prototype.trimEnd if it is unavailable. This package implements the es-shim API interface. It works in an ES3-supported environment and complies with the spec. In an ES6 environment, it will also work properly with Symbols. Most common usage: var trimEnd = require('string.prototype.trimend'); assert(trimEnd(' \\t\\na \\t\\n') === 'a \\t\\n'); if (!String.prototype.trimEnd) { trimEnd.shim(); } assert(trimEnd(' \\t\\na \\t\\n ') === ' \\t\\na \\t\\n '.trimEnd()); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/string.prototype.trimstart/CHANGELOG.html": {
    "href": "node_modules/string.prototype.trimstart/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.8 - 2024-03-21 Commits [actions] use reusable workflows d139c11 [Dev Deps] update aud, npmignore, tape 16ff815 [Deps] update call-bind, define-properties 8dd308d [Refactor] use es-object-atoms instead of es-abstract 4868f56 [meta] add missing engines.node 8c1cce6 v1.0.7 - 2023-09-04 Commits [Dev Deps] update @es-shims/api, @ljharb/eslint-config, aud, tape 58e7aa6 [Deps] update define-properties, es-abstract 8d9a7bf v1.0.6 - 2022-11-07 Commits [meta] use npmignore to autogenerate an npmignore file 0838ae4 [actions] update rebase action to use reusable workflow d6bb784 [Dev Deps] update aud, tape 8734d9a [Deps] update es-abstract 30f593f v1.0.5 - 2022-05-02 Commits [actions] reuse common workflows 61d4009 [actions] use node/install instead of node/run; use codecov action bfe39c4 [Fix] ensure main entry point properly checks the receiver in ES3 engines 36e3730 [Fix] as of unicode v6, the mongolian vowel separator is no longer whitespace 4f77eed [Dev Deps] update eslint, @ljharb/eslint-config, @es-shims/api, safe-publish-latest, tape 59fcb99 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, functions-have-names, tape 486ffcf [actions] update codecov uploader b33ac48 [Dev Deps] update eslint, @ljharb/eslint-config, @es-shims/api, aud, auto-changelog, tape 3c89fa5 [readme] add github actions/codecov badges 00be6b3 [Dev Deps] update eslint, tape 13a08f5 [actions] update workflows 6ac576d [meta] use prepublishOnly script for npm 7+ fa382ca [Deps] update define-properties d57bffe v1.0.4 - 2021-02-23 Commits [meta] do not publish github action workflow files 9c434ec [readme] remove travis badge 7843160 [Dev Deps] update eslint, @ljharb/eslint-config, functions-have-names, has-strict-mode, tape 8b52646 [Dev Deps] update eslint, @ljharb/eslint-config, aud, tape badeda2 [Tests] increase coverage bf8777d [actions] update workflows 61be1c6 [meta] gitignore coverage output c9c98d7 [Deps] update call-bind c8645e8 v1.0.3 - 2020-11-21 Commits [Tests] migrate tests to Github Actions fbc7519 [Tests] add implementation test; run es-shim-api in postlint; use tape runner 3c9330b [Tests] run nyc on all tests 52229ca [Deps] replace es-abstract with call-bind 5e5068d [Dev Deps] update eslint, aud; add safe-publish-latest 42a853e v1.0.2 - 2020-10-20 Commits [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape d032b38 [actions] add \"Allow Edits\" workflow 83e30ba [Deps] update es-abstract 707d85d [actions] switch Automatic Rebase workflow to pull_request_target event 096c6d9 v1.0.1 - 2020-04-09 Commits [meta] add some missing repo metadata 3385da3 [Dev Deps] update auto-changelog 879377d v1.0.0 - 2020-03-30 Commits [Breaking] convert to es-shim API 970922c [meta] add auto-changelog ff30c09 [meta] update readme 816291d [Tests] add npm run lint 3341104 Only apps should have lockfiles f008df7 [actions] add automatic rebasing / merge commit blocking e5ba35c [Tests] use shared travis-ci configs 46516b1 [meta] add funding field 34ae856 [meta] fix non-updated version number 3b0e262 v0.1.0 - 2017-12-19 Commits updated README ab2f6ac v0.0.1 - 2017-12-19 Commits finished polyfill 1c7ca20 created README file: 192ecad Initial commit 14044f8 updated README d4fb6be"
  },
  "node_modules/string.prototype.trimstart/README.html": {
    "href": "node_modules/string.prototype.trimstart/README.html",
    "title": "String.prototype.trimStart | accouter",
    "keywords": "String.prototype.trimStart An ES2019-spec-compliant String.prototype.trimStart shim. Invoke its \"shim\" method to shim String.prototype.trimStart if it is unavailable. This package implements the es-shim API interface. It works in an ES3-supported environment and complies with the spec. In an ES6 environment, it will also work properly with Symbols. Most common usage: var trimStart = require('string.prototype.trimstart'); assert(trimStart(' \\t\\na \\t\\n') === 'a \\t\\n'); if (!String.prototype.trimStart) { trimStart.shim(); } assert(trimStart(' \\t\\na \\t\\n') === ' \\t\\na \\t\\n'.trimStart()); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/strip-ansi-cjs/readme.html": {
    "href": "node_modules/strip-ansi-cjs/readme.html",
    "title": "strip-ansi | accouter",
    "keywords": "strip-ansi Strip ANSI escape codes from a string Install $ npm install strip-ansi Usage const stripAnsi = require('strip-ansi'); stripAnsi('\\u001B[4mUnicorn\\u001B[0m'); //=> 'Unicorn' stripAnsi('\\u001B]8;;https://github.com\\u0007Click\\u001B]8;;\\u0007'); //=> 'Click' strip-ansi for enterprise Available as part of the Tidelift Subscription. The maintainers of strip-ansi and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more. Related strip-ansi-cli - CLI for this module strip-ansi-stream - Streaming version of this module has-ansi - Check if a string has ANSI escape codes ansi-regex - Regular expression for matching ANSI escape codes chalk - Terminal string styling done right Maintainers Sindre Sorhus Josh Junon"
  },
  "node_modules/strip-ansi/readme.html": {
    "href": "node_modules/strip-ansi/readme.html",
    "title": "strip-ansi | accouter",
    "keywords": "strip-ansi Strip ANSI escape codes from a string Install $ npm install strip-ansi Usage const stripAnsi = require('strip-ansi'); stripAnsi('\\u001B[4mUnicorn\\u001B[0m'); //=> 'Unicorn' stripAnsi('\\u001B]8;;https://github.com\\u0007Click\\u001B]8;;\\u0007'); //=> 'Click' strip-ansi for enterprise Available as part of the Tidelift Subscription. The maintainers of strip-ansi and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more. Related strip-ansi-cli - CLI for this module strip-ansi-stream - Streaming version of this module has-ansi - Check if a string has ANSI escape codes ansi-regex - Regular expression for matching ANSI escape codes chalk - Terminal string styling done right Maintainers Sindre Sorhus Josh Junon"
  },
  "node_modules/strip-bom/readme.html": {
    "href": "node_modules/strip-bom/readme.html",
    "title": "strip-bom | accouter",
    "keywords": "strip-bom Strip UTF-8 byte order mark (BOM) from a string From Wikipedia: The Unicode Standard permits the BOM in UTF-8, but does not require nor recommend its use. Byte order has no meaning in UTF-8. Install $ npm install --save strip-bom Usage const stripBom = require('strip-bom'); stripBom('\\uFEFFunicorn'); //=> 'unicorn' Related strip-bom-cli - CLI for this module strip-bom-buf - Buffer version of this module strip-bom-stream - Stream version of this module License MIT © Sindre Sorhus"
  },
  "node_modules/strip-json-comments/readme.html": {
    "href": "node_modules/strip-json-comments/readme.html",
    "title": "strip-json-comments | accouter",
    "keywords": "strip-json-comments Strip comments from JSON. Lets you use comments in your JSON files! This is now possible: { // Rainbows \"unicorn\": /* ❤ */ \"cake\" } It will replace single-line comments // and multi-line comments /**/ with whitespace. This allows JSON error positions to remain as close as possible to the original source. Also available as a Gulp/Grunt/Broccoli plugin. Install $ npm install strip-json-comments Usage const json = `{ // Rainbows \"unicorn\": /* ❤ */ \"cake\" }`; JSON.parse(stripJsonComments(json)); //=> {unicorn: 'cake'} API stripJsonComments(jsonString, options?) jsonString Type: string Accepts a string with JSON and returns a string without comments. options Type: object whitespace Type: boolean Default: true Replace comments with whitespace instead of stripping them entirely. Benchmark $ npm run bench Related strip-json-comments-cli - CLI for this module strip-css-comments - Strip comments from CSS Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "node_modules/stylehacks/README.html": {
    "href": "node_modules/stylehacks/README.html",
    "title": "stylehacks | accouter",
    "keywords": "stylehacks Detect/remove browser hacks from CSS files. Install With npm do: npm install stylehacks --save Example In its default mode, stylehacks will remove hacks from your CSS file, based on the browsers that you wish to support. Input h1 { _color: white; color: rgba(255, 255, 255, 0.5); } Output h1 { color: rgba(255, 255, 255, 0.5); } API stylehacks.detect(node) Type: function Returns: boolean This method will take any PostCSS node, run applicable plugins depending on its type, then will return a boolean depending on whether it found any of the supported hacks. For example, if the decl node found below is passed to the detect function, it will return true. But if the rule node is passed, it will return false instead. h1 { _color: red } postcss([ stylehacks(opts) ]) stylehacks can also be consumed as a PostCSS plugin. See the documentation for examples for your environment. options lint Type: boolean Default: false If lint mode is enabled, stylehacks will not remove hacks from the CSS; instead, it will add warnings to Result#messages. Related stylehacks works well with your existing PostCSS setup: stylelint - Comprehensive & modern CSS linter, to ensure that your code style rules are respected. Contributing Pull requests are welcome. If you add functionality, then please add unit tests to cover it. License MIT © Ben Briggs"
  },
  "node_modules/supports-color/readme.html": {
    "href": "node_modules/supports-color/readme.html",
    "title": "supports-color | accouter",
    "keywords": "supports-color Detect whether a terminal supports color Install $ npm install supports-color Usage const supportsColor = require('supports-color'); if (supportsColor.stdout) { console.log('Terminal stdout supports color'); } if (supportsColor.stdout.has256) { console.log('Terminal stdout supports 256 colors'); } if (supportsColor.stderr.has16m) { console.log('Terminal stderr supports 16 million colors (truecolor)'); } API Returns an Object with a stdout and stderr property for testing either streams. Each property is an Object, or false if color is not supported. The stdout/stderr objects specifies a level of support for color through a .level property and a corresponding flag: .level = 1 and .hasBasic = true: Basic color support (16 colors) .level = 2 and .has256 = true: 256 color support .level = 3 and .has16m = true: Truecolor support (16 million colors) Info It obeys the --color and --no-color CLI flags. For situations where using --color is not possible, use the environment variable FORCE_COLOR=1 (level 1), FORCE_COLOR=2 (level 2), or FORCE_COLOR=3 (level 3) to forcefully enable color, or FORCE_COLOR=0 to forcefully disable. The use of FORCE_COLOR overrides all other color support checks. Explicit 256/Truecolor mode can be enabled using the --color=256 and --color=16m flags, respectively. Related supports-color-cli - CLI for this module chalk - Terminal string styling done right Maintainers Sindre Sorhus Josh Junon Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "node_modules/supports-preserve-symlinks-flag/CHANGELOG.html": {
    "href": "node_modules/supports-preserve-symlinks-flag/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.0 - 2022-01-02 Commits Tests e2f59ad Initial commit dc222aa [meta] do not publish workflow files 5ef77f7 npm init 992b068 read me 6c9afa9 Initial implementation 2f98925 [meta] add auto-changelog 6c476ae [Dev Deps] add eslint, @ljharb/eslint-config d0fffc8 Only apps should have lockfiles ab318ed [meta] add safe-publish-latest 2bb23b3 [meta] add sideEffects flag 600223b"
  },
  "node_modules/supports-preserve-symlinks-flag/README.html": {
    "href": "node_modules/supports-preserve-symlinks-flag/README.html",
    "title": "node-supports-preserve-symlinks-flag | accouter",
    "keywords": "node-supports-preserve-symlinks-flag Determine if the current node version supports the --preserve-symlinks flag. Example var supportsPreserveSymlinks = require('node-supports-preserve-symlinks-flag'); var assert = require('assert'); assert.equal(supportsPreserveSymlinks, null); // in a browser assert.equal(supportsPreserveSymlinks, false); // in node < v6.2 assert.equal(supportsPreserveSymlinks, true); // in node v6.2+ Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/svgo/README.html": {
    "href": "node_modules/svgo/README.html",
    "title": "SVGO | accouter",
    "keywords": "SVGO SVGO, short for SVG Optimizer, is a Node.js library and command-line application for optimizing SVG files. Why? SVG files, especially those exported from vector editors, usually contain a lot of redundant information. This includes editor metadata, comments, hidden elements, default or suboptimal values, and other stuff that can be safely removed or converted without impacting rendering. Installation You can install SVGO globally through npm, yarn, or pnpm. Alternatively, drop the global flag (global/-g) to use it in your Node.js project. # npm npm install -g svgo # yarn yarn global add svgo # pnpm pnpm add -g svgo Command-line usage Process single files: svgo one.svg two.svg -o one.min.svg two.min.svg Process a directory of files recursively with -f/--folder: svgo -f path/to/directory_with_svgs -o path/to/output_directory Help for advanced usage: svgo --help Configuration SVGO has a plugin architecture. You can read more about all plugins in Plugins | SVGO Documentation, and the default plugins in Preset Default | SVGO Documentation. SVGO reads the configuration from svgo.config.js or the --config path/to/config.js command-line option. Some other parameters can be configured though command-line options too. svgo.config.js module.exports = { multipass: false, // boolean datauri: 'base64', // 'base64'|'enc'|'unenc' js2svg: { indent: 4, // number pretty: false, // boolean }, plugins: [ 'preset-default', // built-in plugins enabled by default 'prefixIds', // enable built-in plugins by name // enable built-in plugins with an object to configure plugins { name: 'prefixIds', params: { prefix: 'uwu', }, }, ], }; Default preset Instead of configuring SVGO from scratch, you can tweak the default preset to suit your needs by configuring or disabling the respective plugin. svgo.config.js module.exports = { plugins: [ { name: 'preset-default', params: { overrides: { // disable a default plugin removeViewBox: false, // customize the params of a default plugin inlineStyles: { onlyMatchedOnce: false, }, }, }, }, ], }; You can find a list of the default plugins in the order they run in Preset Default | SVGO Documentation. Custom plugins You can also specify custom plugins: svgo.config.js const importedPlugin = require('./imported-plugin'); module.exports = { plugins: [ // plugin imported from another JavaScript file importedPlugin, // plugin defined inline { name: 'customPlugin', params: { paramName: 'paramValue', }, fn: (ast, params, info) => {}, }, ], }; API usage SVGO provides a few low level utilities. optimize The core of SVGO is optimize function. const { optimize } = require('svgo'); const result = optimize(svgString, { path: 'path-to.svg', // recommended multipass: true, // all other config fields are available here }); const optimizedSvgString = result.data; loadConfig If you write a tool on top of SVGO you may want to resolve the svgo.config.js file. const { loadConfig } = require('svgo'); const config = await loadConfig(); You can also specify a path and customize the current working directory. const config = await loadConfig(configFile, cwd); Other ways to use SVGO Method Reference Web app SVGOMG Grunt task grunt-svgmin Gulp task gulp-svgmin Webpack loader image-minimizer-webpack-plugin PostCSS plugin postcss-svgo Inkscape plugin inkscape-svgo Sketch plugin svgo-compressor Rollup plugin rollup-plugin-svgo Visual Studio Code plugin vscode-svgo Atom plugin atom-svgo Sublime plugin Sublime-svgo Figma plugin Advanced SVG Export Linux app Oh My SVG Browser extension SVG Gobbler API Vector Express Donors SheetJS LLC Fontello License and Copyright This software is released under the terms of the MIT license. Logo by André Castillo."
  },
  "node_modules/svgo/node_modules/commander/CHANGELOG.html": {
    "href": "node_modules/svgo/node_modules/commander/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. (Format adopted after v3.0.0.) 7.2.0 (2021-03-26) Added TypeScript typing for parent property on Command (#1475) TypeScript typing for .attributeName() on Option (#1483) support information in package (#1477) Changed improvements to error messages, README, and tests update dependencies 7.1.0 (2021-02-15) Added support for named imports from ECMAScript modules (#1440) add .cjs to list of expected script file extensions (#1449) allow using option choices and variadic together (#1454) Fixed replace use of deprecated process.mainModule (#1448) regression for legacy command('*') and call when command line includes options (#1464) regression for on('command:*', ...) and call when command line includes unknown options (#1464) display best error for combination of unknown command and unknown option (i.e. unknown command) (#1464) Changed make TypeScript typings tests stricter (#1453) improvements to README and tests 7.0.0 (2021-01-15) Added .enablePositionalOptions() to let program and subcommand reuse same option (#1427) .passThroughOptions() to pass options through to other programs without needing -- (#1427) .allowExcessArguments(false) to show an error message if there are too many command-arguments on command line for the action handler (#1409) .configureOutput() to modify use of stdout and stderr or customise display of errors (#1387) use .addHelpText() to add text before or after the built-in help, for just current command or also for all subcommands (#1296) enhance Option class (#1331) allow hiding options from help allow restricting option arguments to a list of choices allow setting how default value is shown in help .createOption() to support subclassing of automatically created options (like .createCommand()) (#1380) refactor the code generating the help into a separate public Help class (#1365) support sorting subcommands and options in help support specifying wrap width (columns) allow subclassing Help class allow configuring Help class without subclassing Changed Breaking: options are stored safely by default, not as properties on the command (#1409) this especially affects accessing options on program, use program.opts() revert behaviour with .storeOptionsAsProperties() Breaking: action handlers are passed options and command separately (#1409) deprecated callback parameter to .help() and .outputHelp() (removed from README) (#1296) Breaking: errors now displayed using process.stderr.write() instead of console.error() deprecate .on('--help') (removed from README) (#1296) initialise the command description to empty string (previously undefined) (#1365) document and annotate deprecated routines (#1349) Fixed wrapping bugs in help (#1365) first line of command description was wrapping two characters early pad width calculation was not including help option and help command pad width calculation was including hidden options and commands improve backwards compatibility for custom command event listeners (#1403) Deleted Breaking: .passCommandToAction() (#1409) no longer needed as action handler is passed options and command Breaking: \"extra arguments\" parameter to action handler (#1409) if being used to detect excess arguments, there is now an error available by setting .allowExcessArguments(false) Migration Tips The biggest change is the parsed option values. Previously the options were stored by default as properties on the command object, and now the options are stored separately. If you wish to restore the old behaviour and get running quickly you can call .storeOptionsAsProperties(). To allow you to move to the new code patterns incrementally, the action handler will be passed the command twice, to match the new \"options\" and \"command\" parameters (see below). program options Use the .opts() method to access the options. This is available on any command but is used most with the program. program.option('-d, --debug'); program.parse(); // Old code before Commander 7 if (program.debug) console.log(`Program name is ${program.name()}`); // New code const options = program.opts(); if (options.debug) console.log(`Program name is ${program.name()}`); action handler The action handler gets passed a parameter for each command-argument you declared. Previously by default the next parameter was the command object with the options as properties. Now the next two parameters are instead the options and the command. If you only accessed the options there may be no code changes required. program .command('compress <filename>') .option('-t, --trace') // Old code before Commander 7 .action((filename, cmd)) => { if (cmd.trace) console.log(`Command name is ${cmd.name()}`); }); // New code .action((filename, options, command)) => { if (options.trace) console.log(`Command name is ${command.name()}`); }); If you already set .storeOptionsAsProperties(false) you may still need to adjust your code. program .command('compress <filename>') .storeOptionsAsProperties(false) .option('-t, --trace') // Old code before Commander 7 .action((filename, command)) => { if (command.opts().trace) console.log(`Command name is ${command.name()}`); }); // New code .action((filename, options, command)) => { if (command.opts().trace) console.log(`Command name is ${command.name()}`); }); 7.0.0-2 (2020-12-14) (Released in 7.0.0) 7.0.0-1 (2020-11-21) (Released in 7.0.0) 7.0.0-0 (2020-10-25) (Released in 7.0.0) 6.2.1 (2020-12-13) Fixed some tests failed if directory path included a space ([1390]) 6.2.0 (2020-10-25) Added added 'tsx' file extension for stand-alone executable subcommands (#1368) documented second parameter to .description() to describe command arguments (#1353) documentation of special cases with options taking varying numbers of option-arguments (#1332) documentation for terminology (#1361) Fixed add missing TypeScript definition for `.addHelpCommand()' (#1375) removed blank line after \"Arguments:\" in help, to match \"Options:\" and \"Commands:\" (#1360) Changed update dependencies 6.1.0 (2020-08-28) Added include URL to relevant section of README for error for potential conflict between Command properties and option values (#1306) .combineFlagAndOptionalValue(false) to ease upgrade path from older versions of Commander (#1326) allow disabling the built-in help option using .helpOption(false) (#1325) allow just some arguments in argumentDescription to .description() (#1323) Changed tidy async test and remove lint override (#1312) Fixed executable subcommand launching when script path not known (#1322) 6.0.0 (2020-07-21) Added add support for variadic options (#1250) allow options to be added with just a short flag (#1256) Breaking the option property has same case as flag. e.g. flag -n accessed as opts().n (previously uppercase) Breaking throw an error if there might be a clash between option name and a Command property, with advice on how to resolve (#1275) Fixed Options which contain -no- in the middle of the option flag should not be treated as negatable. (#1301) 6.0.0-0 (2020-06-20) (Released in 6.0.0) 5.1.0 (2020-04-25) Added support for multiple command aliases, the first of which is shown in the auto-generated help (#531, #1236) configuration support in addCommand() for hidden and isDefault (#1232) Fixed omit masked help flags from the displayed help (#645, #1247) remove old short help flag when change help flags using helpOption (#1248) Changed remove use of arguments to improve auto-generated help in editors (#1235) rename .command() configuration noHelp to hidden (but not remove old support) (#1232) improvements to documentation update dependencies update tested versions of node eliminate lint errors in TypeScript (#1208) 5.0.0 (2020-03-14) Added support for nested commands with action-handlers (#1 #764 #1149) .addCommand() for adding a separately configured command (#764 #1149) allow a non-executable to be set as the default command (#742 #1149) implicit help command when there are subcommands (previously only if executables) (#1149) customise implicit help command with .addHelpCommand() (#1149) display error message for unknown subcommand, by default (#432 #1088 #1149) display help for missing subcommand, by default (#1088 #1149) combined short options as single argument may include boolean flags and value flag and value (e.g. -a -b -p 80 can be written as -abp80) (#1145) .parseOption() includes short flag and long flag expansions (#1145) .helpInformation() returns help text as a string, previously a private routine (#1169) .parse() implicitly uses process.argv if arguments not specified (#1172) optionally specify where .parse() arguments \"from\", if not following node conventions (#512 #1172) suggest help option along with unknown command error (#1179) TypeScript definition for commands property of Command (#1184) export program property (#1195) createCommand factory method to simplify subclassing (#1191) Fixed preserve argument order in subcommands (#508 #962 #1138) do not emit command:* for executable subcommands (#809 #1149) action handler called whether or not there are non-option arguments (#1062 #1149) combining option short flag and value in single argument now works for subcommands (#1145) only add implicit help command when it will not conflict with other uses of argument (#1153 #1149) implicit help command works with command aliases (#948 #1149) options are validated whether or not there is an action handler (#1149) Changed Breaking .args contains command arguments with just recognised options removed (#1032 #1138) Breaking display error if required argument for command is missing (#995 #1149) tighten TypeScript definition of custom option processing function passed to .option() (#1119) Breaking .allowUnknownOption() (#802 #1138) unknown options included in arguments passed to command action handler unknown options included in .args only recognised option short flags and long flags are expanded (e.g. -ab or --foo=bar) (#1145) Breaking .parseOptions() (#1138) args in returned result renamed operands and does not include anything after first unknown option unknown in returned result has arguments after first unknown option including operands, not just options and values Breaking .on('command:*', callback) and other command events passed (changed) results from .parseOptions, i.e. operands and unknown (#1138) refactor Option from prototype to class (#1133) refactor Command from prototype to class (#1159) changes to error handling (#1165) throw for author error, not just display message preflight for variadic error add tips to missing subcommand executable TypeScript fluent return types changed to be more subclass friendly, return this rather than Command (#1180) .parseAsync returns Promise<this> to be consistent with .parse() (#1180) update dependencies Removed removed EventEmitter from TypeScript definition for Command, eliminating implicit peer dependency on @types/node (#1146) removed private function normalize (the functionality has been integrated into parseOptions) (#1145) parseExpectedArgs is now private (#1149) Migration Tips If you use .on('command:*') or more complicated tests to detect an unrecognised subcommand, you may be able to delete the code and rely on the default behaviour. If you use program.args or more complicated tests to detect a missing subcommand, you may be able to delete the code and rely on the default behaviour. If you use .command('*') to add a default command, you may be be able to switch to isDefault:true with a named command. If you want to continue combining short options with optional values as though they were boolean flags, set combineFlagAndOptionalValue(false) to expand -fb to -f -b rather than -f b. 5.0.0-4 (2020-03-03) (Released in 5.0.0) 5.0.0-3 (2020-02-20) (Released in 5.0.0) 5.0.0-2 (2020-02-10) (Released in 5.0.0) 5.0.0-1 (2020-02-08) (Released in 5.0.0) 5.0.0-0 (2020-02-02) (Released in 5.0.0) Older versions 4.x 3.x 2.x 1.x 0.x"
  },
  "node_modules/svgo/node_modules/commander/Readme.html": {
    "href": "node_modules/svgo/node_modules/commander/Readme.html",
    "title": "Commander.js | accouter",
    "keywords": "Commander.js The complete solution for node.js command-line interfaces. Read this in other languages: English | 简体中文 Commander.js Installation Declaring program variable Options Common option types, boolean and value Default option value Other option types, negatable boolean and boolean|value Required option Variadic option Version option More configuration Custom option processing Commands Specify the argument syntax Action handler Stand-alone executable (sub)commands Automated help Custom help Display help from code .usage and .name .helpOption(flags, description) .addHelpCommand() More configuration Custom event listeners Bits and pieces .parse() and .parseAsync() Parsing Configuration Legacy options as properties TypeScript createCommand() Node options such as --harmony Debugging stand-alone executable subcommands Override exit and output handling Additional documentation Examples Support Commander for enterprise For information about terms used in this document see: terminology Installation npm install commander Declaring program variable Commander exports a global object which is convenient for quick programs. This is used in the examples in this README for brevity. const { program } = require('commander'); program.version('0.0.1'); For larger programs which may use commander in multiple ways, including unit testing, it is better to create a local Command object to use. const { Command } = require('commander'); const program = new Command(); program.version('0.0.1'); For named imports in ECMAScript modules, import from commander/esm.mjs. // index.mjs import { Command } from 'commander/esm.mjs'; const program = new Command(); And in TypeScript: // index.ts import { Command } from 'commander'; const program = new Command(); Options Options are defined with the .option() method, also serving as documentation for the options. Each option can have a short flag (single character) and a long name, separated by a comma or space or vertical bar ('|'). The parsed options can be accessed by calling .opts() on a Command object, and are passed to the action handler. Multi-word options such as \"--template-engine\" are camel-cased, becoming program.opts().templateEngine etc. Multiple short flags may optionally be combined in a single argument following the dash: boolean flags, followed by a single option taking a value (possibly followed by the value). For example -a -b -p 80 may be written as -ab -p80 or even -abp80. You can use -- to indicate the end of the options, and any remaining arguments will be used without being interpreted. By default options on the command line are not positional, and can be specified before or after other arguments. Common option types, boolean and value The two most used option types are a boolean option, and an option which takes its value from the following argument (declared with angle brackets like --expect <value>). Both are undefined unless specified on command line. Example file: options-common.js program .option('-d, --debug', 'output extra debugging') .option('-s, --small', 'small pizza size') .option('-p, --pizza-type <type>', 'flavour of pizza'); program.parse(process.argv); const options = program.opts(); if (options.debug) console.log(options); console.log('pizza details:'); if (options.small) console.log('- small pizza size'); if (options.pizzaType) console.log(`- ${options.pizzaType}`); $ pizza-options -d { debug: true, small: undefined, pizzaType: undefined } pizza details: $ pizza-options -p error: option '-p, --pizza-type <type>' argument missing $ pizza-options -ds -p vegetarian { debug: true, small: true, pizzaType: 'vegetarian' } pizza details: - small pizza size - vegetarian $ pizza-options --pizza-type=cheese pizza details: - cheese program.parse(arguments) processes the arguments, leaving any args not consumed by the program options in the program.args array. The parameter is optional and defaults to process.argv. Default option value You can specify a default value for an option which takes a value. Example file: options-defaults.js program .option('-c, --cheese <type>', 'add the specified type of cheese', 'blue'); program.parse(); console.log(`cheese: ${program.opts().cheese}`); $ pizza-options cheese: blue $ pizza-options --cheese stilton cheese: stilton Other option types, negatable boolean and boolean|value You can define a boolean option long name with a leading no- to set the option value to false when used. Defined alone this also makes the option true by default. If you define --foo first, adding --no-foo does not change the default value from what it would otherwise be. You can specify a default boolean value for a boolean option and it can be overridden on command line. Example file: options-negatable.js program .option('--no-sauce', 'Remove sauce') .option('--cheese <flavour>', 'cheese flavour', 'mozzarella') .option('--no-cheese', 'plain with no cheese') .parse(); const options = program.opts(); const sauceStr = options.sauce ? 'sauce' : 'no sauce'; const cheeseStr = (options.cheese === false) ? 'no cheese' : `${options.cheese} cheese`; console.log(`You ordered a pizza with ${sauceStr} and ${cheeseStr}`); $ pizza-options You ordered a pizza with sauce and mozzarella cheese $ pizza-options --sauce error: unknown option '--sauce' $ pizza-options --cheese=blue You ordered a pizza with sauce and blue cheese $ pizza-options --no-sauce --no-cheese You ordered a pizza with no sauce and no cheese You can specify an option which may be used as a boolean option but may optionally take an option-argument (declared with square brackets like --optional [value]). Example file: options-boolean-or-value.js program .option('-c, --cheese [type]', 'Add cheese with optional type'); program.parse(process.argv); const options = program.opts(); if (options.cheese === undefined) console.log('no cheese'); else if (options.cheese === true) console.log('add cheese'); else console.log(`add cheese type ${options.cheese}`); $ pizza-options no cheese $ pizza-options --cheese add cheese $ pizza-options --cheese mozzarella add cheese type mozzarella For information about possible ambiguous cases, see options taking varying arguments. Required option You may specify a required (mandatory) option using .requiredOption. The option must have a value after parsing, usually specified on the command line, or perhaps from a default value (say from environment). The method is otherwise the same as .option in format, taking flags and description, and optional default value or custom processing. Example file: options-required.js program .requiredOption('-c, --cheese <type>', 'pizza must have cheese'); program.parse(); $ pizza error: required option '-c, --cheese <type>' not specified Variadic option You may make an option variadic by appending ... to the value placeholder when declaring the option. On the command line you can then specify multiple option-arguments, and the parsed option value will be an array. The extra arguments are read until the first argument starting with a dash. The special argument -- stops option processing entirely. If a value is specified in the same argument as the option then no further values are read. Example file: options-variadic.js program .option('-n, --number <numbers...>', 'specify numbers') .option('-l, --letter [letters...]', 'specify letters'); program.parse(); console.log('Options: ', program.opts()); console.log('Remaining arguments: ', program.args); $ collect -n 1 2 3 --letter a b c Options: { number: [ '1', '2', '3' ], letter: [ 'a', 'b', 'c' ] } Remaining arguments: [] $ collect --letter=A -n80 operand Options: { number: [ '80' ], letter: [ 'A' ] } Remaining arguments: [ 'operand' ] $ collect --letter -n 1 -n 2 3 -- operand Options: { number: [ '1', '2', '3' ], letter: true } Remaining arguments: [ 'operand' ] For information about possible ambiguous cases, see options taking varying arguments. Version option The optional version method adds handling for displaying the command version. The default option flags are -V and --version, and when present the command prints the version number and exits. program.version('0.0.1'); $ ./examples/pizza -V 0.0.1 You may change the flags and description by passing additional parameters to the version method, using the same syntax for flags as the option method. program.version('0.0.1', '-v, --vers', 'output the current version'); More configuration You can add most options using the .option() method, but there are some additional features available by constructing an Option explicitly for less common cases. Example file: options-extra.js program .addOption(new Option('-s, --secret').hideHelp()) .addOption(new Option('-t, --timeout <delay>', 'timeout in seconds').default(60, 'one minute')) .addOption(new Option('-d, --drink <size>', 'drink size').choices(['small', 'medium', 'large'])); $ extra --help Usage: help [options] Options: -t, --timeout <delay> timeout in seconds (default: one minute) -d, --drink <size> drink cup size (choices: \"small\", \"medium\", \"large\") -h, --help display help for command $ extra --drink huge error: option '-d, --drink <size>' argument 'huge' is invalid. Allowed choices are small, medium, large. Custom option processing You may specify a function to do custom processing of option-arguments. The callback function receives two parameters, the user specified option-argument and the previous value for the option. It returns the new value for the option. This allows you to coerce the option-argument to the desired type, or accumulate values, or do entirely custom processing. You can optionally specify the default/starting value for the option after the function parameter. Example file: options-custom-processing.js function myParseInt(value, dummyPrevious) { // parseInt takes a string and a radix const parsedValue = parseInt(value, 10); if (isNaN(parsedValue)) { throw new commander.InvalidOptionArgumentError('Not a number.'); } return parsedValue; } function increaseVerbosity(dummyValue, previous) { return previous + 1; } function collect(value, previous) { return previous.concat([value]); } function commaSeparatedList(value, dummyPrevious) { return value.split(','); } program .option('-f, --float <number>', 'float argument', parseFloat) .option('-i, --integer <number>', 'integer argument', myParseInt) .option('-v, --verbose', 'verbosity that can be increased', increaseVerbosity, 0) .option('-c, --collect <value>', 'repeatable value', collect, []) .option('-l, --list <items>', 'comma separated list', commaSeparatedList) ; program.parse(); const options = program.opts(); if (options.float !== undefined) console.log(`float: ${options.float}`); if (options.integer !== undefined) console.log(`integer: ${options.integer}`); if (options.verbose > 0) console.log(`verbosity: ${options.verbose}`); if (options.collect.length > 0) console.log(options.collect); if (options.list !== undefined) console.log(options.list); $ custom -f 1e2 float: 100 $ custom --integer 2 integer: 2 $ custom -v -v -v verbose: 3 $ custom -c a -c b -c c [ 'a', 'b', 'c' ] $ custom --list x,y,z [ 'x', 'y', 'z' ] Commands You can specify (sub)commands using .command() or .addCommand(). There are two ways these can be implemented: using an action handler attached to the command, or as a stand-alone executable file (described in more detail later). The subcommands may be nested (example). In the first parameter to .command() you specify the command name and any command-arguments. The arguments may be <required> or [optional], and the last argument may also be variadic.... You can use .addCommand() to add an already configured subcommand to the program. For example: // Command implemented using action handler (description is supplied separately to `.command`) // Returns new command for configuring. program .command('clone <source> [destination]') .description('clone a repository into a newly created directory') .action((source, destination) => { console.log('clone command called'); }); // Command implemented using stand-alone executable file (description is second parameter to `.command`) // Returns `this` for adding more commands. program .command('start <service>', 'start named service') .command('stop [service]', 'stop named service, or all if no name supplied'); // Command prepared separately. // Returns `this` for adding more commands. program .addCommand(build.makeBuildCommand()); Configuration options can be passed with the call to .command() and .addCommand(). Specifying hidden: true will remove the command from the generated help output. Specifying isDefault: true will run the subcommand if no other subcommand is specified (example). Specify the argument syntax You use .arguments to specify the expected command-arguments for the top-level command, and for subcommands they are usually included in the .command call. Angled brackets (e.g. <required>) indicate required command-arguments. Square brackets (e.g. [optional]) indicate optional command-arguments. You can optionally describe the arguments in the help by supplying a hash as second parameter to .description(). Example file: arguments.js program .version('0.1.0') .arguments('<username> [password]') .description('test command', { username: 'user to login', password: 'password for user, if required' }) .action((username, password) => { console.log('username:', username); console.log('environment:', password || 'no password given'); }); The last argument of a command can be variadic, and only the last argument. To make an argument variadic you append ... to the argument name. For example: program .version('0.1.0') .command('rmdir <dirs...>') .action(function (dirs) { dirs.forEach((dir) => { console.log('rmdir %s', dir); }); }); The variadic argument is passed to the action handler as an array. Action handler The action handler gets passed a parameter for each command-argument you declared, and two additional parameters which are the parsed options and the command object itself. Example file: thank.js program .arguments('<name>') .option('-t, --title <honorific>', 'title to use before name') .option('-d, --debug', 'display some debugging') .action((name, options, command) => { if (options.debug) { console.error('Called %s with options %o', command.name(), options); } const title = options.title ? `${options.title} ` : ''; console.log(`Thank-you ${title}${name}`); }); You may supply an async action handler, in which case you call .parseAsync rather than .parse. async function run() { /* code goes here */ } async function main() { program .command('run') .action(run); await program.parseAsync(process.argv); } A command's options and arguments on the command line are validated when the command is used. Any unknown options or missing arguments will be reported as an error. You can suppress the unknown option checks with .allowUnknownOption(). By default it is not an error to pass more arguments than declared, but you can make this an error with .allowExcessArguments(false). Stand-alone executable (sub)commands When .command() is invoked with a description argument, this tells Commander that you're going to use stand-alone executables for subcommands. Commander will search the executables in the directory of the entry script (like ./examples/pm) with the name program-subcommand, like pm-install, pm-search. You can specify a custom name with the executableFile configuration option. You handle the options for an executable (sub)command in the executable, and don't declare them at the top-level. Example file: pm program .version('0.1.0') .command('install [name]', 'install one or more packages') .command('search [query]', 'search with optional query') .command('update', 'update installed packages', { executableFile: 'myUpdateSubCommand' }) .command('list', 'list packages installed', { isDefault: true }); program.parse(process.argv); If the program is designed to be installed globally, make sure the executables have proper modes, like 755. Automated help The help information is auto-generated based on the information commander already knows about your program. The default help option is -h,--help. Example file: pizza $ node ./examples/pizza --help Usage: pizza [options] An application for pizza ordering Options: -p, --peppers Add peppers -c, --cheese <type> Add the specified type of cheese (default: \"marble\") -C, --no-cheese You do not want any cheese -h, --help display help for command A help command is added by default if your command has subcommands. It can be used alone, or with a subcommand name to show further help for the subcommand. These are effectively the same if the shell program has implicit help: shell help shell --help shell help spawn shell spawn --help Custom help You can add extra text to be displayed along with the built-in help. Example file: custom-help program .option('-f, --foo', 'enable some foo'); program.addHelpText('after', ` Example call: $ custom-help --help`); Yields the following help output: Usage: custom-help [options] Options: -f, --foo enable some foo -h, --help display help for command Example call: $ custom-help --help The positions in order displayed are: beforeAll: add to the program for a global banner or header before: display extra information before built-in help after: display extra information after built-in help afterAll: add to the program for a global footer (epilog) The positions \"beforeAll\" and \"afterAll\" apply to the command and all its subcommands. The second parameter can be a string, or a function returning a string. The function is passed a context object for your convenience. The properties are: error: a boolean for whether the help is being displayed due to a usage error command: the Command which is displaying the help Display help from code .help(): display help information and exit immediately. You can optionally pass { error: true } to display on stderr and exit with an error status. .outputHelp(): output help information without exiting. You can optionally pass { error: true } to display on stderr. .helpInformation(): get the built-in command help information as a string for processing or displaying yourself. .usage and .name These allow you to customise the usage description in the first line of the help. The name is otherwise deduced from the (full) program arguments. Given: program .name(\"my-command\") .usage(\"[global options] command\") The help will start with: Usage: my-command [global options] command .helpOption(flags, description) By default every command has a help option. Override the default help flags and description. Pass false to disable the built-in help option. program .helpOption('-e, --HELP', 'read more information'); .addHelpCommand() A help command is added by default if your command has subcommands. You can explicitly turn on or off the implicit help command with .addHelpCommand() and .addHelpCommand(false). You can both turn on and customise the help command by supplying the name and description: program.addHelpCommand('assist [command]', 'show assistance'); More configuration The built-in help is formatted using the Help class. You can configure the Help behaviour by modifying data properties and methods using .configureHelp(), or by subclassing using .createHelp() if you prefer. The data properties are: helpWidth: specify the wrap width, useful for unit tests sortSubcommands: sort the subcommands alphabetically sortOptions: sort the options alphabetically There are methods getting the visible lists of arguments, options, and subcommands. There are methods for formatting the items in the lists, with each item having a term and description. Take a look at .formatHelp() to see how they are used. Example file: configure-help.js program.configureHelp({ sortSubcommands: true, subcommandTerm: (cmd) => cmd.name() // Just show the name, instead of short usage. }); Custom event listeners You can execute custom actions by listening to command and option events. program.on('option:verbose', function () { process.env.VERBOSE = this.opts().verbose; }); program.on('command:*', function (operands) { console.error(`error: unknown command '${operands[0]}'`); const availableCommands = program.commands.map(cmd => cmd.name()); mySuggestBestMatch(operands[0], availableCommands); process.exitCode = 1; }); Bits and pieces .parse() and .parseAsync() The first argument to .parse is the array of strings to parse. You may omit the parameter to implicitly use process.argv. If the arguments follow different conventions than node you can pass a from option in the second parameter: 'node': default, argv[0] is the application and argv[1] is the script being run, with user parameters after that 'electron': argv[1] varies depending on whether the electron application is packaged 'user': all of the arguments from the user For example: program.parse(process.argv); // Explicit, node conventions program.parse(); // Implicit, and auto-detect electron program.parse(['-f', 'filename'], { from: 'user' }); Parsing Configuration If the default parsing does not suit your needs, there are some behaviours to support other usage patterns. By default program options are recognised before and after subcommands. To only look for program options before subcommands, use .enablePositionalOptions(). This lets you use an option for a different purpose in subcommands. Example file: positional-options.js With positional options, the -b is a program option in the first line and a subcommand option in the second line: program -b subcommand program subcommand -b By default options are recognised before and after command-arguments. To only process options that come before the command-arguments, use .passThroughOptions(). This lets you pass the arguments and following options through to another program without needing to use -- to end the option processing. To use pass through options in a subcommand, the program needs to enable positional options. Example file: pass-through-options.js With pass through options, the --port=80 is a program option in the first line and passed through as a command-argument in the second line: program --port=80 arg program arg --port=80 By default the option processing shows an error for an unknown option. To have an unknown option treated as an ordinary command-argument and continue looking for options, use .allowUnknownOption(). This lets you mix known and unknown options. By default the argument processing does not display an error for more command-arguments than expected. To display an error for excess arguments, use.allowExcessArguments(false). Legacy options as properties Before Commander 7, the option values were stored as properties on the command. This was convenient to code but the downside was possible clashes with existing properties of Command. You can revert to the old behaviour to run unmodified legacy code by using .storeOptionsAsProperties(). program .storeOptionsAsProperties() .option('-d, --debug') .action((commandAndOptions) => { if (commandAndOptions.debug) { console.error(`Called ${commandAndOptions.name()}`); } }); TypeScript If you use ts-node and stand-alone executable subcommands written as .ts files, you need to call your program through node to get the subcommands called correctly. e.g. node -r ts-node/register pm.ts createCommand() This factory function creates a new command. It is exported and may be used instead of using new, like: const { createCommand } = require('commander'); const program = createCommand(); createCommand is also a method of the Command object, and creates a new command rather than a subcommand. This gets used internally when creating subcommands using .command(), and you may override it to customise the new subcommand (example file custom-command-class.js). Node options such as --harmony You can enable --harmony option in two ways: Use #! /usr/bin/env node --harmony in the subcommands scripts. (Note Windows does not support this pattern.) Use the --harmony option when call the command, like node --harmony examples/pm publish. The --harmony option will be preserved when spawning subcommand process. Debugging stand-alone executable subcommands An executable subcommand is launched as a separate child process. If you are using the node inspector for debugging executable subcommands using node --inspect et al, the inspector port is incremented by 1 for the spawned subcommand. If you are using VSCode to debug executable subcommands you need to set the \"autoAttachChildProcesses\": true flag in your launch.json configuration. Override exit and output handling By default Commander calls process.exit when it detects errors, or after displaying the help or version. You can override this behaviour and optionally supply a callback. The default override throws a CommanderError. The override callback is passed a CommanderError with properties exitCode number, code string, and message. The default override behaviour is to throw the error, except for async handling of executable subcommand completion which carries on. The normal display of error messages or version or help is not affected by the override which is called after the display. program.exitOverride(); try { program.parse(process.argv); } catch (err) { // custom processing... } By default Commander is configured for a command-line application and writes to stdout and stderr. You can modify this behaviour for custom applications. In addition, you can modify the display of error messages. Example file: configure-output.js function errorColor(str) { // Add ANSI escape codes to display text in red. return `\\x1b[31m${str}\\x1b[0m`; } program .configureOutput({ // Visibly override write routines as example! writeOut: (str) => process.stdout.write(`[OUT] ${str}`), writeErr: (str) => process.stdout.write(`[ERR] ${str}`), // Highlight errors in color. outputError: (str, write) => write(errorColor(str)) }); Additional documentation There is more information available about: deprecated features still supported for backwards compatibility options taking varying arguments Examples In a single command program, you might not need an action handler. Example file: pizza const { program } = require('commander'); program .description('An application for pizza ordering') .option('-p, --peppers', 'Add peppers') .option('-c, --cheese <type>', 'Add the specified type of cheese', 'marble') .option('-C, --no-cheese', 'You do not want any cheese'); program.parse(); const options = program.opts(); console.log('you ordered a pizza with:'); if (options.peppers) console.log(' - peppers'); const cheese = !options.cheese ? 'no' : options.cheese; console.log(' - %s cheese', cheese); In a multi-command program, you will have action handlers for each command (or stand-alone executables for the commands). Example file: deploy const { Command } = require('commander'); const program = new Command(); program .version('0.0.1') .option('-c, --config <path>', 'set config path', './deploy.conf'); program .command('setup [env]') .description('run setup commands for all envs') .option('-s, --setup_mode <mode>', 'Which setup mode to use', 'normal') .action((env, options) => { env = env || 'all'; console.log('read config from %s', program.opts().config); console.log('setup for %s env(s) with %s mode', env, options.setup_mode); }); program .command('exec <script>') .alias('ex') .description('execute the given remote cmd') .option('-e, --exec_mode <mode>', 'Which exec mode to use', 'fast') .action((script, options) => { console.log('read config from %s', program.opts().config); console.log('exec \"%s\" using %s mode and config %s', script, options.exec_mode, program.opts().config); }).addHelpText('after', ` Examples: $ deploy exec sequential $ deploy exec async` ); program.parse(process.argv); More samples can be found in the examples directory. Support The current version of Commander is fully supported on Long Term Support versions of node, and requires at least node v10. (For older versions of node, use an older version of Commander. Commander version 2.x has the widest support.) The main forum for free and community support is the project Issues on GitHub. Commander for enterprise Available as part of the Tidelift Subscription The maintainers of Commander and thousands of other packages are working with Tidelift to deliver commercial support and maintenance for the open source dependencies you use to build your applications. Save time, reduce risk, and improve code health, while paying the maintainers of the exact dependencies you use. Learn more."
  },
  "node_modules/thenby/README.html": {
    "href": "node_modules/thenby/README.html",
    "title": "thenBy.js usage | accouter",
    "keywords": "thenBy.js usage Sort by property names Sort by unary functions Extra options Sort descending Case insensitive sorting Custom compare function Internationalization: Using javascripts native Intl.Collator A word on performance Installing Install in your HTML Install using npm or yarn thenBy.js usage thenBy is a javascript micro library that helps sorting arrays on multiple keys. It allows you to use the native Array::sort() method of javascript, but pass in multiple functions to sort that are composed with firstBy().thenBy().thenBy() style. Example: // first by length of name, then by population, then by ID data.sort( firstBy(function (v1, v2) { return v1.name.length - v2.name.length; }) .thenBy(function (v1, v2) { return v1.population - v2.population; }) .thenBy(function (v1, v2) { return v1.id - v2.id; }) ); thenBy also offers some nice shortcuts that make the most common ways of sorting even easier and more readable. Sort by property names Javascript sorting relies heavily on passing discriminator functions that return -1, 0 or 1 for a pair of items. While this is very flexible, often you want to sort on the value of a simple property. As a convenience, thenBy.js builds the appropriate compare function for you if you pass in a property name (instead of a function). The example above would then look like this: // first by length of name, then by population, then by ID data.sort( firstBy(function (v1, v2) { return v1.name.length - v2.name.length; }) .thenBy(\"population\") .thenBy(\"id\") ); If an element doesn't have the property defined, it will sort like the empty string (\"\"). Typically, this will be at the top. Sort by unary functions You can also pass a function that takes a single item and returns its sorting key. This turns the above expression into: // first by length of name, then by population, then by ID data.sort( firstBy(function (v) { return v.name.length; }) .thenBy(\"population\") .thenBy(\"id\") ); Note that javascript contains a number of standard functions that can be passed in here as well. The Number() function will make your sorting sort on numeric values instead of lexical values: var values = [\"2\", \"20\", \"03\", \"-2\", \"0\", 200, \"2\"]; var sorted = values.sort(firstBy(Number)); Extra options Sort descending thenBy.js allows you to pass in a second parameter for direction. If you pass in 'desc' or -1, the sorting will be reversed. So: // first by length of name descending, then by population descending, then by ID ascending data.sort( firstBy(function (v1, v2) { return v1.name.length - v2.name.length; }, -1) .thenBy(\"population\", \"desc\") .thenBy(\"id\") ); Case insensitive sorting (as of v1.2.0) All of the shortcut methods allow you to sort case insensitive as well. The second parameter expects an options object (if it is a number, it is interpreted as direction as above). The ignoreCase property can be set to true, like this: // first by name, case insensitive, then by population data.sort( firstBy(\"name\", {ignoreCase:true}) .thenBy(\"population\") ); If you want to use both descending and ignoreCase, you have to use the options syntax for direction as well: // sort by name, case insensitive and descending data.sort(firstBy(\"name\", {ignoreCase:true, direction:\"desc\"})); Custom compare function If you have more specific wishes for the exact sort order, but still want to use the convenience of unary functions or sorting on property names, you can pass in you own compare function in the options. Here we use a compare function that known about the relative values of playing cards:: const cards = ['2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K', 'A']; var cardCompare = (c1, c2) =>{ return cards.indexOf(c1) - cards.indexOf(c2); } var handOfCards = [ { id: 7, suit:\"c\", card:\"A\" }, { id: 8, suit:\"d\", card:\"10\" }, // etc ]; handOfCards.sort(firstBy(\"card\", {cmp: cardCompare, direction: \"desc\"})); You can use the cmp function together with direction, but not with ignoreCase (for obvious reasons). Internationalization: Using javascripts native Intl.Collator One of the more interesting custom compare functions you may want to pass in is the native compare function that is exposed by Intl.Collator. This compare function knows about the different sorting rules in different cultures. Many browsers have these implemented, but in NodeJS, the API is implemented, but only for the English culture. You would use it with thenBy like this: // in German, ä sorts with a var germanCompare = new Intl.Collator('de').compare; // in Swedish, ä sorts after z var swedishCompare = new Intl.Collator('sv').compare; data.sort( firstBy(\"name\", {cmp: swedishCompare}) ); Check the details on using Intl.Collator. A word on performance thenBy constructs a comparer function for you. It does this by combining the functions you pass in with a number of small utility functions that perform tasks like \"reverting\", \"combining the current sort order with the previous one\", etc. Also, these operations try to work correctly, no matter what content is in the sorted array. There are two steps here that cost time: constructing the über-function and running it. The construction time should always be negligible. The run time however can be slower than when you carefully handcraft the compare function. Still, normally you shouldn't worry about this, but if you're sorting very large sets, it could matter. For example, there is some overhead in making several small functions call each other instead of creating one piece of code. Also, if you know your data well, and know that a specific field is alwways present and is always a number, you could code a significantly faster compare function then thenBy's results. The unit tests contain an extreme example. If you use thenBy to combine multiple compare functions into one (where each function expects two parameters), the difference is small. Using unary functions adds some overhead, using direction:desc adds some, using only a property name adds a little, but will check for missing values, which could be optimized. Ignoring case will slow down, but not more so than when handcoded. Installing Install in your HTML To include it into your page/project, just paste the minified code from https://raw.github.com/Teun/thenBy.js/master/thenBy.min.js into yours (699 characters). If you don't want the firstBy function in your global namespace, you can assign it to a local variable (see sample.htm). Install using npm or yarn npm install thenby or yarn add thenby then in your app: var firstBy = require('thenby'); or in TypeScript/ES6: import {firstBy} from \"thenby\"; For a small demo of how TypeScript support looks in a good editor (i.e. VS Code), check this short video. Thanks a lot to bergus, hagabaka, infolyzer and Foxhoundn for their improvements. Thanks to jsgoupil and HonoluluHenk for their help on the TypeScript declaration."
  },
  "node_modules/to-regex-range/README.html": {
    "href": "node_modules/to-regex-range/README.html",
    "title": "to-regex-range | accouter",
    "keywords": "to-regex-range Pass two numbers, get a regex-compatible source string for matching ranges. Validated against more than 2.78 million test assertions. Please consider following this project's author, Jon Schlinkert, and consider starring the project to show your ❤️ and support. Install Install with npm: $ npm install --save to-regex-range What does this do? This libary generates the source string to be passed to new RegExp() for matching a range of numbers. Example const toRegexRange = require('to-regex-range'); const regex = new RegExp(toRegexRange('15', '95')); A string is returned so that you can do whatever you need with it before passing it to new RegExp() (like adding ^ or $ boundaries, defining flags, or combining it another string). Why use this library? Convenience Creating regular expressions for matching numbers gets deceptively complicated pretty fast. For example, let's say you need a validation regex for matching part of a user-id, postal code, social security number, tax id, etc: regex for matching 1 => /1/ (easy enough) regex for matching 1 through 5 => /[1-5]/ (not bad...) regex for matching 1 or 5 => /(1|5)/ (still easy...) regex for matching 1 through 50 => /([1-9]|[1-4][0-9]|50)/ (uh-oh...) regex for matching 1 through 55 => /([1-9]|[1-4][0-9]|5[0-5])/ (no prob, I can do this...) regex for matching 1 through 555 => /([1-9]|[1-9][0-9]|[1-4][0-9]{2}|5[0-4][0-9]|55[0-5])/ (maybe not...) regex for matching 0001 through 5555 => /(0{3}[1-9]|0{2}[1-9][0-9]|0[1-9][0-9]{2}|[1-4][0-9]{3}|5[0-4][0-9]{2}|55[0-4][0-9]|555[0-5])/ (okay, I get the point!) The numbers are contrived, but they're also really basic. In the real world you might need to generate a regex on-the-fly for validation. Learn more If you're interested in learning more about character classes and other regex features, I personally have always found regular-expressions.info to be pretty useful. Heavily tested As of April 07, 2019, this library runs >1m test assertions against generated regex-ranges to provide brute-force verification that results are correct. Tests run in ~280ms on my MacBook Pro, 2.5 GHz Intel Core i7. Optimized Generated regular expressions are optimized: duplicate sequences and character classes are reduced using quantifiers smart enough to use ? conditionals when number(s) or range(s) can be positive or negative uses fragment caching to avoid processing the same exact string more than once Usage Add this library to your javascript application with the following line of code const toRegexRange = require('to-regex-range'); The main export is a function that takes two integers: the min value and max value (formatted as strings or numbers). const source = toRegexRange('15', '95'); //=> 1[5-9]|[2-8][0-9]|9[0-5] const regex = new RegExp(`^${source}$`); console.log(regex.test('14')); //=> false console.log(regex.test('50')); //=> true console.log(regex.test('94')); //=> true console.log(regex.test('96')); //=> false Options options.capture Type: boolean Deafault: undefined Wrap the returned value in parentheses when there is more than one regex condition. Useful when you're dynamically generating ranges. console.log(toRegexRange('-10', '10')); //=> -[1-9]|-?10|[0-9] console.log(toRegexRange('-10', '10', { capture: true })); //=> (-[1-9]|-?10|[0-9]) options.shorthand Type: boolean Deafault: undefined Use the regex shorthand for [0-9]: console.log(toRegexRange('0', '999999')); //=> [0-9]|[1-9][0-9]{1,5} console.log(toRegexRange('0', '999999', { shorthand: true })); //=> \\d|[1-9]\\d{1,5} options.relaxZeros Type: boolean Default: true This option relaxes matching for leading zeros when when ranges are zero-padded. const source = toRegexRange('-0010', '0010'); const regex = new RegExp(`^${source}$`); console.log(regex.test('-10')); //=> true console.log(regex.test('-010')); //=> true console.log(regex.test('-0010')); //=> true console.log(regex.test('10')); //=> true console.log(regex.test('010')); //=> true console.log(regex.test('0010')); //=> true When relaxZeros is false, matching is strict: const source = toRegexRange('-0010', '0010', { relaxZeros: false }); const regex = new RegExp(`^${source}$`); console.log(regex.test('-10')); //=> false console.log(regex.test('-010')); //=> false console.log(regex.test('-0010')); //=> true console.log(regex.test('10')); //=> false console.log(regex.test('010')); //=> false console.log(regex.test('0010')); //=> true Examples Range Result Compile time toRegexRange(-10, 10) -[1-9]\\|-?10\\|[0-9] 132μs toRegexRange(-100, -10) -1[0-9]\\|-[2-9][0-9]\\|-100 50μs toRegexRange(-100, 100) -[1-9]\\|-?[1-9][0-9]\\|-?100\\|[0-9] 42μs toRegexRange(001, 100) 0{0,2}[1-9]\\|0?[1-9][0-9]\\|100 109μs toRegexRange(001, 555) 0{0,2}[1-9]\\|0?[1-9][0-9]\\|[1-4][0-9]{2}\\|5[0-4][0-9]\\|55[0-5] 51μs toRegexRange(0010, 1000) 0{0,2}1[0-9]\\|0{0,2}[2-9][0-9]\\|0?[1-9][0-9]{2}\\|1000 31μs toRegexRange(1, 50) [1-9]\\|[1-4][0-9]\\|50 24μs toRegexRange(1, 55) [1-9]\\|[1-4][0-9]\\|5[0-5] 23μs toRegexRange(1, 555) [1-9]\\|[1-9][0-9]\\|[1-4][0-9]{2}\\|5[0-4][0-9]\\|55[0-5] 30μs toRegexRange(1, 5555) [1-9]\\|[1-9][0-9]{1,2}\\|[1-4][0-9]{3}\\|5[0-4][0-9]{2}\\|55[0-4][0-9]\\|555[0-5] 43μs toRegexRange(111, 555) 11[1-9]\\|1[2-9][0-9]\\|[2-4][0-9]{2}\\|5[0-4][0-9]\\|55[0-5] 38μs toRegexRange(29, 51) 29\\|[34][0-9]\\|5[01] 24μs toRegexRange(31, 877) 3[1-9]\\|[4-9][0-9]\\|[1-7][0-9]{2}\\|8[0-6][0-9]\\|87[0-7] 32μs toRegexRange(5, 5) 5 8μs toRegexRange(5, 6) 5\\|6 11μs toRegexRange(1, 2) 1\\|2 6μs toRegexRange(1, 5) [1-5] 15μs toRegexRange(1, 10) [1-9]\\|10 22μs toRegexRange(1, 100) [1-9]\\|[1-9][0-9]\\|100 25μs toRegexRange(1, 1000) [1-9]\\|[1-9][0-9]{1,2}\\|1000 31μs toRegexRange(1, 10000) [1-9]\\|[1-9][0-9]{1,3}\\|10000 34μs toRegexRange(1, 100000) [1-9]\\|[1-9][0-9]{1,4}\\|100000 36μs toRegexRange(1, 1000000) [1-9]\\|[1-9][0-9]{1,5}\\|1000000 42μs toRegexRange(1, 10000000) [1-9]\\|[1-9][0-9]{1,6}\\|10000000 42μs Heads up! Order of arguments When the min is larger than the max, values will be flipped to create a valid range: toRegexRange('51', '29'); Is effectively flipped to: toRegexRange('29', '51'); //=> 29|[3-4][0-9]|5[0-1] Steps / increments This library does not support steps (increments). A pr to add support would be welcome. History v2.0.0 - 2017-04-21 New features Adds support for zero-padding! v1.0.0 Optimizations Repeating ranges are now grouped using quantifiers. rocessing time is roughly the same, but the generated regex is much smaller, which should result in faster matching. Attribution Inspired by the python library range-regex. About Contributing Pull requests and stars are always welcome. For bugs and feature requests, please create an issue. Running Tests Running and reviewing unit tests is a great way to get familiarized with a library and its API. You can install dependencies and run tests with the following command: $ npm install && npm test Building docs (This project's readme.md is generated by verb, please don't edit the readme directly. Any changes to the readme must be made in the .verb.md readme template.) To generate the readme, run the following command: $ npm install -g verbose/verb#dev verb-generate-readme && verb Related projects You might also be interested in these projects: expand-range: Fast, bash-like range expansion. Expand a range of numbers or letters, uppercase or lowercase. Used… more | homepage fill-range: Fill in a range of numbers or letters, optionally passing an increment or step to… more | homepage micromatch: Glob matching for javascript/node.js. A drop-in replacement and faster alternative to minimatch and multimatch. | homepage repeat-element: Create an array by repeating the given value n times. | homepage repeat-string: Repeat the given string n times. Fastest implementation for repeating a string. | homepage Contributors Commits Contributor 63 jonschlinkert 3 doowb 2 realityking Author Jon Schlinkert GitHub Profile Twitter Profile LinkedIn Profile Please consider supporting me on Patreon, or start your own Patreon page! License Copyright © 2019, Jon Schlinkert. Released under the MIT License. This file was generated by verb-generate-readme, v0.8.0, on April 07, 2019."
  },
  "node_modules/toidentifier/HISTORY.html": {
    "href": "node_modules/toidentifier/HISTORY.html",
    "title": "1.0.1 / 2021-11-14 | accouter",
    "keywords": "1.0.1 / 2021-11-14 pref: enable strict mode 1.0.0 / 2018-07-09 Initial release"
  },
  "node_modules/toidentifier/README.html": {
    "href": "node_modules/toidentifier/README.html",
    "title": "toidentifier | accouter",
    "keywords": "toidentifier Convert a string of words to a JavaScript identifier Install This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install toidentifier Example var toIdentifier = require('toidentifier') console.log(toIdentifier('Bad Request')) // => \"BadRequest\" API This CommonJS module exports a single default function: toIdentifier. toIdentifier(string) Given a string as the argument, it will be transformed according to the following rules and the new string will be returned: Split into words separated by space characters (0x20). Upper case the first character of each word. Join the words together with no separator. Remove all non-word ([0-9a-z_]) characters. License MIT"
  },
  "node_modules/touch/README.html": {
    "href": "node_modules/touch/README.html",
    "title": "node-touch | accouter",
    "keywords": "node-touch For all your node touching needs. Installing npm install touch CLI Usage: See man touch This package exports a binary called nodetouch that works mostly like the unix builtin touch(1). API Usage: var touch = require(\"touch\") Gives you the following functions: touch(filename, options, cb) touch.sync(filename, options) touch.ftouch(fd, options, cb) touch.ftouchSync(fd, options) All the options objects are optional. All the async functions return a Promise. If a callback function is provided, then it's attached to the Promise. Options force like touch -f Boolean time like touch -t <date> Can be a Date object, or any parseable Date string, or epoch ms number. atime like touch -a Can be either a Boolean, or a Date. mtime like touch -m Can be either a Boolean, or a Date. ref like touch -r <file> Must be path to a file. nocreate like touch -c Boolean If neither atime nor mtime are set, then both values are set. If one of them is set, then the other is not. cli This package creates a nodetouch command line executable that works very much like the unix builtin touch(1)"
  },
  "node_modules/typed-array-buffer/CHANGELOG.html": {
    "href": "node_modules/typed-array-buffer/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.2 - 2024-02-19 Commits add types 23c6fba [Deps] update available-typed-arrays 5f68ba1 [Deps] update call-bind 54a92ce [Dev Deps] update tape b0b3342 v1.0.1 - 2024-02-06 Commits [Dev Deps] update aud, available-typed-arrays, npmignore, object-inspect, tape 5334477 [Refactor] use es-errors, so things that only need those do not need get-intrinsic e2511e0 [Deps] update call-bind, get-intrinsic, is-typed-array 36c3b11 [meta] add sideEffects flag 46cc1f4 v1.0.0 - 2023-06-05 Commits Initial implementation, tests, readme 5bc2953 Initial commit 98b8ac9 npm init 6a4a73c Only apps should have lockfiles 7226abf"
  },
  "node_modules/typed-array-buffer/README.html": {
    "href": "node_modules/typed-array-buffer/README.html",
    "title": "typed-array-buffer | accouter",
    "keywords": "typed-array-buffer Get the ArrayBuffer out of a TypedArray, robustly. This will work in node <= 0.10 and < 0.11.4, where there's no prototype accessor, only a nonconfigurable own property. It will also work in modern engines where TypedArray.prototype.buffer has been deleted after this module has loaded. Example const typedArrayBuffer = require('typed-array-buffer'); const assert = require('assert'); const arr = new Uint8Array(0); assert.equal(arr.buffer, typedArrayBuffer(arr)); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/typed-array-byte-length/CHANGELOG.html": {
    "href": "node_modules/typed-array-byte-length/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.1 - 2024-02-20 Commits add types 3144671 [actions] skip ls check on node < 10; remove redundant finisher 0f83947 [Refactor] use gopd 507b948 [Dev Deps] update aud, available-typed-arrays, npmignore, object-inspect, tape aba282d [Deps] update call-bind, has-proto, is-typed-array acfe4a9 [meta] add sideEffects flag 063a8a7 v1.0.0 - 2023-07-14 Commits Initial implementation, tests, readme b8800c8 Initial commit 72723d8 Only apps should have lockfiles a7dfc57"
  },
  "node_modules/typed-array-byte-length/README.html": {
    "href": "node_modules/typed-array-byte-length/README.html",
    "title": "typed-array-byte-offset | accouter",
    "keywords": "typed-array-byte-offset Robustly get the byte offset of a Typed Array, or false if it is not a Typed Array. Works cross-realm, in every engine, even if the byteOffset property is overridden. Example var typedArrayByteOffset = require('typed-array-byte-offset'); var assert = require('assert'); assert.equal(false, typedArrayByteOffset(undefined)); assert.equal(false, typedArrayByteOffset(null)); assert.equal(false, typedArrayByteOffset(false)); assert.equal(false, typedArrayByteOffset(true)); assert.equal(false, typedArrayByteOffset([])); assert.equal(false, typedArrayByteOffset({})); assert.equal(false, typedArrayByteOffset(/a/g)); assert.equal(false, typedArrayByteOffset(new RegExp('a', 'g'))); assert.equal(false, typedArrayByteOffset(new Date())); assert.equal(false, typedArrayByteOffset(42)); assert.equal(false, typedArrayByteOffset(NaN)); assert.equal(false, typedArrayByteOffset(Infinity)); assert.equal(false, typedArrayByteOffset(new Number(42))); assert.equal(false, typedArrayByteOffset('foo')); assert.equal(false, typedArrayByteOffset(Object('foo'))); assert.equal(false, typedArrayByteOffset(function () {})); assert.equal(false, typedArrayByteOffset(function* () {})); assert.equal(false, typedArrayByteOffset(x => x * x)); assert.equal(false, typedArrayByteOffset([])); const buffer = new ArrayBuffer(32); assert.equal(8, typedArrayByteOffset(new Int8Array(buffer, 8))); assert.equal(8, typedArrayByteOffset(new Uint8Array(buffer, 8))); assert.equal(8, typedArrayByteOffset(new Uint8ClampedArray(buffer, 8))); assert.equal(4, typedArrayByteOffset(new Int16Array(buffer, 4))); assert.equal(4, typedArrayByteOffset(new Uint16Array(buffer, 4))); assert.equal(8, typedArrayByteOffset(new Int32Array(buffer, 8))); assert.equal(8, typedArrayByteOffset(new Uint32Array(buffer, 8))); assert.equal(16, typedArrayByteOffset(new Float32Array(buffer, 16))); assert.equal(16, typedArrayByteOffset(new Float64Array(buffer, 16))); assert.equal(16, typedArrayByteOffset(new BigInt64Array(buffer, 16))); assert.equal(16, typedArrayByteOffset(new BigUint64Array(buffer, 16))); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/typed-array-byte-offset/CHANGELOG.html": {
    "href": "node_modules/typed-array-byte-offset/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.2 - 2024-02-20 Commits add types 9eecdd2 [actions] skip ls check on node < 10; remove redundant finisher 4fb4c91 [Deps] update available-typed-arrays, has-proto 805cee2 v1.0.1 - 2024-02-17 Commits [Dev Deps] update aud, npmignore, object-inspect, tape ffe7494 [Deps] update available-typed-arrays, call-bind, is-typed-array 3006bd7 [Refactor] use gopd 45827ea [Dev Deps] update tape e33d080 [meta] add sideEffects flag f1dc0db v1.0.0 - 2023-06-06 Commits Initial implementation, tests, readme f227633 Initial commit 806bbaf npm init 1151981 Only apps should have lockfiles 5fa9933"
  },
  "node_modules/typed-array-byte-offset/README.html": {
    "href": "node_modules/typed-array-byte-offset/README.html",
    "title": "typed-array-byte-offset | accouter",
    "keywords": "typed-array-byte-offset Robustly get the byte offset of a Typed Array, or false if it is not a Typed Array. Works cross-realm, in every engine, even if the byteOffset property is overridden. Example var typedArrayByteOffset = require('typed-array-byte-offset'); var assert = require('assert'); assert.equal(false, typedArrayByteOffset(undefined)); assert.equal(false, typedArrayByteOffset(null)); assert.equal(false, typedArrayByteOffset(false)); assert.equal(false, typedArrayByteOffset(true)); assert.equal(false, typedArrayByteOffset([])); assert.equal(false, typedArrayByteOffset({})); assert.equal(false, typedArrayByteOffset(/a/g)); assert.equal(false, typedArrayByteOffset(new RegExp('a', 'g'))); assert.equal(false, typedArrayByteOffset(new Date())); assert.equal(false, typedArrayByteOffset(42)); assert.equal(false, typedArrayByteOffset(NaN)); assert.equal(false, typedArrayByteOffset(Infinity)); assert.equal(false, typedArrayByteOffset(new Number(42))); assert.equal(false, typedArrayByteOffset('foo')); assert.equal(false, typedArrayByteOffset(Object('foo'))); assert.equal(false, typedArrayByteOffset(function () {})); assert.equal(false, typedArrayByteOffset(function* () {})); assert.equal(false, typedArrayByteOffset(x => x * x)); assert.equal(false, typedArrayByteOffset([])); const buffer = new ArrayBuffer(32); assert.equal(8, typedArrayByteOffset(new Int8Array(buffer, 8))); assert.equal(8, typedArrayByteOffset(new Uint8Array(buffer, 8))); assert.equal(8, typedArrayByteOffset(new Uint8ClampedArray(buffer, 8))); assert.equal(4, typedArrayByteOffset(new Int16Array(buffer, 4))); assert.equal(4, typedArrayByteOffset(new Uint16Array(buffer, 4))); assert.equal(8, typedArrayByteOffset(new Int32Array(buffer, 8))); assert.equal(8, typedArrayByteOffset(new Uint32Array(buffer, 8))); assert.equal(16, typedArrayByteOffset(new Float32Array(buffer, 16))); assert.equal(16, typedArrayByteOffset(new Float64Array(buffer, 16))); assert.equal(16, typedArrayByteOffset(new BigInt64Array(buffer, 16))); assert.equal(16, typedArrayByteOffset(new BigUint64Array(buffer, 16))); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/typed-array-length/CHANGELOG.html": {
    "href": "node_modules/typed-array-length/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.6 - 2024-03-21 Commits [types] vastly improve types 9f68d36 [types] use shared config b6b3cbc [actions] remove redundant finisher c69896e [Tests] actually check types in tests, and add attw e2c3f94 v1.0.5 - 2024-02-20 Commits add types df51e65 [Refactor] use possible-typed-array-names for a single source of truth 84503a3 [actions] update rebase action to use reusable workflow f163023 [Dev Deps] update @ljharb/eslint-config, aud, npmignore, object-inspect, tape 57ca930 [Dev Deps] update aud, is-callable, object-inspect, tape 99343f4 [Refactor] use gopd and has-proto b134a5c [Deps] update call-bind, is-typed-array 3b62f55 [meta] add missing engines.node ff3e9f7 [Deps] update is-typed-array 877f507 [meta] add sideEffects flag 6e91309 v1.0.4 - 2022-05-23 Commits [actions] reuse common workflows dfd4a37 [meta] use npmignore to autogenerate an npmignore file a837e80 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, is-callable, object-inspect, tape 7b05a87 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, object-inspect, tape c495f6e [meta] simplify \"exports\" e42a6b6 [Fix] ensure for-each dependency is properly listed 8ec761c [Deps] update call-bind, is-typed-array 2cc173a [meta] add safe-publish-latest e8e3afa [Deps] update is-typed-array cd8084d v1.0.3 - 2020-12-05 Commits [Tests] migrate tests to Github Actions a578b83 [meta] avoid publishing github workflows f064a4b [Tests] run nyc on all tests 69b841e [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, object-inspect, tape 4594e83 [actions] add \"Allow Edits\" workflow 81e953b [Deps] update is-typed-array; use call-bind instead of es-abstract e7da56b [readme] remove travis badge 6d610d8 [actions] switch Automatic Rebase workflow to pull_request_target event 2d0ad64 v1.0.2 - 2020-04-22 Commits [Dev Deps] update make-arrow-function, make-generator-function 4facf69 [Deps] update is-typed-array, es-abstract aaf3585 [Dev Deps] update aud, auto-changelog f10e298 [meta] allow package.json to be required/imported 104f4c6 [Tests] only audit prod deps c748ab5 [Deps] update es-abstract 6cd213e [Dev Deps] update tape 2b0b2ea [Dev Deps] update @ljharb/eslint-config cf462f3 [Deps] update is-typed-array ff46995 v1.0.1 - 2020-01-19 Commits readme d3643fd [meta] fix \"exports\" field 006e28b v1.0.0 - 2020-01-18 Commits Initial commit 5f9e2ec Tests 6b9cadb Implementation 6a3cb50 npm init 41d42cd [meta] add auto-changelog 4fd159b [meta] add funding field; create FUNDING.yml 6a9fca7 [actions] add automatic rebasing / merge commit blocking 8303296 [Tests] add npm run lint 47a9c21 [Tests] use shared travis-ci configs d0c8915 Only apps should have lockfiles 3eaef9c"
  },
  "node_modules/typed-array-length/README.html": {
    "href": "node_modules/typed-array-length/README.html",
    "title": "typed-array-length | accouter",
    "keywords": "typed-array-length Robustly get the length of a Typed Array, or false if it is not a Typed Array. Works cross-realm, in every engine, even if the length property is overridden. Example var typedArrayLength = require('typed-array-length'); var assert = require('assert'); assert.equal(false, typedArrayLength(undefined)); assert.equal(false, typedArrayLength(null)); assert.equal(false, typedArrayLength(false)); assert.equal(false, typedArrayLength(true)); assert.equal(false, typedArrayLength([])); assert.equal(false, typedArrayLength({})); assert.equal(false, typedArrayLength(/a/g)); assert.equal(false, typedArrayLength(new RegExp('a', 'g'))); assert.equal(false, typedArrayLength(new Date())); assert.equal(false, typedArrayLength(42)); assert.equal(false, typedArrayLength(NaN)); assert.equal(false, typedArrayLength(Infinity)); assert.equal(false, typedArrayLength(new Number(42))); assert.equal(false, typedArrayLength('foo')); assert.equal(false, typedArrayLength(Object('foo'))); assert.equal(false, typedArrayLength(function () {})); assert.equal(false, typedArrayLength(function* () {})); assert.equal(false, typedArrayLength(x => x * x)); assert.equal(false, typedArrayLength([])); assert.equal(1, typedArrayLength(new Int8Array(1))); assert.equal(2, typedArrayLength(new Uint8Array(2))); assert.equal(3, typedArrayLength(new Uint8ClampedArray(3))); assert.equal(4, typedArrayLength(new Int16Array(4))); assert.equal(5, typedArrayLength(new Uint16Array(5))); assert.equal(6, typedArrayLength(new Int32Array(6))); assert.equal(7, typedArrayLength(new Uint32Array(7))); assert.equal(8, typedArrayLength(new Float32Array(8))); assert.equal(9, typedArrayLength(new Float64Array(9))); assert.equal(10, typedArrayLength(new BigInt64Array(10))); assert.equal(11, typedArrayLength(new BigUint64Array(11))); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/ua-parser-js/license.html": {
    "href": "node_modules/ua-parser-js/license.html",
    "title": "| accouter",
    "keywords": "MIT License Copyright (c) 2012-2023 Faisal Salman <f@faisalman.com> Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/ua-parser-js/readme.html": {
    "href": "node_modules/ua-parser-js/readme.html",
    "title": "UAParser.js | accouter",
    "keywords": "UAParser.js JavaScript library to detect Browser, Engine, OS, CPU, and Device type/model from User-Agent data with relatively small footprint (~17KB minified, ~6KB gzipped) that can be used either in browser (client-side) or node.js (server-side). Author : Faisal Salman <f@faisalman.com> Demo : https://faisalman.github.io/ua-parser-js Source : https://github.com/faisalman/ua-parser-js Documentation : v1 : https://github.com/faisalman/ua-parser-js/tree/1.0.35#documentation v2 : https://faisalman.github.io/ua-parser-js-docs/v2 From Our Sponsors: ↗ Become a sponsor Documentation UAParser([user-agent][,extensions]) typeof user-agent \"string\". typeof extensions \"array\". In The Browser environment you dont need to pass the user-agent string to the function, you can just call the funtion and it should automatically get the string from the window.navigator.userAgent, but that is not the case in nodejs. The user-agent string must be passed in nodejs for the function to work. Usually you can find the user agent in: request.headers[\"user-agent\"]. Constructor When you call UAParser with the new keyword UAParser will return a new instance with an empty result object, you have to call one of the available methods to get the information from the user-agent string. Like so: new UAParser([uastring][,extensions]) let parser = new UAParser(\"user-agent\"); // you need to pass the user-agent for nodejs console.log(parser); // {} let parserResults = parser.getResult(); console.log(parserResults); /** { \"ua\": \"\", \"browser\": {}, \"engine\": {}, \"os\": {}, \"device\": {}, \"cpu\": {} } */ When you call UAParser without the new keyword, it will automatically call getResult() function and return the parsed results. UAParser([uastring][,extensions]) returns result object { ua: '', browser: {}, cpu: {}, device: {}, engine: {}, os: {} } Methods Methods table The methods are self explanatory, here's a small overview on all the available methods: getResult() - returns all function object calls, user-agent string, browser info, cpu, device, engine, os: { ua: '', browser: {}, cpu: {}, device: {}, engine: {}, os: {} }. getBrowser() - returns the browser name and version. getDevice() - returns the device model, type, vendor. getEngine() - returns the current browser engine name and version. getOS() - returns the running operating system name and version. getCPU() - returns CPU architectural design name. getUA() - returns the user-agent string. setUA(user-agent) - set a custom user-agent to be parsed. getResult() returns { ua: '', browser: {}, cpu: {}, device: {}, engine: {}, os: {} } getBrowser() returns { name: '', version: '' } # Possible 'browser.name': 2345Explorer, 360 Browser, Alipay, Amaya, Android Browser, Arora, Avant, Avast, AVG, Baidu, Basilisk, Blazer, Bolt, Brave, Bowser, Camino, Chimera, Chrome Headless, Chrome WebView, Chrome, Chromium, Cobalt, Comodo Dragon, Dillo, Dolphin, Doris, DuckDuckGo, Edge, Electron, Epiphany, Facebook, Falkon, Fennec, Firebird, Firefox [Focus/Reality], Flock, Flow, GSA, GoBrowser, Heytap, Huawei Browser, iCab, ICE Browser, IE, IEMobile, IceApe, IceCat, IceDragon, Iceweasel, Instagram, Iridium, Iron, Jasmine, Kakao[Story/Talk], K-Meleon, Kindle, Klar, Klarna, Konqueror, LBBROWSER, Line, LinkedIn, Links, Lunascape, Lynx, MIUI Browser, Maemo, Maxthon, Midori, Minimo, Mobile Safari, Mosaic, Mozilla, NetFront, NetSurf, Netfront, Netscape, NokiaBrowser, Obigo, Oculus Browser, OmniWeb, Opera Coast, Opera [GX/Mini/Mobi/Tablet], PaleMoon, PhantomJS, Phoenix, Polaris, Puffin, QQ, QQBrowser, QQBrowserLite, Quark, QupZilla, RockMelt, Safari, Sailfish Browser, Samsung Internet, SeaMonkey, Silk, Skyfire, Sleipnir, Slim, SlimBrowser, Smart Lenovo Browser, Snapchat, Sogou [Explorer/Mobile], Swiftfox, Tesla, TikTok, Tizen Browser, Twitter, UCBrowser, UP.Browser, Viera, Vivaldi, Vivo Browser, Waterfox, WeChat, Weibo, Yandex, w3m, Whale Browser, ... # 'browser.version' determined dynamically getDevice() returns { model: '', type: '', vendor: '' } # Possible 'device.type': console, mobile, tablet, smarttv, wearable, embedded ########## # NOTE: 'desktop' is not a possible device type. # UAParser only reports info directly available from the UA string, which is not the case for 'desktop' device type. # If you wish to detect desktop devices, you must handle the needed logic yourself. # You can read more about it in this issue: https://github.com/faisalman/ua-parser-js/issues/182 ########## # Possible 'device.vendor': Acer, Alcatel, Amazon, Apple, Archos, ASUS, AT&T, BenQ, BlackBerry, Dell, Essential, Facebook, Fairphone, GeeksPhone, Google, HP, HTC, Huawei, Infinix, Jolla, Kobo, Lenovo, LG, Meizu, Microsoft, Motorola, Nexian, Nintendo, Nokia, Nvidia, OnePlus, OPPO, Ouya, Palm, Panasonic, Pebble, Polytron, Realme, RIM, Roku, Samsung, Sharp, Siemens, Sony[Ericsson], Sprint, Tecno, Tesla, Ulefone, Vivo, Vodafone, Xbox, Xiaomi, Zebra, ZTE, ... # 'device.model' determined dynamically getEngine() returns { name: '', version: '' } # Possible 'engine.name' Amaya, Blink, EdgeHTML, Flow, Gecko, Goanna, iCab, KHTML, LibWeb, Links, Lynx, NetFront, NetSurf, Presto, Tasman, Trident, w3m, WebKit # 'engine.version' determined dynamically getOS() returns { name: '', version: '' } # Possible 'os.name' AIX, Amiga OS, Android[-x86], Arch, Bada, BeOS, BlackBerry, CentOS, Chromium OS, Contiki, Fedora, Firefox OS, FreeBSD, Debian, Deepin, DragonFly, elementary OS, Fuchsia, Gentoo, GhostBSD, GNU, Haiku, HarmonyOS, HP-UX, Hurd, iOS, Joli, KaiOS, Linpus, Linspire,Linux, Mac OS, Maemo, Mageia, Mandriva, Manjaro, MeeGo, Minix, Mint, Morph OS, NetBSD, NetRange, NetTV, Nintendo, OpenBSD, OpenVMS, OS/2, Palm, PC-BSD, PCLinuxOS, Plan9, PlayStation, QNX, Raspbian, RedHat, RIM Tablet OS, RISC OS, Sabayon, Sailfish, SerenityOS, Series40, Slackware, Solaris, SUSE, Symbian, Tizen, Ubuntu, Unix, VectorLinux, Viera, watchOS, WebOS, Windows [Phone/Mobile], Zenwalk, ... # 'os.version' determined dynamically getCPU() returns { architecture: '' } # Possible 'cpu.architecture' 68k, amd64, arm[64/hf], avr, ia[32/64], irix[64], mips[64], pa-risc, ppc, sparc[64] getUA() returns UA string of current instance setUA(uastring) set UA string to be parsed returns current instance Usage Using HTML <!doctype html> <html> <head> <script src=\"ua-parser.min.js\"></script> <script> var parser = new UAParser(); console.log(parser.getResult()); /* /// This will print an object structured like this: { ua: \"\", browser: { name: \"\", version: \"\", major: \"\" //@deprecated }, engine: { name: \"\", version: \"\" }, os: { name: \"\", version: \"\" }, device: { model: \"\", type: \"\", vendor: \"\" }, cpu: { architecture: \"\" } } */ // Default result depends on current window.navigator.userAgent value // Now let's try a custom user-agent string as an example var uastring1 = \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/535.2 (KHTML, like Gecko) Ubuntu/11.10 Chromium/15.0.874.106 Chrome/15.0.874.106 Safari/535.2\"; parser.setUA(uastring1); var result = parser.getResult(); // You can also use UAParser constructor directly without having to create an instance: // var result = UAParser(uastring1); console.log(result.browser); // {name: \"Chromium\", version: \"15.0.874.106\"} console.log(result.device); // {model: undefined, type: undefined, vendor: undefined} console.log(result.os); // {name: \"Ubuntu\", version: \"11.10\"} console.log(result.os.version); // \"11.10\" console.log(result.engine.name); // \"WebKit\" console.log(result.cpu.architecture); // \"amd64\" // Do some other tests var uastring2 = \"Mozilla/5.0 (compatible; Konqueror/4.1; OpenBSD) KHTML/4.1.4 (like Gecko)\"; console.log(parser.setUA(uastring2).getBrowser().name); // \"Konqueror\" console.log(parser.getOS()); // {name: \"OpenBSD\", version: undefined} console.log(parser.getEngine()); // {name: \"KHTML\", version: \"4.1.4\"} var uastring3 = 'Mozilla/5.0 (PlayBook; U; RIM Tablet OS 1.0.0; en-US) AppleWebKit/534.11 (KHTML, like Gecko) Version/7.1.0.7 Safari/534.11'; console.log(parser.setUA(uastring3).getDevice().model); // \"PlayBook\" console.log(parser.getOS()) // {name: \"RIM Tablet OS\", version: \"1.0.0\"} console.log(parser.getBrowser().name); // \"Safari\" </script> </head> <body> </body> </html> Using node.js Note: Device information is not available in the NodeJS environment. $ npm install ua-parser-js var http = require('http'); var parser = require('ua-parser-js'); http.createServer(function (req, res) { // get user-agent header var ua = parser(req.headers['user-agent']); // write the result as response res.end(JSON.stringify(ua, null, ' ')); }) .listen(1337, '127.0.0.1'); console.log('Server running at http://127.0.0.1:1337/'); Using TypeScript $ npm install --save @types/ua-parser-js # Download TS type definition from DefinitelyTyped repository: # https://github.com/DefinitelyTyped/DefinitelyTyped/tree/master/types/ua-parser-js Using jQuery/Zepto ($.ua) Although written in vanilla js, this library will automatically detect if jQuery/Zepto is present and create $.ua object (with values based on its User-Agent) along with window.UAParser constructor. To get/set user-agent you can use: $.ua.get() / $.ua.set(uastring). // Say we are in a browser with default user-agent: 'Mozilla/5.0 (Linux; U; Android 2.3.4; en-us; Sprint APA7373KT Build/GRJ22) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0': // Get the details console.log($.ua.device); // {vendor: \"HTC\", model: \"Evo Shift 4G\", type: \"mobile\"} console.log($.ua.os); // {name: \"Android\", version: \"2.3.4\"} console.log($.ua.os.name); // \"Android\" console.log($.ua.get()); // \"Mozilla/5.0 (Linux; U; Android 2.3.4; en-us; Sprint APA7373KT Build/GRJ22) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0\" // Now lets try to reset to another custom user-agent $.ua.set('Mozilla/5.0 (Linux; U; Android 3.0.1; en-us; Xoom Build/HWI69) AppleWebKit/534.13 (KHTML, like Gecko) Version/4.0 Safari/534.13'); // Test again console.log($.ua.browser.name); // \"Safari\" console.log($.ua.engine.name); // \"Webkit\" console.log($.ua.device); // {vendor: \"Motorola\", model: \"Xoom\", type: \"tablet\"} console.log(parseInt($.ua.browser.version.split('.')[0], 10)); // 4 // Add class to <body> tag // <body class=\"ua-browser-safari ua-devicetype-tablet\"> $('body').addClass('ua-browser-' + $.ua.browser.name + ' ua-devicetype-' + $.ua.device.type); Using Extension UAParser([uastring,] extensions) // Example: var myOwnListOfBrowsers = [ [/(mybrowser)\\/([\\w\\.]+)/i], [UAParser.BROWSER.NAME, UAParser.BROWSER.VERSION] ]; var myParser = new UAParser({ browser: myOwnListOfBrowsers }); var myUA = 'Mozilla/5.0 MyBrowser/1.3'; console.log(myParser.setUA(myUA).getBrowser()); // {name: \"MyBrowser\", version: \"1.3\"} Development Backers & Sponsors Contributors Made with contributors-img. How To Contribute Fork and clone this repository Make some changes as required Write unit test to showcase its functionality Run the test suites to make sure it's not breaking anything $ npm test Submit a pull request under develop branch License MIT License Copyright (c) 2012-2021 Faisal Salman <f@faisalman.com> Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/unbox-primitive/CHANGELOG.html": {
    "href": "node_modules/unbox-primitive/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.2 - 2022-04-24 Commits [actions] reuse common workflows e6420b9 [actions] update codecov uploader b90aff2 [readme] add github actions/codecov badges; update URLs bcc39b9 [Dev Deps] update eslint, @ljharb/eslint-config, object-inspect, safe-publish-latest, tape a704a32 [Refactor] use call-bind instead of function-bind 0a609f1 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, object-inspect, safe-publish-latest, tape 6a45317 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, object-inspect, tape 795c76f [Deps] update has-bigints, has-symbols 257a065 v1.0.1 - 2021-03-25 Commits [Tests] use shared travis-ci configs f977e5f [Tests] migrate tests to Github Actions b89def6 [meta] do not publish github action workflow files 325d1f1 readme 810cd70 [Tests] run nyc on all tests; use tape runner 2f5fb08 [meta] add auto-changelog 03ed375 [actions] add automatic rebasing / merge commit blocking 6dec48d [Dev Deps] update eslint, @ljharb/eslint-config, aud, object-inspect, object-is, tape 528ed88 [actions] check out the entire repo 5095b29 [actions] add \"Allow Edits\" workflow 5aa26d7 [Dev Deps] update eslint, @ljharb/eslint-config, object-inspect, object-is, safe-publish-latest, tape afc18c6 [readme] remove travis badge a025899 [Dev Deps] update auto-changelog 9219a32 [readme] Fix missing paren in example 73f5a33 [Dev Deps] update @ljharb/eslint-config, tape e450acc [Deps] update has-bigints, has-symbols, which-boxed-primitive a4279b5 [Dev Deps] update auto-changelog, in-publish, tape b351548 [actions] switch Automatic Rebase workflow to pull_request_target event f600382 [readme] fix travis links 4d02fa9 [Dev Deps] update auto-changelog; add aud 07e74a3 [meta] add funding field 7ca4bd7 [Tests] only audit prod deps 47d8d5f [Deps] update has-symbols c70c15e v1.0.0 - 2019-08-10 Commits [Tests] add .travis.yml 8c9a5ef Initial commit feaff15 [Tests] add tests 3dd18d6 implementation 472fb41 npm init e9e426f [Tests] add linting 139e74b [meta] create FUNDING.yml a9509e1 Only apps should have lockfiles b3d0834"
  },
  "node_modules/unbox-primitive/README.html": {
    "href": "node_modules/unbox-primitive/README.html",
    "title": "unbox-primitive | accouter",
    "keywords": "unbox-primitive Unbox a boxed JS primitive value. This module works cross-realm/iframe, does not depend on instanceof or mutable properties, and works despite ES6 Symbol.toStringTag. Example var unboxPrimitive = require('unbox-primitive'); var assert = require('assert'); assert.equal(unboxPrimitive(new Boolean(false)), false); assert.equal(unboxPrimitive(new String('f')), 'f'); assert.equal(unboxPrimitive(new Number(42)), 42); const s = Symbol(); assert.equal(unboxPrimitive(Object(s)), s); assert.equal(unboxPrimitive(new BigInt(42)), 42n); // any primitive, or non-boxed-primitive object, will throw Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/undefsafe/README.html": {
    "href": "node_modules/undefsafe/README.html",
    "title": "undefsafe | accouter",
    "keywords": "undefsafe Simple function for retrieving deep object properties without getting \"Cannot read property 'X' of undefined\" Can also be used to safely set deep values. Usage var object = { a: { b: { c: 1, d: [1,2,3], e: 'remy' } } }; console.log(undefsafe(object, 'a.b.e')); // \"remy\" console.log(undefsafe(object, 'a.b.not.found')); // undefined Demo: https://jsbin.com/eroqame/3/edit?js,console Setting var object = { a: { b: [1,2,3] } }; // modified object var res = undefsafe(object, 'a.b.0', 10); console.log(object); // { a: { b: [10, 2, 3] } } console.log(res); // 1 - previous value Star rules in paths As of 1.2.0, undefsafe supports a * in the path if you want to search all of the properties (or array elements) for a particular element. The function will only return a single result, either the 3rd argument validation value, or the first positive match. For example, the following github data: const githubData = { commits: [{ modified: [ \"one\", \"two\" ] }, /* ... */ ] }; // first modified file found in the first commit console.log(undefsafe(githubData, 'commits.*.modified.0')); // returns `two` or undefined if not found console.log(undefsafe(githubData, 'commits.*.modified.*', 'two'));"
  },
  "node_modules/undici-types/README.html": {
    "href": "node_modules/undici-types/README.html",
    "title": "undici-types | accouter",
    "keywords": "undici-types This package is a dual-publish of the undici library types. The undici package still contains types. This package is for users who only need undici types (such as for @types/node). It is published alongside every release of undici, so you can always use the same version. GitHub nodejs/undici Undici Documentation"
  },
  "node_modules/unicorn-magic/readme.html": {
    "href": "node_modules/unicorn-magic/readme.html",
    "title": "unicorn-magic | accouter",
    "keywords": "unicorn-magic Some useful utilities I often need I'm not accepting requests. Install npm install unicorn-magic Usage import {delay} from 'unicorn-magic'; await delay({seconds: 1}); console.log('1 second later'); API See the types."
  },
  "node_modules/universalify/README.html": {
    "href": "node_modules/universalify/README.html",
    "title": "universalify | accouter",
    "keywords": "universalify Make a callback- or promise-based function support both promises and callbacks. Uses the native promise implementation. Installation npm install universalify API universalify.fromCallback(fn) Takes a callback-based function to universalify, and returns the universalified function. Function must take a callback as the last parameter that will be called with the signature (error, result). universalify does not support calling the callback with more than three arguments, and does not ensure that the callback is only called once. function callbackFn (n, cb) { setTimeout(() => cb(null, n), 15) } const fn = universalify.fromCallback(callbackFn) // Works with Promises: fn('Hello World!') .then(result => console.log(result)) // -> Hello World! .catch(error => console.error(error)) // Works with Callbacks: fn('Hi!', (error, result) => { if (error) return console.error(error) console.log(result) // -> Hi! }) universalify.fromPromise(fn) Takes a promise-based function to universalify, and returns the universalified function. Function must return a valid JS promise. universalify does not ensure that a valid promise is returned. function promiseFn (n) { return new Promise(resolve => { setTimeout(() => resolve(n), 15) }) } const fn = universalify.fromPromise(promiseFn) // Works with Promises: fn('Hello World!') .then(result => console.log(result)) // -> Hello World! .catch(error => console.error(error)) // Works with Callbacks: fn('Hi!', (error, result) => { if (error) return console.error(error) console.log(result) // -> Hi! }) License MIT"
  },
  "node_modules/unpipe/HISTORY.html": {
    "href": "node_modules/unpipe/HISTORY.html",
    "title": "1.0.0 / 2015-06-14 | accouter",
    "keywords": "1.0.0 / 2015-06-14 Initial release"
  },
  "node_modules/unpipe/README.html": {
    "href": "node_modules/unpipe/README.html",
    "title": "unpipe | accouter",
    "keywords": "unpipe Unpipe a stream from all destinations. Installation $ npm install unpipe API var unpipe = require('unpipe') unpipe(stream) Unpipes all destinations from a given stream. With stream 2+, this is equivalent to stream.unpipe(). When used with streams 1 style streams (typically Node.js 0.8 and below), this module attempts to undo the actions done in stream.pipe(dest). License MIT"
  },
  "node_modules/update-browserslist-db/README.html": {
    "href": "node_modules/update-browserslist-db/README.html",
    "title": "Update Browserslist DB | accouter",
    "keywords": "Update Browserslist DB CLI tool to update caniuse-lite with browsers DB from Browserslist config. Some queries like last 2 version or >1% depends on actual data from caniuse-lite. npx update-browserslist-db@latest Docs Read full docs here."
  },
  "node_modules/util-deprecate/History.html": {
    "href": "node_modules/util-deprecate/History.html",
    "title": "1.0.2 / 2015-10-07 | accouter",
    "keywords": "1.0.2 / 2015-10-07 use try/catch when checking localStorage (#3, @kumavis) 1.0.1 / 2014-11-25 browser: use console.warn() for deprecation calls browser: more jsdocs 1.0.0 / 2014-04-30 initial commit"
  },
  "node_modules/util-deprecate/README.html": {
    "href": "node_modules/util-deprecate/README.html",
    "title": "util-deprecate | accouter",
    "keywords": "util-deprecate The Node.js util.deprecate() function with browser support In Node.js, this module simply re-exports the util.deprecate() function. In the web browser (i.e. via browserify), a browser-specific implementation of the util.deprecate() function is used. API A deprecate() function is the only thing exposed by this module. // setup: exports.foo = deprecate(foo, 'foo() is deprecated, use bar() instead'); // users see: foo(); // foo() is deprecated, use bar() instead foo(); foo(); License (The MIT License) Copyright (c) 2014 Nathan Rajlich nathan@tootallnate.net Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  "node_modules/utils-merge/README.html": {
    "href": "node_modules/utils-merge/README.html",
    "title": "utils-merge | accouter",
    "keywords": "utils-merge Merges the properties from a source object into a destination object. Install $ npm install utils-merge Usage var a = { foo: 'bar' } , b = { bar: 'baz' }; merge(a, b); // => { foo: 'bar', bar: 'baz' } License The MIT License Copyright (c) 2013-2017 Jared Hanson <http://jaredhanson.net/>"
  },
  "node_modules/validate-npm-package-license/README.html": {
    "href": "node_modules/validate-npm-package-license/README.html",
    "title": "validate-npm-package-license | accouter",
    "keywords": "validate-npm-package-license Give me a string and I'll tell you if it's a valid npm package license string. var valid = require('validate-npm-package-license'); SPDX license identifiers are valid license strings: var assert = require('assert'); var validSPDXExpression = { validForNewPackages: true, validForOldPackages: true, spdx: true }; assert.deepEqual(valid('MIT'), validSPDXExpression); assert.deepEqual(valid('BSD-2-Clause'), validSPDXExpression); assert.deepEqual(valid('Apache-2.0'), validSPDXExpression); assert.deepEqual(valid('ISC'), validSPDXExpression); The function will return a warning and suggestion for nearly-correct license identifiers: assert.deepEqual( valid('Apache 2.0'), { validForOldPackages: false, validForNewPackages: false, warnings: [ 'license should be ' + 'a valid SPDX license expression (without \"LicenseRef\"), ' + '\"UNLICENSED\", or ' + '\"SEE LICENSE IN <filename>\"', 'license is similar to the valid expression \"Apache-2.0\"' ] } ); SPDX expressions are valid, too ... // Simple SPDX license expression for dual licensing assert.deepEqual( valid('(GPL-3.0-only OR BSD-2-Clause)'), validSPDXExpression ); ... except if they contain LicenseRef: var warningAboutLicenseRef = { validForOldPackages: false, validForNewPackages: false, spdx: true, warnings: [ 'license should be ' + 'a valid SPDX license expression (without \"LicenseRef\"), ' + '\"UNLICENSED\", or ' + '\"SEE LICENSE IN <filename>\"', ] }; assert.deepEqual( valid('LicenseRef-Made-Up'), warningAboutLicenseRef ); assert.deepEqual( valid('(MIT OR LicenseRef-Made-Up)'), warningAboutLicenseRef ); If you can't describe your licensing terms with standardized SPDX identifiers, put the terms in a file in the package and point users there: assert.deepEqual( valid('SEE LICENSE IN LICENSE.txt'), { validForNewPackages: true, validForOldPackages: true, inFile: 'LICENSE.txt' } ); assert.deepEqual( valid('SEE LICENSE IN license.md'), { validForNewPackages: true, validForOldPackages: true, inFile: 'license.md' } ); If there aren't any licensing terms, use UNLICENSED: var unlicensed = { validForNewPackages: true, validForOldPackages: true, unlicensed: true }; assert.deepEqual(valid('UNLICENSED'), unlicensed); assert.deepEqual(valid('UNLICENCED'), unlicensed);"
  },
  "node_modules/vary/HISTORY.html": {
    "href": "node_modules/vary/HISTORY.html",
    "title": "1.1.2 / 2017-09-23 | accouter",
    "keywords": "1.1.2 / 2017-09-23 perf: improve header token parsing speed 1.1.1 / 2017-03-20 perf: hoist regular expression 1.1.0 / 2015-09-29 Only accept valid field names in the field argument Ensures the resulting string is a valid HTTP header value 1.0.1 / 2015-07-08 Fix setting empty header from empty field perf: enable strict mode perf: remove argument reassignments 1.0.0 / 2014-08-10 Accept valid Vary header string as field Add vary.append for low-level string manipulation Move to jshttp orgainzation 0.1.0 / 2014-06-05 Support array of fields to set 0.0.0 / 2014-06-04 Initial release"
  },
  "node_modules/vary/README.html": {
    "href": "node_modules/vary/README.html",
    "title": "vary | accouter",
    "keywords": "vary Manipulate the HTTP Vary header Installation This is a Node.js module available through the npm registry. Installation is done using the npm install command: $ npm install vary API var vary = require('vary') vary(res, field) Adds the given header field to the Vary response header of res. This can be a string of a single field, a string of a valid Vary header, or an array of multiple fields. This will append the header if not already listed, otherwise leaves it listed in the current location. // Append \"Origin\" to the Vary header of the response vary(res, 'Origin') vary.append(header, field) Adds the given header field to the Vary response header string header. This can be a string of a single field, a string of a valid Vary header, or an array of multiple fields. This will append the header if not already listed, otherwise leaves it listed in the current location. The new header string is returned. // Get header string appending \"Origin\" to \"Accept, User-Agent\" vary.append('Accept, User-Agent', 'Origin') Examples Updating the Vary header when content is based on it var http = require('http') var vary = require('vary') http.createServer(function onRequest (req, res) { // about to user-agent sniff vary(res, 'User-Agent') var ua = req.headers['user-agent'] || '' var isMobile = /mobi|android|touch|mini/i.test(ua) // serve site, depending on isMobile res.setHeader('Content-Type', 'text/html') res.end('You are (probably) ' + (isMobile ? '' : 'not ') + 'a mobile user') }) Testing $ npm test License MIT"
  },
  "node_modules/which-boxed-primitive/CHANGELOG.html": {
    "href": "node_modules/which-boxed-primitive/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.0.2 - 2020-12-14 Commits [Tests] use shared travis-ci configs 8674582 [Tests] migrate tests to Github Actions dff6643 [meta] do not publish github action workflow files b26112a [meta] make auto-changelog config consistent 8d10175 [readme] fix repo URLs, remove defunct badges ab8db24 [Tests] run nyc on all tests; use tape runner 7d084df [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, object-inspect, tape 576f6f3 [actions] add automatic rebasing / merge commit blocking 97efa53 [actions] add \"Allow Edits\" workflow fb1b4f7 [Dev Deps] update eslint, @ljharb/eslint-config, has-symbols, object-inspect, safe-publish-latest 1e03c61 [Deps] update is-boolean-object, is-number-object, is-string, is-symbol 13673df [Dev Deps] update auto-changelog, in-publish, tape 65a0e15 [Dev Deps] update eslint, @ljharb/eslint-config, tape f8a0afe [Deps] update is-bigint, is-boolean-object e7a1ce2 [actions] switch Automatic Rebase workflow to pull_request_target event e46f193 [Dev Deps] update @ljharb/eslint-config, tape df3da14 [Dev Deps] update auto-changelog; add aud e2e8a12 [meta] add funding field 7df404b [Dev Deps] update auto-changelog 0d6b76d [Tests] only audit prod deps 246151c [meta] fix changelog c2d1685 [readme] Fix spelling error 25fb2b5 v1.0.1 - 2019-08-10 Commits [meta] avoid running safe-publish-latest when not publishing df44b27 v1.0.0 - 2019-08-10 Commits [Tests] add .travis.yml 764b0cf Initial commit da7d068 readme 1395bb2 [Tests] add tests 0ff580f implementation 8811c32 npm init cffdea9 [Tests] add npm run lint a8be993 [meta] add FUNDING.yml 941258c Only apps should have lockfiles 6857316 [Tests] use npx aud in posttest ee48a91"
  },
  "node_modules/which-boxed-primitive/README.html": {
    "href": "node_modules/which-boxed-primitive/README.html",
    "title": "which-boxed-primitive | accouter",
    "keywords": "which-boxed-primitive Which kind of boxed JS primitive is this? This module works cross-realm/iframe, does not depend on instanceof or mutable properties, and works despite ES6 Symbol.toStringTag. Example var whichBoxedPrimitive = require('which-boxed-primitive'); var assert = require('assert'); // unboxed primitives return `null` // boxed primitives return the builtin constructor name assert.equal(whichBoxedPrimitive(undefined), null); assert.equal(whichBoxedPrimitive(null), null); assert.equal(whichBoxedPrimitive(false), null); assert.equal(whichBoxedPrimitive(true), null); assert.equal(whichBoxedPrimitive(new Boolean(false)), 'Boolean'); assert.equal(whichBoxedPrimitive(new Boolean(true)), 'Boolean'); assert.equal(whichBoxedPrimitive(42), null); assert.equal(whichBoxedPrimitive(NaN), null); assert.equal(whichBoxedPrimitive(Infinity), null); assert.equal(whichBoxedPrimitive(new Number(42)), 'Number'); assert.equal(whichBoxedPrimitive(new Number(NaN)), 'Number'); assert.equal(whichBoxedPrimitive(new Number(Infinity)), 'Number'); assert.equal(whichBoxedPrimitive(''), null); assert.equal(whichBoxedPrimitive('foo'), null); assert.equal(whichBoxedPrimitive(new String('')), 'String'); assert.equal(whichBoxedPrimitive(new String('foo')), 'String'); assert.equal(whichBoxedPrimitive(Symbol()), null); assert.equal(whichBoxedPrimitive(Object(Symbol()), 'Symbol'); assert.equal(whichBoxedPrimitive(42n), null); assert.equal(whichBoxedPrimitive(Object(42n), 'BigInt'); // non-boxed-primitive objects return `undefined` assert.equal(whichBoxedPrimitive([]), undefined); assert.equal(whichBoxedPrimitive({}), undefined); assert.equal(whichBoxedPrimitive(/a/g), undefined); assert.equal(whichBoxedPrimitive(new RegExp('a', 'g')), undefined); assert.equal(whichBoxedPrimitive(new Date()), undefined); assert.equal(whichBoxedPrimitive(function () {}), undefined); assert.equal(whichBoxedPrimitive(function* () {}), undefined); assert.equal(whichBoxedPrimitive(x => x * x), undefined); assert.equal(whichBoxedPrimitive([]), undefined); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/which-typed-array/CHANGELOG.html": {
    "href": "node_modules/which-typed-array/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning. v1.1.15 - 2024-03-10 Commits [types] use a namespace; improve type f42bec3 [types] use shared config 464a9e3 [actions] remove redundant finisher; use reusable workflow d114ee8 [Dev Deps] update @types/node, tape, typescript; add @arethetypeswrong/cli 9cc63d8 [types] add a helpful hover description 29ccf8d [Deps] update available-typed-arrays, call-bind, has-tostringtag 7ecfd8e v1.1.14 - 2024-02-01 Commits [patch] add types 49c4d4c [Dev Deps] update aud, npmignore, tape e5fab7b [Deps] update available-typed-arrays, call-bind 97e2b44 [Deps] update has-tostringtag 1efa8bf v1.1.13 - 2023-10-19 Commits [Refactor] avoid call-binding entirely when there is no method to bind 9ff452b v1.1.12 - 2023-10-19 Commits [Fix] somehow node 0.12 - 3 can hit here, and they lack slice but have set c28e9b8 [Deps] update call-bind a648554 [Dev Deps] update tape 7a094d6 v1.1.11 - 2023-07-17 Commits [Fix] node &lt; v0.6 lacks proper Object toString behavior b8fd654 [Dev Deps] update tape e1734c9 v1.1.10 - 2023-07-10 Commits [actions] update rebase action to use reusable workflow 2c10582 [Robustness] use call-bind b2335fd [Dev Deps] update @ljharb/eslint-config, aud, tape ad5e41b v1.1.9 - 2022-11-02 Commits [Dev Deps] update aud, is-callable, tape 9a20b3c [Refactor] use gopd instead of es-abstract helper 00157af [Deps] update is-typed-array 6714240 [meta] add sideEffects flag 89b96cc v1.1.8 - 2022-05-14 Commits [actions] reuse common workflows 95ea6c0 [meta] use npmignore to autogenerate an npmignore file d08436a [readme] add github actions/codecov badges 35ae3af [Dev Deps] update eslint, @ljharb/eslint-config, safe-publish-latest, tape 86e6e3a [actions] update codecov uploader 0aa6e30 [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, tape a881a78 [Refactor] use for-each instead of foreach 9dafa03 [Deps] update es-abstract, is-typed-array 0684022 [Deps] update es-abstract, is-typed-array 633a529 v1.1.7 - 2021-08-30 Commits [Refactor] use globalThis if available 2a16d1f [meta] changelog cleanup ba99f56 [Dev Deps] update @ljharb/eslint-config 19a6e04 [Deps] update available-typed-arrays 50dbc58 [Deps] update is-typed-array c1b83ea v1.1.6 - 2021-08-06 Fixed [Fix] if Symbol.toStringTag exists but is not present, use Object.prototype.toString #51 #49 Commits [Dev Deps] update is-callable, tape 63eb1e3 [Deps] update is-typed-array c5056f0 v1.1.5 - 2021-08-05 Commits [actions] use node/install instead of node/run; use codecov action 63fa8dd [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, is-callable, tape 1107c74 [Deps] update available-typed-arrays, call-bind, es-abstract, is-typed-array f953454 [Fix] use has-tostringtag to behave correctly in the presence of symbol shams 8aee720 [meta] use prepublishOnly script for npm 7+ 6c5167b v1.1.4 - 2020-12-05 Commits [meta] npmignore github action workflows aa427e7 v1.1.3 - 2020-12-05 Commits [Tests] migrate tests to Github Actions 803d4dd [Tests] run nyc on all tests 205a13f [Dev Deps] update eslint, @ljharb/eslint-config, aud, auto-changelog, is-callable, tape 97ceb07 [actions] add \"Allow Edits\" workflow b140492 [Deps] update es-abstract; use call-bind where applicable 2abdb87 [actions] switch Automatic Rebase workflow to pull_request_target event 256d34b [Dev Deps] update auto-changelog; add aud ddea96f [meta] gitignore nyc output 8a812bd v1.1.2 - 2020-04-07 Commits [Dev Deps] update make-arrow-function, make-generator-function 28c61ef [Dev Deps] update @ljharb/eslint-config a233879 [Dev Deps] update auto-changelog df0134c [Fix] move foreach to dependencies 6ef29c0 [Tests] only audit prod deps eb21044 [Deps] update es-abstract 5ef0236 [Dev Deps] update tape 7456037 [Deps] update available-typed-arrays 8a856c9 v1.1.1 - 2020-01-24 Commits [Tests] use shared travis-ci configs 0a627d9 [meta] add auto-changelog 2a14c58 [meta] remove unused Makefile and associated utilities 75f7f22 [Tests] up to node v12.10, v11.15, v10.16, v8.16, v6.17 4162327 [Refactor] use es-abstract’s callBound, available-typed-arrays, has-symbols 9b04a2a [readme] fix repo URLs, remove testling 03ed52f [Dev Deps] update eslint, @ljharb/eslint-config, replace, semver, tape bfbcf3e [actions] add automatic rebasing / merge commit blocking cc88ac5 [meta] create FUNDING.yml acbc723 [Dev Deps] update eslint, @ljharb/eslint-config, is-callable, tape f1ab63e [Dev Deps] update eslint, @ljharb/eslint-config; add safe-publish-latest ac9f50b [Tests] use npx aud instead of nsp or npm audit with hoops aaaa15d [Dev Deps] update eslint, @ljharb/eslint-config, tape 602fc9a [Deps] update available-typed-arrays, is-typed-array b2d69b6 [meta] add funding field 156f613 v1.1.0 - 2019-02-16 Commits [Tests] remove jscs 381c9b4 [Tests] up to node v8.2, v7.10, v6.11, v5.8; improve matrix; newer npm breaks on older node 7015c19 [Tests] up to node v10.0, v9.11, v8.11, v6.14, v4.9; use nvm install-latest-npm ad67885 [Tests] up to node v11.6, v10.15, v8.15, v6.16 dd94bfb [Refactor] use an array instead of an object for storing Typed Array names de98bc1 [meta] ignore test.html 06cfb1b [Tests] up to node v7.0, v6.9, v4.6; improve test matrix df76eaa [New] add BigInt64Array and BigUint64Array d6bca3a [Dev Deps] update jscs, nsp, eslint f23b45b [Dev Deps] update @ljharb/eslint-config, eslint, semver, tape ddb4484 [Dev Deps] update eslint, @ljharb/eslint-config, covert, is-callable, replace, semver, tape 4524e59 [Dev Deps] update tape, jscs, nsp, eslint, @ljharb/eslint-config, semver 1ec7056 [Dev Deps] update jscs, nsp, eslint, @ljharb/eslint-config 799487d [Dev Deps] update tape, jscs, nsp, eslint, @ljharb/eslint-config, semver 8092598 [Tests] up to node v11.10 a5aabb1 [Dev Deps] update @ljharb/eslint-config, eslint, nsp, semver, tape 277be33 [Tests] use npm audit instead of nsp ee97dc7 [Dev Deps] update tape, eslint, @ljharb/eslint-config 262ffb0 [Dev Deps] update jscs, eslint, @ljharb/eslint-config d6bbcfc [Tests] up to node v6.2 2ff89eb Only apps should have lockfiles e2bc271 [Dev Deps] update nsp, eslint, @ljharb/eslint-config b79e93b [Dev Deps] update nsp, eslint, @ljharb/eslint-config 016dbff [Dev Deps] update eslint, tape 6ce4bbc [Tests] on node v10.1 f0683a0 [Tests] up to node v7.2 2f29cef [Dev Deps] update replace 73b5ba6 [Deps] update function-bind c8a18c2 [Tests] on node v5.12 812102b [Tests] on node v5.10 271584f v1.0.1 - 2016-03-19 Commits [Dev Deps] update tape, jscs, nsp, eslint, @ljharb/eslint-config, semver, is-callable 4a628c5 [Dev Deps] update tape, jscs, nsp, eslint, @ljharb/eslint-config, is-callable 8e09372 [Tests] up to node v5.6, v4.3 3a35bf9 [Dev Deps] update jscs, eslint, @ljharb/eslint-config 9410d5e [Fix] Symbol.toStringTag is on the super-[[Prototype]] of Float32Array, not the [[Prototype]]. 7c40a3a [Tests] up to node v5.9, v4.4 07878e7 Use the object form of \"author\" in package.json 65caa56 [Tests] use pretest/posttest for linting/security c170f7e [Deps] update is-typed-array 9ab324e [Deps] update function-bind a723142 [Deps] update is-typed-array ed82ce4 [Tests] on node v4.2 f581c20 v1.0.0 - 2015-10-05 Commits Dotfiles / Makefile 667f89a Tests. a14d05e package.json 560b1aa Read me a22096e Implementation 0b1ae28 Initial commit 4b32f0a"
  },
  "node_modules/which-typed-array/README.html": {
    "href": "node_modules/which-typed-array/README.html",
    "title": "which-typed-array | accouter",
    "keywords": "which-typed-array Which kind of Typed Array is this JavaScript value? Works cross-realm, without instanceof, and despite Symbol.toStringTag. Example var whichTypedArray = require('which-typed-array'); var assert = require('assert'); assert.equal(false, whichTypedArray(undefined)); assert.equal(false, whichTypedArray(null)); assert.equal(false, whichTypedArray(false)); assert.equal(false, whichTypedArray(true)); assert.equal(false, whichTypedArray([])); assert.equal(false, whichTypedArray({})); assert.equal(false, whichTypedArray(/a/g)); assert.equal(false, whichTypedArray(new RegExp('a', 'g'))); assert.equal(false, whichTypedArray(new Date())); assert.equal(false, whichTypedArray(42)); assert.equal(false, whichTypedArray(NaN)); assert.equal(false, whichTypedArray(Infinity)); assert.equal(false, whichTypedArray(new Number(42))); assert.equal(false, whichTypedArray('foo')); assert.equal(false, whichTypedArray(Object('foo'))); assert.equal(false, whichTypedArray(function () {})); assert.equal(false, whichTypedArray(function* () {})); assert.equal(false, whichTypedArray(x => x * x)); assert.equal(false, whichTypedArray([])); assert.equal('Int8Array', whichTypedArray(new Int8Array())); assert.equal('Uint8Array', whichTypedArray(new Uint8Array())); assert.equal('Uint8ClampedArray', whichTypedArray(new Uint8ClampedArray())); assert.equal('Int16Array', whichTypedArray(new Int16Array())); assert.equal('Uint16Array', whichTypedArray(new Uint16Array())); assert.equal('Int32Array', whichTypedArray(new Int32Array())); assert.equal('Uint32Array', whichTypedArray(new Uint32Array())); assert.equal('Float32Array', whichTypedArray(new Float32Array())); assert.equal('Float64Array', whichTypedArray(new Float64Array())); assert.equal('BigInt64Array', whichTypedArray(new BigInt64Array())); assert.equal('BigUint64Array', whichTypedArray(new BigUint64Array())); Tests Simply clone the repo, npm install, and run npm test"
  },
  "node_modules/which/CHANGELOG.html": {
    "href": "node_modules/which/CHANGELOG.html",
    "title": "Changes | accouter",
    "keywords": "Changes 1.3.1 update deps update travis v1.3.0 Add nothrow option to which.sync update tap v1.2.14 appveyor: drop node 5 and 0.x travis-ci: add node 6, drop 0.x v1.2.13 test: Pass missing option to pass on windows update tap update isexe to 2.0.0 neveragain.tech pledge request v1.2.12 Removed unused require v1.2.11 Prevent changelog script from being included in package v1.2.10 Use env.PATH only, not env.Path v1.2.9 fix for paths starting with ../ Remove unused is-absolute module v1.2.8 bullet items in changelog that contain (but don't start with) # v1.2.7 strip 'update changelog' changelog entries out of changelog v1.2.6 make the changelog bulleted v1.2.5 make a changelog, and keep it up to date don't include tests in package Properly handle relative-path executables appveyor Attach error code to Not Found error Make tests pass on Windows v1.2.4 Fix typo v1.2.3 update isexe, fix regression in pathExt handling v1.2.2 update deps, use isexe module, test windows v1.2.1 Sometimes windows PATH entries are quoted Fixed a bug in the check for group and user mode bits. This bug was introduced during refactoring for supporting strict mode. doc cli v1.2.0 Add support for opt.all and -as cli flags test the bin update travis Allow checking for multiple programs in bin/which tap 2 v1.1.2 travis Refactored and fixed undefined error on Windows Support strict mode v1.1.1 test +g exes against secondary groups, if available Use windows exe semantics on cygwin & msys cwd should be first in path on win32, not last Handle lower-case 'env.Path' on Windows Update docs use single-quotes v1.1.0 Add tests, depend on is-absolute v1.0.9 which.js: root is allowed to execute files owned by anyone v1.0.8 don't use graceful-fs v1.0.7 add license to package.json v1.0.6 isc license 1.0.5 Awful typo 1.0.4 Test for path absoluteness properly win: Allow '' as a pathext if cmd has a . in it 1.0.3 Remove references to execPath Make which.sync() work on Windows by honoring the PATHEXT variable. Make isExe() always return true on Windows. MIT 1.0.2 Only files can be exes 1.0.1 Respect the PATHEXT env for win32 support should 0755 the bin binary guts package 1st"
  },
  "node_modules/which/README.html": {
    "href": "node_modules/which/README.html",
    "title": "which | accouter",
    "keywords": "which Like the unix which utility. Finds the first instance of a specified executable in the PATH environment variable. Does not cache the results, so hash -r is not needed when the PATH changes. USAGE var which = require('which') // async usage which('node', function (er, resolvedPath) { // er is returned if no \"node\" is found on the PATH // if it is found, then the absolute path to the exec is returned }) // sync usage // throws if not found var resolved = which.sync('node') // if nothrow option is used, returns null if not found resolved = which.sync('node', {nothrow: true}) // Pass options to override the PATH and PATHEXT environment vars. which('node', { path: someOtherPath }, function (er, resolved) { if (er) throw er console.log('found at %j', resolved) }) CLI USAGE Same as the BSD which(1) binary. usage: which [-as] program ... OPTIONS You may pass an options object as the second argument. path: Use instead of the PATH environment variable. pathExt: Use instead of the PATHEXT environment variable. all: Return all matches, instead of just the first one. Note that this means the function returns an array of strings instead of a single string."
  },
  "node_modules/workerpool/HISTORY.html": {
    "href": "node_modules/workerpool/HISTORY.html",
    "title": "workerpool history | accouter",
    "keywords": "workerpool history https://github.com/josdejong/workerpool 2022-04-11, version 6.2.1 Fix #343: .terminate() sometimes throwing an exception. 2022-01-15, version 6.2.0 Implement callbacks onCreateWorker and onTerminateWorker. Thanks @forty. Fix #326: robustness fix when terminating a workerpool. 2021-06-17, version 6.1.5 Fix v6.1.4 not being marked as latest anymore on npm due to bug fix release v2.3.4. 2021-04-05, version 6.1.4 Fix terminating a pool throwing an error when used in the browser. Regression introduced in v6.1.3. 2021-04-01, version 6.1.3 Fix #147: disregard messages from terminated workers. Thanks @hhprogram and @Madgvox. 2021-03-09, version 6.1.2 Fix #253, add ./src again in the published npm package, reverting the change in v6.1.1 (see also #243). 2021-03-08, version 6.1.1 Remove redundant ./src folder from the published npm package, see #243. Thanks @Nytelife26. 2021-01-31, version 6.1.0 Implemented support for sending events from the worker to the main thread, see #51, #227. Thanks @Akryum. Fix an issue in Node.js nightly, see #230. Thanks @aduh95. Fix #232 workerpool not working on IE 10. 2021-01-16, version 6.0.4 Make evaluation of offloaded functions a bit more secure by using new Function instead of eval. Thanks @tjenkinson. 2020-10-28, version 6.0.3 Fixes and more robustness in terminating workers. Thanks @boneskull. 2020-10-03, version 6.0.2 Fix #32, #175: the promise returned by Pool.terminate() now waits until subprocesses are dead before resolving. Thanks @boneskull. 2020-09-23, version 6.0.1 Removed examples from the npm package. Thanks @madbence. 2020-05-13, version 6.0.0 WARNING: the library entry points are changed and new source maps are added. This may have impact on your project depending on your setup. Created separate library entry points in package.json for node.js and browser. Thanks @boneskull. Generated source maps for both minified and non-minified bundles. Removed deprecation warnings for options.nodeWorker (renamed to options.workerType) and pool.clear() (renamed to pool.terminate()). 2019-12-31, version 5.0.4 Fixed #121: isMainThread not working when using worker_threads. Drop official support for node.js 8 (end of life). 2019-12-23, version 5.0.3 Fixed library not working in the browser. See #106. 2019-11-06, version 5.0.2 Fixed environment detection in browser. See #106. Thanks @acgrid. 2019-10-13, version 5.0.1 Fixed #96: WorkerPool not cancelling any pending tasks on termination. 2019-08-25, version 5.0.0 Deprecated option nodeWorker and created a new, more extensive option workerType giving full control over the selected type of worker. Added new option 'web' to enforce use a Web Worker. See #85, #74. In a node.js environment, the default workerType is changed from 'process' to 'thread'. See #85, #50. Improved detection of environment (browser or node), fixing wrong detection in a Jest test environment. See #85. 2019-08-21, version 4.0.0 Pass argument --max-old-space-size to child processes. Thanks @patte. Removed redundant dependencies, upgraded all devDependencies. Fixed Webpack issues of missing modules child_process and worker_threads. See #43. Bundled library changed due to the upgrade to Webpack 4. This could possibly lead to breaking changes. Implemented new option maxQueueSize. Thanks @colomboe. Fixed exiting workers when the parent process is killed. Thanks @RogerKang. Fixed #81: Option minWorkers: 'max' not using the configured maxWorkers. Fixed not passing nodeWorker to workers initialized when creating a pool. Thanks @spacelan. Internal restructure of the code: moved from lib to src. 2019-03-12, version 3.1.2 Improved error message when a node.js worker unexpectedly exits (see #58). Thanks @stefanpenner. Allocate debug ports safely, this fixes an issue cause workers to exit unexpectedly if more then one worker pool is active, and the process is started with a debugger (node debug or node --inspect). Thanks @stefanpenner. 2019-02-25, version 3.1.1 Fix option nodeWorker: 'auto' not using worker threads when available. Thanks @stefanpenner. 2019-02-17, version 3.1.0 Implemented support for using worker_threads in Node.js, via the new option nodeWorker: 'thread'. Thanks @stefanpenner. 2018-12-11, version 3.0.0 Enable usage in ES6 Webpack projects. Dropped support for AMD module system. 2021-06-17, version 2.3.4 Backport fix for Node.js 16, see #309. Thanks @mansona. 2018-09-12, version 2.3.3 Fixed space in license field in package.json. Thanks @sagotsky. 2018-09-08, version 2.3.2 Add licence field to package.json. Thanks @greyd. 2018-07-24, version 2.3.1 Fixed bug where tasks that are cancelled in a Pool's queue causes following tasks to not run. Thanks @greemo. 2017-09-30, version 2.3.0 New method Pool.terminate(force, timeout) which will replace Pool.clear(force). Thanks @jimsugg. Fixed issue with never terminating zombie child processes. Thanks @jimsugg. 2017-08-20, version 2.2.4 Fixed a debug issue: look for --inspect within argument strings, instead of exact match. Thanks @jimsugg. 2017-08-19, version 2.2.3 Updated all examples to neatly include .catch(...) callbacks. 2017-07-08, version 2.2.2 Fixed #25: timer of a timeout starting when the task is created instead of when the task is started. Thanks @eclipsesk for input. 2017-05-07, version 2.2.1 Fixed #2 and #19: support for debugging child processes. Thanks @tptee. 2016-11-26, version 2.2.0 Implemented #18: method pool.stats(). 2016-10-11, version 2.1.0 Implemented support for registering the workers methods asynchronously. This enables asynchronous initialization of workers, for example when using AMD modules. Thanks @natlibfi-arlehiko. Implemented environment variables platform, isMainThread, and cpus. Thanks @natlibfi-arlehiko. Implemented option minWorkers. Thanks @sergei202. 2016-09-18, version 2.0.0 Replaced conversion of Error-objecting using serializerr to custom implementation to prevent issues with serializing/deserializing functions. This conversion implementation loses the prototype object which means that e.g. 'TypeError' will become just 'Error' in the main code. See #8. Thanks @natlibfi-arlehiko. 2016-09-12, version 1.3.1 Fix for a bug in PhantomJS (see #7). Thanks @natlibfi-arlehiko. 2016-08-21, version 1.3.0 Determine maxWorkers as the number of CPU's minus one in browsers too. See #6. 2016-06-25, version 1.2.1 Fixed #5 error when loading via AMD or bundling using Webpack. 2016-05-22, version 1.2.0 Implemented serializing errors with stacktrace. Thanks @mujx. 2016-01-25, version 1.1.0 Added an error message when wrongly calling pool.proxy. Fixed function worker.pool not accepting both a script and options. See #1. Thanks @freund17. 2014-05-29, version 1.0.0 Merged function Pool.run into Pool.exec, simplifying the API. 2014-05-14, version 0.2.0 Implemented support for cancelling running tasks. Implemented support for cancelling running tasks after a timeout. 2014-05-07, version 0.1.0 Implemented support for both node.js and the browser. Implemented offloading functions. Implemented worker proxy. Added docs and examples. 2014-05-02, version 0.0.1 Module name registered at npm."
  },
  "node_modules/workerpool/README.html": {
    "href": "node_modules/workerpool/README.html",
    "title": "workerpool | accouter",
    "keywords": "workerpool workerpool offers an easy way to create a pool of workers for both dynamically offloading computations as well as managing a pool of dedicated workers. workerpool basically implements a thread pool pattern. There is a pool of workers to execute tasks. New tasks are put in a queue. A worker executes one task at a time, and once finished, picks a new task from the queue. Workers can be accessed via a natural, promise based proxy, as if they are available straight in the main application. workerpool runs on node.js, Chrome, Firefox, Opera, Safari, and IE10+. Features Easy to use Runs in the browser and on node.js Dynamically offload functions to a worker Access workers via a proxy Cancel running tasks Set a timeout on tasks Handles crashed workers Small: 5 kB minified and gzipped Why JavaScript is based upon a single event loop which handles one event at a time. Jeremy Epstein explains this clearly: In Node.js everything runs in parallel, except your code. What this means is that all I/O code that you write in Node.js is non-blocking, while (conversely) all non-I/O code that you write in Node.js is blocking. This means that CPU heavy tasks will block other tasks from being executed. In case of a browser environment, the browser will not react to user events like a mouse click while executing a CPU intensive task (the browser \"hangs\"). In case of a node.js server, the server will not respond to any new request while executing a single, heavy request. For front-end processes, this is not a desired situation. Therefore, CPU intensive tasks should be offloaded from the main event loop onto dedicated workers. In a browser environment, Web Workers can be used. In node.js, child processes and worker_threads are available. An application should be split in separate, decoupled parts, which can run independent of each other in a parallelized way. Effectively, this results in an architecture which achieves concurrency by means of isolated processes and message passing. Install Install via npm: npm install workerpool Load To load workerpool in a node.js application (both main application as well as workers): const workerpool = require('workerpool'); To load workerpool in the browser: <script src=\"workerpool.js\"></script> To load workerpool in a web worker in the browser: importScripts('workerpool.js'); Use Offload functions dynamically In the following example there is a function add, which is offloaded dynamically to a worker to be executed for a given set of arguments. myApp.js const workerpool = require('workerpool'); const pool = workerpool.pool(); function add(a, b) { return a + b; } pool.exec(add, [3, 4]) .then(function (result) { console.log('result', result); // outputs 7 }) .catch(function (err) { console.error(err); }) .then(function () { pool.terminate(); // terminate all workers when done }); Note that both function and arguments must be static and stringifiable, as they need to be sent to the worker in a serialized form. In case of large functions or function arguments, the overhead of sending the data to the worker can be significant. Dedicated workers A dedicated worker can be created in a separate script, and then used via a worker pool. myWorker.js const workerpool = require('workerpool'); // a deliberately inefficient implementation of the fibonacci sequence function fibonacci(n) { if (n < 2) return n; return fibonacci(n - 2) + fibonacci(n - 1); } // create a worker and register public functions workerpool.worker({ fibonacci: fibonacci }); This worker can be used by a worker pool: myApp.js const workerpool = require('workerpool'); // create a worker pool using an external worker script const pool = workerpool.pool(__dirname + '/myWorker.js'); // run registered functions on the worker via exec pool.exec('fibonacci', [10]) .then(function (result) { console.log('Result: ' + result); // outputs 55 }) .catch(function (err) { console.error(err); }) .then(function () { pool.terminate(); // terminate all workers when done }); // or run registered functions on the worker via a proxy: pool.proxy() .then(function (worker) { return worker.fibonacci(10); }) .then(function (result) { console.log('Result: ' + result); // outputs 55 }) .catch(function (err) { console.error(err); }) .then(function () { pool.terminate(); // terminate all workers when done }); Worker can also initialize asynchronously: myAsyncWorker.js define(['workerpool/dist/workerpool'], function(workerpool) { // a deliberately inefficient implementation of the fibonacci sequence function fibonacci(n) { if (n < 2) return n; return fibonacci(n - 2) + fibonacci(n - 1); } // create a worker and register public functions workerpool.worker({ fibonacci: fibonacci }); }); Examples Examples are available in the examples directory: https://github.com/josdejong/workerpool/tree/master/examples API The API of workerpool consists of two parts: a function workerpool.pool to create a worker pool, and a function workerpool.worker to create a worker. pool A workerpool can be created using the function workerpool.pool: workerpool.pool([script: string] [, options: Object]) : Pool When a script argument is provided, the provided script will be started as a dedicated worker. When no script argument is provided, a default worker is started which can be used to offload functions dynamically via Pool.exec. Note that on node.js, script must be an absolute file path like __dirname + '/myWorker.js'. In a browser environment, script can also be a data URL like 'data:application/javascript;base64,...'. This allows embedding the bundled code of a worker in your main application. See examples/embeddedWorker for a demo. The following options are available: minWorkers: number | 'max'. The minimum number of workers that must be initialized and kept available. Setting this to 'max' will create maxWorkers default workers (see below). maxWorkers: number. The default number of maxWorkers is the number of CPU's minus one. When the number of CPU's could not be determined (for example in older browsers), maxWorkers is set to 3. maxQueueSize: number. The maximum number of tasks allowed to be queued. Can be used to prevent running out of memory. If the maximum is exceeded, adding a new task will throw an error. The default value is Infinity. workerType: 'auto' | 'web' | 'process' | 'thread'. In case of 'auto' (default), workerpool will automatically pick a suitable type of worker: when in a browser environment, 'web' will be used. When in a node.js environment, worker_threads will be used if available (Node.js >= 11.7.0), else child_process will be used. In case of 'web', a Web Worker will be used. Only available in a browser environment. In case of 'process', child_process will be used. Only available in a node.js environment. In case of 'thread', worker_threads will be used. If worker_threads are not available, an error is thrown. Only available in a node.js environment. forkArgs: String[]. For process worker type. An array passed as args to child_process.fork forkOpts: Object. For process worker type. An object passed as options to child_process.fork. See nodejs documentation for available options. onCreateWorker: Function. A callback that is called whenever a worker is being created. It can be used to allocate resources for each worker for example. The callback is passed as argument an object with the following properties: forkArgs: String[]: the forkArgs option of this pool forkOpts: Object: the forkOpts option of this pool script: string: the script option of this pool Optionally, this callback can return an object containing one or more of the above properties. The provided properties will be used to override the Pool properties for the worker being created. onTerminateWorker: Function. A callback that is called whenever a worker is being terminated. It can be used to release resources that might have been allocated for this specific worker. The callback is passed as argument an object as described for onCreateWorker, with each property sets with the value for the worker being terminated. Important note on 'workerType': when sending and receiving primitive data types (plain JSON) from and to a worker, the different worker types ('web', 'process', 'thread') can be used interchangeably. However, when using more advanced data types like buffers, the API and returned results can vary. In these cases, it is best not to use the 'auto' setting but have a fixed 'workerType' and good unit testing in place. A worker pool contains the following functions: Pool.exec(method: Function | string, params: Array | null [, options: Object]) : Promise.<*, Error> Execute a function on a worker with given arguments. When method is a string, a method with this name must exist at the worker and must be registered to make it accessible via the pool. The function will be executed on the worker with given parameters. When method is a function, the provided function fn will be stringified, send to the worker, and executed there with the provided parameters. The provided function must be static, it must not depend on variables in a surrounding scope. The following options are available: on: (payload: any) => void. An event listener, to handle events sent by the worker for this execution. See Events for more details. Pool.proxy() : Promise.<Object, Error> Create a proxy for the worker pool. The proxy contains a proxy for all methods available on the worker. All methods return promises resolving the methods result. Pool.stats() : Object Retrieve statistics on workers, and active and pending tasks. Returns an object containing the following properties: { totalWorkers: 0, busyWorkers: 0, idleWorkers: 0, pendingTasks: 0, activeTasks: 0 } Pool.terminate([force: boolean [, timeout: number]]) If parameter force is false (default), workers will finish the tasks they are working on before terminating themselves. Any pending tasks will be rejected with an error 'Pool terminated'. When force is true, all workers are terminated immediately without finishing running tasks. If timeout is provided, worker will be forced to terminate when the timeout expires and the worker has not finished. The function Pool.exec and the proxy functions all return a Promise. The promise has the following functions available: Promise.then(fn: Function.<result: *>) Get the result of the promise once resolve. Promise.catch(fn: Function.<error: Error>) Get the error of the promise when rejected. Promise.cancel() A running task can be cancelled. The worker executing the task is enforced to terminate immediately. The promise will be rejected with a Promise.CancellationError. Promise.timeout(delay: number) Cancel a running task when it is not resolved or rejected within given delay in milliseconds. The timer will start when the task is actually started, not when the task is created and queued. The worker executing the task is enforced to terminate immediately. The promise will be rejected with a Promise.TimeoutError. Example usage: const workerpool = require('workerpool'); function add(a, b) { return a + b; } const pool1 = workerpool.pool(); // offload a function to a worker pool1.exec(add, [2, 4]) .then(function (result) { console.log(result); // will output 6 }) .catch(function (err) { console.error(err); }); // create a dedicated worker const pool2 = workerpool.pool(__dirname + '/myWorker.js'); // supposed myWorker.js contains a function 'fibonacci' pool2.exec('fibonacci', [10]) .then(function (result) { console.log(result); // will output 55 }) .catch(function (err) { console.error(err); }); // create a proxy to myWorker.js pool2.proxy() .then(function (myWorker) { return myWorker.fibonacci(10) }) .then(function (result) { console.log(result); // will output 55 }) .catch(function (err) { console.error(err); }); // create a pool with a specified maximum number of workers const pool3 = workerpool.pool({maxWorkers: 7}); worker A worker is constructed as: workerpool.worker([methods: Object.<String, Function>]) Argument methods is optional can can be an object with functions available in the worker. Registered functions will be available via the worker pool. Example usage: // file myWorker.js const workerpool = require('workerpool'); function add(a, b) { return a + b; } function multiply(a, b) { return a * b; } // create a worker and register functions workerpool.worker({ add: add, multiply: multiply }); Asynchronous results can be handled by returning a Promise from a function in the worker: // file myWorker.js const workerpool = require('workerpool'); function timeout(delay) { return new Promise(function (resolve, reject) { setTimeout(resolve, delay) }); } // create a worker and register functions workerpool.worker({ timeout: timeout }); Events You can send data back from workers to the pool while the task is being executed using the workerEmit function: workerEmit(payload: any) This function only works inside a worker and during a task. Example: // file myWorker.js const workerpool = require('workerpool'); function eventExample(delay) { workerpool.workerEmit({ status: 'in_progress' }); workerpool.workerEmit({ status: 'complete' }); return true; } // create a worker and register functions workerpool.worker({ eventExample: eventExample }); To receive those events, you can use the on option of the pool exec method: pool.exec('eventExample', [], { on: function (payload) { if (payload.status === 'in_progress') { console.log('In progress...'); } else if (payload.status === 'complete') { console.log('Done!'); } } }) Utilities Following properties are available for convenience: platform: The Javascript platform. Either node or browser isMainThread: Whether the code is running in main thread or not (Workers) cpus: The number of CPUs/cores available Roadmap Implement functions for parallel processing: map, reduce, forEach, filter, some, every, ... Implement graceful degradation on old browsers not supporting webworkers: fallback to processing tasks in the main application. Implement session support: be able to handle a series of related tasks by a single worker, which can keep a state for the session. Related libraries https://github.com/andywer/threads.js https://github.com/piscinajs/piscina https://github.com/learnboost/cluster https://github.com/adambom/parallel.js https://github.com/padolsey/operative https://github.com/calvinmetcalf/catiline https://github.com/Unitech/pm2 https://github.com/godaddy/node-cluster-service https://github.com/ramesaliyev/EasyWebWorker https://github.com/rvagg/node-worker-farm Build First clone the project from github: git clone git://github.com/josdejong/workerpool.git cd workerpool Install the project dependencies: npm install Then, the project can be build by executing the build script via npm: npm run build This will build the library workerpool.js and workerpool.min.js from the source files and put them in the folder dist. Test To execute tests for the library, install the project dependencies once: npm install Then, the tests can be executed: npm test To test code coverage of the tests: npm run coverage To see the coverage results, open the generated report in your browser: ./coverage/lcov-report/index.html Publish Describe changes in HISTORY.md Update version in package.json, run npm install to update it in package-lock.json too. Push to github Deploy to npm via npm publish Add a git tag with the version number like: git tag v1.2.3 git push --tags License Copyright (C) 2014-2022 Jos de Jong wjosdejong@gmail.com Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
  },
  "node_modules/wrap-ansi-cjs/readme.html": {
    "href": "node_modules/wrap-ansi-cjs/readme.html",
    "title": "wrap-ansi | accouter",
    "keywords": "wrap-ansi Wordwrap a string with ANSI escape codes Install $ npm install wrap-ansi Usage const chalk = require('chalk'); const wrapAnsi = require('wrap-ansi'); const input = 'The quick brown ' + chalk.red('fox jumped over ') + 'the lazy ' + chalk.green('dog and then ran away with the unicorn.'); console.log(wrapAnsi(input, 20)); API wrapAnsi(string, columns, options?) Wrap words to the specified column width. string Type: string String with ANSI escape codes. Like one styled by chalk. Newline characters will be normalized to \\n. columns Type: number Number of columns to wrap the text to. options Type: object hard Type: boolean Default: false By default the wrap is soft, meaning long words may extend past the column width. Setting this to true will make it hard wrap at the column width. wordWrap Type: boolean Default: true By default, an attempt is made to split words at spaces, ensuring that they don't extend past the configured columns. If wordWrap is false, each column will instead be completely filled splitting words as necessary. trim Type: boolean Default: true Whitespace on all lines is removed by default. Set this option to false if you don't want to trim. Related slice-ansi - Slice a string with ANSI escape codes cli-truncate - Truncate a string to a specific width in the terminal chalk - Terminal string styling done right jsesc - Generate ASCII-only output from Unicode strings. Useful for creating test fixtures. Maintainers Sindre Sorhus Josh Junon Benjamin Coe Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "node_modules/wrap-ansi/readme.html": {
    "href": "node_modules/wrap-ansi/readme.html",
    "title": "wrap-ansi | accouter",
    "keywords": "wrap-ansi Wordwrap a string with ANSI escape codes Install $ npm install wrap-ansi Usage const chalk = require('chalk'); const wrapAnsi = require('wrap-ansi'); const input = 'The quick brown ' + chalk.red('fox jumped over ') + 'the lazy ' + chalk.green('dog and then ran away with the unicorn.'); console.log(wrapAnsi(input, 20)); API wrapAnsi(string, columns, options?) Wrap words to the specified column width. string Type: string String with ANSI escape codes. Like one styled by chalk. Newline characters will be normalized to \\n. columns Type: number Number of columns to wrap the text to. options Type: object hard Type: boolean Default: false By default the wrap is soft, meaning long words may extend past the column width. Setting this to true will make it hard wrap at the column width. wordWrap Type: boolean Default: true By default, an attempt is made to split words at spaces, ensuring that they don't extend past the configured columns. If wordWrap is false, each column will instead be completely filled splitting words as necessary. trim Type: boolean Default: true Whitespace on all lines is removed by default. Set this option to false if you don't want to trim. Related slice-ansi - Slice a string with ANSI escape codes cli-truncate - Truncate a string to a specific width in the terminal chalk - Terminal string styling done right jsesc - Generate ASCII-only output from Unicode strings. Useful for creating test fixtures. Maintainers Sindre Sorhus Josh Junon Benjamin Coe Get professional support for this package with a Tidelift subscription Tidelift helps make open source sustainable for maintainers while giving companies assurances about security, maintenance, and licensing for their dependencies."
  },
  "node_modules/wrappy/README.html": {
    "href": "node_modules/wrappy/README.html",
    "title": "wrappy | accouter",
    "keywords": "wrappy Callback wrapping utility USAGE var wrappy = require(\"wrappy\") // var wrapper = wrappy(wrapperFunction) // make sure a cb is called only once // See also: http://npm.im/once for this specific use case var once = wrappy(function (cb) { var called = false return function () { if (called) return called = true return cb.apply(this, arguments) } }) function printBoo () { console.log('boo') } // has some rando property printBoo.iAmBooPrinter = true var onlyPrintOnce = once(printBoo) onlyPrintOnce() // prints 'boo' onlyPrintOnce() // does nothing // random property is retained! assert.equal(onlyPrintOnce.iAmBooPrinter, true)"
  },
  "node_modules/ws/README.html": {
    "href": "node_modules/ws/README.html",
    "title": "ws: a Node.js WebSocket library | accouter",
    "keywords": "ws: a Node.js WebSocket library ws is a simple to use, blazing fast, and thoroughly tested WebSocket client and server implementation. Passes the quite extensive Autobahn test suite: server, client. Note: This module does not work in the browser. The client in the docs is a reference to a back end with the role of a client in the WebSocket communication. Browser clients must use the native WebSocket object. To make the same code work seamlessly on Node.js and the browser, you can use one of the many wrappers available on npm, like isomorphic-ws. Table of Contents Protocol support Installing Opt-in for performance API docs WebSocket compression Usage examples Sending and receiving text data Sending binary data Simple server External HTTP/S server Multiple servers sharing a single HTTP/S server Client authentication Server broadcast Round-trip time Use the Node.js streams API Other examples FAQ How to get the IP address of the client? How to detect and close broken connections? How to connect via a proxy? Changelog License Protocol support HyBi drafts 07-12 (Use the option protocolVersion: 8) HyBi drafts 13-17 (Current default, alternatively option protocolVersion: 13) Installing npm install ws Opt-in for performance There are 2 optional modules that can be installed along side with the ws module. These modules are binary addons which improve certain operations. Prebuilt binaries are available for the most popular platforms so you don't necessarily need to have a C++ compiler installed on your machine. npm install --save-optional bufferutil: Allows to efficiently perform operations such as masking and unmasking the data payload of the WebSocket frames. npm install --save-optional utf-8-validate: Allows to efficiently check if a message contains valid UTF-8. To not even try to require and use these modules, use the WS_NO_BUFFER_UTIL and WS_NO_UTF_8_VALIDATE environment variables. These might be useful to enhance security in systems where a user can put a package in the package search path of an application of another user, due to how the Node.js resolver algorithm works. API docs See /doc/ws.md for Node.js-like documentation of ws classes and utility functions. WebSocket compression ws supports the permessage-deflate extension which enables the client and server to negotiate a compression algorithm and its parameters, and then selectively apply it to the data payloads of each WebSocket message. The extension is disabled by default on the server and enabled by default on the client. It adds a significant overhead in terms of performance and memory consumption so we suggest to enable it only if it is really needed. Note that Node.js has a variety of issues with high-performance compression, where increased concurrency, especially on Linux, can lead to catastrophic memory fragmentation and slow performance. If you intend to use permessage-deflate in production, it is worthwhile to set up a test representative of your workload and ensure Node.js/zlib will handle it with acceptable performance and memory usage. Tuning of permessage-deflate can be done via the options defined below. You can also use zlibDeflateOptions and zlibInflateOptions, which is passed directly into the creation of raw deflate/inflate streams. See the docs for more options. import WebSocket, { WebSocketServer } from 'ws'; const wss = new WebSocketServer({ port: 8080, perMessageDeflate: { zlibDeflateOptions: { // See zlib defaults. chunkSize: 1024, memLevel: 7, level: 3 }, zlibInflateOptions: { chunkSize: 10 * 1024 }, // Other options settable: clientNoContextTakeover: true, // Defaults to negotiated value. serverNoContextTakeover: true, // Defaults to negotiated value. serverMaxWindowBits: 10, // Defaults to negotiated value. // Below options specified as default values. concurrencyLimit: 10, // Limits zlib concurrency for perf. threshold: 1024 // Size (in bytes) below which messages // should not be compressed if context takeover is disabled. } }); The client will only use the extension if it is supported and enabled on the server. To always disable the extension on the client set the perMessageDeflate option to false. import WebSocket from 'ws'; const ws = new WebSocket('ws://www.host.com/path', { perMessageDeflate: false }); Usage examples Sending and receiving text data import WebSocket from 'ws'; const ws = new WebSocket('ws://www.host.com/path'); ws.on('open', function open() { ws.send('something'); }); ws.on('message', function message(data) { console.log('received: %s', data); }); Sending binary data import WebSocket from 'ws'; const ws = new WebSocket('ws://www.host.com/path'); ws.on('open', function open() { const array = new Float32Array(5); for (var i = 0; i < array.length; ++i) { array[i] = i / 2; } ws.send(array); }); Simple server import { WebSocketServer } from 'ws'; const wss = new WebSocketServer({ port: 8080 }); wss.on('connection', function connection(ws) { ws.on('message', function message(data) { console.log('received: %s', data); }); ws.send('something'); }); External HTTP/S server import { createServer } from 'https'; import { readFileSync } from 'fs'; import { WebSocketServer } from 'ws'; const server = createServer({ cert: readFileSync('/path/to/cert.pem'), key: readFileSync('/path/to/key.pem') }); const wss = new WebSocketServer({ server }); wss.on('connection', function connection(ws) { ws.on('message', function message(data) { console.log('received: %s', data); }); ws.send('something'); }); server.listen(8080); Multiple servers sharing a single HTTP/S server import { createServer } from 'http'; import { parse } from 'url'; import { WebSocketServer } from 'ws'; const server = createServer(); const wss1 = new WebSocketServer({ noServer: true }); const wss2 = new WebSocketServer({ noServer: true }); wss1.on('connection', function connection(ws) { // ... }); wss2.on('connection', function connection(ws) { // ... }); server.on('upgrade', function upgrade(request, socket, head) { const { pathname } = parse(request.url); if (pathname === '/foo') { wss1.handleUpgrade(request, socket, head, function done(ws) { wss1.emit('connection', ws, request); }); } else if (pathname === '/bar') { wss2.handleUpgrade(request, socket, head, function done(ws) { wss2.emit('connection', ws, request); }); } else { socket.destroy(); } }); server.listen(8080); Client authentication import { createServer } from 'http'; import { WebSocketServer } from 'ws'; const server = createServer(); const wss = new WebSocketServer({ noServer: true }); wss.on('connection', function connection(ws, request, client) { ws.on('message', function message(data) { console.log(`Received message ${data} from user ${client}`); }); }); server.on('upgrade', function upgrade(request, socket, head) { // This function is not defined on purpose. Implement it with your own logic. authenticate(request, function next(err, client) { if (err || !client) { socket.write('HTTP/1.1 401 Unauthorized\\r\\n\\r\\n'); socket.destroy(); return; } wss.handleUpgrade(request, socket, head, function done(ws) { wss.emit('connection', ws, request, client); }); }); }); server.listen(8080); Also see the provided example using express-session. Server broadcast A client WebSocket broadcasting to all connected WebSocket clients, including itself. import WebSocket, { WebSocketServer } from 'ws'; const wss = new WebSocketServer({ port: 8080 }); wss.on('connection', function connection(ws) { ws.on('message', function message(data, isBinary) { wss.clients.forEach(function each(client) { if (client.readyState === WebSocket.OPEN) { client.send(data, { binary: isBinary }); } }); }); }); A client WebSocket broadcasting to every other connected WebSocket clients, excluding itself. import WebSocket, { WebSocketServer } from 'ws'; const wss = new WebSocketServer({ port: 8080 }); wss.on('connection', function connection(ws) { ws.on('message', function message(data, isBinary) { wss.clients.forEach(function each(client) { if (client !== ws && client.readyState === WebSocket.OPEN) { client.send(data, { binary: isBinary }); } }); }); }); Round-trip time import WebSocket from 'ws'; const ws = new WebSocket('wss://websocket-echo.com/'); ws.on('open', function open() { console.log('connected'); ws.send(Date.now()); }); ws.on('close', function close() { console.log('disconnected'); }); ws.on('message', function message(data) { console.log(`Round-trip time: ${Date.now() - data} ms`); setTimeout(function timeout() { ws.send(Date.now()); }, 500); }); Use the Node.js streams API import WebSocket, { createWebSocketStream } from 'ws'; const ws = new WebSocket('wss://websocket-echo.com/'); const duplex = createWebSocketStream(ws, { encoding: 'utf8' }); duplex.pipe(process.stdout); process.stdin.pipe(duplex); Other examples For a full example with a browser client communicating with a ws server, see the examples folder. Otherwise, see the test cases. FAQ How to get the IP address of the client? The remote IP address can be obtained from the raw socket. import { WebSocketServer } from 'ws'; const wss = new WebSocketServer({ port: 8080 }); wss.on('connection', function connection(ws, req) { const ip = req.socket.remoteAddress; }); When the server runs behind a proxy like NGINX, the de-facto standard is to use the X-Forwarded-For header. wss.on('connection', function connection(ws, req) { const ip = req.headers['x-forwarded-for'].split(',')[0].trim(); }); How to detect and close broken connections? Sometimes the link between the server and the client can be interrupted in a way that keeps both the server and the client unaware of the broken state of the connection (e.g. when pulling the cord). In these cases ping messages can be used as a means to verify that the remote endpoint is still responsive. import { WebSocketServer } from 'ws'; function heartbeat() { this.isAlive = true; } const wss = new WebSocketServer({ port: 8080 }); wss.on('connection', function connection(ws) { ws.isAlive = true; ws.on('pong', heartbeat); }); const interval = setInterval(function ping() { wss.clients.forEach(function each(ws) { if (ws.isAlive === false) return ws.terminate(); ws.isAlive = false; ws.ping(); }); }, 30000); wss.on('close', function close() { clearInterval(interval); }); Pong messages are automatically sent in response to ping messages as required by the spec. Just like the server example above your clients might as well lose connection without knowing it. You might want to add a ping listener on your clients to prevent that. A simple implementation would be: import WebSocket from 'ws'; function heartbeat() { clearTimeout(this.pingTimeout); // Use `WebSocket#terminate()`, which immediately destroys the connection, // instead of `WebSocket#close()`, which waits for the close timer. // Delay should be equal to the interval at which your server // sends out pings plus a conservative assumption of the latency. this.pingTimeout = setTimeout(() => { this.terminate(); }, 30000 + 1000); } const client = new WebSocket('wss://websocket-echo.com/'); client.on('open', heartbeat); client.on('ping', heartbeat); client.on('close', function clear() { clearTimeout(this.pingTimeout); }); How to connect via a proxy? Use a custom http.Agent implementation like https-proxy-agent or socks-proxy-agent. Changelog We're using the GitHub releases for changelog entries. License MIT"
  },
  "node_modules/xmlhttprequest-ssl/README.html": {
    "href": "node_modules/xmlhttprequest-ssl/README.html",
    "title": "node-XMLHttpRequest | accouter",
    "keywords": "node-XMLHttpRequest Fork of node-XMLHttpRequest by driverdan. Forked and published to npm because a pull request is not being created and merged. Changes made by rase- are needed for engine.io-client. Usage Here's how to include the module in your project and use as the browser-based XHR object. var XMLHttpRequest = require(\"xmlhttprequest-ssl\").XMLHttpRequest; var xhr = new XMLHttpRequest(); Note: use the lowercase string \"xmlhttprequest-ssl\" in your require(). On case-sensitive systems (eg Linux) using uppercase letters won't work. Original README Usage Here's how to include the module in your project and use as the browser-based XHR object. var XMLHttpRequest = require(\"xmlhttprequest\").XMLHttpRequest; var xhr = new XMLHttpRequest(); Note: use the lowercase string \"xmlhttprequest\" in your require(). On case-sensitive systems (eg Linux) using uppercase letters won't work. Versions Version 2.0.0 introduces a potentially breaking change concerning local file system requests. If these requests fail this library now returns the errno (or -1) as the response status code instead of returning status code 0. Prior to 1.4.0 version numbers were arbitrary. From 1.4.0 on they conform to the standard major.minor.bugfix. 1.x shouldn't necessarily be considered stable just because it's above 0.x. Since the XMLHttpRequest API is stable this library's API is stable as well. Major version numbers indicate significant core code changes. Minor versions indicate minor core code changes or better conformity to the W3C spec. License MIT license. See LICENSE for full details. Supports Async and synchronous requests GET, POST, PUT, and DELETE requests All spec methods (open, send, abort, getRequestHeader, getAllRequestHeaders, event methods) Requests to all domains Known Issues / Missing Features For a list of open issues or to report your own visit the github issues page. Local file access may have unexpected results for non-UTF8 files Synchronous requests don't set headers properly Synchronous requests freeze node while waiting for response (But that's what you want, right? Stick with async!). Some events are missing, such as abort getRequestHeader is case-sensitive Cookies aren't persisted between requests Missing XML support Missing basic auth"
  },
  "node_modules/y18n/CHANGELOG.html": {
    "href": "node_modules/y18n/CHANGELOG.html",
    "title": "Change Log | accouter",
    "keywords": "Change Log All notable changes to this project will be documented in this file. See standard-version for commit guidelines. 5.0.8 (2021-04-07) Bug Fixes deno: force modern release for Deno (b1c215a) 5.0.7 (2021-04-07) Bug Fixes deno: force release for deno (#121) (d3f2560) 5.0.6 (2021-04-05) Bug Fixes webpack: skip readFileSync if not defined (#117) (6966fa9) 5.0.5 (2020-10-25) Bug Fixes address prototype pollution issue (#108) (a9ac604) 5.0.4 (2020-10-16) Bug Fixes exports: node 13.0 and 13.1 require the dotted object form with a string fallback (#105) (4f85d80) 5.0.3 (2020-10-16) Bug Fixes exports: node 13.0-13.6 require a string fallback (#103) (e39921e) 5.0.2 (2020-10-01) Bug Fixes deno: update types for deno ^1.4.0 (#100) (3834d9a) 5.0.1 (2020-09-05) Bug Fixes main had old index path (#98) (124f7b0) 5.0.0 (2020-09-05) ⚠ BREAKING CHANGES exports maps are now used, which modifies import behavior. drops Node 6 and 4. begin following Node.js LTS schedule (#89) Features add support for ESM and Deno #95) (4d7ae94) Build System drops Node 6 and 4. begin following Node.js LTS schedule (#89) (3cc0c28) 4.0.1 (2020-10-25) Bug Fixes address prototype pollution issue (#108) (a9ac604) 4.0.0 (2017-10-10) Bug Fixes allow support for falsy values like 0 in tagged literal (#45) (c926123) Features __: added tagged template literal support (#44) (0598daf) BREAKING CHANGES __: dropping Node 0.10/Node 0.12 support"
  },
  "node_modules/y18n/README.html": {
    "href": "node_modules/y18n/README.html",
    "title": "y18n | accouter",
    "keywords": "y18n The bare-bones internationalization library used by yargs. Inspired by i18n. Examples simple string translation: const __ = require('y18n')().__; console.log(__('my awesome string %s', 'foo')); output: my awesome string foo using tagged template literals const __ = require('y18n')().__; const str = 'foo'; console.log(__`my awesome string ${str}`); output: my awesome string foo pluralization support: const __n = require('y18n')().__n; console.log(__n('one fish %s', '%d fishes %s', 2, 'foo')); output: 2 fishes foo Deno Example As of v5 y18n supports Deno: import y18n from \"https://deno.land/x/y18n/deno.ts\"; const __ = y18n({ locale: 'pirate', directory: './test/locales' }).__ console.info(__`Hi, ${'Ben'} ${'Coe'}!`) You will need to run with --allow-read to load alternative locales. JSON Language Files The JSON language files should be stored in a ./locales folder. File names correspond to locales, e.g., en.json, pirate.json. When strings are observed for the first time they will be added to the JSON file corresponding to the current locale. Methods require('y18n')(config) Create an instance of y18n with the config provided, options include: directory: the locale directory, default ./locales. updateFiles: should newly observed strings be updated in file, default true. locale: what locale should be used. fallbackToLanguage: should fallback to a language-only file (e.g. en.json) be allowed if a file matching the locale does not exist (e.g. en_US.json), default true. y18n.__(str, arg, arg, arg) Print a localized string, %s will be replaced with args. This function can also be used as a tag for a template literal. You can use it like this: __`hello ${'world'}`. This will be equivalent to __('hello %s', 'world'). y18n.__n(singularString, pluralString, count, arg, arg, arg) Print a localized string with appropriate pluralization. If %d is provided in the string, the count will replace this placeholder. y18n.setLocale(str) Set the current locale being used. y18n.getLocale() What locale is currently being used? y18n.updateLocale(obj) Update the current locale with the key value pairs in obj. Supported Node.js Versions Libraries in this ecosystem make a best effort to track Node.js' release schedule. Here's a post on why we think this is important. License ISC"
  },
  "node_modules/yaml/README.html": {
    "href": "node_modules/yaml/README.html",
    "title": "YAML | accouter",
    "keywords": "YAML yaml is a definitive library for YAML, the human friendly data serialization standard. This library: Supports both YAML 1.1 and YAML 1.2 and all common data schemas, Passes all of the yaml-test-suite tests, Can accept any string as input without throwing, parsing as much YAML out of it as it can, and Supports parsing, modifying, and writing YAML comments and blank lines. The library is released under the ISC open source license, and the code is available on GitHub. It has no external dependencies and runs on Node.js as well as modern browsers. For the purposes of versioning, any changes that break any of the documented endpoints or APIs will be considered semver-major breaking changes. Undocumented library internals may change between minor versions, and previous APIs may be deprecated (but not removed). The minimum supported TypeScript version of the included typings is 3.9; for use in earlier versions you may need to set skipLibCheck: true in your config. This requirement may be updated between minor versions of the library. For more information, see the project's documentation site: eemeli.org/yaml To install: npm install yaml Note: These docs are for yaml@2. For v1, see the v1.10.0 tag for the source and eemeli.org/yaml/v1 for the documentation. The development and maintenance of this library is sponsored by: API Overview The API provided by yaml has three layers, depending on how deep you need to go: Parse & Stringify, Documents, and the underlying Lexer/Parser/Composer. The first has the simplest API and \"just works\", the second gets you all the bells and whistles supported by the library along with a decent AST, and the third lets you get progressively closer to YAML source, if that's your thing. A command-line tool is also included. import { parse, stringify } from 'yaml' // or import YAML from 'yaml' // or const YAML = require('yaml') Parse & Stringify parse(str, reviver?, options?): value stringify(value, replacer?, options?): string Documents Document constructor(value, replacer?, options?) #anchors #contents #directives #errors #warnings isDocument(foo): boolean parseAllDocuments(str, options?): Document[] parseDocument(str, options?): Document Content Nodes isAlias(foo): boolean isCollection(foo): boolean isMap(foo): boolean isNode(foo): boolean isPair(foo): boolean isScalar(foo): boolean isSeq(foo): boolean new Scalar(value) new YAMLMap() new YAMLSeq() doc.createAlias(node, name?): Alias doc.createNode(value, options?): Node doc.createPair(key, value): Pair visit(node, visitor) Parsing YAML new Lexer().lex(src) new Parser(onNewLine?).parse(src) new Composer(options?).compose(tokens) YAML.parse # file.yml YAML: - A human-readable data serialization language - https://en.wikipedia.org/wiki/YAML yaml: - A complete JavaScript implementation - https://www.npmjs.com/package/yaml import fs from 'fs' import YAML from 'yaml' YAML.parse('3.14159') // 3.14159 YAML.parse('[ true, false, maybe, null ]\\n') // [ true, false, 'maybe', null ] const file = fs.readFileSync('./file.yml', 'utf8') YAML.parse(file) // { YAML: // [ 'A human-readable data serialization language', // 'https://en.wikipedia.org/wiki/YAML' ], // yaml: // [ 'A complete JavaScript implementation', // 'https://www.npmjs.com/package/yaml' ] } YAML.stringify import YAML from 'yaml' YAML.stringify(3.14159) // '3.14159\\n' YAML.stringify([true, false, 'maybe', null]) // `- true // - false // - maybe // - null // ` YAML.stringify({ number: 3, plain: 'string', block: 'two\\nlines\\n' }) // `number: 3 // plain: string // block: | // two // lines // ` Browser testing provided by:"
  },
  "node_modules/yargs-parser/CHANGELOG.html": {
    "href": "node_modules/yargs-parser/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. See standard-version for commit guidelines. 20.2.4 (2020-11-09) Bug Fixes deno: address import issues in Deno (#339) (3b54e5e) 20.2.3 (2020-10-16) Bug Fixes exports: node 13.0 and 13.1 require the dotted object form with a string fallback (#336) (3ae7242) 20.2.2 (2020-10-14) Bug Fixes exports: node 13.0-13.6 require a string fallback (#333) (291aeda) 20.2.1 (2020-10-01) Bug Fixes deno: update types for deno ^1.4.0 (#330) (0ab92e5) 20.2.0 (2020-09-21) Features string-utils: export looksLikeNumber helper (#324) (c8580a2) Bug Fixes unknown-options-as-args: convert positionals that look like numbers (#326) (f85ebb4) 20.1.0 (2020-09-20) Features adds parse-positional-numbers configuration (#321) (9cec00a) Bug Fixes build: update release-please; make labels kick off builds (#323) (09f448b) 20.0.0 (2020-09-09) ⚠ BREAKING CHANGES do not ship type definitions (#318) Bug Fixes only strip camel case if hyphenated (#316) (95a9e78), closes #315 Code Refactoring do not ship type definitions (#318) (8fbd56f) 19.0.4 (2020-08-27) Bug Fixes build: fixing publication (#310) (5d3c6c2) 19.0.3 (2020-08-27) Bug Fixes build: switch to action for publish (#308) (5c2f305) 19.0.2 (2020-08-27) Bug Fixes types: envPrefix should be optional (#305) (ae3f180) 19.0.1 (2020-08-09) Bug Fixes build: push tag created for deno (2186a14) 19.0.0 (2020-08-09) ⚠ BREAKING CHANGES adds support for ESM and Deno (#295) ts: projects using @types/yargs-parser may see variations in type definitions. drops Node 6. begin following Node.js LTS schedule (#278) Features adds support for ESM and Deno (#295) (195bc4a) expose camelCase and decamelize helpers (#296) (39154ce) deps: update to latest camelcase/decamelize (#281) (8931ab0) Bug Fixes boolean numeric short option (#294) (f600082) raise permission error for Deno if config load fails (#298) (1174e2b) deps: update dependency decamelize to v3 (#274) (4d98698) types: switch back to using Partial types (#293) (bdc80ba) Build System drops Node 6. begin following Node.js LTS schedule (#278) (9014ed7) Code Refactoring ts: move index.js to TypeScript (#292) (f78d2b9) 18.1.3 (2020-04-16) Bug Fixes setArg: options using camel-case and dot-notation populated twice (#268) (f7e15b9) 18.1.2 (2020-03-26) Bug Fixes array, nargs: support -o=--value and --option=--value format (#262) (41d3f81) 18.1.1 (2020-03-16) Bug Fixes __proto__ will now be replaced with ___proto___ in parse (#258), patching a potential prototype pollution vulnerability. This was reported by the Snyk Security Research Team.(63810ca) 18.1.0 (2020-03-07) Features introduce single-digit boolean aliases (#255) (9c60265) 18.0.0 (2020-03-02) ⚠ BREAKING CHANGES the narg count is now enforced when parsing arrays. Features NaN can now be provided as a value for nargs, indicating \"at least\" one value is expected for array (#251) (9db4be8) 17.1.0 (2020-03-01) Features introduce greedy-arrays config, for specifying whether arrays consume multiple positionals (#249) (60e880a) 17.0.1 (2020-02-29) Bug Fixes normalized keys were not enumerable (#247) (57119f9) 17.0.0 (2020-02-10) ⚠ BREAKING CHANGES this reverts parsing behavior of booleans to that of yargs@14 objects used during parsing are now created with a null prototype. There may be some scenarios where this change in behavior leaks externally. Features boolean arguments will not be collected into an implicit array (#236) (34c4e19) introduce nargs-eats-options config option (#246) (d50822a) Bug Fixes address bugs with \"uknown-options-as-args\" (bc023e3) array should take precedence over nargs, but enforce nargs (#243) (4cbc188) support keys that collide with object prototypes (#234) (1587b6d) unknown options terminated with digits now handled by unknown-options-as-args (#238) (d36cdfa) 16.1.0 (2019-11-01) ⚠ BREAKING CHANGES populate error if incompatible narg/count or array/count options are used (#191) Features options that have had their default value used are now tracked (#211) (a525234) populate error if incompatible narg/count or array/count options are used (#191) (84a401f) Reverts revert 16.0.0 CHANGELOG entry (920320a)"
  },
  "node_modules/yargs-parser/README.html": {
    "href": "node_modules/yargs-parser/README.html",
    "title": "yargs-parser | accouter",
    "keywords": "yargs-parser The mighty option parser used by yargs. visit the yargs website for more examples, and thorough usage instructions. Example npm i yargs-parser --save const argv = require('yargs-parser')(process.argv.slice(2)) console.log(argv) node example.js --foo=33 --bar hello { _: [], foo: 33, bar: 'hello' } or parse a string! const argv = require('yargs-parser')('--foo=99 --bar=33') console.log(argv) { _: [], foo: 99, bar: 33 } Convert an array of mixed types before passing to yargs-parser: const parse = require('yargs-parser') parse(['-f', 11, '--zoom', 55].join(' ')) // <-- array to string parse(['-f', 11, '--zoom', 55].map(String)) // <-- array of strings Deno Example As of v19 yargs-parser supports Deno: import parser from \"https://deno.land/x/yargs_parser/deno.ts\"; const argv = parser('--foo=99 --bar=9987930', { string: ['bar'] }) console.log(argv) ESM Example As of v19 yargs-parser supports ESM (both in Node.js and in the browser): Node.js: import parser from 'yargs-parser' const argv = parser('--foo=99 --bar=9987930', { string: ['bar'] }) console.log(argv) Browsers: <!doctype html> <body> <script type=\"module\"> import parser from \"https://unpkg.com/yargs-parser@19.0.0/browser.js\"; const argv = parser('--foo=99 --bar=9987930', { string: ['bar'] }) console.log(argv) </script> </body> API parser(args, opts={}) Parses command line arguments returning a simple mapping of keys and values. expects: args: a string or array of strings representing the options to parse. opts: provide a set of hints indicating how args should be parsed: opts.alias: an object representing the set of aliases for a key: {alias: {foo: ['f']}}. opts.array: indicate that keys should be parsed as an array: {array: ['foo', 'bar']}. Indicate that keys should be parsed as an array and coerced to booleans / numbers: {array: [{ key: 'foo', boolean: true }, {key: 'bar', number: true}]}. opts.boolean: arguments should be parsed as booleans: {boolean: ['x', 'y']}. opts.coerce: provide a custom synchronous function that returns a coerced value from the argument provided (or throws an error). For arrays the function is called only once for the entire array: {coerce: {foo: function (arg) {return modifiedArg}}}. opts.config: indicate a key that represents a path to a configuration file (this file will be loaded and parsed). opts.configObjects: configuration objects to parse, their properties will be set as arguments: {configObjects: [{'x': 5, 'y': 33}, {'z': 44}]}. opts.configuration: provide configuration options to the yargs-parser (see: configuration). opts.count: indicate a key that should be used as a counter, e.g., -vvv = {v: 3}. opts.default: provide default values for keys: {default: {x: 33, y: 'hello world!'}}. opts.envPrefix: environment variables (process.env) with the prefix provided should be parsed. opts.narg: specify that a key requires n arguments: {narg: {x: 2}}. opts.normalize: path.normalize() will be applied to values set to this key. opts.number: keys should be treated as numbers. opts.string: keys should be treated as strings (even if they resemble a number -x 33). returns: obj: an object representing the parsed value of args key/value: key value pairs for each argument and their aliases. _: an array representing the positional arguments. [optional] --: an array with arguments after the end-of-options flag --. require('yargs-parser').detailed(args, opts={}) Parses a command line string, returning detailed information required by the yargs engine. expects: args: a string or array of strings representing options to parse. opts: provide a set of hints indicating how args, inputs are identical to require('yargs-parser')(args, opts={}). returns: argv: an object representing the parsed value of args key/value: key value pairs for each argument and their aliases. _: an array representing the positional arguments. [optional] --: an array with arguments after the end-of-options flag --. error: populated with an error object if an exception occurred during parsing. aliases: the inferred list of aliases built by combining lists in opts.alias. newAliases: any new aliases added via camel-case expansion: boolean: { fooBar: true } defaulted: any new argument created by opts.default, no aliases included. boolean: { foo: true } configuration: given by default settings and opts.configuration. Configuration The yargs-parser applies several automated transformations on the keys provided in args. These features can be turned on and off using the configuration field of opts. var parsed = parser(['--no-dice'], { configuration: { 'boolean-negation': false } }) short option groups default: true. key: short-option-groups. Should a group of short-options be treated as boolean flags? node example.js -abc { _: [], a: true, b: true, c: true } if disabled: node example.js -abc { _: [], abc: true } camel-case expansion default: true. key: camel-case-expansion. Should hyphenated arguments be expanded into camel-case aliases? node example.js --foo-bar { _: [], 'foo-bar': true, fooBar: true } if disabled: node example.js --foo-bar { _: [], 'foo-bar': true } dot-notation default: true key: dot-notation Should keys that contain . be treated as objects? node example.js --foo.bar { _: [], foo: { bar: true } } if disabled: node example.js --foo.bar { _: [], \"foo.bar\": true } parse numbers default: true key: parse-numbers Should keys that look like numbers be treated as such? node example.js --foo=99.3 { _: [], foo: 99.3 } if disabled: node example.js --foo=99.3 { _: [], foo: \"99.3\" } parse positional numbers default: true key: parse-positional-numbers Should positional keys that look like numbers be treated as such. node example.js 99.3 { _: [99] } if disabled: node example.js 99.3 { _: ['99.3'] } boolean negation default: true key: boolean-negation Should variables prefixed with --no be treated as negations? node example.js --no-foo { _: [], foo: false } if disabled: node example.js --no-foo { _: [], \"no-foo\": true } combine arrays default: false key: combine-arrays Should arrays be combined when provided by both command line arguments and a configuration file. duplicate arguments array default: true key: duplicate-arguments-array Should arguments be coerced into an array when duplicated: node example.js -x 1 -x 2 { _: [], x: [1, 2] } if disabled: node example.js -x 1 -x 2 { _: [], x: 2 } flatten duplicate arrays default: true key: flatten-duplicate-arrays Should array arguments be coerced into a single array when duplicated: node example.js -x 1 2 -x 3 4 { _: [], x: [1, 2, 3, 4] } if disabled: node example.js -x 1 2 -x 3 4 { _: [], x: [[1, 2], [3, 4]] } greedy arrays default: true key: greedy-arrays Should arrays consume more than one positional argument following their flag. node example --arr 1 2 { _[], arr: [1, 2] } if disabled: node example --arr 1 2 { _[2], arr: [1] } Note: in v18.0.0 we are considering defaulting greedy arrays to false. nargs eats options default: false key: nargs-eats-options Should nargs consume dash options as well as positional arguments. negation prefix default: no- key: negation-prefix The prefix to use for negated boolean variables. node example.js --no-foo { _: [], foo: false } if set to quux: node example.js --quuxfoo { _: [], foo: false } populate -- default: false. key: populate-- Should unparsed flags be stored in -- or _. If disabled: node example.js a -b -- x y { _: [ 'a', 'x', 'y' ], b: true } If enabled: node example.js a -b -- x y { _: [ 'a' ], '--': [ 'x', 'y' ], b: true } set placeholder key default: false. key: set-placeholder-key. Should a placeholder be added for keys not set via the corresponding CLI argument? If disabled: node example.js -a 1 -c 2 { _: [], a: 1, c: 2 } If enabled: node example.js -a 1 -c 2 { _: [], a: 1, b: undefined, c: 2 } halt at non-option default: false. key: halt-at-non-option. Should parsing stop at the first positional argument? This is similar to how e.g. ssh parses its command line. If disabled: node example.js -a run b -x y { _: [ 'b' ], a: 'run', x: 'y' } If enabled: node example.js -a run b -x y { _: [ 'b', '-x', 'y' ], a: 'run' } strip aliased default: false key: strip-aliased Should aliases be removed before returning results? If disabled: node example.js --test-field 1 { _: [], 'test-field': 1, testField: 1, 'test-alias': 1, testAlias: 1 } If enabled: node example.js --test-field 1 { _: [], 'test-field': 1, testField: 1 } strip dashed default: false key: strip-dashed Should dashed keys be removed before returning results? This option has no effect if camel-case-expansion is disabled. If disabled: node example.js --test-field 1 { _: [], 'test-field': 1, testField: 1 } If enabled: node example.js --test-field 1 { _: [], testField: 1 } unknown options as args default: false key: unknown-options-as-args Should unknown options be treated like regular arguments? An unknown option is one that is not configured in opts. If disabled node example.js --unknown-option --known-option 2 --string-option --unknown-option2 { _: [], unknownOption: true, knownOption: 2, stringOption: '', unknownOption2: true } If enabled node example.js --unknown-option --known-option 2 --string-option --unknown-option2 { _: ['--unknown-option'], knownOption: 2, stringOption: '--unknown-option2' } Supported Node.js Versions Libraries in this ecosystem make a best effort to track Node.js' release schedule. Here's a post on why we think this is important. Special Thanks The yargs project evolves from optimist and minimist. It owes its existence to a lot of James Halliday's hard work. Thanks substack beep boop \\o/ License ISC"
  },
  "node_modules/yargs-unparser/CHANGELOG.html": {
    "href": "node_modules/yargs-unparser/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. See standard-version for commit guidelines. 2.0.0 (2020-10-02) ⚠ BREAKING CHANGES upgrade deps drop Node 6/8 (#71) Code Refactoring upgrade deps drop Node 6/8 (#71) (c686882) 1.6.4 (2020-10-01) Bug Fixes security: upgraded flat to version ^5.0.2 (9bd7c67) 1.6.3 (2020-06-17) Bug Fixes test automatic publish (209a487) 1.6.2 (2020-06-17) Bug Fixes readme: marketing was injected dubiously into README (#60) (1167667) 1.6.1 (2020-06-17) Bug Fixes deps: downgrade yargs, such that we continue supporting Node 6 (#57) (f69406c) 1.6.0 (2019-07-30) Bug Fixes security: update deps addressing recent audit vulnerabilities (#40) (2e74f1b) address bug with camelCased flattened keys (#32) (981533a) deps: updated the lodash version to fix vulnerability (#39) (7375966) package: update yargs to version 10.0.3 (f1eb4cb) package: update yargs to version 11.0.0 (6aa7c91) Features add interoperation with minimist (ba477f5) 1.5.0 (2018-11-30) Bug Fixes package: update yargs to version 10.0.3 (f1eb4cb) package: update yargs to version 11.0.0 (6aa7c91) Features add interoperation with minimist (ba477f5) 1.4.0 (2017-12-30) Features add interoperation with minimist (ba477f5)"
  },
  "node_modules/yargs-unparser/README.html": {
    "href": "node_modules/yargs-unparser/README.html",
    "title": "yargs-unparser | accouter",
    "keywords": "yargs-unparser Converts back a yargs argv object to its original array form. Probably the unparser word doesn't even exist, but it sounds nice and goes well with yargs-parser. The code originally lived in MOXY's GitHub but was later moved here for discoverability. Installation $ npm install yargs-unparser Usage const parse = require('yargs-parser'); const unparse = require('yargs-unparser'); const argv = parse(['--no-boolean', '--number', '4', '--string', 'foo'], { boolean: ['boolean'], number: ['number'], string: ['string'], }); // { boolean: false, number: 4, string: 'foo', _: [] } const unparsedArgv = unparse(argv); // ['--no-boolean', '--number', '4', '--string', 'foo']; The second argument of unparse accepts an options object: alias: The aliases so that duplicate options aren't generated default: The default values so that the options with default values are omitted command: The command first argument so that command names and positional arguments are handled correctly Example with command options const yargs = require('yargs'); const unparse = require('yargs-unparser'); const argv = yargs .command('my-command <positional>', 'My awesome command', (yargs) => yargs .option('boolean', { type: 'boolean' }) .option('number', { type: 'number' }) .option('string', { type: 'string' }) ) .parse(['my-command', 'hello', '--no-boolean', '--number', '4', '--string', 'foo']); // { positional: 'hello', boolean: false, number: 4, string: 'foo', _: ['my-command'] } const unparsedArgv = unparse(argv, { command: 'my-command <positional>', }); // ['my-command', 'hello', '--no-boolean', '--number', '4', '--string', 'foo']; Caveats The returned array can be parsed again by yargs-parser using the default configuration. If you used custom configuration that you want yargs-unparser to be aware, please fill an issue. If you coerce in weird ways, things might not work correctly. Tests $ npm test $ npm test -- --watch during development Supported Node.js Versions Libraries in this ecosystem make a best effort to track Node.js' release schedule. Here's a post on why we think this is important. License MIT License"
  },
  "node_modules/yargs/README.html": {
    "href": "node_modules/yargs/README.html",
    "title": "Yargs | accouter",
    "keywords": "Yargs Yargs be a node.js library fer hearties tryin' ter parse optstrings Description Yargs helps you build interactive command line tools, by parsing arguments and generating an elegant user interface. It gives you: commands and (grouped) options (my-program.js serve --port=5000). a dynamically generated help menu based on your arguments: mocha [spec..] Run tests with Mocha Commands mocha inspect [spec..] Run tests with Mocha [default] mocha init <path> create a client-side Mocha setup at <path> Rules & Behavior --allow-uncaught Allow uncaught errors to propagate [boolean] --async-only, -A Require all tests to use a callback (async) or return a Promise [boolean] bash-completion shortcuts for commands and options. and tons more. Installation Stable version: npm i yargs Bleeding edge version with the most recent features: npm i yargs@next Usage Simple Example #!/usr/bin/env node const yargs = require('yargs/yargs') const { hideBin } = require('yargs/helpers') const argv = yargs(hideBin(process.argv)).argv if (argv.ships > 3 && argv.distance < 53.5) { console.log('Plunder more riffiwobbles!') } else { console.log('Retreat from the xupptumblers!') } $ ./plunder.js --ships=4 --distance=22 Plunder more riffiwobbles! $ ./plunder.js --ships 12 --distance 98.7 Retreat from the xupptumblers! Note: hideBin is a shorthand for process.argv.slice(2). It has the benefit that it takes into account variations in some environments, e.g., Electron. Complex Example #!/usr/bin/env node const yargs = require('yargs/yargs') const { hideBin } = require('yargs/helpers') yargs(hideBin(process.argv)) .command('serve [port]', 'start the server', (yargs) => { return yargs .positional('port', { describe: 'port to bind on', default: 5000 }) }, (argv) => { if (argv.verbose) console.info(`start server on :${argv.port}`) serve(argv.port) }) .option('verbose', { alias: 'v', type: 'boolean', description: 'Run with verbose logging' }) .parse() Run the example above with --help to see the help for the application. Supported Platforms TypeScript yargs has type definitions at @types/yargs. npm i @types/yargs --save-dev See usage examples in docs. Deno As of v16, yargs supports Deno: import yargs from 'https://deno.land/x/yargs/deno.ts' import { Arguments } from 'https://deno.land/x/yargs/deno-types.ts' yargs(Deno.args) .command('download <files...>', 'download a list of files', (yargs: any) => { return yargs.positional('files', { describe: 'a list of files to do something with' }) }, (argv: Arguments) => { console.info(argv) }) .strictCommands() .demandCommand(1) .parse() ESM As of v16,yargs supports ESM imports: import yargs from 'yargs' import { hideBin } from 'yargs/helpers' yargs(hideBin(process.argv)) .command('curl <url>', 'fetch the contents of the URL', () => {}, (argv) => { console.info(argv) }) .demandCommand(1) .parse() Usage in Browser See examples of using yargs in the browser in docs. Community Having problems? want to contribute? join our community slack. Documentation Table of Contents Yargs' API Examples Parsing Tricks Stop the Parser Negating Boolean Arguments Numbers Arrays Objects Quotes Advanced Topics Composing Your App Using Commands Building Configurable CLI Apps Customizing Yargs' Parser Bundling yargs Contributing Supported Node.js Versions Libraries in this ecosystem make a best effort to track Node.js' release schedule. Here's a post on why we think this is important."
  },
  "node_modules/yargs/node_modules/yargs-parser/CHANGELOG.html": {
    "href": "node_modules/yargs/node_modules/yargs-parser/CHANGELOG.html",
    "title": "Changelog | accouter",
    "keywords": "Changelog All notable changes to this project will be documented in this file. See standard-version for commit guidelines. 21.1.1 (2022-08-04) Bug Fixes typescript: ignore .cts files during publish (#454) (d69f9c3), closes #452 21.1.0 (2022-08-03) Features allow the browser build to be imported (#443) (a89259f) Bug Fixes halt-at-non-option: prevent known args from being parsed when \"unknown-options-as-args\" is enabled (#438) (c474bc1) node version check now uses process.versions.node (#450) (d07bcdb) parse options ending with 3+ hyphens (#434) (4f1060b) 21.0.1 (2022-02-27) Bug Fixes return deno env object (#432) (b00eb87) 21.0.0 (2021-11-15) ⚠ BREAKING CHANGES drops support for 10 (#421) Bug Fixes esm json import (#416) (90f970a) parser should preserve inner quotes (#407) (ae11f49) Code Refactoring drops support for 10 (#421) (3aaf878) 20.2.9 (2021-06-20) Bug Fixes build: fixed automated release pipeline (1fe9135) 20.2.8 (2021-06-20) Bug Fixes locale: Turkish camelize and decamelize issues with toLocaleLowerCase/toLocaleUpperCase (2617303) perf: address slow parse when using unknown-options-as-args (#394) (441f059) string-utils: detect [0,1] ranged values as numbers (#388) (efcc32c) 20.2.7 (2021-03-10) Bug Fixes deno: force release for Deno (6687c97) 20.2.6 (2021-02-22) Bug Fixes populate--: -- should always be array (#354) (585ae8f) 20.2.5 (2021-02-13) Bug Fixes do not lowercase camel cased string (#348) (5f4da1f) 20.2.4 (2020-11-09) Bug Fixes deno: address import issues in Deno (#339) (3b54e5e) 20.2.3 (2020-10-16) Bug Fixes exports: node 13.0 and 13.1 require the dotted object form with a string fallback (#336) (3ae7242) 20.2.2 (2020-10-14) Bug Fixes exports: node 13.0-13.6 require a string fallback (#333) (291aeda) 20.2.1 (2020-10-01) Bug Fixes deno: update types for deno ^1.4.0 (#330) (0ab92e5) 20.2.0 (2020-09-21) Features string-utils: export looksLikeNumber helper (#324) (c8580a2) Bug Fixes unknown-options-as-args: convert positionals that look like numbers (#326) (f85ebb4) 20.1.0 (2020-09-20) Features adds parse-positional-numbers configuration (#321) (9cec00a) Bug Fixes build: update release-please; make labels kick off builds (#323) (09f448b) 20.0.0 (2020-09-09) ⚠ BREAKING CHANGES do not ship type definitions (#318) Bug Fixes only strip camel case if hyphenated (#316) (95a9e78), closes #315 Code Refactoring do not ship type definitions (#318) (8fbd56f) 19.0.4 (2020-08-27) Bug Fixes build: fixing publication (#310) (5d3c6c2) 19.0.3 (2020-08-27) Bug Fixes build: switch to action for publish (#308) (5c2f305) 19.0.2 (2020-08-27) Bug Fixes types: envPrefix should be optional (#305) (ae3f180) 19.0.1 (2020-08-09) Bug Fixes build: push tag created for deno (2186a14) 19.0.0 (2020-08-09) ⚠ BREAKING CHANGES adds support for ESM and Deno (#295) ts: projects using @types/yargs-parser may see variations in type definitions. drops Node 6. begin following Node.js LTS schedule (#278) Features adds support for ESM and Deno (#295) (195bc4a) expose camelCase and decamelize helpers (#296) (39154ce) deps: update to latest camelcase/decamelize (#281) (8931ab0) Bug Fixes boolean numeric short option (#294) (f600082) raise permission error for Deno if config load fails (#298) (1174e2b) deps: update dependency decamelize to v3 (#274) (4d98698) types: switch back to using Partial types (#293) (bdc80ba) Build System drops Node 6. begin following Node.js LTS schedule (#278) (9014ed7) Code Refactoring ts: move index.js to TypeScript (#292) (f78d2b9) 18.1.3 (2020-04-16) Bug Fixes setArg: options using camel-case and dot-notation populated twice (#268) (f7e15b9) 18.1.2 (2020-03-26) Bug Fixes array, nargs: support -o=--value and --option=--value format (#262) (41d3f81) 18.1.1 (2020-03-16) Bug Fixes __proto__ will now be replaced with ___proto___ in parse (#258), patching a potential prototype pollution vulnerability. This was reported by the Snyk Security Research Team.(63810ca) 18.1.0 (2020-03-07) Features introduce single-digit boolean aliases (#255) (9c60265) 18.0.0 (2020-03-02) ⚠ BREAKING CHANGES the narg count is now enforced when parsing arrays. Features NaN can now be provided as a value for nargs, indicating \"at least\" one value is expected for array (#251) (9db4be8) 17.1.0 (2020-03-01) Features introduce greedy-arrays config, for specifying whether arrays consume multiple positionals (#249) (60e880a) 17.0.1 (2020-02-29) Bug Fixes normalized keys were not enumerable (#247) (57119f9) 17.0.0 (2020-02-10) ⚠ BREAKING CHANGES this reverts parsing behavior of booleans to that of yargs@14 objects used during parsing are now created with a null prototype. There may be some scenarios where this change in behavior leaks externally. Features boolean arguments will not be collected into an implicit array (#236) (34c4e19) introduce nargs-eats-options config option (#246) (d50822a) Bug Fixes address bugs with \"uknown-options-as-args\" (bc023e3) array should take precedence over nargs, but enforce nargs (#243) (4cbc188) support keys that collide with object prototypes (#234) (1587b6d) unknown options terminated with digits now handled by unknown-options-as-args (#238) (d36cdfa) 16.1.0 (2019-11-01) ⚠ BREAKING CHANGES populate error if incompatible narg/count or array/count options are used (#191) Features options that have had their default value used are now tracked (#211) (a525234) populate error if incompatible narg/count or array/count options are used (#191) (84a401f) Reverts revert 16.0.0 CHANGELOG entry (920320a)"
  },
  "node_modules/yargs/node_modules/yargs-parser/README.html": {
    "href": "node_modules/yargs/node_modules/yargs-parser/README.html",
    "title": "yargs-parser | accouter",
    "keywords": "yargs-parser The mighty option parser used by yargs. visit the yargs website for more examples, and thorough usage instructions. Example npm i yargs-parser --save const argv = require('yargs-parser')(process.argv.slice(2)) console.log(argv) $ node example.js --foo=33 --bar hello { _: [], foo: 33, bar: 'hello' } or parse a string! const argv = require('yargs-parser')('--foo=99 --bar=33') console.log(argv) { _: [], foo: 99, bar: 33 } Convert an array of mixed types before passing to yargs-parser: const parse = require('yargs-parser') parse(['-f', 11, '--zoom', 55].join(' ')) // <-- array to string parse(['-f', 11, '--zoom', 55].map(String)) // <-- array of strings Deno Example As of v19 yargs-parser supports Deno: import parser from \"https://deno.land/x/yargs_parser/deno.ts\"; const argv = parser('--foo=99 --bar=9987930', { string: ['bar'] }) console.log(argv) ESM Example As of v19 yargs-parser supports ESM (both in Node.js and in the browser): Node.js: import parser from 'yargs-parser' const argv = parser('--foo=99 --bar=9987930', { string: ['bar'] }) console.log(argv) Browsers: <!doctype html> <body> <script type=\"module\"> import parser from \"https://unpkg.com/yargs-parser@19.0.0/browser.js\"; const argv = parser('--foo=99 --bar=9987930', { string: ['bar'] }) console.log(argv) </script> </body> API parser(args, opts={}) Parses command line arguments returning a simple mapping of keys and values. expects: args: a string or array of strings representing the options to parse. opts: provide a set of hints indicating how args should be parsed: opts.alias: an object representing the set of aliases for a key: {alias: {foo: ['f']}}. opts.array: indicate that keys should be parsed as an array: {array: ['foo', 'bar']}. Indicate that keys should be parsed as an array and coerced to booleans / numbers: {array: [{ key: 'foo', boolean: true }, {key: 'bar', number: true}]}. opts.boolean: arguments should be parsed as booleans: {boolean: ['x', 'y']}. opts.coerce: provide a custom synchronous function that returns a coerced value from the argument provided (or throws an error). For arrays the function is called only once for the entire array: {coerce: {foo: function (arg) {return modifiedArg}}}. opts.config: indicate a key that represents a path to a configuration file (this file will be loaded and parsed). opts.configObjects: configuration objects to parse, their properties will be set as arguments: {configObjects: [{'x': 5, 'y': 33}, {'z': 44}]}. opts.configuration: provide configuration options to the yargs-parser (see: configuration). opts.count: indicate a key that should be used as a counter, e.g., -vvv = {v: 3}. opts.default: provide default values for keys: {default: {x: 33, y: 'hello world!'}}. opts.envPrefix: environment variables (process.env) with the prefix provided should be parsed. opts.narg: specify that a key requires n arguments: {narg: {x: 2}}. opts.normalize: path.normalize() will be applied to values set to this key. opts.number: keys should be treated as numbers. opts.string: keys should be treated as strings (even if they resemble a number -x 33). returns: obj: an object representing the parsed value of args key/value: key value pairs for each argument and their aliases. _: an array representing the positional arguments. [optional] --: an array with arguments after the end-of-options flag --. require('yargs-parser').detailed(args, opts={}) Parses a command line string, returning detailed information required by the yargs engine. expects: args: a string or array of strings representing options to parse. opts: provide a set of hints indicating how args, inputs are identical to require('yargs-parser')(args, opts={}). returns: argv: an object representing the parsed value of args key/value: key value pairs for each argument and their aliases. _: an array representing the positional arguments. [optional] --: an array with arguments after the end-of-options flag --. error: populated with an error object if an exception occurred during parsing. aliases: the inferred list of aliases built by combining lists in opts.alias. newAliases: any new aliases added via camel-case expansion: boolean: { fooBar: true } defaulted: any new argument created by opts.default, no aliases included. boolean: { foo: true } configuration: given by default settings and opts.configuration. Configuration The yargs-parser applies several automated transformations on the keys provided in args. These features can be turned on and off using the configuration field of opts. var parsed = parser(['--no-dice'], { configuration: { 'boolean-negation': false } }) short option groups default: true. key: short-option-groups. Should a group of short-options be treated as boolean flags? $ node example.js -abc { _: [], a: true, b: true, c: true } if disabled: $ node example.js -abc { _: [], abc: true } camel-case expansion default: true. key: camel-case-expansion. Should hyphenated arguments be expanded into camel-case aliases? $ node example.js --foo-bar { _: [], 'foo-bar': true, fooBar: true } if disabled: $ node example.js --foo-bar { _: [], 'foo-bar': true } dot-notation default: true key: dot-notation Should keys that contain . be treated as objects? $ node example.js --foo.bar { _: [], foo: { bar: true } } if disabled: $ node example.js --foo.bar { _: [], \"foo.bar\": true } parse numbers default: true key: parse-numbers Should keys that look like numbers be treated as such? $ node example.js --foo=99.3 { _: [], foo: 99.3 } if disabled: $ node example.js --foo=99.3 { _: [], foo: \"99.3\" } parse positional numbers default: true key: parse-positional-numbers Should positional keys that look like numbers be treated as such. $ node example.js 99.3 { _: [99.3] } if disabled: $ node example.js 99.3 { _: ['99.3'] } boolean negation default: true key: boolean-negation Should variables prefixed with --no be treated as negations? $ node example.js --no-foo { _: [], foo: false } if disabled: $ node example.js --no-foo { _: [], \"no-foo\": true } combine arrays default: false key: combine-arrays Should arrays be combined when provided by both command line arguments and a configuration file. duplicate arguments array default: true key: duplicate-arguments-array Should arguments be coerced into an array when duplicated: $ node example.js -x 1 -x 2 { _: [], x: [1, 2] } if disabled: $ node example.js -x 1 -x 2 { _: [], x: 2 } flatten duplicate arrays default: true key: flatten-duplicate-arrays Should array arguments be coerced into a single array when duplicated: $ node example.js -x 1 2 -x 3 4 { _: [], x: [1, 2, 3, 4] } if disabled: $ node example.js -x 1 2 -x 3 4 { _: [], x: [[1, 2], [3, 4]] } greedy arrays default: true key: greedy-arrays Should arrays consume more than one positional argument following their flag. $ node example --arr 1 2 { _: [], arr: [1, 2] } if disabled: $ node example --arr 1 2 { _: [2], arr: [1] } Note: in v18.0.0 we are considering defaulting greedy arrays to false. nargs eats options default: false key: nargs-eats-options Should nargs consume dash options as well as positional arguments. negation prefix default: no- key: negation-prefix The prefix to use for negated boolean variables. $ node example.js --no-foo { _: [], foo: false } if set to quux: $ node example.js --quuxfoo { _: [], foo: false } populate -- default: false. key: populate-- Should unparsed flags be stored in -- or _. If disabled: $ node example.js a -b -- x y { _: [ 'a', 'x', 'y' ], b: true } If enabled: $ node example.js a -b -- x y { _: [ 'a' ], '--': [ 'x', 'y' ], b: true } set placeholder key default: false. key: set-placeholder-key. Should a placeholder be added for keys not set via the corresponding CLI argument? If disabled: $ node example.js -a 1 -c 2 { _: [], a: 1, c: 2 } If enabled: $ node example.js -a 1 -c 2 { _: [], a: 1, b: undefined, c: 2 } halt at non-option default: false. key: halt-at-non-option. Should parsing stop at the first positional argument? This is similar to how e.g. ssh parses its command line. If disabled: $ node example.js -a run b -x y { _: [ 'b' ], a: 'run', x: 'y' } If enabled: $ node example.js -a run b -x y { _: [ 'b', '-x', 'y' ], a: 'run' } strip aliased default: false key: strip-aliased Should aliases be removed before returning results? If disabled: $ node example.js --test-field 1 { _: [], 'test-field': 1, testField: 1, 'test-alias': 1, testAlias: 1 } If enabled: $ node example.js --test-field 1 { _: [], 'test-field': 1, testField: 1 } strip dashed default: false key: strip-dashed Should dashed keys be removed before returning results? This option has no effect if camel-case-expansion is disabled. If disabled: $ node example.js --test-field 1 { _: [], 'test-field': 1, testField: 1 } If enabled: $ node example.js --test-field 1 { _: [], testField: 1 } unknown options as args default: false key: unknown-options-as-args Should unknown options be treated like regular arguments? An unknown option is one that is not configured in opts. If disabled $ node example.js --unknown-option --known-option 2 --string-option --unknown-option2 { _: [], unknownOption: true, knownOption: 2, stringOption: '', unknownOption2: true } If enabled $ node example.js --unknown-option --known-option 2 --string-option --unknown-option2 { _: ['--unknown-option'], knownOption: 2, stringOption: '--unknown-option2' } Supported Node.js Versions Libraries in this ecosystem make a best effort to track Node.js' release schedule. Here's a post on why we think this is important. Special Thanks The yargs project evolves from optimist and minimist. It owes its existence to a lot of James Halliday's hard work. Thanks substack beep boop \\o/ License ISC"
  },
  "node_modules/yocto-queue/readme.html": {
    "href": "node_modules/yocto-queue/readme.html",
    "title": "yocto-queue | accouter",
    "keywords": "yocto-queue Tiny queue data structure You should use this package instead of an array if you do a lot of Array#push() and Array#shift() on large arrays, since Array#shift() has linear time complexity O(n) while Queue#dequeue() has constant time complexity O(1). That makes a huge difference for large arrays. A queue is an ordered list of elements where an element is inserted at the end of the queue and is removed from the front of the queue. A queue works based on the first-in, first-out (FIFO) principle. Install $ npm install yocto-queue Usage const Queue = require('yocto-queue'); const queue = new Queue(); queue.enqueue('🦄'); queue.enqueue('🌈'); console.log(queue.size); //=> 2 console.log(...queue); //=> '🦄 🌈' console.log(queue.dequeue()); //=> '🦄' console.log(queue.dequeue()); //=> '🌈' API queue = new Queue() The instance is an Iterable, which means you can iterate over the queue front to back with a “for…of” loop, or use spreading to convert the queue to an array. Don't do this unless you really need to though, since it's slow. .enqueue(value) Add a value to the queue. .dequeue() Remove the next value in the queue. Returns the removed value or undefined if the queue is empty. .clear() Clear the queue. .size The size of the queue. Related quick-lru - Simple “Least Recently Used” (LRU) cache"
  }
}